Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@article{Visscher2017,
abstract = {Application of the experimental design of genome-wide association studies (GWASs) is now 10 years old (young), and here we review the remarkable range of discoveries it has facilitated in population and complex-trait genetics, the biology of diseases, and translation toward new therapeutics. We predict the likely discoveries in the next 10 years, when GWASs will be based on millions of samples with array data imputed to a large fully sequenced reference panel and on hundreds of thousands of samples with whole-genome sequencing data.},
author = {Visscher, Peter M. and Wray, Naomi R. and Zhang, Qian and Sklar, Pamela and McCarthy, Mark I. and Brown, Matthew A. and Yang, Jian},
doi = {10.1016/j.ajhg.2017.06.005},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Human Genetics/Visscher et al. - 2017 - 10 Years of GWAS Discovery Biology, Function, and Translation.pdf:pdf},
issn = {15376605},
journal = {American Journal of Human Genetics},
keywords = {GWAS,SNP,auto-immune disease,genome-wide association study,heritability,obesity,schizophrenia},
mendeley-tags = {GWAS},
number = {1},
pages = {5--22},
pmid = {28686856},
publisher = {ElsevierCompany.},
title = {{10 Years of GWAS Discovery: Biology, Function, and Translation}},
url = {http://dx.doi.org/10.1016/j.ajhg.2017.06.005},
volume = {101},
year = {2017}
}
@article{Lafzi2018,
author = {Lafzi, Atefeh and Moutinho, Catia and Picelli, Simone and Heyn, Holger},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Protocols/Lafzi et al. - 2018 - Tutorial guidelines for the experimental design of single-cell RNA sequencing studies.pdf:pdf},
journal = {Nature Protocols},
keywords = {single cell},
mendeley-tags = {single cell},
pages = {2742--2757},
title = {{Tutorial: guidelines for the experimental design of single-cell RNA sequencing studies}},
volume = {13},
year = {2018}
}
@article{Montazeri2019,
abstract = {Systematic perturbation screens provided comprehensive resources for the elucidation of cancer driver genes. However, few algorithms have been developed to robustly interrogate such datasets, particularly with limited number of samples. Here we developed a computational tool called APSiC (Analysis of Perturbation Screens for identifying novel Cancer genes) and applied it to the large-scale deep shRNA screen DRIVE1 to unveil novel genetic and non-genetic driver genes. APSiC identified both well-known and novel drivers across all cancer types and within individual cancer types. The analysis of individual cancer types revealed that cancer drivers segregate by cell of origin and that genes involved in mRNA splicing may be oncogenic or tumor suppressive depending on the cancer type. We discovered and functionally demonstrated that LRRC4B is a novel putative tumor suppressor gene in breast cancer. The analysis of DRIVE using APSiC is provided as a web portal and represents a valuable resource for the discovery of novel cancer genes.},
author = {Montazeri, Hesam and Coto-Llerena, Mairene and Bianco, Gaia and Zangeneh, Ehsan and Taha-Mehlitz, Stephanie and Paradiso, Viola and Srivatsa, Sumana and de Weck, Antoine and Roma, Guglielmo and Lanzafame, Manuela and Bolli, Martin and Beerenwinkel, Niko and von Fl{\"{u}}e, Markus and Terracciano, Luigi M. and Piscuoglio, Salvatore and Ng, Charlotte K. Y.},
journal = {biorXiv},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
title = {{APSiC: Analysis of Perturbation Screens for the Identification of Novel Cancer Genes}},
year = {2019}
}
@article{Vieth2019,
abstract = {The recent rapid spread of single cell RNA sequencing (scRNA-seq) methods has created a large variety of experimental and computational pipelines for which best practices have not yet been established. Here, we use simulations based on five scRNA-seq library protocols in combination with nine realistic differential expression (DE) setups to systematically evaluate three mapping, four imputation, seven normalisation and four differential expression testing approaches resulting in {\~{}}3000 pipelines, allowing us to also assess interactions among pipeline steps. We find that choices of normalisation and library preparation protocols have the biggest impact on scRNA-seq analyses. Specifically, we find that library preparation determines the ability to detect symmetric expression differences, while normalisation dominates pipeline performance in asymmetric DE-setups. Finally, we illustrate the importance of informed choices by showing that a good scRNA-seq pipeline can have the same impact on detecting a biological signal as quadrupling the sample size.},
author = {Vieth, Beate and Parekh, Swati and Ziegenhain, Christoph and Enard, Wolfgang and Hellmann, Ines},
doi = {10.1038/s41467-019-12266-7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Vieth et al. - 2019 - A systematic evaluation of single cell RNA-seq analysis pipelines.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
keywords = {differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {1},
pages = {1--11},
pmid = {31604912},
publisher = {Springer US},
title = {{A systematic evaluation of single cell RNA-seq analysis pipelines}},
url = {http://dx.doi.org/10.1038/s41467-019-12266-7},
volume = {10},
year = {2019}
}
@article{Hart2016,
abstract = {Background: The adaptation of the CRISPR-Cas9 system to pooled library gene knockout screens in mammalian cells represents a major technological leap over RNA interference, the prior state of the art. New methods for analyzing the data and evaluating results are needed. Results: We offer BAGEL (Bayesian Analysis of Gene EssentiaLity), a supervised learning method for analyzing gene knockout screens. Coupled with gold-standard reference sets of essential and nonessential genes, BAGEL offers significantly greater sensitivity than current methods, while computational optimizations reduce runtime by an order of magnitude. Conclusions: Using BAGEL, we identify {\~{}}2000 fitness genes in pooled library knockout screens in human cell lines at 5 {\%} FDR, a major advance over competing platforms. BAGEL shows high sensitivity and specificity even across screens performed by different labs using different libraries and reagents.},
author = {Hart, Traver and Moffat, Jason},
doi = {10.1186/s12859-016-1015-8},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Bioinformatics/Hart, Moffat - 2016 - BAGEL A computational framework for identifying essential genes from pooled library screens.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {CRISPR,Cancer,Essential genes,Functional genomics,Genetic screens,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {1},
pages = {1--7},
pmid = {27083490},
publisher = {BMC Bioinformatics},
title = {{BAGEL: A computational framework for identifying essential genes from pooled library screens}},
volume = {17},
year = {2016}
}
@article{Xie2018,
abstract = {Simultaneously detecting CRISPR-based perturbations and induced transcriptional changes in the same cell is a powerful approach to unraveling genome function. Several lentiviral approaches have been developed, some of which rely on the detection of distally located genetic barcodes as an indirect proxy of sgRNA identity. Since barcodes are often several kilobases from their corresponding sgRNAs, viral recombination-mediated swapping of barcodes and sgRNAs is feasible. Using a self-circularization-based sgRNA-barcode library preparation protocol, we estimate the recombination rate to be {\~{}}50{\%} and we trace this phenomenon to the pooled viral packaging step. Recombination is random, and decreases the signal-to-noise ratio of the assay. Our results suggest that alternative approaches can increase the throughput and sensitivity of single-cell perturbation assays.},
author = {Xie, Shiqi and Cooley, Anne and Armendariz, Daniel and Zhou, Pei and Hon, Gary C.},
doi = {10.1371/journal.pone.0198635},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/PLoS ONE/Xie et al. - 2018 - Frequent sgRNA-barcode recombination in single-cell perturbation assays.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
month = {jun},
number = {6},
publisher = {Public Library of Science},
title = {{Frequent sgRNA-barcode recombination in single-cell perturbation assays}},
volume = {13},
year = {2018}
}
@article{Jaitin2016,
abstract = {In multicellular organisms, dedicated regulatory circuits control cell type diversity and responses. The crosstalk and redundancies within these circuits and substantial cellular heterogeneity pose a major research challenge. Here, we present CRISP-seq, an integrated method for massively parallel single-cell RNA sequencing (RNA-seq) and clustered regularly interspaced short palindromic repeats (CRISPR)-pooled screens. We show that profiling the genomic perturbation and transcriptome in the same cell enables us to simultaneously elucidate the function of multiple factors and their interactions. We applied CRISP-seq to probe regulatory circuits of innate immunity. By sampling tens of thousands of perturbed cells in vitro and in mice, we identified interactions and redundancies between developmental and signaling-dependent factors. These include opposing effects of Cebpb and Irf8 in regulating the monocyte/macrophage versus dendritic cell lineages and differential functions for Rela and Stat1/2 in monocyte versus dendritic cell responses to pathogens. This study establishes CRISP-seq as a broadly applicable, comprehensive, and unbiased approach for elucidating mammalian regulatory circuits.},
author = {Jaitin, Diego Adhemar and Weiner, Assaf and Yofe, Ido and Lara-Astiaso, David and Keren-Shaul, Hadas and David, Eyal and Salame, Tomer Meir and Tanay, Amos and van Oudenaarden, Alexander and Amit, Ido},
doi = {10.1016/j.cell.2016.11.039},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Jaitin et al. - 2016 - Dissecting Immune Circuits by Linking CRISPR-Pooled Screens with Single-Cell RNA-Seq.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {CRISPR,CRISPR/Cas9,Kathryn,RNA-seq,functional genomics,gene networks,genetic screen,immune response,innate immunity,single-cell RNA-seq,transcriptomics},
mendeley-tags = {CRISPR,Kathryn},
number = {7},
pages = {1883--1896.e15},
publisher = {Elsevier Inc.},
title = {{Dissecting Immune Circuits by Linking CRISPR-Pooled Screens with Single-Cell RNA-Seq}},
volume = {167},
year = {2016}
}
@article{Datlinger2017,
abstract = {CRISPR-based genetic screens are accelerating biological discovery, but current methods have inherent limitations. Widely used pooled screens are restricted to simple readouts including cell proliferation and sortable marker proteins. Arrayed screens allow for comprehensive molecular readouts such as transcriptome profiling, but at much lower throughput. Here we combine pooled CRISPR screening with single-cell RNA sequencing into a broadly applicable workflow, directly linking guide RNA expression to transcriptome responses in thousands of individual cells. Our method for CRISPR droplet sequencing (CROP-seq) enables pooled CRISPR screens with single-cell transcriptome resolution, which will facilitate high-throughput functional dissection of complex regulatory mechanisms and heterogeneous cell populations.},
author = {Datlinger, Paul and Rendeiro, Andr{\'{e}} F. and Schmidl, Christian and Krausgruber, Thomas and Traxler, Peter and Klughammer, Johanna and Schuster, Linda C. and Kuchler, Amelie and Alpar, Donat and Bock, Christoph},
doi = {10.1038/nmeth.4177},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Datlinger et al. - 2017 - Pooled CRISPR screening with single-cell transcriptome readout.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {3},
pages = {297--301},
pmid = {28099430},
publisher = {Nature Publishing Group},
title = {{Pooled CRISPR screening with single-cell transcriptome readout}},
volume = {14},
year = {2017}
}
@article{Fulco2016,
abstract = {Gene expression in mammals is regulated by noncoding elements that can affect physiology and disease, yet the functions and target genes of most noncoding elements remain unknown. We present a high-throughput approach that uses clustered regularly interspaced short palindromic repeats (CRISPR) interference (CRISPRi) to discover regulatory elements and identify their target genes. We assess {\textgreater}1 megabase of sequence in the vicinity of two essential transcription factors, MYC and GATA1, and identify nine distal enhancers that control gene expression and cellular proliferation. Quantitative features of chromatin state and chromosome conformation distinguish the seven enhancers that regulate MYC from other elements that do not, suggesting a strategy for predicting enhancer-promoter connectivity. This CRISPRi-based approach can be applied to dissect transcriptional networks and interpret the contributions of noncoding genetic variation to human disease.},
annote = {Supplementary materials (p. 13) contain a very useful literature review on methods to predict promoter-enhancer interactions.

Also a very simple heuristic method (p. 14 and p. 21 of the supplement) is developed to predict enhancer-gene regulation based on chromatin contact and activity.},
author = {Fulco, Charles P. and Munschauer, Mathias and Anyoha, Rockwell and Munson, Glen and Grossman, Sharon R. and Perez, Elizabeth M. and Kane, Michael and Cleary, Brian and Lander, Eric S. and Engreitz, Jesse M.},
doi = {10.1126/science.aag2445},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Fulco et al. - 2016 - Systematic mapping of functional enhancer-promoter connections with CRISPR interference.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Science/Fulco et al. - 2016 - Systematic mapping of functional enhancer-promoter connections with CRISPR interference.pdf:pdf},
issn = {10959203},
journal = {Science},
keywords = {CRISPR,Kathryn,gene-enhancer},
mendeley-tags = {CRISPR,Kathryn,gene-enhancer},
number = {6313},
pages = {769--773},
pmid = {27708057},
title = {{Systematic mapping of functional enhancer-promoter connections with CRISPR interference}},
volume = {354},
year = {2016}
}
@article{Sanjana2017,
abstract = {Genome editing technologies such as clustered regularly interspaced short palindromic repeats (CRISPR) systems have ushered in a new era of targeted DNA manipulation. The easy programmability of CRISPR using short oligonucleotides enables rapid synthesis of large-scale libraries for functional genetic screens. Here we present fundamental concepts and methods for pooled CRISPR screens and review biological results from recent genome-scale loss-of-function and gain-of-function screens. We also discuss new frontiers in pooled screens, including novel effector domains for functional screens and applications in the noncoding genome.},
author = {Sanjana, Neville E.},
doi = {10.1016/j.ab.2016.05.014},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Analytical Biochemistry/Sanjana - 2017 - Genome-scale CRISPR pooled screens.pdf:pdf},
issn = {10960309},
journal = {Analytical Biochemistry},
keywords = {CRISPR,Cancer,Cas9,Genetic screens,Genome engineering,Kathryn,Noncoding},
mendeley-tags = {CRISPR,Kathryn},
pages = {95--99},
publisher = {Elsevier Inc},
title = {{Genome-scale CRISPR pooled screens}},
url = {http://dx.doi.org/10.1016/j.ab.2016.05.014},
volume = {532},
year = {2017}
}
@article{Gilbert2013,
abstract = {The genetic interrogation and reprogramming of cells requires methods for robust and precise targeting of genes for expression or repression. The CRISPR-associated catalytically inactive dCas9 protein offers a general platform for RNA-guided DNA targeting. Here, we show that fusion of dCas9 to effector domains with distinct regulatory functions enables stable and efficient transcriptional repression or activation in human and yeast cells, with the site of delivery determined solely by a coexpressed short guide (sg)RNA. Coupling of dCas9 to a transcriptional repressor domain can robustly silence expression of multiple endogenous genes. RNA-seq analysis indicates that CRISPR interference (CRISPRi)-mediated transcriptional repression is highly specific. Our results establish that the CRISPR system can be used as a modular and flexible DNA-binding platform for the recruitment of proteins to a target DNA sequence, revealing the potential of CRISPRi as a general tool for the precise regulation of gene expression in eukaryotic cells. {\textcopyright} 2013 Elsevier Inc.},
author = {Gilbert, Luke A. and Larson, Matthew H. and Morsut, Leonardo and Liu, Zairan and Brar, Gloria A. and Torres, Sandra E. and Stern-Ginossar, Noam and Brandman, Onn and Whitehead, Evan H. and Doudna, Jennifer A. and Lim, Wendell A. and Weissman, Jonathan S. and Qi, Lei S.},
doi = {10.1016/j.cell.2013.06.044},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Gilbert et al. - 2013 - CRISPR-mediated modular RNA-guided regulation of transcription in eukaryotes.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
number = {2},
pages = {442},
publisher = {Elsevier Inc.},
title = {{CRISPR-mediated modular RNA-guided regulation of transcription in eukaryotes}},
url = {http://dx.doi.org/10.1016/j.cell.2013.06.044},
volume = {154},
year = {2013}
}
@article{Yu2016,
abstract = {Motivation: Functional genomics (FG) screens, using RNAi or CRISPR technology, have become a standard tool for systematic, genome-wide loss-of-function studies for therapeutic target discovery. As in many large-scale assays, however, off-target effects, variable reagents' potency and experimental noise must be accounted for appropriately control for false positives. Indeed, rigorous statistical analysis of high-throughput FG screening data remains challenging, particularly when integrative analyses are used to combine multiple sh/sgRNAs targeting the same gene in the library. Method: We use large RNAi and CRISPR repositories that are publicly available to evaluate a novel meta-analysis approach for FG screens via Bayesian hierarchical modeling, Screening Bayesian Evaluation and Analysis Method (ScreenBEAM). Results: Results from our analysis show that the proposed strategy, which seamlessly combines all available data, robustly outperforms classical algorithms developed for microarray data sets as well as recent approaches designed for next generation sequencing technologies. Remarkably, the ScreenBEAM algorithm works well even when the quality of FG screens is relatively low, which accounts for about 80-95{\%} of the public datasets. Availability and implementation: R package and source code are available at: https://github.com/jyyu/ScreenBEAM. Contact:, jose.silva@mssm.edu, yujiyang@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.},
author = {Yu, Jiyang and Silva, Jose and Califano, Andrea},
doi = {10.1093/bioinformatics/btv556},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Yu, Silva, Califano - 2016 - ScreenBEAM A novel meta-analysis algorithm for functional genomics screens via Bayesian hierarchical modeli.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {2},
pages = {260--267},
title = {{ScreenBEAM: A novel meta-analysis algorithm for functional genomics screens via Bayesian hierarchical modeling}},
volume = {32},
year = {2016}
}
@techreport{Reid2003,
abstract = {We describe some recent approaches to likelihood based inference in the presence of nuisance parameters. Our approach is based on plotting the likelihood function and the {\$}p{\$}-value function, using recently developed third order approximations. Orthogonal parameters and adjustments to profile likelihood are also discussed. Connections to classical approaches of conditional and marginal inference are outlined.},
archivePrefix = {arXiv},
arxivId = {physics/0312079},
author = {Reid, N. and Fraser, D. A. S.},
eprint = {0312079},
file = {::},
keywords = {nuisance parameters},
mendeley-tags = {nuisance parameters},
primaryClass = {physics},
title = {{Likelihood inference in the presence of nuisance parameters}},
url = {http://arxiv.org/abs/physics/0312079},
year = {2003}
}
@article{Diao2017,
abstract = {Millions of cis-regulatory elements are predicted to be present in the human genome, but direct evidence for their biological function is scarce. Here we report a high-throughput method, cis-regulatory element scan by tiling-deletion and sequencing (CREST-seq), for the unbiased discovery and functional assessment of cis-regulatory sequences in the genome. We used it to interrogate the 2-Mb POU5F1 locus in human embryonic stem cells, and identified 45 cis-regulatory elements. A majority of these elements have active chromatin marks, DNase hypersensitivity, and occupancy by multiple transcription factors, which confirms the utility of chromatin signatures in cis-element mapping. Notably, 17 of them are previously annotated promoters of functionally unrelated genes, and like typical enhancers, they form extensive spatial contacts with the POU5F1 promoter. These results point to the commonality of enhancer-like promoters in the human genome.},
author = {Diao, Yarui and Fang, Rongxin and Li, Bin and Meng, Zhipeng and Yu, Juntao and Qiu, Yunjiang and Lin, Kimberly C. and Huang, Hui and Liu, Tristin and Marina, Ryan J. and Jung, Inkyung and Shen, Yin and Guan, Kun Liang and Ren, Bing},
doi = {10.1038/nmeth.4264},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Diao et al. - 2017 - A tiling-deletion-based genetic screen for cis-regulatory element identification in mammalian cells.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
month = {may},
number = {6},
pages = {629--635},
publisher = {Nature Publishing Group},
title = {{A tiling-deletion-based genetic screen for cis-regulatory element identification in mammalian cells}},
volume = {14},
year = {2017}
}
@article{Jansakul2008,
abstract = {When overdispersion is present in count data, a negative binomial (NB) model is commonly used in place of the standard Poisson model. However, the model is sometimes not adequate because of the occurrence of excess zeros and a zero-inflated negative binomial (ZNB) model may be more appropriate. This article proposes a general score test statistic for comparing a ZNB regression model to the NB model and the test is extended to a composite score test. Simulation results indicate that the test performs reasonably well and has a sampling distribution under the null hypothesis (NB model) approximated by the usual $\chi$2 distribution. Use of the test is illustrated on a set of apple shoot propagation data. The composite score test is found to indicate suitable models.},
author = {Jansakul, N. and Hinde, John P.},
doi = {10.1080/03610910802421632},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Communications in Statistics Simulation and Computation/Jansakul, Hinde - 2008 - Score Tests for Extra-Zero Models in Zero-Inflated Negative Binomial Models.pdf:pdf},
isbn = {0361091080242},
issn = {15324141},
journal = {Communications in Statistics: Simulation and Computation},
keywords = {Count data,Overdispersion,Score test,Zero-inflation,count data},
mendeley-tags = {count data},
number = {1},
pages = {92--108},
title = {{Score Tests for Extra-Zero Models in Zero-Inflated Negative Binomial Models}},
volume = {38},
year = {2008}
}
@article{Daley2018,
abstract = {Pooled CRISPR screens allow researchers to interrogate genetic causes of complex phenotypes at the genome-wide scale and promise higher specificity and sensitivity compared to competing technologies. Unfortunately, two problems exist, particularly for CRISPRi/a screens: variability in guide efficiency and large rare off-target effects. We present a method, CRISPhieRmix, that resolves these issues by using a hierarchical mixture model with a broad-tailed null distribution. We show that CRISPhieRmix allows for more accurate and powerful inferences in large-scale pooled CRISPRi/a screens. We discuss key issues in the analysis and design of screens, particularly the number of guides needed for faithful full discovery.},
author = {Daley, Timothy P. and Lin, Zhixiang and Lin, Xueqiu and Liu, Yanxia and Wong, Wing Hung and Qi, Lei S.},
doi = {10.1186/s13059-018-1538-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Daley et al. - 2018 - CRISPhieRmix A hierarchical mixture model for CRISPR pooled screens.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Daley et al. - 2018 - CRISPhieRmix A hierarchical mixture model for CRISPR pooled screens.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {CRISPR,CRISPR activation,CRISPR interference,CRISPR screen,FDR,Kathryn,Local fdr,Mixture models,Multiple testing,sgRNA design},
mendeley-tags = {CRISPR,FDR,Kathryn,Multiple testing},
number = {1},
pages = {1--13},
publisher = {Genome Biology},
title = {{CRISPhieRmix: A hierarchical mixture model for CRISPR pooled screens}},
volume = {19},
year = {2018}
}
@article{Zheng2019,
abstract = {The genomes of multicellular organisms are extensively folded into 3D chromosome territories within the nucleus 1 . Advanced 3D genome-mapping methods that combine proximity ligation and high-throughput sequencing (such as chromosome conformation capture, Hi-C) 2 , and chromatin immunoprecipitation techniques (such as chromatin interaction analysis by paired-end tag sequencing, ChIA-PET) 3 , have revealed topologically associating domains 4 with frequent chromatin contacts, and have identified chromatin loops mediated by specific protein factors for insulation and regulation of transcription 5–7 . However, these methods rely on pairwise proximity ligation and reflect population-level views, and thus cannot reveal the detailed nature of chromatin interactions. Although single-cell Hi-C 8 potentially overcomes this issue, this method may be limited by the sparsity of data that is inherent to current single-cell assays. Recent advances in microfluidics have opened opportunities for droplet-based genomic analysis 9 but this approach has not yet been adapted for chromatin interaction analysis. Here we describe a strategy for multiplex chromatin-interaction analysis via droplet-based and barcode-linked sequencing, which we name ChIA-Drop. We demonstrate the robustness of ChIA-Drop in capturing complex chromatin interactions with single-molecule precision, which has not been possible using methods based on population-level pairwise contacts. By applying ChIA-Drop to Drosophila cells, we show that chromatin topological structures predominantly consist of multiplex chromatin interactions with high heterogeneity; ChIA-Drop also reveals promoter-centred multivalent interactions, which provide topological insights into transcription.},
author = {Zheng, Meizhen and Tian, Simon Zhongyuan and Capurso, Daniel and Kim, Minji and Maurya, Rahul and Lee, Byoungkoo and Piecuch, Emaly and Gong, Liang and Zhu, Jacqueline Jufen and Li, Zhihui and Wong, Chee Hong and Ngan, Chew Yee and Wang, Ping and Ruan, Xiaoan and Wei, Chia Lin and Ruan, Yijun},
doi = {10.1038/s41586-019-0949-1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Zheng et al. - 2019 - Multiplex chromatin interactions with single-molecule precision.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {HI-C,single cell},
mendeley-tags = {HI-C,single cell},
number = {7745},
pages = {558--562},
publisher = {Springer US},
title = {{Multiplex chromatin interactions with single-molecule precision}},
url = {http://dx.doi.org/10.1038/s41586-019-0949-1},
volume = {566},
year = {2019}
}
@article{Jia2017,
abstract = {Background: Clustered regularly-interspaced short palindromic repeats (CRISPR) screens are usually implemented in cultured cells to identify genes with critical functions. Although several methods have been developed or adapted to analyze CRISPR screening data, no single specific algorithm has gained popularity. Thus, rigorous procedures are needed to overcome the shortcomings of existing algorithms. Methods: We developed a Permutation-Based Non-Parametric Analysis (PBNPA) algorithm, which computes p-values at the gene level by permuting sgRNA labels, and thus it avoids restrictive distributional assumptions. Although PBNPA is designed to analyze CRISPR data, it can also be applied to analyze genetic screens implemented with siRNAs or shRNAs and drug screens. Results: We compared the performance of PBNPA with competing methods on simulated data as well as on real data. PBNPA outperformed recent methods designed for CRISPR screen analysis, as well as methods used for analyzing other functional genomics screens, in terms of Receiver Operating Characteristics (ROC) curves and False Discovery Rate (FDR) control for simulated data under various settings. Remarkably, the PBNPA algorithm showed better consistency and FDR control on published real data as well. Conclusions: PBNPA yields more consistent and reliable results than its competitors, especially when the data quality is low. R package of PBNPA is available at: https://cran.r-project.org/web/packages/PBNPA/.},
author = {Jia, Gaoxiang and Wang, Xinlei and Xiao, Guanghua},
doi = {10.1186/s12864-017-3938-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Genomics/Jia, Wang, Xiao - 2017 - A permutation-based non-parametric analysis of CRISPR screen data.pdf:pdf},
isbn = {1286401739},
issn = {14712164},
journal = {BMC Genomics},
keywords = {CRISPR,False discovery rate,Functional genomics,Kathryn,Multiple testing,Negative selection,Next generation sequencing,Positive selection,RNA interference,gene-enhancer},
mendeley-tags = {CRISPR,Kathryn,Multiple testing,gene-enhancer},
number = {1},
pages = {1--11},
publisher = {BMC Genomics},
title = {{A permutation-based non-parametric analysis of CRISPR screen data}},
volume = {18},
year = {2017}
}
@article{Chen2018,
abstract = {Read counting and unique molecular identifier (UMI) counting are the principal gene expression quantification schemes used in single-cell RNA-sequencing (scRNA-seq) analysis. By using multiple scRNA-seq datasets, we reveal distinct distribution differences between these schemes and conclude that the negative binomial model is a good approximation for UMI counts, even in heterogeneous populations. We further propose a novel differential expression analysis algorithm based on a negative binomial model with independent dispersions in each group (NBID). Our results show that this properly controls the FDR and achieves better power for UMI counts when compared to other recently developed packages for scRNA-seq analysis.},
author = {Chen, Wenan and Li, Yan and Easton, John and Finkelstein, David and Wu, Gang and Chen, Xiang},
doi = {10.1186/s13059-018-1438-9},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Chen et al. - 2018 - UMI-count modeling and differential expression analysis for single-cell RNA sequencing.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Differential expression analysis,Negative binomial,Unique molecular identifier,differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {1},
pages = {1--17},
pmid = {29855333},
publisher = {Genome Biology},
title = {{UMI-count modeling and differential expression analysis for single-cell RNA sequencing}},
volume = {19},
year = {2018}
}
@article{Dixit2016,
abstract = {Genetic screens help infer gene function in mammalian cells, but it has remained difficult to assay complex phenotypes—such as transcriptional profiles—at scale. Here, we develop Perturb-seq, combining single-cell RNA sequencing (RNA-seq) and clustered regularly interspaced short palindromic repeats (CRISPR)-based perturbations to perform many such assays in a pool. We demonstrate Perturb-seq by analyzing 200,000 cells in immune cells and cell lines, focusing on transcription factors regulating the response of dendritic cells to lipopolysaccharide (LPS). Perturb-seq accurately identifies individual gene targets, gene signatures, and cell states affected by individual perturbations and their genetic interactions. We posit new functions for regulators of differentiation, the anti-viral response, and mitochondrial function during immune activation. By decomposing many high content measurements into the effects of perturbations, their interactions, and diverse cell metadata, Perturb-seq dramatically increases the scope of pooled genomic assays.},
author = {Dixit, Atray and Parnas, Oren and Li, Biyu and Chen, Jenny and Fulco, Charles P. and Jerby-Arnon, Livnat and Marjanovic, Nemanja D. and Dionne, Danielle and Burks, Tyler and Raychowdhury, Raktima and Adamson, Britt and Norman, Thomas M. and Lander, Eric S. and Weissman, Jonathan S. and Friedman, Nir and Regev, Aviv},
doi = {10.1016/j.cell.2016.11.038},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Dixit et al. - 2016 - Perturb-Seq Dissecting Molecular Circuits with Scalable Single-Cell RNA Profiling of Pooled Genetic Screens.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {CRISPR,epistasis,genetic interactions,genetics,pooled screen,single-cell RNA-seq,to-read},
mendeley-tags = {CRISPR,genetics,to-read},
month = {dec},
pages = {1853--1866},
publisher = {Cell Press},
title = {{Perturb-Seq: Dissecting Molecular Circuits with Scalable Single-Cell RNA Profiling of Pooled Genetic Screens}},
volume = {167},
year = {2016}
}
@article{Gaffney2019,
abstract = {A new study presents a powerful experimental approach, CRISPRi-FlowFISH, for mapping regulatory interactions, and uses it to characterize thousands of putative enhancer–gene pairs. The results suggest that most current approaches for predicting enhancer–gene interactions perform poorly, but a simple mathematical model combining distance with enhancer activity shows promise.},
author = {Gaffney, Daniel J},
doi = {10.1038/s41588-019-0540-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Gaffney - 2019 - Mapping and predicting gene – enhancer.pdf:pdf},
issn = {1546-1718},
journal = {Nature Genetics},
keywords = {CRISPR,gene regulation,gene-enhancer,genetics},
mendeley-tags = {CRISPR,gene regulation,gene-enhancer,genetics},
pages = {1662--1663},
publisher = {Springer US},
title = {{Mapping and predicting gene – enhancer}},
url = {http://dx.doi.org/10.1038/s41588-019-0540-6},
volume = {51},
year = {2019}
}
@article{Canver2015,
abstract = {Enhancers, critical determinants of cellular identity, are commonly recognized by correlative chromatin marks and gain-of-function potential, although only loss-of-function studies can demonstrate their requirement in the native genomic context. Previously, we identified an erythroid enhancer of human BCL11A, subject to common genetic variation associated with the fetal haemoglobin level, the mouse orthologue of which is necessary for erythroid BCL11A expression. Here we develop pooled clustered regularly interspaced palindromic repeat (CRISPR)-Cas9 guide RNA libraries to perform in situ saturating mutagenesis of the human and mouse enhancers. This approach reveals critical minimal features and discrete vulnerabilities of these enhancers. Despite conserved function of the composite enhancers, their architecture diverges. The crucial human sequences appear to be primate-specific. Through editing of primary human progenitors and mouse transgenesis, we validate the BCL11A erythroid enhancer as a target for fetal haemoglobin reinduction. The detailed enhancer map will inform therapeutic genome editing, and the screening approach described here is generally applicable to functional interrogation of non-coding genomic elements.},
author = {Canver, Matthew C. and Smith, Elenoe C. and Sher, Falak and Pinello, Luca and Sanjana, Neville E. and Shalem, Ophir and Chen, Diane D. and Schupp, Patrick G. and Vinjamur, Divya S. and Garcia, Sara P. and Luc, Sidinh and Kurita, Ryo and Nakamura, Yukio and Fujiwara, Yuko and Maeda, Takahiro and Yuan, Guo Cheng and Zhang, Feng and Orkin, Stuart H. and Bauer, Daniel E.},
doi = {10.1038/nature15521},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Canver et al. - 2015 - BCL11A enhancer dissection by Cas9-mediated in situ saturating mutagenesis.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {7577},
pages = {192--197},
pmid = {26375006},
title = {{BCL11A enhancer dissection by Cas9-mediated in situ saturating mutagenesis}},
volume = {527},
year = {2015}
}
@article{Delmans2016,
abstract = {Background: The advent of high throughput RNA-seq at the single-cell level has opened up new opportunities to elucidate the heterogeneity of gene expression. One of the most widespread applications of RNA-seq is to identify genes which are differentially expressed between two experimental conditions. Results: We present a discrete, distributional method for differential gene expression (D3E), a novel algorithm specifically designed for single-cell RNA-seq data. We use synthetic data to evaluate D3E, demonstrating that it can detect changes in expression, even when the mean level remains unchanged. Since D3E is based on an analytically tractable stochastic model, it provides additional biological insights by quantifying biologically meaningful properties, such as the average burst size and frequency. We use D3E to investigate experimental data, and with the help of the underlying model, we directly test hypotheses about the driving mechanism behind changes in gene expression. Conclusion: Evaluation using synthetic data shows that D3E performs better than other methods for identifying differentially expressed genes since it is designed to take full advantage of the information available from single-cell RNA-seq experiments. Moreover, the analytical model underlying D3E makes it possible to gain additional biological insights.},
author = {Delmans, Mihails and Hemberg, Martin},
doi = {10.1186/s12859-016-0944-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Bioinformatics/Delmans, Hemberg - 2016 - Discrete distributional differential expression (D3E) - a tool for gene expression analysis of single-cell RNA.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Differential gene expression,Single-cell RNA-seq,Software,Stochastic gene expression,Transcriptional bursting model,differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {1},
pages = {1--13},
publisher = {BMC Bioinformatics},
title = {{Discrete distributional differential expression (D3E) - a tool for gene expression analysis of single-cell RNA-seq data}},
url = {http://dx.doi.org/10.1186/s12859-016-0944-6},
volume = {17},
year = {2016}
}
@article{Wheeler,
author = {Wheeler, Emily C and Vu, Anthony Q and Einstein, Jaclyn M and Disalvo, Matthew and Ahmed, Noorsher and Nostrand, Eric L Van and Shishkin, Alexander A and Jin, Wenhao and Allbritton, Nancy L and Yeo, Gene W},
doi = {10.1038/s41592-020-0826-8},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Wheeler et al. - Unknown - Pooled CRISPR screens with imaging on microraft arrays reveals stress granule-regulatory factors.pdf:pdf},
issn = {1548-7105},
journal = {Nature Methods},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
publisher = {Springer US},
title = {{Pooled CRISPR screens with imaging on microraft arrays reveals stress granule-regulatory factors}},
url = {http://dx.doi.org/10.1038/s41592-020-0826-8}
}
@article{Zamanighomi2019,
abstract = {Systems for CRISPR-based combinatorial perturbation of two or more genes are emerging as powerful tools for uncovering genetic interactions. However, systematic identification of these relationships is complicated by sample, reagent, and biological variability. We develop a variational Bayes approach (GEMINI) that jointly analyzes all samples and reagents to identify genetic interactions in pairwise knockout screens. The improved accuracy and scalability of GEMINI enables the systematic analysis of combinatorial CRISPR knockout screens, regardless of design and dimension. GEMINI is available as an open source R package on GitHub at https://github.com/sellerslab/gemini.},
author = {Zamanighomi, Mahdi and Jain, Sidharth S. and Ito, Takahiro and Pal, Debjani and Daley, Timothy P. and Sellers, William R.},
doi = {10.1186/s13059-019-1745-9},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Zamanighomi et al. - 2019 - GEMINI A variational Bayesian approach to identify genetic interactions from combinatorial CRISPR screens.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {CRISPR,Combinatorial,Double knockout,GEMINI,Genetic interactions,Synthetic lethality,Variational inference,interactions},
mendeley-tags = {CRISPR,interactions},
number = {1},
pages = {1--10},
pmid = {31300006},
publisher = {Genome Biology},
title = {{GEMINI: A variational Bayesian approach to identify genetic interactions from combinatorial CRISPR screens}},
volume = {20},
year = {2019}
}
@article{Qiu2017,
abstract = {Single-cell gene expression studies promise to reveal rare cell types and cryptic states, but the high variability of single-cell RNA-seq measurements frustrates efforts to assay transcriptional differences between cells. We introduce the Census algorithm to convert relative RNA-seq expression levels into relative transcript counts without the need for experimental spike-in controls. Analyzing changes in relative transcript counts led to dramatic improvements in accuracy compared to normalized read counts and enabled new statistical tests for identifying developmentally regulated genes. Census counts can be analyzed with widely used regression techniques to reveal changes in cell-fate-dependent gene expression, splicing patterns and allelic imbalances. We reanalyzed single-cell data from several developmental and disease studies, and demonstrate that Census enabled robust analysis at multiple layers of gene regulation. Census is freely available through our updated single-cell analysis toolkit, Monocle 2.},
author = {Qiu, Xiaojie and Hill, Andrew and Packer, Jonathan and Lin, Dejun and Ma, Yi An and Trapnell, Cole},
doi = {10.1038/nmeth.4150},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Qiu et al. - 2017 - Single-cell mRNA quantification and differential analysis with Census.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {single cell},
mendeley-tags = {single cell},
number = {3},
pages = {309--315},
title = {{Single-cell mRNA quantification and differential analysis with Census}},
volume = {14},
year = {2017}
}
@article{Katsevich2020c,
author = {Katsevich, Eugene and Roeder, Kathryn},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Katsevich, Roeder - 2020 - Conditional resampling improves calibration in single cell CRISPR screen analysis(2).pdf:pdf},
journal = {bioRxiv},
keywords = {crispr methods,crispr screen},
mendeley-tags = {crispr methods,crispr screen},
title = {{Conditional resampling improves calibration in single cell CRISPR screen analysis}},
url = {https://www.biorxiv.org/content/10.1101/2020.08.13.250092v2},
year = {2020}
}
@article{Koike-Yusa2014,
abstract = {Identification of genes influencing a phenotype of interest is frequently achieved through genetic screening by RNA interference (RNAi) or knockouts. However, RNAi may only achieve partial depletion of gene activity, and knockout-based screens are difficult in diploid mammalian cells. Here we took advantage of the efficiency and high throughput of genome editing based on type II, clustered, regularly interspaced, short palindromic repeats (CRISPR)-CRISPR-associated (Cas) systems to introduce genome-wide targeted mutations in mouse embryonic stem cells (ESCs). We designed 87,897 guide RNAs (gRNAs) targeting 19,150 mouse protein-coding genes and used a lentiviral vector to express these gRNAs in ESCs that constitutively express Cas9. Screening the resulting ESC mutant libraries for resistance to either Clostridium septicum alpha-toxin or 6-thioguanine identified 27 known and 4 previously unknown genes implicated in these phenotypes. Our results demonstrate the potential for efficient loss-of-function screening using the CRISPR-Cas9 system. {\textcopyright} 2014 Nature America, Inc.},
author = {Koike-Yusa, Hiroko and Li, Yilong and Tan, E. Pien and Velasco-Herrera, Martin Del Castillo and Yusa, Kosuke},
doi = {10.1038/nbt.2800},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Koike-Yusa et al. - 2014 - Genome-wide recessive genetic screening in mammalian cells with a lentiviral CRISPR-guide RNA library.pdf:pdf},
issn = {15461696},
journal = {Nature Biotechnology},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {3},
pages = {267--273},
title = {{Genome-wide recessive genetic screening in mammalian cells with a lentiviral CRISPR-guide RNA library}},
volume = {32},
year = {2014}
}
@article{Louis1982,
author = {Louis, Thomas A .},
file = {::},
journal = {Journal of the Royal Statistical Society, Series B},
keywords = {em algorithm,maximum likelihood,observed information,speeding,statistics},
mendeley-tags = {em algorithm,statistics},
number = {2},
pages = {226--233},
title = {{Finding the Observed Information Matrix when Using the EM Algorithm}},
volume = {44},
year = {1982}
}
@article{Simeonov2017,
abstract = {The majority of genetic variants associated with common human diseases map to enhancers, non-coding elements that shape cell-type-specific transcriptional programs and responses to extracellular cues1-3. Systematic mapping of functional enhancers and their biological contexts is required to understand the mechanisms by which variation in non-coding genetic sequences contributes to disease. Functional enhancers can be mapped by genomic sequence disruption4-6, but this approach is limited to the subset of enhancers that are necessary in the particular cellular context being studied. We hypothesized that recruitment of a strong transcriptional activator to an enhancer would be sufficient to drive target gene expression, even if that enhancer was not currently active in the assayed cells. Here we describe a discovery platform that can identify stimulus-responsive enhancers for a target gene independent of stimulus exposure. We used tiled CRISPR activation (CRISPRa)7 to synthetically recruit a transcriptional activator to sites across large genomic regions (more than 100 kilobases) surrounding two key autoimmunity risk loci, CD69 and IL2RA. We identified several CRISPRa-responsive elements with chromatin features of stimulus-responsive enhancers, including an IL2RA enhancer that harbours an autoimmunity risk variant. Using engineered mouse models, we found that sequence perturbation of the disease-associated Il2ra enhancer did not entirely block Il2ra expression, but rather delayed the timing of gene activation in response to specific extracellular signals. Enhancer deletion skewed polarization of naive T cells towards a pro-inflammatory T helper (TH17) cell state and away from a regulatory T cell state. This integrated approach identifies functional enhancers and reveals how non-coding variation associated with human immune dysfunction alters context-specific gene programs.},
author = {Simeonov, Dimitre R. and Gowen, Benjamin G. and Boontanrart, Mandy and Roth, Theodore L. and Gagnon, John D. and Mumbach, Maxwell R. and Satpathy, Ansuman T. and Lee, Youjin and Bray, Nicolas L. and Chan, Alice Y. and Lituiev, Dmytro S. and Nguyen, Michelle L. and Gate, Rachel E. and Subramaniam, Meena and Li, Zhongmei and Woo, Jonathan M. and Mitros, Therese and Ray, Graham J. and Curie, Gemma L. and Naddaf, Nicki and Chu, Julia S. and Ma, Hong and Boyer, Eric and {Van Gool}, Frederic and Huang, Hailiang and Liu, Ruize and Tobin, Victoria R. and Schumann, Kathrin and Daly, Mark J. and Farh, Kyle K. and Ansel, K. Mark and Ye, Chun J. and Greenleaf, William J. and Anderson, Mark S. and Bluestone, Jeffrey A. and Chang, Howard Y. and Corn, Jacob E. and Marson, Alexander},
doi = {10.1038/nature23875},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Simeonov et al. - 2017 - Discovery of stimulation-responsive immune enhancers with CRISPR activation.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {7670},
pages = {111--115},
pmid = {28854172},
publisher = {Nature Publishing Group},
title = {{Discovery of stimulation-responsive immune enhancers with CRISPR activation}},
volume = {549},
year = {2017}
}
@article{Bodapati2020,
abstract = {Genome-wide pooled CRISPR-Cas-mediated knockout, activation, and repression screens are powerful tools for functional genomic investigations. Despite their increasing importance, there is currently little guidance on how to design and analyze CRISPR-pooled screens. Here, we provide a review of the commonly used algorithms in the computational analysis of pooled CRISPR screens. We develop a comprehensive simulation framework to benchmark and compare the performance of these algorithms using both synthetic and real datasets. Our findings inform parameter choices of CRISPR screens and provide guidance to researchers on the design and analysis of pooled CRISPR screens.},
author = {Bodapati, Sunil and Daley, Timothy P. and Lin, Xueqiu and Zou, James and Qi, Lei S.},
doi = {10.1186/s13059-020-01972-x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Bodapati et al. - 2020 - A benchmark of algorithms for the analysis of pooled CRISPR screens.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Benchmarking,CRISPR,CRISPR activation,CRISPR interference,CRISPR knockoout,CRISPR screen,Screen algorithms,Simulation},
mendeley-tags = {CRISPR},
number = {1},
pages = {1--13},
pmid = {32151271},
publisher = {Genome Biology},
title = {{A benchmark of algorithms for the analysis of pooled CRISPR screens}},
volume = {21},
year = {2020}
}
@article{Wang2019e,
abstract = {Background: The analysis of single-cell RNA sequencing (scRNAseq) data plays an important role in understanding the intrinsic and extrinsic cellular processes in biological and biomedical research. One significant effort in this area is the detection of differentially expressed (DE) genes. scRNAseq data, however, are highly heterogeneous and have a large number of zero counts, which introduces challenges in detecting DE genes. Addressing these challenges requires employing new approaches beyond the conventional ones, which are based on a nonzero difference in average expression. Several methods have been developed for differential gene expression analysis of scRNAseq data. To provide guidance on choosing an appropriate tool or developing a new one, it is necessary to evaluate and compare the performance of differential gene expression analysis methods for scRNAseq data. Results: In this study, we conducted a comprehensive evaluation of the performance of eleven differential gene expression analysis software tools, which are designed for scRNAseq data or can be applied to them. We used simulated and real data to evaluate the accuracy and precision of detection. Using simulated data, we investigated the effect of sample size on the detection accuracy of the tools. Using real data, we examined the agreement among the tools in identifying DE genes, the run time of the tools, and the biological relevance of the detected DE genes. Conclusions: In general, agreement among the tools in calling DE genes is not high. There is a trade-off between true-positive rates and the precision of calling DE genes. Methods with higher true positive rates tend to show low precision due to their introducing false positives, whereas methods with high precision show low true positive rates due to identifying few DE genes. We observed that current methods designed for scRNAseq data do not tend to show better performance compared to methods designed for bulk RNAseq data. Data multimodality and abundance of zero read counts are the main characteristics of scRNAseq data, which play important roles in the performance of differential gene expression analysis methods and need to be considered in terms of the development of new methods.},
author = {Wang, Tianyu and Li, Boyang and Nelson, Craig E. and Nabavi, Sheida},
doi = {10.1186/s12859-019-2599-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Bioinformatics/Wang et al. - 2019 - Comparative analysis of differential gene expression analysis tools for single-cell RNA sequencing data.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Comparative analysis,Differential gene expression analysis,RNAseq,Single-cell,differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {1},
pages = {1--16},
publisher = {BMC Bioinformatics},
title = {{Comparative analysis of differential gene expression analysis tools for single-cell RNA sequencing data}},
volume = {20},
year = {2019}
}
@article{Efron1994,
abstract = {Missing data refers to a class of problems made difficult by the absence of some portions of a familiar data structure. For example, a regression problem might have some missing values in the predictor vectors. This article concerns nonparametric approaches to assessing the accuracy of an estimator in a missing data situation. Three main topics are discussed: bootstrap methods for missing data, these methods' relationship to the theory of multiple imputation, and computationally efficient ways of executing them. The simplest form of nonparametric bootstrap confidence interval turns out to give convenient and accurate answers. There are interesting practical and theoretical differences between bootstrap methods and the multiple imputation approach, as well as some useful similarities. {\textcopyright} 1994 Taylor {\&} Francis Group, LLC.},
author = {Efron, Bradley},
doi = {10.1080/01621459.1994.10476768},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Efron - 1994 - Missing data, imputation, and the bootstrap.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Bayesian bootstrap,Bootstrap confidence intervals,Data augmentation,Ignorable nonresponse,Nonparametric MLE,bootstrap,missing data},
mendeley-tags = {bootstrap,missing data},
number = {426},
pages = {463--475},
title = {{Missing data, imputation, and the bootstrap}},
volume = {89},
year = {1994}
}
@article{Hicks2018,
abstract = {Until recently, high-throughput gene expression technology, such asRNA-Sequencing (RNA-seq) required hundreds of thousands of cells to produce reliable measurements. Recent technical advances permit genome-wide gene expression measurement at the single-cell level. Single-cell RNA-Seq (scRNA-seq) is the most widely used and numerous publications are based on data produced with this technology. However, RN A-seq and scRNA-seq data are markedly different. In particular, unlike RNA-seq, the majority ofreported expression levels in scRNA-seq are zeros, which could be either biologically-driven, genes not expressing RNA at the time of measurement, or technically-driven, genes expressing RNA, but not at a sufficient level to be detected by sequencing technology. Another difference is that the proportion of genes reporting the expression level to be zero varies substantially across single cells compared to RNA-seq samples. However, it remains unclear to what extent this cell-to-cell variation is being driven by technical rather than biological variation. Furthermore, while systematic errors, including batch effects, have been widely reported as a major challenge in high-throughput technologies, these issues have received minimal attention in published studies based on scRNA-seq technology. Here, we use an assessment experiment to examine data from published studies and demonstrate that systematic errors can explain a substantial percentage of observed cell-to-cell expression variability. Specifically, we present evidence that some of these reported zeros are driven by technical variation by demonstrating that scRNA-seq produces more zeros than expected and that this bias is greater for lower expressed genes. In addition, this missing data problem is exacerbated by the fact that this technical variation varies cell-to-cell. Then, we show how this technical cell-to-cell variability can be confused with novel biological results. Finally, we demonstrate and discuss how batch-effects and confounded experiments can intensify the problem.},
author = {Hicks, Stephanie C. and Townes, F. William and Teng, Mingxiang and Irizarry, Rafael A.},
doi = {10.1093/biostatistics/kxx053},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biostatistics/Hicks et al. - 2018 - Missing data and technical variability in single-cell RNA-sequencing experiments.pdf:pdf},
issn = {14684357},
journal = {Biostatistics},
keywords = {Censoring,Confounding.,Genomics,Missing not at random (MNAR),Single-cell RNA-Sequencing,single cell},
mendeley-tags = {single cell},
number = {4},
pages = {562--578},
title = {{Missing data and technical variability in single-cell RNA-sequencing experiments}},
volume = {19},
year = {2018}
}
@article{Lause2020,
abstract = {Standard preprocessing of single-cell RNA-seq UMI data includes normalization by sequencing depth to remove this technical variability, and nonlinear transformation to stabilize the variance across genes with different expression levels. Instead, two recent papers propose to use statistical count models for these tasks: Hafemeister and Satija (2019) recommend using Pearson residuals from negative binomial regression, while Townes et al. (2019) recommend fitting a generalized PCA model. Here, we investigate the connection between these approaches theoretically and empirically, and compare their effects on downstream processing. We show that the model of Hafemeister and Satija (2019) produces noisy parameter estimates because it is overspecified (which is why the original paper employs post-hoc regularization). When specified more parsimoniously, it has a simple analytic solution equivalent to the rank-one Poisson GLM-PCA of Townes et al. (2019). Further, our analysis indicates that per-gene overdispersion estimates in Hafemeister and Satija (2019) are biased, and that the data analyzed in that paper are in fact consistent with constant overdispersion parameter across genes. We then use negative control data without biological variability to estimate the technical overdispersion of UMI counts, and find that across several different experimental protocols, the data suggest very moderate overdispersion. Finally, we argue that analytic Pearson residuals (or, equivalently, rank-one GLM-PCA or negative binomial regression after regularization) strongly outperform standard preprocessing for identifying biologically variable genes, and capture more biologically meaningful variation when used for dimensionality reduction, compared to other methods.},
author = {Lause, Jan and Berens, Philipp and Kobak, Dmitry},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Lause, Berens, Kobak - 2020 - Analytic Pearson residuals for normalization of single-cell RNA-seq UMI data.pdf:pdf},
journal = {bioRxiv},
keywords = {single cell},
mendeley-tags = {single cell},
title = {{Analytic Pearson residuals for normalization of single-cell RNA-seq UMI data}},
url = {https://doi.org/10.1101/2020.12.01.405886},
year = {2020}
}
@article{Savoca2000,
abstract = {This paper presents an overview of the theory of measurement error bias in ordinary regression estimators when several binary explanatory variables are mismeasured. This situation commonly occurs in health-related applications where the effects of illness are modeled in a multivariate framework and where health conditions are usually 0-1 survey responses indicating the absence or presence of diseases. An analysis of the effect of psychiatric diseases on male earnings provides an empirical example that indicates extensive measurement error bias even in sophisticated survey measures that are designed to simulate clinical diagnoses. A corrected covariance matrix is constructed from a validity study of the survey mental health indicators. When ordinary least squares estimators are adjusted by this correction matrix, the estimated earnings effects drop for certain diseases (drug abuse, general phobic disorders) and rise for others (anti-social personality).},
author = {Savoca, E.},
doi = {10.1023/A:1012541005920},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Health Services and Outcomes Research Methodology/Savoca - 2000 - Measurement errors in binary regressors An application to measuring the effects of specific psychiatric diseases on earn.pdf:pdf},
issn = {13873741},
journal = {Health Services and Outcomes Research Methodology},
keywords = {Binary variables,Measurement error,Multiple regression,Psychiatric diseases,error-in-variables},
mendeley-tags = {error-in-variables},
number = {2},
pages = {149--164},
title = {{Measurement errors in binary regressors: An application to measuring the effects of specific psychiatric diseases on earnings}},
volume = {1},
year = {2000}
}
@article{Shalem2014,
abstract = {The simplicity of programming the CRISPR (clustered regularly interspaced short palindromic repeats)–associated nuclease Cas9 to modify specific genomic loci suggests a new way to interrogate gene function on a genome-wide scale. We show that lentiviral delivery of a genome-scale CRISPR-Cas9 knockout (GeCKO) library targeting 18,080 genes with 64,751 unique guide sequences enables both negative and positive selection screening in human cells. First, we used the GeCKO library to identify genes essential for cell viability in cancer and pluripotent stem cells. Next, in a melanoma model, we screened for genes whose loss is involved in resistance to vemurafenib, a therapeutic RAF inhibitor. Our highest-ranking candidates include previously validated genes NF1 and MED12, as well as novel hits NF2, CUL3, TADA2B, and TADA1. We observe a high level of consistency between independent guide RNAs targeting the same gene and a high rate of hit confirmation, demonstrating the promise of genome-scale screening with Cas9.},
author = {Shalem, Ophir and Sanjana, Neville E. and Hartenian, Ella and Shi, Xi and Scott, David A. and Mikkelsen, Tarjei S. and Heckl, Dirk and Ebert, Benjamin L. and Root, David E. and Doench, John G. and Zhang, Feng},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Shalem et al. - 2014 - Genome-Scale CRISPR-Cas9 Knockout Screening in Human Cells.pdf:pdf},
journal = {Science},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {33},
pages = {84--87},
title = {{Genome-Scale CRISPR-Cas9 Knockout Screening in Human Cells}},
volume = {343},
year = {2014}
}
@article{Finkelstein2020,
abstract = {When data contains measurement errors, it is necessary to make assumptions relating the observed, erroneous data to the unobserved true phenomena of interest. These assumptions should be justifiable on substantive grounds, but are often motivated by mathematical convenience, for the sake of exactly identifying the target of inference. We adopt the view that it is preferable to present bounds under justifiable assumptions than to pursue exact identification under dubious ones. To that end, we demonstrate how a broad class of modeling assumptions involving discrete variables, including common measurement error and conditional independence assumptions, can be expressed as linear constraints on the parameters of the model. We then use linear programming techniques to produce sharp bounds for factual and counterfactual distributions under measurement error in such models. We additionally propose a procedure for obtaining outer bounds on non-linear models. Our method yields sharp bounds in a number of important settings -- such as the instrumental variable scenario with measurement error -- for which no bounds were previously known.},
archivePrefix = {arXiv},
arxivId = {2012.12449},
author = {Finkelstein, Noam and Adams, Roy and Saria, Suchi and Shpitser, Ilya},
eprint = {2012.12449},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Finkelstein et al. - 2020 - Partial Identifiability in Discrete Data With Measurement Error.pdf:pdf},
journal = {arXiv},
keywords = {count data,missing data},
mendeley-tags = {count data,missing data},
title = {{Partial Identifiability in Discrete Data With Measurement Error}},
url = {http://arxiv.org/abs/2012.12449},
year = {2020}
}
@article{Ahlmann-Eltze2020a,
abstract = {Motivation: The Gamma-Poisson distribution is a theoretically and empirically motivated model for the sampling variability of single cell RNA-sequencing counts (Gr{\&}uumln et al., 2014; Townes et al., 2019; Svensson, 2020; Silverman et al., 2018; Hafemeister and Satija, 2019) and an essential building block for analysis approaches including differential expression analysis (Robinson et al., 2010; McCarthy et al., 2012; Anders and Huber, 2010; Love et al., 2014), principal component analysis (Townes et al., 2019) and factor analysis(Risso et al., 2018). Existing implementations for inferring its parameters from data often struggle with the size of single cell datasets, which typically comprise thousands or millions of cells; at the same time, they do not take full advantage of the fact that zero and other small numbers are frequent in the data. These limitations have hampered uptake of the model, leaving room for statistically inferior approaches such as logarithm(-like) transformation. Results: We present a new R package for fitting the Gamma-Poisson distribution to data with the characteristics of modern single cell datasets more quickly and more accurately than existing methods. The software can work with data on disk without having to load them into RAM simultaneously. {\#}{\#}{\#} Competing Interest Statement The authors have declared no competing interest.},
author = {Ahlmann-Eltze, Constantin and Huber, Wolfgang},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Ahlmann-Eltze, Huber - 2020 - glmGamPoi Fitting Gamma-Poisson Generalized Linear Models on Single Cell Count Data.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Ahlmann-Eltze, Huber - 2020 - glmGamPoi Fitting Gamma-Poisson Generalized Linear Models on Single Cell Count Data(2).pdf:pdf},
journal = {Bioinformatics},
keywords = {negative binomial,single cell},
mendeley-tags = {negative binomial,single cell},
title = {{glmGamPoi: Fitting Gamma-Poisson Generalized Linear Models on Single Cell Count Data}},
url = {https://www.biorxiv.org/content/10.1101/2020.08.13.249623v1},
year = {2020}
}
@article{Wang2018e,
abstract = {Differential gene expression analysis is one of the significant efforts in single cell RNA sequencing (scRNAseq) analysis to discover the specific changes in expression levels of individual cell types. Since scRNAseq exhibits multimodality, large amounts of zero counts, and sparsity, it is different from the traditional bulk RNA sequencing (RNAseq) data. The new challenges of scRNAseq data promote the development of new methods for identifying differentially expressed (DE) genes. In this study, we proposed a new method, SigEMD, that combines a data imputation approach, a logistic regression model and a nonparametric method based on the Earth Mover's Distance, to precisely and efficiently identify DE genes in scRNAseq data. The regression model and data imputation are used to reduce the impact of large amounts of zero counts, and the nonparametric method is used to improve the sensitivity of detecting DE genes from multimodal scRNAseq data. By additionally employing gene interaction network information to adjust the final states of DE genes, we further reduce the false positives of calling DE genes. We used simulated datasets and real datasets to evaluate the detection accuracy of the proposed method and to compare its performance with those of other differential expression analysis methods. Results indicate that the proposed method has an overall powerful performance in terms of precision in detection, sensitivity, and specificity.},
author = {Wang, Tianyu and Nabavi, Sheida},
doi = {10.1016/j.ymeth.2018.04.017},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Methods/Wang, Nabavi - 2018 - SigEMD A powerful method for differential gene expression analysis in single-cell RNA sequencing data.pdf:pdf},
issn = {10959130},
journal = {Methods},
keywords = {Data imputation,Differential gene expression analysis,Multimodal data,Nonparametric models,Single-cell RNAseq,differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {February},
pages = {25--32},
publisher = {Elsevier},
title = {{SigEMD: A powerful method for differential gene expression analysis in single-cell RNA sequencing data}},
url = {https://doi.org/10.1016/j.ymeth.2018.04.017},
volume = {145},
year = {2018}
}
@article{Hsu2018,
author = {Hsu, Jonathan and Fulco, Charles and Cole, Mitchel and Canver, Matthew and Pellin, Danilo and Sher, Falak},
doi = {10.1038/s41592-018-0228-3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Hsu et al. - 2018 - CRISPR-SURF discovering regulatory elements by deconvolution of CRISPR tiling screen data.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Hsu et al. - 2018 - CRISPR-SURF discovering regulatory elements by deconvolution of CRISPR tiling screen data.pdf:pdf},
issn = {1548-7091},
journal = {Nature Methods},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
month = {dec},
number = {12},
pages = {990--992},
title = {{CRISPR-SURF: discovering regulatory elements by deconvolution of CRISPR tiling screen data}},
volume = {15},
year = {2018}
}
@article{Basu1977,
abstract = {Eliminating nuisance parameters from a model is universally recognized as a major problem of statistics. A surprisingly large number of elimination methods have been proposed by various writers on the topic. In this article we propose to critically review two such elimination methods. We shall be concerned with some particular cases of the marginalizing and the conditioning methods. The origin of these methods may be traced to the work of Sir Ronald A. Fisher. The contents of the marginalization and the conditionality arguments are then reexamined from the Bayesian point of view. This article should be regarded as a sequel to the author's three-part essay (Basu 1975) on statistical information and likelihood. {\textcopyright} 1977, Taylor {\&} Francis Group, LLC.},
author = {Basu, Debabrata},
doi = {10.1080/01621459.1977.10481002},
file = {::},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Ancillary and S-ancillary statistics,Marginalization and conditionality arguments,Specific and partial sufficiency,Unrelated parameters,nuisance parameters},
mendeley-tags = {nuisance parameters},
number = {358},
pages = {355--366},
title = {{On the elimination of nuisance parameters}},
volume = {72},
year = {1977}
}
@article{Imkeller2019,
abstract = {Pooled CRISPR screens are a powerful tool to probe genotype-phenotype relationships at genome-wide scale. They are based on a library of target-specific guide RNAs (gRNAs) that is applied to a pool of cells, with the aim to induce a single genetic perturbation in each cell. Detection of viability phenotypes depends on statistical comparison of the frequencies of these gRNAs before and after cell proliferation. Here, we report empirical and theoretical evidence for asymmetries in gRNA count ratios, and we show how failure to consider asymmetric null distribution of the data leads to loss of detection power. We present a biology-based, generative probabilistic model to show that the asymmetry is generated during the proliferation phase of the screen and that it is mainly driven by the distribution width of the gRNA library. Based on these observations we develop a statistical test that improves hit detection at reduced experiment size. The method is implemented in the open source package 'gscreend' (submission to Bioconductor pending).},
author = {Imkeller, Katharina and Ambrosi, Giulia and Boutros, Michael and Huber, Wolfgang},
doi = {10.1101/699348},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Imkeller et al. - 2019 - Modelling asymmetric count ratios in CRISPR screens to decrease experiment size and improve phenotype detection.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,Kathryn,Multiple testing},
mendeley-tags = {CRISPR,Kathryn,Multiple testing},
title = {{Modelling asymmetric count ratios in CRISPR screens to decrease experiment size and improve phenotype detection}},
url = {https://www.biorxiv.org/content/10.1101/699348v1},
year = {2019}
}
@article{Hu2018,
abstract = {The current paradigm of genomic studies of complex diseases is association and correlation analysis. Despite significant progress in dissecting the genetic architecture of complex diseases by genome-wide association studies (GWAS), the identified genetic variants by GWAS can only explain a small proportion of the heritability of complex diseases. A large fraction of genetic variants is still hidden. Association analysis has limited power to unravel mechanisms of complex diseases. It is time to shift the paradigm of genomic analysis from association analysis to causal inference. Causal inference is an essential component for the discovery of mechanism of diseases. This paper will review the major platforms of the genomic analysis in the past and discuss the perspectives of causal inference as a general framework of genomic analysis. In genomic data analysis, we usually consider four types of associations: association of discrete variables (DNA variation) with continuous variables (phenotypes and gene expressions), association of continuous variables (expressions, methylations, and imaging signals) with continuous variables (gene expressions, imaging signals, phenotypes, and physiological traits), association of discrete variables (DNA variation) with binary trait (disease status) and association of continuous variables (gene expressions, methylations, phenotypes, and imaging signals) with binary trait (disease status). In this paper, we will review algorithmic information theory as a general framework for causal discovery and the recent development of statistical methods for causal inference on discrete data, and discuss the possibility of extending the association analysis of discrete variable with disease to the causal analysis for discrete variable and disease.},
author = {Hu, Pengfei and Jiao, Rong and Jin, Li and Xiong, Momiao},
doi = {10.3389/fgene.2018.00238},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Frontiers in Genetics/Hu et al. - 2018 - Application of causal inference to genomic analysis Advances in methodology.pdf:pdf},
issn = {16648021},
journal = {Frontiers in Genetics},
keywords = {Additive noise models for discrete variables,Association analysis,CRISPR,Causal inference,Entropy,Genomic analysis,causality},
mendeley-tags = {CRISPR,causality},
number = {JUL},
title = {{Application of causal inference to genomic analysis: Advances in methodology}},
volume = {9},
year = {2018}
}
@article{Fulco2019a,
abstract = {Mammalian genomes harbor millions of noncoding elements called enhancers that quantitatively regulate gene expression, but it remains unclear which enhancers regulate which genes. Here we describe an experimental approach, based on CRISPR interference, RNA FISH, and flow cytometry (CRISPRi-FlowFISH), to perturb enhancers in the genome, and apply it to test {\textgreater}3,000 potential regulatory enhancer-gene connections across multiple genomic loci. A simple equation based on a mechanistic model for enhancer function performed remarkably well at predicting the complex patterns of regulatory connections we observe in our CRISPR dataset. This Activity-by-Contact (ABC) model involves multiplying measures of enhancer activity and enhancer-promoter 3D contacts, and can predict enhancer-gene connections in a given cell type based on chromatin state maps. Together, CRISPRi-FlowFISH and the ABC model provide a systematic approach to map and predict which enhancers regulate which genes, and will help to interpret the functions of the thousands of disease risk variants in the noncoding genome.},
author = {Fulco, Charles P and Nasser, Joseph and Jones, Thouis R and Munson, Glen and Bergman, Drew T and Subramanian, Vidya and Grossman, Sharon R and Anyoha, Rockwell and Patwardhan, Tejal A and Nguyen, Tung H and Kane, Michael and Doughty, Benjamin and Perez, Elizabeth M and Durand, Neva C and Stamenova, Elena K and Aiden, Erez Lieberman and Lander, Eric S and Engreitz, Jesse M},
doi = {10.1101/529990},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Fulco et al. - 2019 - Activity-by-Contact model of enhancer specificity from thousands of CRISPR perturbations (CRISPRi FlowFISH).pdf:pdf},
issn = {1546-1718},
journal = {Nature Genetics},
keywords = {CRISPR,gene-enhancer,genetics},
mendeley-tags = {CRISPR,gene-enhancer,genetics},
number = {December},
pages = {1664--1669},
publisher = {Springer US},
title = {{Activity-by-Contact model of enhancer specificity from thousands of CRISPR perturbations (CRISPRi FlowFISH)}},
url = {https://www.biorxiv.org/content/10.1101/529990v1},
volume = {51},
year = {2019}
}
@article{Fiaux2019,
abstract = {CRISPR regulatory screens are a powerful technology for discovering sequences that control gene expression, however, a lack of analysis methods limits their effectiveness. In addition, method performance is difficult to assess due to an absence of datasets where the identities of true regulatory sequences are known. To address these problems, we developed an analysis method, RELICS, and a simulation framework, CRSsim, for CRISPR regulatory screens. RELICS detects regulatory elements by modeling guide counts across multiple pools representing different conditions or expression levels and CRSsim generates realistic datasets where the ground truth is known. We used CRSsim to generate 4320 datasets representing 144 scenarios with different characteristics. We compared analysis methods on these datasets and found that RELICS has the best performance under most conditions. We applied RELICS to 8 published datasets for 15 genes and identify previously-validated elements as well as multiple putative elements that were missed by other methods.},
author = {Fiaux, Patrick C and Chen, Hsiuyi and Graham, McVicker},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Fiaux, Chen, Graham - 2019 - Discovering functional sequences with RELICS, an analysis method for CRISPR regulatory screens.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
title = {{Discovering functional sequences with RELICS, an analysis method for CRISPR regulatory screens}},
year = {2019}
}
@book{Efron2018,
author = {Efron, Bradley},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Efron - 2018 - Exponential Families in Theory and Practice.pdf:pdf},
keywords = {exponential families,generalized linear models},
mendeley-tags = {exponential families,generalized linear models},
title = {{Exponential Families in Theory and Practice}},
url = {http://statweb.stanford.edu/{~}ckirby/brad/STATS305B{\_}Part-1.pdf},
year = {2018}
}
@misc{Zhou2019,
abstract = {The vast majority of the mammalian genome consists of DNAs that do not encode protein sequences. For decades, the functional potentials of these noncoding DNAs have remained poorly understood. Large-scale studies, such as the Encyclopedia of DNA Elements project and genome-wide association studies, have suggested that the noncoding genome functions in a wide variety of biological and physiological process [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}1{\textless}/a{\textgreater}]. However, it has been technically challenging to attribute functions to a plethora of noncoding elements in any given biological context, largely due to a lack of convenient high-throughput approaches.
The recently developed clustered regularly interspaced short palindromic repeats (CRISPR)-Cas system enables efficient and precise perturbation of DNA sequences in the genome, thus offering an unprecedented opportunity to associate functions or phenotypes with genetic elements [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}2{\textless}/a{\textgreater}]. Directed by a single-guide RNA (sgRNA) with a region complementary to the target DNA, Cas nuclease cleaves the genomic DNA at the target locus to generate a double-strand DNA break (DSB), which is subsequently repaired through an internal error-prone nonhomologous end-joining (NHEJ) pathway, resulting in an insertion or deletion (indel) that often disrupts gene function [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}3{\textless}/a{\textgreater}]. The CRISPR-Cas system has been further engineered to regulate gene expression at will through the fusion of the catalytically inactive Cas9 (dCas9) with transcriptional activators, repressors or other effectors, enabling transcriptional activation (CRISPR activation, CRISPRa), inhibition (CRISPR interference, CRISPRi) or epigenetic modifications [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}3{\textless}/a{\textgreater}].
Owing to its programmability and multiplexability, the CRISPR-Cas system is especially potent in high-throughput functional genomics. To achieve this, sgRNAs are designed {\textless}em{\textgreater}in silico{\textless}/em{\textgreater} and synthesized as a pool before being cloned into lentiviral vectors to generate a library of viruses for target cell transduction. After phenotypic selection, such as drug resistance/sensitivity or fluorescence-activated cell sorting, candidate genes responsible for the functions of interests are revealed through next-generation sequencing (NGS) analysis of sgRNA barcodes from enriched or depleted cell populations [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}4{\textless}/a{\textgreater}].
Despite the power of pooled CRISPR screening in the dissection of key genes in a variety of biological processes, the majority of such screens hitherto have mainly targeted protein-coding genes. This is because the small indels ({\textless}10 bp) created by NHEJ are unlikely to produce loss-of-function phenotypes on the noncoding elements. Recently, endeavors have been made to probe the noncoding regions in mammalian genome by exploiting customized CRISPR-based screens.
As much as 76{\%} of genomic DNA is transcribed into RNAs, while less than 2{\%} encodes proteins [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}5{\textless}/a{\textgreater}]. Long noncoding RNAs (lncRNAs), which are at least 200 nucleotides in length, are the major subsets of the human transcriptome [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}5{\textless}/a{\textgreater}]. The first high-throughput method to identify functional lncRNAs is through a specially designed CRISPR approach that employs paired gRNAs (pgRNAs) to produce genomic deletions (Fig. {\textless}a class="link link-reveal link-table xref-fig"{\textgreater}1a{\textless}/a{\textgreater}). A pgRNA library comprising 12 472 gRNA pairs specific for 671 human lncRNAs was assembled, and the screening identified 51 lncRNAs that modulate tumor cell growth [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}6{\textless}/a{\textgreater}]. Alternatively, CRISPRi and CRISPRa have been employed to investigate functional lncRNAs by perturbing lncRNA transcription in two opposite directions (Fig. {\textless}a class="link link-reveal link-table xref-fig"{\textgreater}1b{\textless}/a{\textgreater}). Genome-scale CRISPRi screens were performed in seven different cell lines, using an sgRNA library targeting the transcriptional start site (TSS) of 16 401 lncRNAs. This assay revealed that ∼500 lncRNA loci are important for cell growth [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}7{\textless}/a{\textgreater}]. Intriguingly, despite more than 1300 lncRNA genes being expressed in all seven cell lines tested, none of them was identified in all screens, suggesting that lncRNAs exert distinct functions in diverse cellular contexts. Moreover, Joung {\textless}em{\textgreater}et al.{\textless}/em{\textgreater} performed a CRISPRa screen to globally map lncRNA loci relevant to drug resistance. By targeting the TSS of more than 10 000 lncRNA loci, 11 were identified whose overexpression conferred cell resistance to BRAF inhibitors [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}8{\textless}/a{\textgreater}].
Although lncRNA functional screening at a genome-wide scale could be achieved, the CRISPRi and CRISPRa approaches have limitations, mainly owing to their insu

{\textless}p{\textgreater}-Abstract Truncated-{\textless}/p{\textgreater}},
author = {Zhou, Zhuo and Wei, Wensheng},
booktitle = {National Science Review},
doi = {10.1093/nsr/nwy138},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/National Science Review/Zhou, Wei - 2019 - Interrogating the noncoding genome in a high-throughput fashion.pdf:pdf},
issn = {2053714X},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
month = {may},
number = {3},
pages = {397--399},
publisher = {Oxford University Press},
title = {{Interrogating the noncoding genome in a high-throughput fashion}},
volume = {6},
year = {2019}
}
@article{Lazzarotto2020,
author = {Lazzarotto, Cicera R and Malinin, Nikolay L and Li, Yichao and Zhang, Ruochi and Yang, Yang and Lee, Gahyun and Cowley, Eleanor and He, Yanghua and Lan, Xin and Jividen, Kasey and Katta, Varun and Kolmakova, Natalia G and Petersen, Christopher T and Qi, Qian and Strelcov, Evgheni and Maragh, Samantha and Krenciute, Giedre and Ma, Jian and Cheng, Yong and Tsai, Shengdar Q},
doi = {10.1038/s41587-020-0555-7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Lazzarotto et al. - 2020 - CHANGE-seq reveals genetic and epigenetic effects on CRISPR – Cas9 genome-wide activity.pdf:pdf},
issn = {1546-1696},
journal = {Nature Biotechnology},
keywords = {CRISPR,to-read},
mendeley-tags = {CRISPR,to-read},
publisher = {Springer US},
title = {{CHANGE-seq reveals genetic and epigenetic effects on CRISPR – Cas9 genome-wide activity}},
url = {http://dx.doi.org/10.1038/s41587-020-0555-7},
year = {2020}
}
@article{Fuchs1982,
abstract = {In many studies the values of one or more variables are missing for subsets of the original sample. This article focuses on the problem of obtaining maximum likelihood estimates (MLE) for the parameters of log-linear models under this type of incomplete data. The appropriate systems of equations are presented and the expectation-maximization (EM) algorithm (Dempster, Laird, and Rubin 1977) is suggested as one of the possible methods for solving them. The algorithm has certain advantages but other alternatives may be computationally more effective. Tests of fit for log-linear models in the presence of incomplete data are considered. The data from the Protective Services Project for Older Persons (Blenkner, Bloom, and Nielsen 1971; Blenkner, Bloom, and Weber 1974) are used to illustrate the procedures discussed in the article. {\textcopyright} 1982 Taylor {\&} Francis Group, LLC.},
author = {Fuchs, Camil},
doi = {10.1080/01621459.1982.10477795},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Fuchs - 1982 - Maximum likelihood estimation and model selection in contingency tables with missing data.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Contingency tables,EM algorithm,Maximum likelihood estimation,Missing data,Nested models,em algorithm,missing data},
mendeley-tags = {em algorithm,missing data},
number = {378},
pages = {270--278},
title = {{Maximum likelihood estimation and model selection in contingency tables with missing data}},
volume = {77},
year = {1982}
}
@article{Hart2015,
abstract = {Summary The ability to perturb genes in human cells is crucial for elucidating gene function and holds great potential for finding therapeutic targets for diseases such as cancer. To extend the catalog of human core and context-dependent fitness genes, we have developed a high-complexity second-generation genome-scale CRISPR-Cas9 gRNA library and applied it to fitness screens in five human cell lines. Using an improved Bayesian analytical approach, we consistently discover 5-fold more fitness genes than were previously observed. We present a list of 1,580 human core fitness genes and describe their general properties. Moreover, we demonstrate that context-dependent fitness genes accurately recapitulate pathway-specific genetic vulnerabilities induced by known oncogenes and reveal cell-type-specific dependencies for specific receptor tyrosine kinases, even in oncogenic KRAS backgrounds. Thus, rigorous identification of human cell line fitness genes using a high-complexity CRISPR-Cas9 library affords a high-resolution view of the genetic vulnerabilities of a cell.},
author = {Hart, Traver and Chandrashekhar, Megha and Aregger, Michael and Steinhart, Zachary and Brown, Kevin R. and MacLeod, Graham and Mis, Monika and Zimmermann, Michal and Fradet-Turcotte, Amelie and Sun, Song and Mero, Patricia and Dirks, Peter and Sidhu, Sachdev and Roth, Frederick P. and Rissland, Olivia S. and Durocher, Daniel and Angers, Stephane and Moffat, Jason},
doi = {10.1016/j.cell.2015.11.015},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Hart et al. - 2015 - High-Resolution CRISPR Screens Reveal Fitness Genes and Genotype-Specific Cancer Liabilities.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {6},
pages = {1515--1526},
pmid = {26627737},
publisher = {Elsevier Inc.},
title = {{High-Resolution CRISPR Screens Reveal Fitness Genes and Genotype-Specific Cancer Liabilities}},
url = {http://dx.doi.org/10.1016/j.cell.2015.11.015},
volume = {163},
year = {2015}
}
@article{Peets2019,
abstract = {Genetic screens based on CRISPR/Cas technology are a powerful tool for understanding cellular phenotypes. However, the coverage and replicate requirements result in large experiment sizes, which are limiting when samples are scarce, or the protocols are expensive and laborious. Here, we present an approach to reduce the scale of genome-wide perturbation screens up to fivefold without sacrificing performance. To do so, we deliver two randomly paired gRNAs into each cell, and rely on recent advances in gRNA design, as well as availability of gRNA effect measurements, to reduce the number of gRNAs per gene. We designed a human genome-wide library that has effective size of 30,000 constructs, yet targets each gene with three gRNAs. Our minimized double guide RNA library gives similar results to a standard single gRNA one, but using substantially fewer cells. We demonstrate that genome-wide screens can be optimized in a demanding model of induced pluripotent stem cells, reducing reagent cost 70{\%} per replicate compared to conventional approach, while retaining high performance. The screen design and the reduction in scale it provides will enable functional genomics experiments across many possible combinations of environments and genetic backgrounds, as well as in hard to obtain and culture primary cells.},
author = {Peets, Elin Madli and Crepaldi, Luca and Zhou, Yan and Allen, Felicity and Elmentaite, Rasa and Noell, Guillaume and Turner, Gemma and Parts, Leopold and Campus, Wellcome Genome},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Peets et al. - 2019 - Minimized double guide RNA libraries enable scale-limited CRISPR Cas9 screens.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,gene-enhancer},
mendeley-tags = {CRISPR,gene-enhancer},
title = {{Minimized double guide RNA libraries enable scale-limited CRISPR / Cas9 screens}},
year = {2019}
}
@article{Du2017,
abstract = {We describe a combinatorial CRISPR interference (CRISPRi) screening platform for mapping genetic interactions in mammalian cells. We targeted 107 chromatin-regulation factors in human cells with pools of either single or double single guide RNAs (sgRNAs) to downregulate individual genes or gene pairs, respectively. Relative enrichment analysis of individual sgRNAs or sgRNA pairs allowed for quantitative characterization of genetic interactions, and comparison with protein-protein-interaction data revealed a functional map of chromatin regulation.},
author = {Du, Dan and Roguev, Assen and Gordon, David E. and Chen, Meng and Chen, Si Han and Shales, Michael and Shen, John Paul and Ideker, Trey and Mali, Prashant and Qi, Lei S. and Krogan, Nevan J.},
doi = {10.1038/nmeth.4286},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Du et al. - 2017 - Genetic interaction mapping in mammalian cells using CRISPR interference.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {CRISPR,interactions},
mendeley-tags = {CRISPR,interactions},
number = {6},
pages = {577--580},
title = {{Genetic interaction mapping in mammalian cells using CRISPR interference}},
volume = {14},
year = {2017}
}
@article{Hart2014,
abstract = {Technological advancement has opened the door to systematic genetics in mammalian cells. Genome-scale loss-of-function screens can assay fitness defects induced by partial gene knockdown, using RNA interference, or complete gene knockout, using new CRISPR techniques. These screens can reveal the basic blueprint required for cellular proliferation. Moreover, comparing healthy to cancerous tissue can uncover genes that are essential only in the tumor; these genes are targets for the development of specific anticancer therapies. Unfortunately, progress in this field has been hampered by off-target effects of perturbation reagents and poorly quantified error rates in large-scale screens. To improve the quality of information derived from these screens, and to provide a framework for understanding the capabilities and limitations of CRISPR technology, we derive gold-standard reference sets of essential and nonessential genes, and provide a Bayesian classifier of gene essentiality that outperforms current methods on both RNAi and CRISPR screens. Our results indicate that CRISPR technology is more sensitive than RNAi and that both techniques have nontrivial false discovery rates that can be mitigated by rigorous analytical methods.},
author = {Hart, Traver and Brown, Kevin R and Sircoulomb, Fabrice and Rottapel, Robert and Moffat, Jason},
doi = {10.15252/msb.20145216},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Molecular Systems Biology/Hart et al. - 2014 - Measuring error rates in genomic perturbation screens gold standards for human functional genomics.pdf:pdf},
issn = {1744-4292},
journal = {Molecular Systems Biology},
keywords = {15252,20145216,CRISPR,Kathryn,cancer,chromatin,crispr,doi 10,epigenetics,essential genes,functional genomics,genomics,msb,received 20 february 2014,resources,revised 10 april,rnai,shrna,subject categories methods},
mendeley-tags = {CRISPR,Kathryn},
number = {7},
pages = {733},
title = {{Measuring error rates in genomic perturbation screens: gold standards for human functional genomics}},
volume = {10},
year = {2014}
}
@article{Cong2013,
abstract = {Functional elucidation of causal genetic variants and elements requires precise genome editing technologies. The type II prokaryotic CRISPR (clustered regularly interspaced short palindromic repeats)/Cas adaptive immune system has been shown to facilitate RNA-guided site-specific DNA cleavage. We engineered two different type II CRISPR/Cas systems and demonstrate that Cas9 nucleases can be directed by short RNAs to induce precise cleavage at endogenous genomic loci in human and mouse cells. Cas9 can also be converted into a nicking enzyme to facilitate homology-directed repair with minimal mutagenic activity. Lastly, multiple guide sequences can be encoded into a single CRISPR array to enable simultaneous editing of several sites within the mammalian genome, demonstrating easy programmability and wide applicability of the RNA-guided nuclease technology.},
author = {Cong, Le and Ran, F. Ann and Cox, David and Lin, Shuailiang and Barretto, Robert and Habib, Naomi and Hsu, Patrick D. and Wu, Xuebing and Jiang, Wenyan and Marraffini, Luciano A. and Zhang, Feng},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Cong et al. - 2013 - Multiplex Genome Engineering Using CRISPRCas Systems.pdf:pdf},
journal = {Science},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
pages = {819--823},
title = {{Multiplex Genome Engineering Using CRISPR/Cas Systems}},
volume = {339},
year = {2013}
}
@article{Ibrahim1992,
abstract = {This article examines incomplete data for the class of generalized linear models, in which incompleteness is due to partially missing covariates on some observations. Under the assumption that the missing data are missing at random, it is shown that the E step of the EM algorithm for any generalized linear model can be expressed as a weighted complete data log-likelihood when the unobserved covariates are assumed to come from a discrete distribution with finite range. Expressing the E step in this manner allows for a straightforward maximization in the M step, thus leading to maximum likelihood estimates (MLE's) for the parameters. Asymptotic variances of the MLE's are also derived, and results are illustrated with two examples.},
author = {Ibrahim, Joseph G.},
doi = {10.1111/j.1467-842X.1992.tb01062.x},
file = {::},
issn = {1467842X},
journal = {Journal of the American Statistical Association},
keywords = {EM algorithm,Gaussian quadrature,em algorithm,generalized linear model,incomplete data,statistics},
mendeley-tags = {em algorithm,statistics},
number = {411},
pages = {765--769},
title = {{Incomplete Data in Generalized Linear Models}},
volume = {85},
year = {1990}
}
@article{Doench2018,
abstract = {The rapid development of CRISPR-based gene manipulation has enabled various approaches for high-throughput functional genomics. This Review guides users through the practicalities of CRISPR-based functional genomics screens, including study design options, best-practice approaches, pitfalls to avoid and data analysis strategies.},
author = {Doench, John G.},
doi = {10.1038/nrg.2017.97},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Reviews Genetics/Doench - 2018 - Am I ready for CRISPR A user's guide to genetic screens.pdf:pdf},
issn = {14710064},
journal = {Nature Reviews Genetics},
keywords = {CRISPR,Kathryn,gene-enhancer,genetics},
mendeley-tags = {CRISPR,Kathryn,gene-enhancer,genetics},
number = {2},
pages = {67--80},
publisher = {Nature Publishing Group},
title = {{Am I ready for CRISPR? A user's guide to genetic screens}},
url = {http://dx.doi.org/10.1038/nrg.2017.97},
volume = {19},
year = {2018}
}
@article{Mccarty2020,
author = {Mccarty, Nicholas S and Graham, Alicia E and Studen{\'{a}}, Lucie and Ledesma-amaro, Rodrigo},
doi = {10.1038/s41467-020-15053-x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Mccarty et al. - 2020 - Multiplexed CRISPR technologies for gene editing.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
publisher = {Springer US},
title = {{Multiplexed CRISPR technologies for gene editing}},
url = {http://dx.doi.org/10.1038/s41467-020-15053-x},
volume = {11},
year = {2020}
}
@article{Townes2019,
abstract = {Single-cell RNA-Seq (scRNA-Seq) profiles gene expression of individual cells. Recent scRNA-Seq datasets have incorporated unique molecular identifiers (UMIs). Using negative controls, we show UMI counts follow multinomial sampling with no zero inflation. Current normalization procedures such as log of counts per million and feature selection by highly variable genes produce false variability in dimension reduction. We propose simple multinomial methods, including generalized principal component analysis (GLM-PCA) for non-normal distributions, and feature selection using deviance. These methods outperform the current practice in a downstream clustering assessment using ground truth datasets.},
author = {Townes, F. William and Hicks, Stephanie C. and Aryee, Martin J. and Irizarry, Rafael A.},
doi = {10.1186/s13059-019-1861-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Townes et al. - 2019 - Feature selection and dimension reduction for single-cell RNA-Seq based on a multinomial model.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Townes et al. - 2019 - Feature selection and dimension reduction for single-cell RNA-Seq based on a multinomial model.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Dimension reduction,GLM-PCA,Gene expression,Principal component analysis,RNA-Seq,Single cell,Variable genes,single cell},
mendeley-tags = {single cell},
number = {1},
pages = {1--16},
publisher = {Genome Biology},
title = {{Feature selection and dimension reduction for single-cell RNA-Seq based on a multinomial model}},
volume = {20},
year = {2019}
}
@article{Little1985,
author = {Little, Roderick J . A . and Schluchter, Mark D .},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Little, Schluchter - 1985 - Maximum Likelihood Estimation for Mixed Continuous and Categorical Data with Missing Values Published by Ox.pdf:pdf},
journal = {Biometrika},
keywords = {em algorithm,missing data},
mendeley-tags = {em algorithm,missing data},
number = {3},
pages = {497--512},
title = {{Maximum Likelihood Estimation for Mixed Continuous and Categorical Data with Missing Values Published by : Oxford University Press on behalf of Biometrika Trust Stable URL : ht}},
volume = {72},
year = {1985}
}
@article{Wang2014,
abstract = {The bacterial clustered regularly interspaced short palindromic repeats (CRISPR)-Cas9 system for genome editing has greatly expanded the toolbox for mammalian genetics, enabling the rapid generation of isogenic cell lines and mice with modified alleles. Here, we describe a pooled, loss-of-function genetic screening approach suitable for both positive and negative selection that uses a genome-scale lentiviral single-guide RNA (sgRNA) library. sgRNA expression cassettes were stably integrated into the genome, which enabled a complex mutant pool to be tracked by massively parallel sequencing. We used a library containing 73,000 sgRNAs to generate knockout collections and performed screens in two human cell lines. A screen for resistance to the nucleotide analog 6-thioguanine identified all expected members of the DNA mismatch repair pathway, whereas another for the DNA topoisomerase II (TOP2A) poison etoposide identified TOP2A, as expected, and also cyclin-dependent kinase 6, CDK6. A negative selection screen for essential genes identified numerous gene sets corresponding to fundamental processes. Last, we show that sgRNA efficiency is associated with specific sequence motifs, enabling the prediction of more effective sgRNAs. Collectively, these results establish Cas9/sgRNA screens as a powerful tool for systematic genetic analysis in mammalian cells.},
author = {Wang, Tim and Wei, Jenny J. and Sabatini, David M. and Lander, Eric S.},
doi = {10.1136/bmjspcare-2011-000063},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Wang et al. - 2014 - Genetic screens in human cells using the CRISPR-Cas9 system.pdf:pdf},
issn = {20454368},
journal = {Science},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
pages = {80--84},
pmid = {24336569},
title = {{Genetic screens in human cells using the CRISPR-Cas9 system}},
volume = {343},
year = {2014}
}
@article{Hafemeister2019,
abstract = {Single-cell RNA-seq (scRNA-seq) data exhibits significant cell-to-cell variation due to technical factors, including the number of molecules detected in each cell, which can confound biological heterogeneity with technical effects. To address this, we present a modeling framework for the normalization and variance stabilization of molecular count data from scRNA-seq experiments. We propose that the Pearson residuals from "regularized negative binomial regression," where cellular sequencing depth is utilized as a covariate in a generalized linear model, successfully remove the influence of technical characteristics from downstream analyses while preserving biological heterogeneity. Importantly, we show that an unconstrained negative binomial model may overfit scRNA-seq data, and overcome this by pooling information across genes with similar abundances to obtain stable parameter estimates. Our procedure omits the need for heuristic steps including pseudocount addition or log-transformation and improves common downstream analytical tasks such as variable gene selection, dimensional reduction, and differential expression. Our approach can be applied to any UMI-based scRNA-seq dataset and is freely available as part of the R package sctransform, with a direct interface to our single-cell toolkit Seurat.},
author = {Hafemeister, Christoph and Satija, Rahul},
doi = {10.1186/s13059-019-1874-1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Hafemeister, Satija - 2019 - Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial re.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Hafemeister, Satija - 2019 - Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial(2).pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Kathryn,Normalization,Single-cell RNA-seq,single cell},
mendeley-tags = {Kathryn,single cell},
number = {1},
pages = {1--15},
publisher = {Genome Biology},
title = {{Normalization and variance stabilization of single-cell RNA-seq data using regularized negative binomial regression}},
volume = {20},
year = {2019}
}
@article{Wang2018d,
abstract = {Single-cell RNA sequencing (scRNA-seq) enables the quantifica tion of each gene's expression distribution across cells, thu allowing the assessment of the dispersion, nonzero fraction, and other aspects of its distribution beyond the mean. These sta tistical characterizations of the gene expression distribution are critical for understanding expression variation and for selecting marker genes for population heterogeneity. However, scRNA-seq data are noisy, with each cell typically sequenced at low cov erage, thus making it difficult to infer properties of the gene expression distribution from raw counts. Based on a reexamina tion of nine public datasets, we propose a simple technical noise model for scRNA-seq data with unique molecular identifiers (UMI) We develop deconvolution of single-cell expression distribution (DESCEND), a method that deconvolves the true cross-cell gene expression distribution from observed scRNA-seq counts, lead ing to improved estimates of properties of the distribution such as dispersion and nonzero fraction. DESCEND can adjust for cell level covariates such as cell size, cell cycle, and batch effects DESCEND's noise model and estimation accuracy are further eval uated through comparisons to RNA FISH data, through data split ting and simulations and through its effectiveness in removing known batch effects. We demonstrate how DESCEND can clarify and improve downstream analyses such as finding differentially expressed genes, identifying cell types, and selecting differentia tion markers.},
author = {Wang, Jingshu and Huang, Mo and Torre, Eduardo and Dueck, Hannah and Shaffer, Sydney and Murray, John and Raj, Arjun and Li, Mingyao and Zhang, Nancy R.},
doi = {10.1073/pnas.1721085115},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/Wang et al. - 2018 - Gene expression distribution deconvolution in single-cell RNA sequencing.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Differential expression,Gini coefficient,Highly variable gene,RNA sequencing,Single-cell transcriptomics,single cell},
mendeley-tags = {single cell},
number = {28},
pages = {E6437--E6446},
pmid = {29946020},
title = {{Gene expression distribution deconvolution in single-cell RNA sequencing}},
volume = {115},
year = {2018}
}
@article{Sarkar2020,
abstract = {How to model and analyze scRNA-seq data has been the subject of considerable confusion and debate. The high proportion of zero counts in a typical scRNA-seq data matrix has garnered particular attention, and lead to widespread but inconsistent use of terminology such as "dropout" and "missing data." Here, we argue that much of this terminology is unhelpful and confusing, and outline simple ways of thinking about models for scRNA-seq data that can help avoid this confusion. The key ideas are: (1) observed scRNA-seq counts reflect both the actual expression level of each gene in each cell and the measurement process, and it is important for models to explicitly distinguish contributions from these two distinct factors; and (2) the measurement process can be adequately described by a simple Poisson model, a claim for which we provide both theoretical and empirical support. We show how these ideas lead to a simple, flexible statistical framework that encompasses a number of commonly used models and analysis methods, and how this framework makes explicit their different assumptions and helps interpret their results. We also illustrate how explicitly separating models for expression and measurement can help address questions of biological interest, such as whether mRNA expression levels are multi-modal among cells.},
author = {Sarkar, Abhishek and Stephens, Matthew},
doi = {10.1101/2020.04.07.030007},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Sarkar, Stephens - 2020 - Separating measurement and expression models clarifies confusion in single cell RNA-seq analysis.pdf:pdf},
journal = {bioRxiv},
keywords = {single cell},
mendeley-tags = {single cell},
title = {{Separating measurement and expression models clarifies confusion in single cell RNA-seq analysis}},
url = {https://doi.org/10.1101/2020.04.07.030007},
year = {2020}
}
@article{Ma2015,
abstract = {West Nile virus (WNV) causes an acute neurological infection attended by massive neuronal cell death. However, the mechanism(s) behind the virusinduced cell death is poorly understood. Using a library containing 77,406 sgRNAs targeting 20,121 genes, we performed a genome-wide screen followed by a second screen with a sub-library. Among the genes identified, seven genes, EMC2, EMC3, SEL1L, DERL2, UBE2G2, UBE2J1, and HRD1, stood out as having the strongest phenotype, whose knockout conferred strong protection against WNVinduced cell death with two different WNV strains and in three cell lines. Interestingly, knockout of these genes did not block WNV replication. Thus, these appear to be essential genes that link WNV replication to downstream cell death pathway(s). In addition, the fact that all of these genes belong to the ER-associated protein degradation (ERAD) pathway suggests that this might be the primary driver of WNV-induced cell death.},
author = {Ma, Hongming and Dang, Ying and Wu, Yonggan and Jia, Gengxiang and Anaya, Edgar and Zhang, Junli and Abraham, Sojan and Choi, Jang Gi and Shi, Guojun and Qi, Ling and Manjunath, N. and Wu, Haoquan},
doi = {10.1016/j.celrep.2015.06.049},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell Reports/Ma et al. - 2015 - A CRISPR-based screen identifies genes essential for west-nile-virus-induced cell death.pdf:pdf},
issn = {22111247},
journal = {Cell Reports},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {4},
pages = {673--683},
publisher = {The Authors},
title = {{A CRISPR-based screen identifies genes essential for west-nile-virus-induced cell death}},
url = {http://dx.doi.org/10.1016/j.celrep.2015.06.049},
volume = {12},
year = {2015}
}
@article{Wang2017a,
abstract = {Learning directed acyclic graphs using both observational and interventional data is now a fundamentally important problem due to recent technological developments in genomics that generate such single-cell gene expression data at a very large scale. In order to utilize this data for learning gene regulatory networks, efficient and reliable causal inference algorithms are needed that can make use of both observational and interventional data. In this paper, we present two algorithms of this type and prove that both are consistent under the faithfulness assumption. These algorithms are interventional adaptations of the Greedy SP algorithm and are the first algorithms using both observational and interventional data with consistency guarantees. Moreover, these algorithms have the advantage that they are nonparametric, which makes them useful also for analyzing non-Gaussian data. In this paper, we present these two algorithms and their consistency guarantees, and we analyze their performance on simulated data, protein signaling data, and single-cell gene expression data.},
archivePrefix = {arXiv},
arxivId = {1705.10220},
author = {Wang, Yuhao and Solus, Liam and Yang, Karren Dai and Uhler, Caroline},
eprint = {1705.10220},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Advances in Neural Information Processing Systems/Wang et al. - 2017 - Permutation-based causal inference algorithms with interventions.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {CRISPR,causality},
mendeley-tags = {CRISPR,causality},
number = {Nips 2017},
pages = {5823--5832},
title = {{Permutation-based causal inference algorithms with interventions}},
volume = {2017-Decem},
year = {2017}
}
@article{Norman2019,
abstract = {How cellular and organismal complexity emerges from combinatorial expression of genes is a central question in biology. High-content phenotyping approaches such as Perturb-seq (single-cell RNA-sequencing pooled CRISPR screens) present an opportunity for exploring such genetic interactions (GIs) at scale. Here, we present an analytical framework for interpreting high-dimensional landscapes of cell states (manifolds) constructed from transcriptional phenotypes. We applied this approach to Perturb-seq profiling of strong GIs mined from a growth-based, gain-of-function GI map. Exploration of this manifold enabled ordering of regulatory pathways, principled classification of GIs (e.g., identifying suppressors), and mechanistic elucidation of synergistic interactions, including an unexpected synergy between CBL and CNN1 driving erythroid differentiation. Finally, we applied recommender system machine learning to predict interactions, facilitating exploration of vastly larger GI manifolds.},
author = {Norman, Thomas M. and Horlbeck, Max A. and Replogle, Joseph M. and Ge, Alex Y. and Xu, Albert and Jost, Marco and Gilbert, Luke A. and Weissman, Jonathan S.},
doi = {10.1126/science.aax4438},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Norman et al. - 2019 - Exploring genetic interaction manifolds constructed from rich single-cell phenotypes.pdf:pdf},
issn = {0036-8075},
journal = {Science},
keywords = {CRISPR,genetics,to-read},
mendeley-tags = {CRISPR,genetics,to-read},
number = {6455},
pages = {786--793},
title = {{Exploring genetic interaction manifolds constructed from rich single-cell phenotypes}},
volume = {365},
year = {2019}
}
@article{Li2015,
abstract = {High-throughput CRISPR screens have shown great promise in functional genomics. We present MAGeCK-VISPR, a comprehensive quality control (QC), analysis, and visualization workflow for CRISPR screens. MAGeCK-VISPR defines a set of QC measures to assess the quality of an experiment, and includes a maximum-likelihood algorithm to call essential genes simultaneously under multiple conditions. The algorithm uses a generalized linear model to deconvolute different effects, and employs expectation-maximization to iteratively estimate sgRNA knockout efficiency and gene essentiality. MAGeCK-VISPR also includes VISPR, a framework for the interactive visualization and exploration of QC and analysis results.},
author = {Li, Wei and K{\"{o}}ster, Johannes and Xu, Han and Chen, Chen Hao and Xiao, Tengfei and Liu, Jun S. and Brown, Myles and Liu, X. Shirley},
doi = {10.1186/s13059-015-0843-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Li et al. - 2015 - Quality control, modeling, and visualization of CRISPR screens with MAGeCK-VISPR.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {CRISPR,CRISPR/Cas9,D3,Data-driven documents,Expectation-Maximization,Kathryn,Maximum likelihood,Negative binomial,Quality contro,Screening,Visualization},
mendeley-tags = {CRISPR,Kathryn},
month = {dec},
number = {1},
pmid = {26673418},
publisher = {BioMed Central Ltd.},
title = {{Quality control, modeling, and visualization of CRISPR screens with MAGeCK-VISPR}},
volume = {16},
year = {2015}
}
@article{Aigner1973,
author = {Aigner, Dennis J.},
doi = {10.1016/0304-4076(73)90005-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Econometrics/Aigner - 1973 - Regression with a binary independent variable subject to errors of observation.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {error-in-variables},
mendeley-tags = {error-in-variables},
number = {1},
pages = {49--59},
title = {{Regression with a binary independent variable subject to errors of observation}},
volume = {1},
year = {1973}
}
@article{Tukey1980,
author = {Tukey, John W},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The American Statistician/Tukey - 1980 - We Need Both Exploratory and Confirmatory.pdf:pdf},
journal = {The American Statistician},
keywords = {adaptive data analysis,canonical,to-skim},
mendeley-tags = {adaptive data analysis,canonical,to-skim},
number = {1},
pages = {23--25},
title = {{We Need Both Exploratory and Confirmatory}},
volume = {34},
year = {1980}
}
@article{Schildknecht2016,
abstract = {Signal detection in functional magnetic resonance imaging (fMRI) inherently involves the problem of testing a large number of hypotheses. A popular strategy to address this multiplicity is the control of the false discovery rate (FDR). In this work we consider the case where prior knowledge is available to partition the set of all hypotheses into disjoint subsets or families, e. g., by a-priori knowledge on the functionality of certain regions of interest. If the proportion of true null hypotheses differs between families, this structural information can be used to increase statistical power. We propose a two-stage multiple test procedure which first excludes those families from the analysis for which there is no strong evidence for containing true alternatives. We show control of the family-wise error rate at this first stage of testing. Then, at the second stage, we proceed to test the hypotheses within each non-excluded family and obtain asymptotic control of the FDR within each family at this second stage. Our main mathematical result is that this two-stage strategy implies asymptotic control of the FDR with respect to all hypotheses. In simulations we demonstrate the increased power of this new procedure in comparison with established procedures in situations with highly unbalanced families. Finally, we apply the proposed method to simulated and to real fMRI data.},
author = {Schildknecht, Konstantin and Tabelow, Karsten and Dickhaus, Thorsten},
doi = {10.1371/journal.pone.0149016},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/PLoS ONE/Schildknecht, Tabelow, Dickhaus - 2016 - More specific signal detection in functional magnetic resonance imaging by false discovery rate.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
number = {2},
pages = {1--21},
title = {{More specific signal detection in functional magnetic resonance imaging by false discovery rate control for hierarchically structured systems of hypotheses}},
volume = {11},
year = {2016}
}
@article{MetV15,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25849665{\}}{\{}25849665{\}}},
author = {Moser, G and Lee, S H and Hayes, B J and Goddard, M E and Wray, N R and Visscher, P M},
journal = {PLoS Genetics},
keywords = {GWAS},
mendeley-tags = {GWAS},
month = {apr},
number = {4},
pages = {e1004969},
title = {{{\{}S{\}}imultaneous discovery, estimation and prediction analysis of complex traits using a bayesian mixture model}},
volume = {11},
year = {2015}
}
@article{PetR06,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/16862161{\}}{\{}16862161{\}}},
author = {Price, A L and Patterson, N J and Plenge, R M and Weinblatt, M E and Shadick, N A and Reich, D},
journal = {Nature Genetics},
keywords = {GWAS,canonical,population stratification,principal components},
mendeley-tags = {GWAS,canonical,population stratification,principal components},
number = {8},
pages = {904--909},
title = {{Principal components analysis corrects for stratification in genome-wide association studies}},
volume = {38},
year = {2006}
}
@article{S86,
author = {Simes, R. J.},
journal = {Biometrika},
keywords = {FWER,Multiple testing,canonical},
mendeley-tags = {FWER,Multiple testing,canonical},
number = {3},
pages = {751--754},
title = {{An improved Bonferroni procedure for multiple tests of significance}},
volume = {73},
year = {1986}
}
@article{Fan2020,
abstract = {Power and reproducibility are key to enabling refined scientific discoveries in contemporary big data applications with general high-dimensional nonlinear models. In this article, we provide theoretical foundations on the power and robustness for the model-X knockoffs procedure introduced recently in Cand{\`{e}}s, Fan, Janson and Lv in high-dimensional setting when the covariate distribution is characterized by Gaussian graphical model. We establish that under mild regularity conditions, the power of the oracle knockoffs procedure with known covariate distribution in high-dimensional linear models is asymptotically one as sample size goes to infinity. When moving away from the ideal case, we suggest the modified model-X knockoffs method called graphical nonlinear knockoffs (RANK) to accommodate the unknown covariate distribution. We provide theoretical justifications on the robustness of our modified procedure by showing that the false discovery rate (FDR) is asymptotically controlled at the target level and the power is asymptotically one with the estimated covariate distribution. To the best of our knowledge, this is the first formal theoretical result on the power for the knockoffs procedure. Simulation results demonstrate that compared to existing approaches, our method performs competitively in both FDR control and power. A real dataset is analyzed to further assess the performance of the suggested knockoffs procedure. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1709.00092},
author = {Fan, Yingying and Demirkaya, Emre and Li, Gaorong and Lv, Jinchi},
doi = {10.1080/01621459.2018.1546589},
eprint = {1709.00092},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Fan et al. - 2020 - RANK Large-Scale Inference With Graphical Nonlinear Knockoffs.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Big data,Graphical nonlinear knockoffs,High-dimensional nonlinear models,Large-scale inference and FDR,Power,Reproducibility,Robustness},
month = {jan},
number = {529},
pages = {362--379},
publisher = {American Statistical Association},
title = {{RANK: Large-Scale Inference With Graphical Nonlinear Knockoffs}},
volume = {115},
year = {2020}
}
@article{Xie2017,
abstract = {The study of enhancers has been hampered by the scarcity of methods to systematically quantify their endogenous activity. We develop Mosaic-seq to systematically perturb enhancers and measure their endogenous activities at single-cell resolution. Mosaic-seq uses a CRISPR barcoding system to jointly measure a cell's transcriptome and its sgRNA modulators, thus quantifying the effects of dCas9- KRAB-mediated enhancer repression in single cells. Applying Mosaic-seq to 71 constituent enhancers from 15 super-enhancers, our analysis of 51,448 sgRNA-induced transcriptomes finds that only a small number of constituents are major effectors of target gene expression. Binding of p300 and RNAPII are key features of these constituents. We determine two key parameters of enhancer activity in single cells: their penetrance in a population and their contribution to expression in these cells. Through combinatorial interrogation, we find that simultaneous repression of multiple weak constituents can alter super-enhancer activity in a manner greatly exceeding repression of individual constituents.},
author = {Xie, Shiqi and Duan, Jialei and Li, Boxun and Zhou, Pei and Hon, Gary C.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Molecular Cell/Xie et al. - 2017 - Multiplexed Engineering and Analysis of Combinatorial Enhancer Activity in Single Cells.pdf:pdf},
journal = {Molecular Cell},
keywords = {CRISPR,Kathryn,gene-enhancer,genetics},
mendeley-tags = {CRISPR,Kathryn,gene-enhancer,genetics},
pages = {285--299},
title = {{Multiplexed Engineering and Analysis of Combinatorial Enhancer Activity in Single Cells}},
volume = {66},
year = {2017}
}
@article{Dobriban2018a,
author = {Dobriban, Edgar and Wager, Stefan},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Dobriban, Wager - 2018 - High-dimensional asymptotics of prediction ridge regression and classification.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {1},
pages = {247--279},
title = {{High-dimensional asymptotics of prediction: ridge regression and classification}},
volume = {46},
year = {2018}
}
@article{SetY11,
author = {Siegmund, David O. and Zhang, Nancy R. and Yakir, Benjamin},
journal = {Biometrika},
keywords = {FDR,spatial data},
mendeley-tags = {FDR,spatial data},
number = {4},
pages = {979--985},
publisher = {Biometrika Trust},
title = {{False discovery rate for scanning statistics}},
volume = {98},
year = {2011}
}
@article{ZS14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/24531419{\}}{\{}24531419{\}}},
author = {Zhou, X and Stephens, M},
journal = {Nature Methods},
month = {apr},
number = {4},
pages = {407--409},
title = {{{\{}E{\}}fficient multivariate linear mixed model algorithms for genome-wide association studies}},
volume = {11},
year = {2014}
}
@book{KR90,
address = {New York},
annote = {An introduction to cluster analysis,
A Wiley-Interscience Publication},
author = {Kaufman, Leonard and Rousseeuw, Peter J},
doi = {10.1002/9780470316801},
isbn = {0-471-87876-6},
pages = {xvi+342},
publisher = {John Wiley {\&} Sons Inc.},
series = {Wiley Series in Probability and Mathematical Statistics: Applied Probability and Statistics},
title = {{Finding groups in data}},
url = {http://dx.doi.org/10.1002/9780470316801},
year = {1990}
}
@article{Romano2019a,
abstract = {This paper introduces a machine for sampling approximate model-X knockoffs for arbitrary and unspecified data distributions using deep generative models. The main idea is to iteratively refine a knockoff sampling mechanism until a criterion measuring the validity of the produced knockoffs is optimized; this criterion is inspired by the popular maximum mean discrepancy in machine learning and can be thought of as measuring the distance to pairwise exchangeability between original and knockoff features. By building upon the existing model-X framework, we thus obtain a flexible and model-free statistical tool to perform controlled variable selection. Extensive numerical experiments and quantitative tests confirm the generality, effectiveness, and power of our deep knockoff machines. Finally, we apply this new method to a real study of mutations linked to changes in drug resistance in the human immunodeficiency virus.},
author = {Romano, Yaniv and Sesia, Matteo and Cand{\`{e}}s, Emmanuel},
doi = {10.1080/01621459.2019.1660174},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Romano, Sesia, Cand{\`{e}}s - 2019 - Deep Knockoffs.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {FDR,Variable selection,false discovery rate,generative models,high-dimensional regression,knockoffs,neural networks,nonparametric methods,variable selection},
mendeley-tags = {FDR,high-dimensional regression,knockoffs,variable selection},
number = {0},
pages = {1--27},
publisher = {Taylor {\&} Francis},
title = {{Deep Knockoffs}},
url = {http://dx.doi.org/10.1080/01621459.2019.1660174},
volume = {0},
year = {2019}
}
@inproceedings{Bridges,
address = {New York, NY, USA},
author = {Nystrom, Nicholas A and Levine, Michael J and Roskies, Ralph Z and Scott, J Ray},
booktitle = {Proceedings of the 2015 XSEDE Conference: Scientific Advancements Enabled by Enhanced Cyberinfrastructure},
doi = {10.1145/2792745.2792775},
isbn = {978-1-4503-3720-5},
keywords = {GPU,HPC,Hadoop,applications,architecture,big data,data analytics,database,research,usability},
pages = {30:1----30:8},
publisher = {ACM},
series = {XSEDE '15},
title = {{Bridges: A Uniquely Flexible HPC Resource for New Communities and Data Analytics}},
year = {2015}
}
@article{Jankova2020,
author = {Jankova, Jana and Shah, Rajen D and Buhlmann, Peter},
doi = {10.1111/rssb.12371},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society, Series B/Jankova, Shah, Buhlmann - 2020 - Goodness-of-fit testing in high dimensional generalized linear models.pdf:pdf},
journal = {Journal of the Royal Statistical Society, Series B},
keywords = {debiasing,generalized linear models,goodness-of-fit testing,group testing,high dimensional data,high-dimensional regression,residual prediction},
mendeley-tags = {high-dimensional regression},
title = {{Goodness-of-fit testing in high dimensional generalized linear models}},
year = {2020}
}
@article{Xiang2020,
author = {Xiang, Yunhua and Simon, Noah},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/International Conference on Machine Learning/Xiang, Simon - 2020 - A Flexible Framework for Nonparametric Graphical Modeling that Accommodates Machine Learning.pdf:pdf},
journal = {International Conference on Machine Learning},
title = {{A Flexible Framework for Nonparametric Graphical Modeling that Accommodates Machine Learning}},
year = {2020}
}
@article{GS11,
author = {Guan, Yongtao and Stephens, Matthew},
journal = {The Annals of Applied Statistics},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
number = {3},
pages = {1780--1815},
title = {{Bayesian variable selection regression for genome-wide association studies and other large scale problems}},
volume = {5},
year = {2011}
}
@book{L02,
address = {New York},
author = {Lange, Kenneth},
edition = {Second},
isbn = {0-387-95389-2},
keywords = {genetics},
mendeley-tags = {genetics},
pages = {xviii+361},
publisher = {Springer-Verlag},
series = {Statistics for Biology and Health},
title = {{Mathematical and statistical methods for genetic analysis}},
year = {2002}
}
@article{Fulco2016,
abstract = {Gene expression in mammals is regulated by noncoding elements that can affect physiology and disease, yet the functions and target genes of most noncoding elements remain unknown. We present a high-throughput approach that uses clustered regularly interspaced short palindromic repeats (CRISPR) interference (CRISPRi) to discover regulatory elements and identify their target genes. We assess {\textgreater}1 megabase of sequence in the vicinity of two essential transcription factors, MYC and GATA1, and identify nine distal enhancers that control gene expression and cellular proliferation. Quantitative features of chromatin state and chromosome conformation distinguish the seven enhancers that regulate MYC from other elements that do not, suggesting a strategy for predicting enhancer-promoter connectivity. This CRISPRi-based approach can be applied to dissect transcriptional networks and interpret the contributions of noncoding genetic variation to human disease.},
annote = {Supplementary materials (p. 13) contain a very useful literature review on methods to predict promoter-enhancer interactions.

Also a very simple heuristic method (p. 14 and p. 21 of the supplement) is developed to predict enhancer-gene regulation based on chromatin contact and activity.},
author = {Fulco, Charles P. and Munschauer, Mathias and Anyoha, Rockwell and Munson, Glen and Grossman, Sharon R. and Perez, Elizabeth M. and Kane, Michael and Cleary, Brian and Lander, Eric S. and Engreitz, Jesse M.},
doi = {10.1126/science.aag2445},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Fulco et al. - 2016 - Systematic mapping of functional enhancer-promoter connections with CRISPR interference.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Science/Fulco et al. - 2016 - Systematic mapping of functional enhancer-promoter connections with CRISPR interference.pdf:pdf},
issn = {10959203},
journal = {Science},
keywords = {CRISPR,Kathryn,gene-enhancer},
mendeley-tags = {CRISPR,Kathryn,gene-enhancer},
number = {6313},
pages = {769--773},
pmid = {27708057},
title = {{Systematic mapping of functional enhancer-promoter connections with CRISPR interference}},
volume = {354},
year = {2016}
}
@article{PetP10,
abstract = {Understanding the genetic mechanisms underlying natural variation in gene expression is a central goal of both medical and evolutionary genetics, and studies of expression quantitative trait loci (eQTLs) have become an important tool for achieving this goal. Although all eQTL studies so far have assayed messenger RNA levels using expression microarrays, recent advances in RNA sequencing enable the analysis of transcript variation at unprecedented resolution. We sequenced RNA from 69 lymphoblastoid cell lines derived from unrelated Nigerian individuals that have been extensively genotyped by the International HapMap Project. By pooling data from all individuals, we generated a map of the transcriptional landscape of these cells, identifying extensive use of unannotated untranslated regions and more than 100 new putative protein-coding exons. Using the genotypes from the HapMap project, we identified more than a thousand genes at which genetic variation influences overall expression levels or splicing. We demonstrate that eQTLs near genes generally act by a mechanism involving allele-specific expression, and that variation that influences the inclusion of an exon is enriched within and near the consensus splice sites. Our results illustrate the power of high-throughput sequencing for the joint analysis of variation in transcription, splicing and allele-specific expression across individuals.},
annote = {20220758},
author = {Pickrell, Joseph K and Marioni, John C and Pai, Athma A and Degner, Jacob F and Engelhardt, Barbara E and Nkadori, Everlyne and Veyrieras, Jean-Baptiste and Stephens, Matthew and Gilad, Yoav and Pritchard, Jonathan K},
journal = {Nature},
keywords = {gene expression,genetics},
mendeley-tags = {gene expression,genetics},
pages = {768--772},
title = {{{\{}Understanding{\}} Mechanisms Underlying Human gene Expression Variation with {\{}RNA{\}} Sequencing}},
volume = {464},
year = {2010}
}
@article{Wang2020,
abstract = {Non-coding transcriptional regulatory elements are critical for controlling the spatiotemporal expression of genes. Here, we demonstrate that the sizes and number of enhancers linked to a gene reflect its disease pathogenicity. Moreover, genes with redundant enhancer domains are depleted of cis-acting genetic variants that disrupt gene expression, and they are buffered against the effects of disruptive non-coding mutations. Our results demonstrate that dosage-sensitive genes have evolved a robustness to the disruptive effects of genetic variation by expanding their regulatory domains. This solves a puzzle about why genes associated with human disease are depleted of cis-eQTLs (cis-expression quantitative trait loci), suggesting that this relationship might complicate gene identification in causal genome-wide association studies (GWASs) using eQTL information, and establishes a framework for identifying non-coding regulatory variation with phenotypic consequences.},
author = {Wang, Xinchen and Goldstein, David B.},
doi = {10.1016/j.ajhg.2020.01.012},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Human Genetics/Wang, Goldstein - 2020 - Enhancer Domains Predict Gene Pathogenicity and Inform Gene Discovery in Complex Disease.pdf:pdf},
issn = {15376605},
journal = {American Journal of Human Genetics},
keywords = {EDS,Mendelian disease,causal gene,eQTLs,enhancer,enhancer domains,gene regulation,gene-enhancer,intolerance,pathogenicity},
mendeley-tags = {gene-enhancer},
number = {2},
pages = {215--233},
publisher = {ElsevierCompany.},
title = {{Enhancer Domains Predict Gene Pathogenicity and Inform Gene Discovery in Complex Disease}},
url = {https://doi.org/10.1016/j.ajhg.2020.01.012},
volume = {106},
year = {2020}
}
@article{Lu2019b,
abstract = {Gene expression and phenotype association can be affected by potential unmeasured confounders from multiple sources, leading to biased estimates of the associations. Since genetic variants largely explain gene expression variations, they can be used as instruments in studying the association between gene expressions and phenotype in the framework of high dimensional instrumental variable (IV) regression. However, because the dimensions of both genetic variants and gene expressions are often larger than the sample size, statistical inferences such as hypothesis testing for such high dimensional IV models are not trivial and have not been investigated in literature. The problem is more challenging since the instrumental variables (e.g., genetic variants) have to be selected among a large set of genetic variants. This paper considers the problem of hypothesis testing for sparse IV regression models and presents methods for testing single regression coefficient and multiple testing of multiple coefficients, where the test statistic for each single coefficient is constructed based on an inverse regression. A multiple testing procedure is developed for selecting variables and is shown to control the false discovery rate. Simulations are conducted to evaluate the performance of our proposed methods. These methods are illustrated by an analysis of a yeast dataset in order to identify genes that are associated with growth in the presence of hydrogen peroxide.},
archivePrefix = {arXiv},
arxivId = {1910.09628},
author = {Lu, Jiarui and Li, Hongzhe},
eprint = {1910.09628},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Lu, Li - 2019 - Hypothesis Testing in High-Dimensional Instrumental Variables Regression with an Application to Genomics Data.pdf:pdf},
keywords = {debiased estimation,fdr control,genetical genomics,instrumental variable},
title = {{Hypothesis Testing in High-Dimensional Instrumental Variables Regression with an Application to Genomics Data}},
url = {http://arxiv.org/abs/1910.09628},
year = {2019}
}
@article{Zhu2020,
author = {Zhu, Chenxu and Preissl, Sebastian and Ren, Bing},
doi = {10.1038/s41592-019-0691-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Zhu, Preissl, Ren - 2020 - Single-cell multimodal omics the power of many.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
number = {1},
pages = {11--14},
pmid = {31907462},
title = {{Single-cell multimodal omics: the power of many}},
volume = {17},
year = {2020}
}
@article{CetS15_set,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26076425{\}}{\{}26076425{\}}},
author = {Casale, F P and Rakitsch, B and Lippert, C and Stegle, O},
journal = {Nature Methods},
keywords = {GWAS,multiple phenotypes},
mendeley-tags = {GWAS,multiple phenotypes},
month = {aug},
number = {8},
pages = {755--758},
title = {{{\{}E{\}}fficient set tests for the genetic analysis of correlated traits}},
volume = {12},
year = {2015}
}
@article{BetN15LD,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25642630{\}}{\{}25642630{\}}},
author = {Bulik-Sullivan, B K and [...] and Neale, B M},
journal = {Nature Genetics},
keywords = {GWAS,linear mixed models},
mendeley-tags = {GWAS,linear mixed models},
month = {mar},
number = {3},
pages = {291--295},
title = {{{\{}L{\}}{\{}D{\}} {\{}S{\}}core regression distinguishes confounding from polygenicity in genome-wide association studies}},
volume = {47},
year = {2015}
}
@article{LetR03,
abstract = {High-dimensional data sets generated by high-throughput technologies, such as DNA microarray, are often the outputs of complex networked systems driven by hidden regulatory signals. Traditional statistical methods for computing low-dimensional or hidden representations of these data sets, such as principal component analysis and independent component analysis, ignore the underlying network structures and provide decompositions based purely on a priori statistical constraints on the computed component signals. The resulting decomposition thus provides a phenomenological model for the observed data and does not necessarily contain physically or biologically meaningful signals. Here, we develop a method, called network component analysis, for uncovering hidden regulatory signals from outputs of networked systems, when only a partial knowledge of the underlying network topology is available. The a priori network structure information is first tested for compliance with a set of identifiability criteria. For networks that satisfy the criteria, the signals from the regulatory nodes and their strengths of influence on each output node can be faithfully reconstructed. This method is first validated experimentally by using the absorbance spectra of a network of various hemoglobin species. The method is then applied to microarray data generated from yeast Saccharamyces cerevisiae and the activities of various transcription factors during cell cycle are reconstructed by using recently discovered connectivity information for the underlying transcriptional regulatory networks.},
annote = {14673099},
author = {Liao, J C and Boscolo, R and Yang, Y L and Tran, L M and Sabatti, C and Roychowdhury, V P},
doi = {10.1073/pnas.2136632100},
journal = {Proceedings of the National Academy of Sciences},
keywords = {genetics,networks},
mendeley-tags = {genetics,networks},
number = {26},
pages = {15522--15527},
title = {{Network component analysis: reconstruction of regulatory signals in biological systems}},
url = {http://www.hubmed.org/display.cgi?uids=14673099},
volume = {100},
year = {2003}
}
@article{Jansakul2008,
abstract = {When overdispersion is present in count data, a negative binomial (NB) model is commonly used in place of the standard Poisson model. However, the model is sometimes not adequate because of the occurrence of excess zeros and a zero-inflated negative binomial (ZNB) model may be more appropriate. This article proposes a general score test statistic for comparing a ZNB regression model to the NB model and the test is extended to a composite score test. Simulation results indicate that the test performs reasonably well and has a sampling distribution under the null hypothesis (NB model) approximated by the usual $\chi$2 distribution. Use of the test is illustrated on a set of apple shoot propagation data. The composite score test is found to indicate suitable models.},
author = {Jansakul, N. and Hinde, John P.},
doi = {10.1080/03610910802421632},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Communications in Statistics Simulation and Computation/Jansakul, Hinde - 2008 - Score Tests for Extra-Zero Models in Zero-Inflated Negative Binomial Models.pdf:pdf},
isbn = {0361091080242},
issn = {15324141},
journal = {Communications in Statistics: Simulation and Computation},
keywords = {Count data,Overdispersion,Score test,Zero-inflation,count data},
mendeley-tags = {count data},
number = {1},
pages = {92--108},
title = {{Score Tests for Extra-Zero Models in Zero-Inflated Negative Binomial Models}},
volume = {38},
year = {2008}
}
@article{FetT10,
author = {Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
journal = {arXiv},
keywords = {groups,high-dimensional regression,unpublished},
mendeley-tags = {groups,high-dimensional regression,unpublished},
title = {{A note on the group lasso and a sparse group lasso}},
year = {2010}
}
@article{Crowder1976,
author = {{Martin J. Crowder}},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society, Series B (Methodological)/Martin J. Crowder - 1976 - On the Method of Maximum-Likelihood for Dependent Observations.pdf:pdf},
journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
keywords = {asymptotic efficiency,asymptotic normality,asymptotics,dependent observations,maximum-likelihood estimates,tency},
mendeley-tags = {asymptotics},
number = {1},
pages = {45--53},
title = {{On the Method of Maximum-Likelihood for Dependent Observations}},
volume = {36},
year = {1976}
}
@article{Moore2019,
abstract = {Many genome-wide collections of candidate cis-regulatory elements (cCREs) have been defined using genomic and epigenomic data, but it remains a major challenge to connect these elements to their target genes. To facilitate the development of computational methods for predicting target genes, we developed a Benchmark of candidate Enhancer-Gene Interactions (BENGI) by integrating the Registry of cCREs we developed recently with experimentally-derived genomic interactions. We used BENGI to test several published computational methods for linking enhancers with genes, including signal correlation and the supervised learning methods TargetFinder and PEP. We found that while TargetFinder was the best performing method, it was modestly better than a baseline distance method for most benchmark datasets while trained and tested within the same cell type and that TargetFinder often did not outperform the distance method when applied across cell types. Our results suggest that current computational methods need to be improved and that BENGI presents a useful framework for method development and testing.},
author = {Moore, Jill E. and Pratt, Henry and Purcaro, Michael and Weng, Zhiping},
doi = {10.1101/745844},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Moore et al. - 2019 - A curated benchmark of enhancer-gene interactions for evaluating enhancer-target gene prediction methods.pdf:pdf},
journal = {bioRxiv},
keywords = {Kathryn,gene-enhancer,genetics},
mendeley-tags = {Kathryn,gene-enhancer,genetics},
title = {{A curated benchmark of enhancer-gene interactions for evaluating enhancer-target gene prediction methods}},
url = {https://www.biorxiv.org/content/10.1101/745844v1?rss=1},
year = {2019}
}
@article{Schraivogel2020,
abstract = {The transcriptome contains rich information on molecular, cellular and organismal phenotypes. However, experimental and statistical limitations constrain sensitivity and throughput of genetic screening with single-cell transcriptomics readout. To overcome these limitations, we introduce targeted Perturb-seq (TAP-seq), a sensitive, inexpensive and platform-independent method focusing single-cell RNA-seq coverage on genes of interest, thereby increasing the sensitivity and scale of genetic screens by orders of magnitude. TAP-seq permits routine analysis of thousands of CRISPR-mediated perturbations within a single experiment, detects weak effects and lowly expressed genes, and decreases sequencing requirements by up to 50-fold. We apply TAP-seq to generate perturbation-based enhancer–target gene maps for 1,778 enhancers within 2.5{\%} of the human genome. We thereby show that enhancer–target association is jointly determined by three-dimensional contact frequency and epigenetic states, allowing accurate prediction of enhancer targets throughout the genome. In addition, we demonstrate that TAP-seq can identify cell subtypes with only 100 sequencing reads per cell.},
author = {Schraivogel, Daniel and Gschwind, Andreas R. and Milbank, Jennifer H. and Leonce, Daniel R. and Jakob, Petra and Mathur, Lukas and Korbel, Jan O. and Merten, Christoph A. and Velten, Lars and Steinmetz, Lars M.},
doi = {10.1038/s41592-020-0837-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Schraivogel et al. - 2020 - Targeted Perturb-seq enables genome-scale genetic screens in single cells(2).pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Schraivogel et al. - 2020 - Targeted Perturb-seq enables genome-scale genetic screens in single cells.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {CRISPR,crispr screen,single cell},
mendeley-tags = {CRISPR,crispr screen,single cell},
number = {6},
pages = {629--635},
pmid = {32483332},
publisher = {Springer US},
title = {{Targeted Perturb-seq enables genome-scale genetic screens in single cells}},
url = {http://dx.doi.org/10.1038/s41592-020-0837-5},
volume = {17},
year = {2020}
}
@article{FoygelBarber2019a,
abstract = {We consider the problem of distribution-free predictive inference, with the goal of producing predictive coverage guarantees that hold conditionally rather than marginally. Existing methods such as conformal prediction offer marginal coverage guarantees, where predictive coverage holds on average over all possible test points, but this is not sufficient for many practical applications where we would like to know that our predictions are valid for a given individual, not merely on average over a population. On the other hand, exact conditional inference guarantees are known to be impossible without imposing assumptions on the underlying distribution. In this work we aim to explore the space in between these two, and examine what types of relaxations of the conditional coverage property would alleviate some of the practical concerns with marginal coverage guarantees while still being possible to achieve in a distribution-free setting.},
archivePrefix = {arXiv},
arxivId = {1903.04684v1},
author = {{Foygel Barber}, Rina and Cand{\`{e}}s, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
eprint = {1903.04684v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Foygel Barber et al. - 2019 - The limits of distribution-free conditional predictive inference.pdf:pdf},
journal = {arXiv},
keywords = {conformal prediction,to-skim,unpublished},
mendeley-tags = {conformal prediction,to-skim,unpublished},
title = {{The limits of distribution-free conditional predictive inference}},
year = {2019}
}
@article{TetT16,
author = {Tibshirani, Ryan J and Taylor, Jonathan and Lockhart, Richard and Tibshirani, Robert},
journal = {Journal of the American Statistical Association},
keywords = {post-selection inference},
mendeley-tags = {post-selection inference},
number = {514},
pages = {600--620},
publisher = {Taylor {\&} Francis},
title = {{Exact post-selection inference for sequential regression procedures}},
volume = {111},
year = {2016}
}
@article{DetC10,
author = {Denny, Joshua C. and Ritchie, Marylyn D. and Basford, Melissa A. and Pulley, Jill M. and Bastarache, Lisa and Brown-Gentry, Kristin and Wang, Deede and Masys, Dan R. and Roden, Dan M. and Crawford, Dana C.},
journal = {Bioinformatics},
keywords = {PheWAS,genetics},
mendeley-tags = {PheWAS,genetics},
number = {9},
pages = {1205--1210},
publisher = {Oxford University Press},
title = {{PheWAS: demonstrating the feasibility of a phenome-wide scan to discover gene--disease associations}},
volume = {26},
year = {2010}
}
@article{Xie2019,
abstract = {Single-cell screens enable high-throughput functional assessment of enhancers in their endogenous genomic context. However, the design of current studies limits their application to identifying the primary gene targets of enhancers. Here, we improve the experimental and computational parameters of single-cell enhancer screens to identify the secondary gene targets of enhancers. Our analysis of {\textgreater}500 putative enhancers in K562 cells reveals an interwoven enhancer-driven gene regulatory network. We find that enhancers from distinct genomic loci converge to modulate the expression of common sub-modules, including the $\alpha$- and $\beta$-globin loci, by directly regulating transcription factors. Our analysis suggests that several genetic variants associated with myeloid blood cell traits alter the activity of a distal enhancer of MYB (∼140 kb away), with downstream consequences on hemoglobin genes expression and cell state. These data have implications for the understanding of enhancer-associated traits and emphasize the flexibility of controlling transcriptional systems by modifying enhancer activity.},
author = {Xie, Shiqi and Armendariz, Daniel and Zhou, Pei and Duan, Jialei and Hon, Gary C.},
doi = {10.1016/j.celrep.2019.10.073},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell Reports/Xie et al. - 2019 - Global Analysis of Enhancer Targets Reveals Convergent Enhancer-Driven Regulatory Modules.pdf:pdf},
issn = {22111247},
journal = {Cell Reports},
keywords = {CRISPR,GWAS,enhancer,gene-enhancer,regulatory network,single-cell screen},
mendeley-tags = {CRISPR,gene-enhancer},
number = {9},
pages = {2570--2578.e5},
pmid = {31775028},
publisher = {ElsevierCompany.},
title = {{Global Analysis of Enhancer Targets Reveals Convergent Enhancer-Driven Regulatory Modules}},
volume = {29},
year = {2019}
}
@article{ST03,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/12883005{\}}{\{}12883005{\}}},
author = {Storey, J D and Tibshirani, R},
journal = {Proceedings of the National Academy of Sciences},
keywords = {GWAS,Multiple testing,genetics},
mendeley-tags = {GWAS,Multiple testing,genetics},
month = {aug},
number = {16},
pages = {9440--9445},
title = {{{\{}S{\}}tatistical significance for genomewide studies}},
volume = {100},
year = {2003}
}
@article{NMR12a,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/22286219{\}}{\{}22286219{\}}},
author = {Kettunen, J and Tukiainen, T and Sarin, A P and Ortega-Alonso, A and Tikkanen, E and Lyytikainen, L P and Kangas, A J and Soininen, P and Wurtz, P and Silander, K and Dick, D M and Rose, R J and Savolainen, M J and Viikari, J and Kahonen, M and Lehtimaki, T and Pietilainen, K H and Inouye, M and McCarthy, M I and Jula, A and Eriksson, J and Raitakari, O T and Salomaa, V and Kaprio, J and Jarvelin, M R and Peltonen, L and Perola, M and Freimer, N B and Ala-Korpela, M and Palotie, A and Ripatti, S},
journal = {Nature Genetics},
keywords = {GWAS},
mendeley-tags = {GWAS},
month = {mar},
number = {3},
pages = {269--276},
title = {{{\{}G{\}}enome-wide association study identifies multiple loci influencing human serum metabolite levels}},
volume = {44},
year = {2012}
}
@inproceedings{Woodworth2018,
abstract = {The problem of handling adaptivity in data analysis, intentional or not, permeates a variety of fields, including test-set overfitting in ML challenges and the accumulation of invalid scientific discoveries. We propose a mechanism for answering an arbitrarily long sequence of potentially adaptive statistical queries, by charging a price for each query and using the proceeds to collect additional samples. Crucially, we guarantee statistical validity without any assumptions on how the queries are generated. We also ensure with high probability that the cost for M non-adaptive queries is O(log M), while the cost to a potentially adaptive user who makes M queries that do not depend on any others is O(p M).},
author = {Woodworth, Blake and Feldman, Vitaly and Rosset, Saharon and Srebro, Nathan},
booktitle = {NIPS},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/NIPS/Woodworth et al. - 2018 - The Everlasting Database Statistical Validity at a Fair Price.pdf:pdf},
keywords = {adaptive data analysis,to-skim},
mendeley-tags = {adaptive data analysis,to-skim},
title = {{The Everlasting Database: Statistical Validity at a Fair Price}},
year = {2018}
}
@article{Fan2007,
abstract = {The advance of technology facilitates the collection of statistical data. Flexible and refined statistical models are widely sought in a large array of statistical problems. The question arises frequently whether or not a family of parametric or nonparametric models fit adequately the given data. In this paper we give a selective overview on nonparametric inferences using generalized likelihood ratio (GLR) statistics. We introduce generalized likelihood ratio statistics to test various null hypotheses against nonparametric alternatives. The trade-off between the flexibility of alternative models and the power of the statistical tests is emphasized. Well-established Wilks' phenomena are discussed for a variety of semi- and non-parametric models, which sheds light on other research using GLR tests. A number of open topics worthy of further study are given in a discussion section. {\textcopyright} 2007 Sociedad de Estad{\'{i}}stica e Investigaci{\'{o}}n Operativa.},
author = {Fan, Jianqing and Jiang, Jiancheng},
doi = {10.1007/s11749-007-0080-8},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Test/Fan, Jiang - 2007 - Nonparametric inference with generalized likelihood ratio tests.pdf:pdf},
issn = {11330686},
journal = {Test},
keywords = {Asymptotic null distribution,Bootstrap,Generalized likelihood ratio,Nonparametric test,Power function,Wilks' phenomenon,asymptotics},
mendeley-tags = {asymptotics},
number = {3},
pages = {409--444},
title = {{Nonparametric inference with generalized likelihood ratio tests}},
volume = {16},
year = {2007}
}
@article{Thomas2019,
abstract = {To increase the utility of Gene Ontology (GO) annotations for interpretation of genome-wide experimental data, we have developed GO-CAM, a structured framework for linking multiple GO annotations into an integrated model of a biological system. We expect that GO-CAM will enable new applications in pathway and network analysis, as well as improve standard GO annotations for traditional GO-based applications.},
author = {Thomas, Paul D and Hill, David P and Mi, Huaiyu and Osumi-sutherland, David and Auken, Kimberly Van and Carbon, Seth and Balhoff, James P and Albou, Laurent-philippe and Good, Benjamin and Gaudet, Pascale and Lewis, Suzanna E and Mungall, Christopher J},
doi = {10.1038/s41588-019-0500-1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Thomas et al. - 2019 - Gene Ontology Causal Activity Modeling (GO-CAM) moves beyond GO annotations to structured descriptions of biologi.pdf:pdf},
issn = {1546-1718},
journal = {Nature Genetics},
keywords = {Gene Ontology,enrichment analysis,genetics},
mendeley-tags = {Gene Ontology,enrichment analysis,genetics},
publisher = {Springer US},
title = {{Gene Ontology Causal Activity Modeling (GO-CAM) moves beyond GO annotations to structured descriptions of biological functions and systems}},
url = {http://dx.doi.org/10.1038/s41588-019-0500-1},
year = {2019}
}
@article{Song2010a,
author = {Song, Lingyun and Crawford, Gregory E.},
doi = {10.1101/pdb.prot5384},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cold Spring Harbor Protocols/Song, Crawford - 2010 - DNase-seq A high-resolution technique for mapping active gene regulatory elements across the genome from mammali.pdf:pdf},
issn = {15596095},
journal = {Cold Spring Harbor Protocols},
number = {2},
pages = {1--12},
title = {{DNase-seq: A high-resolution technique for mapping active gene regulatory elements across the genome from mammalian cells}},
volume = {5},
year = {2010}
}
@techreport{Tippens2019,
author = {Tippens, Nathaniel D and Liang, Jin and Leung, King Y and Ozer, Abdullah and Booth, James G and Lis, John T},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Tippens et al. - 2019 - Transcription imparts architecture, function, and logic to enhancer units.pdf:pdf},
keywords = {Kathryn,eSTARR-seq,enhancer,massively parallel reporter assays,unpublished},
mendeley-tags = {Kathryn,eSTARR-seq,enhancer,massively parallel reporter assays,unpublished},
title = {{Transcription imparts architecture, function, and logic to enhancer units}},
year = {2019}
}
@article{KX09,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/19680538{\}}{\{}19680538{\}}},
author = {Kim, Seyoung and Xing, Eric P},
journal = {PLoS Genetics},
keywords = {GWAS,multiple phenotypes},
mendeley-tags = {GWAS,multiple phenotypes},
number = {8},
pages = {e1000587},
publisher = {Public Library of Science},
title = {{Statistical estimation of correlated genome associations to a quantitative trait network}},
volume = {5},
year = {2009}
}
@article{Ke2017,
abstract = {Consider a linear model {\$}y = X \backslashbeta + z{\$}, {\$}z \backslashsim N(0, \backslashsigma{\^{}}2 I{\_}n){\$}. The Gram matrix {\$}\backslashTheta = \backslashfrac{\{}1{\}}{\{}n{\}} X'X{\$} is non-sparse, but it is approximately the sum of two components, a low-rank matrix and a sparse matrix, where neither component is known to us. We are interested in the Rare/Weak signal setting where all but a small fraction of the entries of {\$}\backslashbeta{\$} are nonzero, and the nonzero entries are relatively small individually. The goal is to rank the variables in a way so as to maximize the area under the ROC curve. We propose Factor-adjusted Covariate Assisted Ranking (FA-CAR) as a two-step approach to variable ranking. In the FA-step, we use PCA to reduce the linear model to a new one where the Gram matrix is approximately sparse. In the CAR-step, we rank variables by exploiting the local covariate structures. FA-CAR is easy to use and computationally fast, and it is effective in resolving signal cancellation, a challenge we face in regression models. FA-CAR is related to the recent idea of Covariate Assisted Screening and Estimation (CASE), but two methods are for different goals and are thus very different. We compare the ROC curve of FA-CAR with some other ranking ideas on numerical experiments, and show that FA-CAR has several advantages. Using a Rare/Weak signal model, we derive the convergence rate of the minimum sure-screening model size of FA-CAR. Our theoretical analysis contains several new ingredients, especially a new perturbation bound for PCA.},
archivePrefix = {arXiv},
arxivId = {1705.10370},
author = {Ke, Zheng Tracy and Yang, Fan},
eprint = {1705.10370},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Ke, Yang - 2017 - Covariate Assisted Variable Ranking.pdf:pdf},
journal = {arXiv},
keywords = {correlation,to-skim,unpublished},
mendeley-tags = {correlation,to-skim,unpublished},
month = {may},
title = {{Covariate Assisted Variable Ranking}},
url = {http://arxiv.org/abs/1705.10370},
year = {2017}
}
@article{Kwak2019,
author = {Kwak, Hojoong and Fuda, Nicholas J and Core, Leighton J and Lis, John T},
doi = {10.1126/science.1229386},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Kwak et al. - 2013 - Precise Maps of RNA Polymerase Reveal How Promoters Direct Initiation and Pausing.pdf:pdf},
journal = {Science},
keywords = {Kathryn,eRNA},
mendeley-tags = {Kathryn,eRNA},
number = {950},
pages = {950--953},
title = {{Precise Maps of RNA Polymerase Reveal How Promoters Direct Initiation and Pausing}},
url = {www.sciencemag.org/cgi/content/full/339/6122/950/DC1},
volume = {339},
year = {2013}
}
@article{Lehmann1949,
author = {Lehmann, E . L . and Stein, C.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Mathematical Statistics/Lehmann, Stein - 1949 - On the Theory of Some Non-Parametric Hypotheses.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
number = {1},
pages = {28--45},
title = {{On the Theory of Some Non-Parametric Hypotheses}},
volume = {20},
year = {1949}
}
@article{Rosset2020,
abstract = {In statistical prediction, classical approaches for model selection and model evaluation based on covariance penalties are still widely used. Most of the literature on this topic is based on what we call the “Fixed-X” assumption, where covariate values are assumed to be nonrandom. By contrast, it is often more reasonable to take a “Random-X” view, where the covariate values are independently drawn for both training and prediction. To study the applicability of covariance penalties in this setting, we propose a decomposition of Random-X prediction error in which the randomness in the covariates contributes to both the bias and variance components. This decomposition is general, but we concentrate on the fundamental case of ordinary least-squares (OLS) regression. We prove that in this setting the move from Fixed-X to Random-X prediction results in an increase in both bias and variance. When the covariates are normally distributed and the linear model is unbiased, all terms in this decomposition are explicitly computable, which yields an extension of Mallows' Cp that we call RCp. RCp also holds asymptotically for certain classes of nonnormal covariates. When the noise variance is unknown, plugging in the usual unbiased estimate leads to an approach that we call (Formula presented.), which is closely related to Sp, and generalized cross-validation (GCV). For excess bias, we propose an estimate based on the “shortcut-formula” for ordinary cross-validation (OCV), resulting in an approach we call RCp+. Theoretical arguments and numerical simulations suggest that RCp+ is typically superior to OCV, though the difference is small. We further examine the Random-X error of other popular estimators. The surprising result we get for ridge regression is that, in the heavily regularized regime, Random-X variance is smaller than Fixed-X variance, which can lead to smaller overall Random-X error. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1704.08160},
author = {Rosset, Saharon and Tibshirani, Ryan J.},
doi = {10.1080/01621459.2018.1424632},
eprint = {1704.08160},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Rosset, Tibshirani - 2020 - From Fixed-X to Random-X Regression Bias-Variance Decompositions, Covariance Penalties, and Prediction Error.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Bias-variance decomposition,Covariance penalties,Random-X regression},
number = {529},
pages = {138--151},
publisher = {Taylor {\&} Francis},
title = {{From Fixed-X to Random-X Regression: Bias-Variance Decompositions, Covariance Penalties, and Prediction Error Estimation}},
url = {https://doi.org/10.1080/01621459.2018.1424632},
volume = {115},
year = {2020}
}
@book{VanderLaan2018,
address = {New York},
author = {van der Laan, Mark J. and Rose, Sherri},
doi = {10.1007/978-3-319-65304-4},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/van der Laan, Rose - 2011 - Targeted learning Causal inference for observational and experimental data.pdf:pdf},
isbn = {978-3-319-65303-7},
keywords = {causality},
mendeley-tags = {causality},
publisher = {Springer},
title = {{Targeted learning: Causal inference for observational and experimental data}},
url = {https://www.springer.com/gp/book/9783319653037{\%}0Ahttp://link.springer.com/10.1007/978-3-319-65304-4},
year = {2011}
}
@article{SetP09,
abstract = {Genome-wide association studies (GWAS) of longitudinal birth cohorts enable joint investigation of environmental and genetic influences on complex traits. We report GWAS results for nine quantitative metabolic traits (triglycerides, high-density lipoprotein, low-density lipoprotein, glucose, insulin, C-reactive protein, body mass index, and systolic and diastolic blood pressure) in the Northern Finland Birth Cohort 1966 (NFBC1966), drawn from the most genetically isolated Finnish regions. We replicate most previously reported associations for these traits and identify nine new associations, several of which highlight genes with metabolic functions: high-density lipoprotein with NR1H3 (LXRA), low-density lipoprotein with AR and FADS1-FADS2, glucose with MTNR1B, and insulin with PANK1. Two of these new associations emerged after adjustment of results for body mass index. Gene-environment interaction analyses suggested additional associations, which will require validation in larger samples. The currently identified loci, together with quantified environmental exposures, explain little of the trait variation in NFBC1966. The association observed between low-density lipoprotein and an infrequent variant in AR suggests the potential of such a cohort for identifying associations with both common, low-impact and rarer, high-impact quantitative trait loci.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/19060910{\}}{\{}19060910{\}}},
author = {Sabatti, C and Service, S K and Hartikainen, A L and Pouta, A and Ripatti, S and Brodsky, J and Jones, C G and Zaitlen, N A and Varilo, T and Kaakinen, M and Sovio, U and Ruokonen, A and Laitinen, J and Jakkula, E and Coin, L and Hoggart, C and Collins, A and Turunen, H and Gabriel, S and Elliot, P and McCarthy, M I and Daly, M J and J{\"{a}}rvelin, M R and Freimer, N B and Peltonen, L},
doi = {10.1038/ng.271},
journal = {Nature Genetics},
keywords = {GWAS},
mendeley-tags = {GWAS},
number = {1},
pages = {35--46},
title = {{Genome-wide association analysis of metabolic traits in a birth cohort from a founder population}},
url = {http://www.hubmed.org/display.cgi?uids=19060910},
volume = {41},
year = {2009}
}
@article{May2012,
abstract = {Development and function of the human heart depend on the dynamic control of tissue-specific gene expression by distant-acting transcriptional enhancers. To generate an accurate genome-wide map of human heart enhancers, we used an epigenomic enhancer discovery approach and identified ∼6,200 candidate enhancer sequences directly from fetal and adult human heart tissue. Consistent with their predicted function, these elements were markedly enriched near genes implicated in heart development, function and disease. To further validate their in vivo enhancer activity, we tested 65 of these human sequences in a transgenic mouse enhancer assay and observed that 43 (66{\%}) drove reproducible reporter gene expression in the heart. These results support the discovery of a genome-wide set of noncoding sequences highly enriched in human heart enhancers that is likely to facilitate downstream studies of the role of enhancers in development and pathological conditions of the heart.},
author = {May, Dalit and Blow, Matthew J. and Kaplan, Tommy and McCulley, David J. and Jensen, Brian C. and Akiyama, Jennifer A. and Holt, Amy and Plajzer-Frick, Ingrid and Shoukry, Malak and Wright, Crystal and Afzal, Veena and Simpson, Paul C. and Rubin, Edward M. and Black, Brian L. and Bristow, James and Pennacchio, Len A. and Visel, Axel},
doi = {10.1038/ng.1006},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/May et al. - 2012 - Large-scale discovery of enhancers from human heart tissue.pdf:pdf},
issn = {10614036},
journal = {Nature Genetics},
keywords = {Kathryn,enhancer},
mendeley-tags = {Kathryn,enhancer},
number = {1},
pages = {89--93},
publisher = {Nature Publishing Group},
title = {{Large-scale discovery of enhancers from human heart tissue}},
url = {http://dx.doi.org/10.1038/ng.1006},
volume = {44},
year = {2012}
}
@article{DAGGER,
author = {Ramdas, Aaditya and Chen, Jianbo and Wainwright, Martin J. and Jordan, Michael I.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Ramdas et al. - 2019 - DAGGER A sequential algorithm for FDR control on DAGs.pdf:pdf},
journal = {Biometrika},
keywords = {FDR,Multiple testing,hierarchical multiple testing},
mendeley-tags = {FDR,Multiple testing,hierarchical multiple testing},
number = {1},
pages = {69--86},
title = {{DAGGER: A sequential algorithm for FDR control on DAGs}},
volume = {106},
year = {2019}
}
@article{Davies2008,
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Guo, Wenge and Peddada, Shyamal},
doi = {10.1038/jid.2014.371},
eprint = {NIHMS150003},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Stat Appl Genet Mol Biol/Guo, Peddada - 2008 - Adaptive Choice of the Number of Bootstrap Samples in Large Scale Multiple Testing Wenge.pdf:pdf},
isbn = {6176321972},
issn = {15378276},
journal = {Stat Appl Genet Mol Biol},
keywords = {Monte Carlo,Multiple testing},
mendeley-tags = {Monte Carlo,Multiple testing},
number = {1},
pmid = {1000000221},
title = {{Adaptive Choice of the Number of Bootstrap Samples in Large Scale Multiple Testing Wenge}},
volume = {7},
year = {2008}
}
@article{Cao2018,
abstract = {Although we can increasingly measure transcription, chromatin, methylation, etc. at single cell resolution, most assays survey only one aspect of cellular biology. Here we describe sci-CAR, a combinatorial indexing-based co-assay that jointly profiles chromatin accessibility and mRNA in each of thousands of single cells. As a proof-of-concept, we apply sci-CAR to 4,825 cells comprising a time-series of dexamethasone treatment, as well as to 11,296 cells from the adult mouse kidney. With the resulting data, we compare the pseudotemporal dynamics of chromatin accessibility and gene expression, reconstruct the chromatin accessibility profiles of cell types defined by RNA profiles, and link cis-regulatory sites to their target genes on the basis of the covariance of chromatin accessibility and transcription across large numbers of single cells.},
author = {Cao, Junyue and Cusanovich, Darren A. and Ramani, Vijay and Aghamirzaie, Delasa and Pliner, Hannah A. and Hill, Andrew J. and Daza, Riza M. and McFaline-Figueroa, Jose L. and Packer, Jonathan S. and Christiansen, Lena and Steemers, Frank J. and Adey, Andrew C. and Trapnell, Cole and Shendure, Jay},
doi = {10.1126/science.aau0730(2018)},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Cao et al. - 2018 - Joint profiling of chromatin accessibility and gene expression in thousands of single cells(2).pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Science/Cao et al. - 2018 - Joint profiling of chromatin accessibility and gene expression in thousands of single cells.pdf:pdf},
issn = {10959203},
journal = {Science},
keywords = {multi-omics,single cell},
mendeley-tags = {multi-omics,single cell},
number = {September},
pages = {1380--1385},
title = {{Joint profiling of chromatin accessibility and gene expression in thousands of single cells}},
volume = {1385},
year = {2018}
}
@article{Buhlmann2013,
abstract = {We propose a method for constructing p-values for general hypotheses in a high-dimensional linear model. The hypotheses can be local for testing a single regression parameter or they may be more global involving several up to all parameters. Furthermore, when considering many hypotheses, we show how to adjust for multiple testing taking dependence among the p-values into account. Our technique is based on Ridge estimation with an additional correction term due to a substantial projection bias in high dimensions. We prove strong error control for our p-values and provide sufficient conditions for detection: for the former, we do not make any assumption on the size of the true underlying regression coefficients while regarding the latter, our procedure might not be optimal in terms of power. We demonstrate the method in simulated examples and a real data application.},
author = {B{\"{u}}hlmann, Peter},
doi = {10.3150/12-BEJSP11},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bernoulli/B{\"{u}}hlmann - 2013 - Statistical significance in high-dimensional linear models.pdf:pdf},
journal = {Bernoulli},
keywords = {Westfall-Young permutation procedure,global testing,high-dimensional regression,lasso,multiple testing,ridge regression,variable selection},
mendeley-tags = {high-dimensional regression},
number = {4},
pages = {1212--1242},
title = {{Statistical significance in high-dimensional linear models}},
volume = {19},
year = {2013}
}
@article{GS11mt,
author = {Goeman, Jelle and Solari, Aldo},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistical Science/Goeman, Solari - 2011 - Multiple testing for exploratory research.pdf:pdf},
journal = {Statistical Science},
keywords = {Multiple testing,canonical,simultaneous inference},
mendeley-tags = {Multiple testing,canonical,simultaneous inference},
number = {4},
pages = {584--597},
publisher = {JSTOR},
title = {{Multiple testing for exploratory research}},
volume = {26},
year = {2011}
}
@article{BetJ18,
author = {Bycroft, Clare and Freeman, Colin and Petkova, Desislava and Band, Gavin and Elliott, Lloyd T. and Sharp, Kevin and Motyer, Allan and Vukcevic, Damjan and Delaneau, Olivier and O'Connell, Jared and Cortes, Adrian and Welsh, Samantha and Young, Alan and Effingham, Mark and McVean, Gil and Leslie, Stephen and Allen, Naomi and Donnelly, Peter and Marchini, Jonathan},
journal = {Nature},
keywords = {genetics},
mendeley-tags = {genetics},
number = {7726},
pages = {203},
publisher = {Nature Publishing Group},
title = {{The UK Biobank resource with deep phenotyping and genomic data}},
volume = {562},
year = {2018}
}
@article{Svensson2020,
author = {Svensson, Valentine},
doi = {10.1038/s41587-020-0413-7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Svensson - 2020 - Droplet scRNA-seq is not zero-inflated.pdf:pdf},
issn = {15461696},
journal = {Nature Biotechnology},
keywords = {single cell},
mendeley-tags = {single cell},
pages = {142--150},
pmid = {32034392},
title = {{Droplet scRNA-seq is not zero-inflated}},
volume = {38},
year = {2020}
}
@article{Bates2020a,
abstract = {This paper proposes a novel statistical method to address population structure in genome-wide association studies while controlling the false discovery rate, which overcomes some limitations of existing approaches. Our solution accounts for linkage disequilibrium and diverse ancestries by combining conditional testing via knockoffs with hidden Markov models from state-of-the-art phasing methods. Furthermore, we account for familial relatedness by describing the joint distribution of haplotypes sharing long identical-by-descent segments with a generalized hidden Markov model. Extensive simulations affirm the validity of this method, while applications to UK Biobank phenotypes yield many more discoveries compared to BOLT-LMM, most of which are confirmed by the Japan Biobank and FinnGen data.},
author = {Bates, Stephen and Cand{\`{e}}s, Emmanuel and Marchini, Jonathan and Sabatti, Chiara},
doi = {10.1101/2020.08.04.236703},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv Genomics/Bates et al. - 2020 - Controlling the false discovery rate in GWAS with population structure.pdf:pdf},
journal = {bioRxiv Genomics},
keywords = {GWAS,knockoffs},
mendeley-tags = {GWAS,knockoffs},
title = {{Controlling the false discovery rate in GWAS with population structure}},
url = {http://biorxiv.org/cgi/content/short/2020.08.04.236703v1?rss=1{\&}utm{\_}source=researcher{\_}app{\&}utm{\_}medium=referral{\&}utm{\_}campaign=RESR{\_}MRKT{\_}Researcher{\_}inbound},
year = {2020}
}
@article{P07,
author = {Paul, D},
journal = {Statistica Sinica},
pages = {1617--1642},
title = {{Asymptotics of sample eigenstructure for a large dimensional spiked covariance model}},
volume = {17},
year = {2007}
}
@article{Kartik2019,
abstract = {Two active hypothesis testing problems are formulated. In these problems, the agent can perform a fixed number of experiments and then decide on one of the hypotheses. The agent is also allowed to declare its experiments inconclusive if needed. The first problem is an asymmetric formulation in which the the objective is to minimize the probability of incorrectly declaring a particular hypothesis to be true while ensuring that the probability of correctly declaring that hypothesis is moderately high. This formulation can be seen as a generalization of the formulation in the classical Chernoff-Stein lemma to an active setting. The second problem is a symmetric formulation in which the objective is to minimize the probability of making an incorrect inference (misclassification probability) while ensuring that the true hypothesis is declared conclusively with moderately high probability. For these problems, lower and upper bounds on the optimal misclassification probabilities are derived and these bounds are shown to be asymptotically tight. Classical approaches for experiment selection suggest use of randomized and, in some cases, open-loop strategies. As opposed to these classical approaches, fully deterministic and adaptive experiment selection strategies are provided. It is shown that these strategies are asymptotically optimal and further, using numerical experiments, it is demonstrated that these novel experiment selection strategies (coupled with appropriate inference strategies) have a significantly better performance in the non-asymptotic regime.},
archivePrefix = {arXiv},
arxivId = {1911.06912},
author = {Kartik, Dhruva and Nayyar, Ashutosh and Mitra, Urbashi},
eprint = {1911.06912},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Kartik, Nayyar, Mitra - 2019 - Fixed-horizon Active Hypothesis Testing.pdf:pdf},
pages = {1--45},
title = {{Fixed-horizon Active Hypothesis Testing}},
url = {http://arxiv.org/abs/1911.06912},
year = {2019}
}
@article{BS06,
author = {Baik, J and Silverstein, J},
journal = {Journal of Multivariate Analysis},
pages = {1382--1408},
title = {{Eigenvalues of large sample covariance matrices of spiked population models}},
volume = {97},
year = {2006}
}
@article{CG10,
abstract = {Although genome-wide association (GWA) studies for common variants have thus far succeeded in explaining only a modest fraction of the genetic components of human common diseases, recent advances in next-generation sequencing technologies could rapidly facilitate substantial progress. This outcome is expected if much of the missing genetic control is due to gene variants that are too rare to be picked up by GWA studies and have relatively large effects on risk. Here, we evaluate the evidence for an important role of rare gene variants of major effect in common diseases and outline discovery strategies for their identification.},
annote = {20479773},
author = {Cirulli, E T and Goldstein, D B},
doi = {10.1038/nrg2779},
journal = {Nature Reviews Genetics},
keywords = {rare variants,whole genome sequencing},
mendeley-tags = {rare variants,whole genome sequencing},
number = {6},
pages = {415--425},
title = {{Uncovering the roles of rare variants in common disease through whole-genome sequencing}},
url = {http://www.hubmed.org/display.cgi?uids=20479773},
volume = {11},
year = {2010}
}
@article{Schweder1982,
author = {Schweder, T. and Spjotvoll, E.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Schweder, Spjotvoll - 1982 - Plots of P-Values to Evaluate Many Tests Simultaneously.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {493--502},
title = {{Plots of P-Values to Evaluate Many Tests Simultaneously}},
volume = {69},
year = {1982}
}
@article{Robins2001,
author = {Robins, James M. and Rotnitzky, Andrea},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistica Sinica/Robins, Rotnitzky - 2001 - Comment on the Bickel and Kwon article, Inference for semiparametric models Some questions and an answer.pdf:pdf},
journal = {Statistica Sinica},
keywords = {causality},
mendeley-tags = {causality},
number = {4},
pages = {920--936},
title = {{Comment on the Bickel and Kwon article, "Inference for semiparametric models: Some questions and an answer"}},
volume = {11},
year = {2001}
}
@article{Taylor2018,
abstract = {Inspired by sample splitting and the reusable holdout introduced in the field of differential privacy, we consider selective inference with a random-ized response. We discuss two major advantages of using a randomized response for model selection. First, the selectively valid tests are more powerful after randomized selection. Second, it allows consistent estimation and weak convergence of selective inference procedures. Under independent sampling, we prove a selective (or privatized) central limit theorem that transfers procedures valid under asymptotic normality without selection to their corresponding selective counterparts. This allows selective inference in nonparametric settings. Finally, we propose a framework of inference after combining multiple randomized selection procedures. We focus on the classical asymptotic setting, leaving the interesting high-dimensional asymptotic questions for future work.},
author = {Taylor, Jonathan},
doi = {10.1214/17-AOS1564},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Taylor - 2018 - Selective inference with a randomized response.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {62J05,62M40,Selective inference,differential privacy,nonparametric,randomization,selective inference},
mendeley-tags = {randomization,selective inference},
number = {2},
pages = {679--710},
title = {{Selective inference with a randomized response}},
url = {https://doi.org/10.1214/17-AOS1564},
volume = {46},
year = {2018}
}
@article{CF09,
author = {Chumbley, Justin R and Friston, Karl J},
journal = {Neuroimage},
number = {1},
pages = {62--70},
publisher = {Elsevier},
title = {{False discovery rate revisited: FDR and topological inference using Gaussian random fields}},
volume = {44},
year = {2009}
}
@article{SetK13,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23453885{\}}{\{}23453885{\}}},
author = {Smoller, J W and [...] and Kendler, K},
journal = {Lancet},
keywords = {genetics,multiple phenotypes},
mendeley-tags = {genetics,multiple phenotypes},
month = {apr},
number = {9875},
pages = {1371--1379},
title = {{{\{}I{\}}dentification of risk loci with shared effects on five major psychiatric disorders: a genome-wide analysis}},
volume = {381},
year = {2013}
}
@misc{treeQTL,
annote = {$\backslash$url{\{}http://www.bioinformatics.org/treeqtl/{\}} [Accessed: 2016]},
author = {Peterson, C B},
keywords = {genetics,hierarchical multiple testing,software},
mendeley-tags = {genetics,hierarchical multiple testing,software},
title = {{{\{}$\backslash$tt TreeQTL{\}}: {\{}H{\}}ierarchical error control for {\{}eQTL{\}} studies}},
year = {2015}
}
@article{Yang2020,
abstract = {CRISPR/Cas9 based functional screening coupled with single-cell RNA-seq (“single-cell CRISPR screening”) unravels gene regulatory networks and enhancer-gene regulations in a large scale. We propose scMAGeCK, a computational framework to systematically identify genes and non-coding elements associated with multiple expression-based phenotypes in single-cell CRISPR screening. scMAGeCK identified genes and enhancers that modulate the expression of a known proliferation marker, MKI67 (Ki-67), a result that resembles the outcome of proliferation-linked CRISPR screening. We further performed single-cell CRISPR screening on mouse embryonic stem cells (mESC), and identified key genes associated with different pluripotency states. scMAGeCK enabled an unbiased construction of genotype-phenotype network, where multiple phenotypes can be regulated by different gene perturbations. Finally, we studied key factors that improve the statistical power of single-cell CRISPR screens, including target gene expression and the number of guide RNAs (gRNAs) per cell. Collectively, scMAGeCK is a novel and effective computational tool to study genotype-phenotype relationships at a single-cell level.},
author = {Yang, Lin and Zhu, Yuqing and Yu, Hua and Chen, Sitong and Chu, Yulan and Huang, He and Zhang, Jin and Li, Wei},
doi = {10.1101/658146},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Yang et al. - 2020 - Linking genotypes with multiple phenotypes in single-cell CRISPR screens.pdf:pdf},
journal = {Genome Biology},
keywords = {CRISPR,single cell},
mendeley-tags = {CRISPR,single cell},
publisher = {Genome Biology},
title = {{Linking genotypes with multiple phenotypes in single-cell CRISPR screens}},
volume = {21},
year = {2020}
}
@article{Weinstein2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2007.15346v1},
author = {Weinstein, Asaf and Su, Weijie J and Bogdan, Malgorzata and Barber, Rina F and Candes, Emmanuel J},
eprint = {arXiv:2007.15346v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Weinstein et al. - 2020 - A Power Analysis for Knockoffs with the Lasso.pdf:pdf},
journal = {arXiv},
keywords = {AMP,high-dimensional regression,knockoffs},
mendeley-tags = {AMP,high-dimensional regression,knockoffs},
title = {{A Power Analysis for Knockoffs with the Lasso}},
year = {2020}
}
@article{Ignatiadis2016,
abstract = {P i /w i (where w i is the weight of hypothesis i) 6. This approach is known to control the FDR if the weights are prespecified and thus independent of the data. However, the optimal choice of weights is rarely known in practice, and a generally applicable data-driven method is desirable 7-11. We developed IHW as a multiple testing procedure that applies the weighted BH method 6 using weights derived from the data (Online Methods and Supplementary Note 2). The input to IHW is a two-column table of P-values and covariates. The covariate can be any continuous or categorical variable that is thought to provide information on the statistical properties of the hypothesis tests while remaining independent of the P-value under the null hypothesis 9. Such covariates exist in many applications and are often apparent to domain experts (Table 1). The conditional independence property can be verified either mathematically 9 or empirically 12. Simple diagnostic plots of the data can help assess these assumptions. For example, a histogram of all P-values will typically show a mixture of a uniform distribution (corresponding to the true null hypotheses) and an enrichment of small P-values to the left (corresponding to the alternatives) (Fig. 1a). Splitting the hypotheses into groups based on the values of a good covariate will alter the proportion and/or the shape of the alternative distribution between the groups (Fig. 1b-d). If all histograms look the same, the covariate is uninformative, and its use will not lead to an increase in power. If the tails are no longer uniform, independence under the null is violated, and application of IHW is not valid. IHW is motivated by considering multiple testing as a resource allocation problem 6 : given a budget of acceptable FDR, how can it be distributed among the hypotheses in such a way as to obtain the best possible power overall? The first idea is to use the covariate to assign hypothesis weights. We approximate the covariate-weight relationship by a stepwise constant function. No further assumptions (e.g., monotonicity) are needed. The second idea is that the number of discoveries of the weighted BH procedure with given weights is an empirical indicator of the method's power. Therefore, a good choice of the covariate-weight function should lead to a high number of discoveries. The basic steps of IHW are as follows. First, we divide the tests into groups based on the covariate. Each group is associated with a weight so that all hypotheses within a group are assigned the same weight. For each possible choice of weights, we apply the weighted BH procedure at level $\alpha$ and calculate the total number of discoveries. We choose the weights leading to the highest number of discoveries. For many applications, this approach ('naive IHW') provides satisfactory results but it has two shortcomings: first, the underlying optimization problem is difficult and does not easily scale to problems with millions of tests. Second, the naive IHW approach},
author = {Ignatiadis, Nikolaos and Klaus, Bernd and Zaugg, Judith B and Huber, Wolfgang},
doi = {10.1038/nmeth.3885},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Ignatiadis et al. - 2016 - Data-driven hypothesis weighting increases detection power in genome-scale multiple testing.pdf:pdf},
journal = {Nature Methods},
keywords = {genetics,weighted multiple testing},
mendeley-tags = {genetics,weighted multiple testing},
number = {7},
pages = {577--580},
title = {{Data-driven hypothesis weighting increases detection power in genome-scale multiple testing}},
url = {http://www.bioconductor.},
volume = {13},
year = {2016}
}
@article{UWS16,
abstract = {We introduce new statistical methods for analyzing genomic datasets that measure many effects in many conditions (e.g. gene expression changes under many treatments). These new methods improve on existing methods by allowing for arbitrary correlations among conditions. This flexible approach increases power, improves effect-size estimates, and facilitates more quantitative assessments of effect-size heterogeneity than simple "shared/condition-specific" assessments. We illustrate these features through a detailed analysis of locally-acting ("cis") eQTLs in 44 human tissues (data from GTEx project). Our analysis identifies more eQTLs than existing approaches, consistent with improved power. More importantly, although eQTLs are often shared broadly among tissues, our more quantitative approach highlights that effect sizes can vary considerably among tissues: some shared eQTLs show stronger effects in a subset of biologically-related tissues (e.g. brain-related tissues), or in only a single tissue (e.g. testis; transformed-fibroblasts). Our methods are widely applicable, computationally tractable for many conditions, and available at https://github.com/stephenslab/mashr.},
author = {Urbut, Sarah Margaret and Wang, Gao and Stephens, Matthew},
doi = {10.1101/096552},
journal = {bioRxiv},
keywords = {multiple phenotypes,unpublished},
mendeley-tags = {multiple phenotypes,unpublished},
publisher = {Cold Spring Harbor Labs Journals},
title = {{Flexible statistical methods for estimating and testing effects in genomic studies with multiple conditions}},
url = {http://biorxiv.org/content/early/2016/12/24/096552},
year = {2016}
}
@article{CetD11,
annote = {21852963},
author = {Cotsapas, C and Voight, B F and Rossin, E and Lage, K and Neale, B M and Wallace, C and Abecasis, G R and Barrett, J C and Behrens, T and Cho, J and {De Jager}, P L and Elder, J T and Graham, R R and Gregersen, P and Klareskog, L and Siminovitch, K A and van Heel, D A and Wijmenga, C and Worthington, J and Todd, J A and Hafler, D A and Rich, S S and Daly, M J},
journal = {PLoS Genetics},
keywords = {GWAS,genetics,multiple phenotypes},
mendeley-tags = {GWAS,genetics,multiple phenotypes},
month = {aug},
pages = {e1002254},
title = {{{\{}P{\}}ervasive sharing of genetic effects in autoimmune disease}},
volume = {7},
year = {2011}
}
@article{SetS15,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25642138{\}}{\{}25642138{\}}},
author = {Sun, Wenguang and Reich, Brian J. and Cai, T. Tony and Guindani, Michele and Schwartzman, Armin},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society Series B (Statistical Methodology)/Sun et al. - 2015 - False Discovery Control in Large-Scale Spatial Multiple Testing.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,spatial data},
mendeley-tags = {FDR,spatial data},
number = {1},
pages = {59--83},
title = {{False Discovery Control in Large-Scale Spatial Multiple Testing}},
volume = {77},
year = {2015}
}
@article{Roquain2009,
abstract = {How to weigh the Benjamini-Hochberg procedure? In the context of multiple hypothesis testing, we propose a new step-wise procedure that controls the false discovery rate (FDR) and we prove it to be more powerful than any weighted Benjamini-Hochberg procedure. Both finite-sample and asymptotic results are presented. Moreover, we illustrate good performance of our procedure in simulations and a genomics application. This work is particularly useful in the case of heterogeneous p-value distributions .},
author = {Roquain, Etienne and {Van De Wiel}, Mark A},
doi = {10.1214/09-EJS430},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Electronic Journal of Statistics/Roquain, Van De Wiel - 2009 - Optimal weighting for false discovery rate control.pdf:pdf},
issn = {1935-7524},
journal = {Electronic Journal of Statistics},
keywords = {AMS 2000 subject classifications: Primary 62J15,FDR,Multiple testing,multiple testing,p-value weighting,power maximization,secondary 62G10 Keywords and phrases: False discov,weighted multiple testing},
mendeley-tags = {FDR,Multiple testing,weighted multiple testing},
pages = {678--711},
title = {{Optimal weighting for false discovery rate control}},
volume = {3},
year = {2009}
}
@article{Sultan2008,
author = {Sultan, Marc and Schulz, Marcel H and Richard, Hugues and Magen, Alon and Klingenhoff, Andreas and Scherf, Matthias and Seifert, Martin and Borodina, Tatjana and Soldatov, Aleksey and Parkhomchuk, Dmitri and Schmidt, Dominic and Keeffe, Sean O and Haas, Stefan and Vingron, Martin and Lehrach, Hans and Yaspo, Marie-laure},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Sultan et al. - 2008 - A global view of gene activity and alternative splicing by deep sequencing of the human transcriptome.pdf:pdf},
journal = {Science},
pages = {956--961},
title = {{A global view of gene activity and alternative splicing by deep sequencing of the human transcriptome}},
volume = {321},
year = {2008}
}
@article{Vierstra2020,
abstract = {Combinatorial binding of transcription factors to regulatory DNA underpins gene regulation in all organisms. Genetic variation in regulatory regions has been connected with diseases and diverse phenotypic traits1, but it remains challenging to distinguish variants that affect regulatory function2. Genomic DNase I footprinting enables the quantitative, nucleotide-resolution delineation of sites of transcription factor occupancy within native chromatin3–6. However, only a small fraction of such sites have been precisely resolved on the human genome sequence6. Here, to enable comprehensive mapping of transcription factor footprints, we produced high-density DNase I cleavage maps from 243 human cell and tissue types and states and integrated these data to delineate about 4.5 million compact genomic elements that encode transcription factor occupancy at nucleotide resolution. We map the fine-scale structure within about 1.6 million DNase I-hypersensitive sites and show that the overwhelming majority are populated by well-spaced sites of single transcription factor–DNA interaction. Cell-context-dependent cis-regulation is chiefly executed by wholesale modulation of accessibility at regulatory DNA rather than by differential transcription factor occupancy within accessible elements. We also show that the enrichment of genetic variants associated with diseases or phenotypic traits in regulatory regions1,7 is almost entirely attributable to variants within footprints, and that functional variants that affect transcription factor occupancy are nearly evenly partitioned between loss- and gain-of-function alleles. Unexpectedly, we find increased density of human genetic variation within transcription factor footprints, revealing an unappreciated driver of cis-regulatory evolution. Our results provide a framework for both global and nucleotide-precision analyses of gene regulatory mechanisms and functional genetic variation.},
author = {Vierstra, Jeff and Lazar, John and Sandstrom, Richard and Halow, Jessica and Lee, Kristen and Bates, Daniel and Diegel, Morgan and Dunn, Douglas and Neri, Fidencio and Haugen, Eric and Rynes, Eric and Reynolds, Alex and Nelson, Jemma and Johnson, Audra and Frerker, Mark and Buckley, Michael and Kaul, Rajinder and Meuleman, Wouter and Stamatoyannopoulos, John A.},
doi = {10.1038/s41586-020-2528-x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Vierstra et al. - 2020 - Global reference mapping of human transcription factor footprints.pdf:pdf},
isbn = {4158602025},
issn = {14764687},
journal = {Nature},
keywords = {CRISPR,to-read},
mendeley-tags = {CRISPR,to-read},
number = {7818},
pages = {729--736},
pmid = {32728250},
publisher = {Springer US},
title = {{Global reference mapping of human transcription factor footprints}},
url = {http://dx.doi.org/10.1038/s41586-020-2528-x},
volume = {583},
year = {2020}
}
@article{Gazal2018,
author = {Gazal, Steven and Marquez-Luna, Carla and Finucane, Hilary K and Price, Alkes L},
doi = {10.1101/256412},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Gazal et al. - 2018 - Reconciling S-LDSC and LDAK models and functional enrichment estimates.pdf:pdf},
journal = {bioRxiv},
keywords = {functional annotation,genetics,to-skim,unpublished},
mendeley-tags = {functional annotation,genetics,to-skim,unpublished},
title = {{Reconciling S-LDSC and LDAK models and functional enrichment estimates}},
url = {http://dx.doi.org/10.1101/256412},
year = {2018}
}
@article{ABDJ,
author = {Abramovich, F and Benjamini, Y and Donoho, D.{\~{}}L. and Johnstone, I.{\~{}}M.},
journal = {The Annals of Statistics},
keywords = {FDR},
mendeley-tags = {FDR},
number = {2},
pages = {584--653},
title = {{Adapting to unknown sparsity by controlling the false discovery rate}},
volume = {34},
year = {2006}
}
@article{Peters2016,
abstract = {What is the difference of a prediction that is made with a causal model and a non-causal model? Suppose we intervene on the predictor variables or change the whole environment. The predictions from a causal model will in general work as well under interventions as for observational data. In contrast, predictions from a non-causal model can potentially be very wrong if we actively intervene on variables. Here, we propose to exploit this invariance of a prediction under a causal model for causal inference: given different experimental settings (for example various interventions) we collect all models that do show invariance in their predictive accuracy across settings and interventions. The causal model will be a member of this set of models with high probability. This approach yields valid confidence intervals for the causal relationships in quite general scenarios. We examine the example of structural equation models in more detail and provide sufficient assumptions under which the set of causal predictors becomes identifiable. We further investigate robustness properties of our approach under model misspecification and discuss possible extensions. The empirical properties are studied for various data sets, including large-scale gene perturbation experiments.},
author = {Peters, Jonas and Meinshausen, Nicolai and B{\"{u}}hlmann, Peter},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society Series B (Statistical Methodology)/Peters, Meinshausen, B{\"{u}}hlmann - 2016 - Causal inference using invariant prediction identification and confidence intervals (with discus.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {causal discovery,causal inference,causality,confidence intervals,invariant prediction,to-skim},
mendeley-tags = {causality,to-skim},
number = {5},
pages = {947--1012},
title = {{Causal inference using invariant prediction: identification and confidence intervals (with discussion)}},
volume = {78},
year = {2016}
}
@article{PetS09,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/19571811{\}}{\{}19571811{\}}},
author = {Purcell, S M and Wray, N R and Stone, J L and Visscher, P M and O'Donovan, M C and Sullivan, P F and Sklar, P},
journal = {Nature},
month = {aug},
number = {7256},
pages = {748--752},
title = {{{\{}C{\}}ommon polygenic variation contributes to risk of schizophrenia and bipolar disorder}},
volume = {460},
year = {2009}
}
@article{TC01,
author = {Tusher, Virginia G. and Tibshirani, Robert and Chu, Gilbert},
journal = {Proceedings of the National Academy of Sciences},
keywords = {genetics},
mendeley-tags = {genetics},
number = {9},
pages = {5116--5121},
title = {{Significance analysis of microarrays applied to the ionizing radiation response}},
volume = {98},
year = {2001}
}
@article{Chen2018,
abstract = {Read counting and unique molecular identifier (UMI) counting are the principal gene expression quantification schemes used in single-cell RNA-sequencing (scRNA-seq) analysis. By using multiple scRNA-seq datasets, we reveal distinct distribution differences between these schemes and conclude that the negative binomial model is a good approximation for UMI counts, even in heterogeneous populations. We further propose a novel differential expression analysis algorithm based on a negative binomial model with independent dispersions in each group (NBID). Our results show that this properly controls the FDR and achieves better power for UMI counts when compared to other recently developed packages for scRNA-seq analysis.},
author = {Chen, Wenan and Li, Yan and Easton, John and Finkelstein, David and Wu, Gang and Chen, Xiang},
doi = {10.1186/s13059-018-1438-9},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Chen et al. - 2018 - UMI-count modeling and differential expression analysis for single-cell RNA sequencing.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Differential expression analysis,Negative binomial,Unique molecular identifier,differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {1},
pages = {1--17},
pmid = {29855333},
publisher = {Genome Biology},
title = {{UMI-count modeling and differential expression analysis for single-cell RNA sequencing}},
volume = {19},
year = {2018}
}
@book{TSH,
address = {New York},
author = {Lehmann, E. L. and Romano, Joseph P.},
doi = {10.2307/2982206},
edition = {Third},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Lehmann, Romano - 2005 - Testing Statistical Hypotheses.pdf:pdf},
isbn = {0387988645},
issn = {09641998},
publisher = {Springer},
title = {{Testing Statistical Hypotheses}},
year = {2005}
}
@article{Whalen2019,
author = {Whalen, Sean and Pollard, Katherine S.},
doi = {10.1038/s41588-019-0473-0},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Whalen, Pollard - 2019 - Reply to ‘Inflated performance measures in enhancer–promoter interaction-prediction methods'.pdf:pdf},
issn = {1061-4036},
journal = {Nature Genetics},
keywords = {Kathryn,gene-enhancer,genetics},
mendeley-tags = {Kathryn,gene-enhancer,genetics},
number = {8},
pages = {1198--1200},
title = {{Reply to ‘Inflated performance measures in enhancer–promoter interaction-prediction methods'}},
volume = {51},
year = {2019}
}
@article{Duchi2018,
author = {Duchi, John},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Technical Report, Stanford University/Duchi - 2018 - A few notes on contiguity, asymptotics, and local asymptotic normality.pdf:pdf},
journal = {Technical Report, Stanford University},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
title = {{A few notes on contiguity, asymptotics, and local asymptotic normality}},
year = {2018}
}
@article{Meissner2005,
abstract = {We describe a large-scale random approach termed reduced representation bisulfite sequencing (RRBS) for analyzing and comparing genomic methylation patterns. BgIII restriction fragments were size-selected to 500-600 bp, equipped with adapters, treated with bisulfite, PCR amplified, cloned and sequenced. We constructed RRBS libraries from murine ES cells and from ES cells lacking DNA methyltransferases Dnmt3a and 3b and with knocked-down (kd) levels of Dnmt1 (Dnmt[1kd, 3a-/-,3b-/-]). Sequencing of 960 RRBS clones from Dnmt[1kd,3a-/-,3b-/-] cells generated 343 kb of non-redundant bisulfite sequence covering 66212 cytosines in the genome. All but 38 cytosines had been converted to uracil indicating a conversion rate of {\textgreater}99.9{\%}. Of the remaining cytosines 35 were found in CpG and 3 in CpT dinucleotides. Non-CpG methylation was {\textgreater}250-fold reduced compared with wild-type ES cells, consistent with a role for Dnmt3a and/or Dnmt3b in CpA and CpT methylation. Closer inspection revealed neither a consensus sequence around the methylated sites nor evidence for clustering of residual methylation in the genome. Our findings indicate random loss rather than specific maintenance of methylation in Dnmt[1kd,3a-/-,3b-/-] cells. Near-complete bisulfite conversion and largely unbiased representation of RRBS libraries suggest that random shotgun bisulfite sequencing can be scaled to a genome-wide approach. {\textcopyright} The Author 2005. Published by Oxford University Press. All rights reserved.},
author = {Meissner, Alexander and Gnirke, Andreas and Bell, George W. and Ramsahoye, Bernard and Lander, Eric S. and Jaenisch, Rudolf},
doi = {10.1093/nar/gki901},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nucleic Acids Research/Meissner et al. - 2005 - Reduced representation bisulfite sequencing for comparative high-resolution DNA methylation analysis.pdf:pdf},
issn = {03051048},
journal = {Nucleic Acids Research},
number = {18},
pages = {5868--5877},
pmid = {16224102},
title = {{Reduced representation bisulfite sequencing for comparative high-resolution DNA methylation analysis}},
volume = {33},
year = {2005}
}
@article{WetZ17,
author = {Wang, Jing and Vasaikar, Suhas and Shi, Zhiao and Greer, Michael and Zhang, Bing},
journal = {Nucleic acids research},
keywords = {Gene Ontology,software},
mendeley-tags = {Gene Ontology,software},
number = {W1},
pages = {W130----W137},
publisher = {Oxford University Press},
title = {{WebGestalt 2017: a more comprehensive, powerful, flexible and interactive gene set enrichment analysis toolkit}},
volume = {45},
year = {2017}
}
@article{Hung2019,
abstract = {Large-scale replication studies like the Reproducibility Project: Psychology (RP:P) provide invaluable systematic data on scientific replicability, but most analyses and interpretations of the data fail to agree on the definition of "replicability" and disentangle the inexorable consequences of known selection bias from competing explanations. We discuss three concrete definitions of replicability based on (1) whether published findings about the signs of effects are mostly correct, (2) how effective replication studies are in reproducing whatever true effect size was present in the original experiment, and (3) whether true effect sizes tend to diminish in replication. We apply techniques from multiple testing and post-selection inference to develop new methods that answer these questions while explicitly accounting for selection bias. Re-analyzing the RP:P data, we estimate that 22 out of 68 (32{\%}) original directional claims were false (upper confidence bound 47{\%}); by comparison, we estimate that among claims significant at the stricter significance threshold 0.005, only 2.2 out of 33 (7{\%}) were directionally false (upper confidence bound 18{\%}). In addition, we compute selection-adjusted confidence intervals for the difference in effect size between original and replication studies and, after adjusting for multiplicity, identify five (11{\%}) which exclude zero (exact replication). We estimate that the effect size declined by at least 20{\%} in the replication study relative to the original study in 16 of the 46 (35{\%}) study pairs (lower confidence bound 11{\%}). Our methods make no distributional assumptions about the true effect sizes.},
archivePrefix = {arXiv},
arxivId = {1903.08747},
author = {Hung, Kenneth and Fithian, William},
eprint = {1903.08747},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Hung, Fithian - 2019 - Statistical Methods for Replicability Assessment.pdf:pdf},
journal = {arXiv},
title = {{Statistical Methods for Replicability Assessment}},
url = {http://arxiv.org/abs/1903.08747},
year = {2019}
}
@article{Song2019,
abstract = {Mutations in gene regulatory elements have been associated with a wide range of complex neuropsychiatric disorders. However, due to their cell-type specificity and difficulties in characterizing their regulatory targets, the ability to identify causal genetic variants has remained limited. To address these constraints, we perform an integrative analysis of chromatin interactions, open chromatin regions and transcriptomes using promoter capture Hi-C, assay for transposase-accessible chromatin with highthroughput sequencing (ATAC-seq) and RNA sequencing, respectively, in four functionally distinct neural cell types: induced pluripotent stem cell (iPSC)-induced excitatory neurons and lower motor neurons, iPSC-derived hippocampal dentate gyruslike neurons and primary astrocytes. We identify hundreds of thousands of long-range cis-interactions between promoters and distal promoter-interacting regions, enabling us to link regulatory elements to their target genes and reveal putative processes that are dysregulated in disease. Finally, we validate several promoter-interacting regions by using clustered regularly interspaced short palindromic repeats (CRISPR) techniques in human excitatory neurons, demonstrating that CDK5RAP3, STRAP and DRD2 are transcriptionally regulated by physically linked enhancers.},
author = {Song, Michael and Yang, Xiaoyu and Ren, Xingjie and Maliskova, Lenka and Li, Bingkun and Jones, Ian R. and Wang, Chao and Jacob, Fadi and Wu, Kenneth and Tragli, Michela and Tam, Tsz Wai and Jamieson, Kirsty and Lu, Si-Yao and Ming, Guo-Li and Li, Yun and Yao, Jun and Weiss, Lauren A. and Dixon, Jesse R. and Judge, Luke M. and Conklin, Bruce R. and Song, Hongjun and Gan, Li and Shen, Yin},
doi = {10.1038/s41588-019-0472-1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Song et al. - 2019 - Mapping cis-regulatory chromatin contacts in neural cells links neuropsychiatric disorder risk variants to target g.pdf:pdf},
journal = {Nature Genetics},
keywords = {Kathryn,enhancer,gene-enhancer,genetics},
mendeley-tags = {Kathryn,enhancer,gene-enhancer,genetics},
pages = {1252--1262},
title = {{Mapping cis-regulatory chromatin contacts in neural cells links neuropsychiatric disorder risk variants to target genes}},
url = {https://doi.org/10.1038/s41588-019-0472-1},
volume = {51},
year = {2019}
}
@article{pmid22549815,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/22549815{\}}{\{}22549815{\}}},
author = {Valdar, W and Sabourin, J and Nobel, A and Holmes, C C},
journal = {Genetic Epidemiology},
keywords = {LASSO,genetics},
mendeley-tags = {LASSO,genetics},
month = {apr},
title = {{{\{}R{\}}eprioritizing {\{}G{\}}enetic {\{}A{\}}ssociations in {\{}H{\}}it {\{}R{\}}egions {\{}U{\}}sing {\{}L{\}}{\{}A{\}}{\{}S{\}}{\{}S{\}}{\{}O{\}}-{\{}B{\}}ased {\{}R{\}}esample {\{}M{\}}odel {\{}A{\}}veraging}},
year = {2012}
}
@article{Wang2011,
abstract = {Mammalian genomes are populated with thousands of transcriptional enhancers that orchestrate cell-type-specific gene expression programs, but how those enhancers are exploited to institute alternative, signal-dependent transcriptional responses remains poorly understood. Here we present evidence that cell-lineage-specific factors, such as FoxA1, can simultaneously facilitate and restrict key regulated transcription factors, exemplified by the androgen receptor (AR), to act on structurally and functionally distinct classes of enhancer. Consequently, FoxA1 downregulation, an unfavourable prognostic sign in certain advanced prostate tumours, triggers dramatic reprogramming of the hormonal response by causing a massive switch in AR binding to a distinct cohort of pre-established enhancers. These enhancers are functional, as evidenced by the production of enhancer-templated non-coding RNA (eRNA) based on global nuclear run-on sequencing (GRO-seq) analysis, with a unique class apparently requiring no nucleosome remodelling to induce specific enhancer-promoter looping and gene activation. GRO-seq data also suggest that liganded AR induces both transcription initiation and elongation. Together, these findings reveal a large repository of active enhancers that can be dynamically tuned to elicit alternative gene expression programs, which may underlie many sequential gene expression events in development, cell differentiation and disease progression.},
author = {Wang, Dong and Garcia-Bassets, Ivan and Benner, Chris and Li, Wenbo and Su, Xue and Zhou, Yiming and Qiu, Jinsong and Liu, Wen and Kaikkonen, Minna U. and Ohgi, Kenneth A. and Glass, Christopher K. and Rosenfeld, Michael G. and Fu, Xiang Dong},
doi = {10.1038/nature10006},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Wang et al. - 2011 - Reprogramming transcription by distinct classes of enhancers functionally defined by eRNA.pdf:pdf},
issn = {00280836},
journal = {Nature},
keywords = {Kathryn,eRNA},
mendeley-tags = {Kathryn,eRNA},
number = {7351},
pages = {390--397},
publisher = {Nature Publishing Group},
title = {{Reprogramming transcription by distinct classes of enhancers functionally defined by eRNA}},
url = {http://dx.doi.org/10.1038/nature10006},
volume = {474},
year = {2011}
}
@article{Dolejsi2014,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25061809{\}}{\{}25061809{\}}},
author = {Dolejsi, E and Bodenstorfer, B and Frommlet, F},
journal = {PLOS One},
number = {7},
pages = {e103322},
title = {{Analyzing genome-wide association studies with an {\{}FDR{\}} controlling modification of the {\{}B{\}}ayesian {\{}I{\}}nformation {\{}C{\}}riterion}},
volume = {9},
year = {2014}
}
@article{GTExPilot,
author = {Ardlie, K G and Deluca, D S and Segr{\`{e}}, A V and Sullivan, T J and Young, T R and Gelfand, E T and Trowbridge, C A and Maller, J B and Tukiainen, T and al. Lek, M $\backslash$textitet},
journal = {Science},
keywords = {eQTL,genetics},
mendeley-tags = {eQTL,genetics},
number = {6235},
pages = {648--660},
publisher = {American Association for the Advancement of Science},
title = {{The Genotype-Tissue Expression (GTEx) pilot analysis: Multitissue gene regulation in humans}},
volume = {348},
year = {2015}
}
@article{BHY09,
abstract = {We explain the problem of selective inference in complex research using a recently published study: a replicability study of the associations in order to reveal and establish risk loci for type 2 diabetes. The false discovery rate approach to such problems will be reviewed, and we further address two problems: (i) setting confidence intervals on the size of the risk at the selected locations and (ii) selecting the replicable results.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/19805444{\}}{\{}19805444{\}}},
author = {Benjamini, Y and Heller, R and Yekutieli, D},
doi = {10.1098/rsta.2009.0127},
journal = {Philos Transact A Math Phys Eng Sci},
number = {1906},
pages = {4255--4271},
title = {{Selective inference in complex research}},
url = {http://www.hubmed.org/display.cgi?uids=19805444},
volume = {367},
year = {2009}
}
@article{Rosenbaum2002,
abstract = {By slightly reframing the concept of covariance adjustment in randomized experiments, a method of exact permutation inference is derived that is entirely free of distributional assumptions and uses the random assignment of treatments as the "reasoned basis for inference." This method of exact permutation inference may be used with many forms of covariance adjustment, including robust regression and locally weighted smoothers. The method is then generalized to observational studies where treatments were not randomly assigned, so that sensitivity to hidden biases must be examined. Adjustments using an instrumental variable are also discussed. The methods are illustrated using data from two observational studies.},
author = {Rosenbaum, Paul R.},
doi = {10.1214/ss/1042727942},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistical Science/Rosenbaum - 2002 - Covariance adjustment in randomized experiments and observational studies.pdf:pdf},
issn = {08834237},
journal = {Statistical Science},
keywords = {Covariance adjustment,Matching,Observational studies,Permutation inference,Propensity score,Randomization inference,Sensitivity analysis},
number = {3},
pages = {286--327},
title = {{Covariance adjustment in randomized experiments and observational studies}},
volume = {17},
year = {2002}
}
@article{BSB15,
archivePrefix = {arXiv},
arxivId = {math.ST/1511.09078},
author = {Brzyski, D and Su, W and Bogdan, M},
eprint = {1511.09078},
journal = {arXiv},
keywords = {62J07,90C25,FDR,G.1.6,G.3,Mathematics - Statistics Theory,Multiple testing,high-dimensional regression,unpublished},
mendeley-tags = {FDR,Multiple testing,high-dimensional regression,unpublished},
month = {nov},
primaryClass = {math.ST},
title = {{Group SLOPE - adaptive selection of groups of predictors}},
year = {2015}
}
@article{lei2016adapt,
author = {Lei, Lihua and Fithian, William},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,Multiple testing,structured multiple testing},
mendeley-tags = {FDR,Multiple testing,structured multiple testing},
number = {4},
pages = {649--679},
publisher = {Wiley Online Library},
title = {{AdaPT: an interactive procedure for multiple testing with side information}},
volume = {80},
year = {2018}
}
@article{Foss2007,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/17952072{\}}{\{}17952072{\}}},
author = {Foss, E J and Radulovic, D and Shaffer, S A and Ruderfer, D M and Bedalov, A and Goodlett, D R and Kruglyak, L},
journal = {Nature Genetics},
number = {11},
pages = {1369--1375},
title = {{Genetic basis of proteome variation in yeast}},
volume = {39},
year = {2007}
}
@article{Wasserman2009,
abstract = {This paper explores the following question: what kind of statistical guarantees can be given when doing variable selection in high-dimensional mod-els? In particular, we look at the error rates and power of some multi-stage regression methods. In the first stage we fit a set of candidate models. In the second stage we select one model by cross-validation. In the third stage we use hypothesis testing to eliminate some variables. We refer to the first two stages as "screening" and the last stage as "cleaning." We consider three screening methods: the lasso, marginal regression, and forward stepwise regression. Our method gives consistent variable selection under certain conditions .},
author = {Wasserman, Larry and Roeder, Kathryn},
doi = {10.1214/08-AOS646},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Wasserman, Roeder - 2009 - High-dimensional variable selection.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {Lasso,high-dimensional regression,screening,sparsity,stepwise regression},
mendeley-tags = {Lasso,high-dimensional regression,screening,sparsity},
number = {5A},
pages = {2178--2201},
title = {{High-dimensional variable selection}},
volume = {37},
year = {2009}
}
@article{HKS05,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/15961458{\}}{\{}15961458{\}}},
author = {Halperin, E and Kimmel, G and Shamir, R},
journal = {Bioinformatics},
month = {jun},
pages = {195--203},
title = {{{\{}T{\}}ag {\{}S{\}}{\{}N{\}}{\{}P{\}} selection in genotype data for maximizing {\{}S{\}}{\{}N{\}}{\{}P{\}} prediction accuracy}},
volume = {21 Suppl 1},
year = {2005}
}
@article{BR08,
author = {Blanchard, Gilles and Roquain, Etienne},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Electronic Journal of Statistics/Blanchard, Roquain - 2008 - Two simple sufficient conditions for FDR control.pdf:pdf},
journal = {Electronic Journal of Statistics},
keywords = {FDR},
mendeley-tags = {FDR},
pages = {963--992},
publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
title = {{Two simple sufficient conditions for FDR control}},
volume = {2},
year = {2008}
}
@article{Robins2009,
abstract = {We consider the minimax rate of testing or estimation of non-linear functionals defined on semiparametric models. Existing methods appear not capable of determining a lower bound on the minimax rate if the semiparametric model is indexed by several infinite-dimensional parameters. These methods test a single null distribution to a convex mixture of perturbed distributions. To cope with semiparametric functionals we extend these methods to comparing two convex mixtures. The first mixture is obtained by perturbing a first parameter of the model, and the second by perturbing in addition a second parameter. We obtain a lower bound on the affinity of the resulting pair of mixtures of product measures in terms of three parameters that measure the sizes and asymmetry of the perturbations. We apply the new result to two examples: the estimation of a mean response when response data are missing at random, and the estimation of an expected conditional covariance. {\textcopyright} 2009, Institute of Mathematical Statistics. All rights reserved.},
author = {Robins, James and Li, Lingling and {Van der Vaart}, Aad},
doi = {10.1214/09-EJS479},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Electronic Journal of Statistics/Robins, Li, Van der Vaart - 2009 - Semiparametric minimax rates.pdf:pdf},
issn = {19357524},
journal = {Electronic Journal of Statistics},
keywords = {Hellinger affinity,Hellinger distance,Missing data,Mixtures,Nonlinear functional,Nonparametric estimation},
number = {September},
pages = {1305--1321},
title = {{Semiparametric minimax rates}},
volume = {3},
year = {2009}
}
@article{Hemerik2018,
abstract = {When permutation methods are used in practice, often a limited number of random permutations are used to decrease the computational burden. However, most theoretical literature assumes that the whole permutation group is used, and methods based on random permutations tend to be seen as approximate. There exists a very limited amount of literature on exact testing with random permutations, and only recently a thorough proof of exactness was given. In this paper, we provide an alternative proof, viewing the test as a “conditional Monte Carlo test” as it has been called in the literature. We also provide extensions of the result. Importantly, our results can be used to prove properties of various multiple testing procedures based on random permutations.},
archivePrefix = {arXiv},
arxivId = {1411.7565},
author = {Hemerik, Jesse and Goeman, Jelle},
doi = {10.1007/s11749-017-0571-1},
eprint = {1411.7565},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Test/Hemerik, Goeman - 2018 - Exact testing with random permutations.pdf:pdf},
isbn = {1174901705711},
issn = {11330686},
journal = {Test},
keywords = {Nonparametric test,Permutation test,Resampling},
number = {4},
pages = {811--825},
publisher = {Springer Berlin Heidelberg},
title = {{Exact testing with random permutations}},
url = {https://doi.org/10.1007/s11749-017-0571-1},
volume = {27},
year = {2018}
}
@article{Koike-Yusa2014,
abstract = {Identification of genes influencing a phenotype of interest is frequently achieved through genetic screening by RNA interference (RNAi) or knockouts. However, RNAi may only achieve partial depletion of gene activity, and knockout-based screens are difficult in diploid mammalian cells. Here we took advantage of the efficiency and high throughput of genome editing based on type II, clustered, regularly interspaced, short palindromic repeats (CRISPR)-CRISPR-associated (Cas) systems to introduce genome-wide targeted mutations in mouse embryonic stem cells (ESCs). We designed 87,897 guide RNAs (gRNAs) targeting 19,150 mouse protein-coding genes and used a lentiviral vector to express these gRNAs in ESCs that constitutively express Cas9. Screening the resulting ESC mutant libraries for resistance to either Clostridium septicum alpha-toxin or 6-thioguanine identified 27 known and 4 previously unknown genes implicated in these phenotypes. Our results demonstrate the potential for efficient loss-of-function screening using the CRISPR-Cas9 system. {\textcopyright} 2014 Nature America, Inc.},
author = {Koike-Yusa, Hiroko and Li, Yilong and Tan, E. Pien and Velasco-Herrera, Martin Del Castillo and Yusa, Kosuke},
doi = {10.1038/nbt.2800},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Koike-Yusa et al. - 2014 - Genome-wide recessive genetic screening in mammalian cells with a lentiviral CRISPR-guide RNA library.pdf:pdf},
issn = {15461696},
journal = {Nature Biotechnology},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {3},
pages = {267--273},
title = {{Genome-wide recessive genetic screening in mammalian cells with a lentiviral CRISPR-guide RNA library}},
volume = {32},
year = {2014}
}
@article{Wang2019f,
abstract = {Meta-analysis combines results from multiple studies aiming to increase power in finding their common effect. It would typically reject the null hypothesis of no effect if any one of the studies shows strong significance. The partial conjunction null hypothesis is rejected only when at least r of n component hypotheses are nonnull with r = 1 corresponding to a usual meta-analysis. Compared with meta-analysis, it can encourage replicable findings across studies. A by-product of it when applied to different r values is a confidence interval of r quantifying the proportion of nonnull studies. Benjamini and Heller (2008) provided a valid test for the partial conjunction null by ignoring the r − 1 smallest p-values and applying a valid meta-analysis p-value to the remaining n − r + 1 p-values. We provide sufficient and necessary conditions of admissible combined p-value for the partial conjunction hypothesis among monotone tests. Non-monotone tests always dominate monotone tests but are usually too unreasonable to be used in practice. Based on these findings, we propose a generalized form of Benjamini and Heller's test which allows usage of various types of meta-analysis p-values, and apply our method to an example in assessing replicable benefit of new anticoagulants across subgroups of patients for stroke prevention.},
archivePrefix = {arXiv},
arxivId = {1508.00934},
author = {Wang, Jingshu and Owen, Art B.},
doi = {10.1080/01621459.2017.1385465},
eprint = {1508.00934},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Wang, Owen - 2019 - Admissibility in Partial Conjunction Testing.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Combined p-values,Meta-analysis,Power,Replicable findings,Subgroup analysis,partial conjunction},
mendeley-tags = {partial conjunction},
number = {525},
pages = {158--168},
title = {{Admissibility in Partial Conjunction Testing}},
url = {https://doi.org/10.1080/01621459.2017.1385465},
volume = {114},
year = {2019}
}
@article{YetN06,
author = {Yekutieli, Daniel and Reiner-Benaim, Anat and Benjamini, Yoav and Elmer, Gregory I and Kafkafi, Neri and Letwin, Noah E and Lee, Norman H},
doi = {10.1111/j.1467-9574.2006.00343.x},
issn = {0039-0402},
journal = {Statist. Neerlandica},
number = {4},
pages = {414--437},
title = {{Approaches to multiplicity issues in complex research in microarray analysis}},
url = {http://dx.doi.org/10.1111/j.1467-9574.2006.00343.x},
volume = {60},
year = {2006}
}
@article{Lu2019a,
abstract = {Genome-wide mapping of chromatin interactions at high resolution remains experimentally and computationally challenging. Here we used a low-input “easy Hi-C” (eHi- C) protocol to map the 3D genome architecture in neurogenesis and brain tissues, and also developed an improved Hi-C bias-correction pipeline (HiCorr) enabling better identification of enhancer loops or aggregates at sub-TAD level. We compared ultra-deep 3D genome maps from 10 human tissue- or cell types, with a focus on stem cells and neural development. We found several large loci in skin-derived human iPSC lines showing recurrent 3D compartmental memory of somatic heterochromatin. Chromatin loop interactions, but not genome compartments, are hallmarks of neural differentiation. Interestingly, we observed many cell type- or differentiation-specific enhancer aggregates spanning large neighborhoods, supporting a phase-separation mechanism that stabilizes enhancer contacts during development. Finally, we demonstrated that chromatin loop outperforms eQTL in explaining neurological GWAS results, revealing a unique value of high-resolution 3D genome maps in elucidating the disease etiology.},
author = {Lu, Leina and Liu, Xiaoxiao and Huang, Wei-kai and Giusti-rodr{\'{i}}guez, Paola and Cui, Jian and Zhang, Shanshan and Xu, Wanying and Wen, Zhexing and Ma, Shufeng and Rosen, Jonathan D. and Xu, Zheng and Bartels, Cynthia and Kawaguchi, Riki and Hu, Ming and Scacheri, Peter and Rong, Zhili and Li, Yun and Sullivan, Patrick F. and Song, Hongjun and Ming, Guo-li and Li, Yan and Jin, Fulai},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Lu et al. - 2019 - Robust Hi-C chromatin loop maps in human neurogenesis and brain tissues at high- resolution.pdf:pdf},
journal = {bioRxiv},
keywords = {HI-C,Kathryn,gene-enhancer},
mendeley-tags = {HI-C,Kathryn,gene-enhancer},
title = {{Robust Hi-C chromatin loop maps in human neurogenesis and brain tissues at high- resolution}},
year = {2019}
}
@article{BetR17,
author = {Blanchard, G and Neuvial, P and Roquain, E},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Blanchard, Neuvial, Roquain - 2017 - Post hoc inference via joint family-wise error rate control.pdf:pdf},
journal = {arXiv},
keywords = {Multiple testing,simultaneous inference,unpublished},
mendeley-tags = {Multiple testing,simultaneous inference,unpublished},
title = {{Post hoc inference via joint family-wise error rate control}},
year = {2017}
}
@phdthesis{Dehman2016,
author = {Dehman, Alia},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Dehman - 2016 - Spatial Clustering of Linkage Disequilibrium blocks for Genome-Wide Association Studies.pdf:pdf},
keywords = {GWAS,to-skim},
mendeley-tags = {GWAS,to-skim},
title = {{Spatial Clustering of Linkage Disequilibrium blocks for Genome-Wide Association Studies}},
url = {https://tel.archives-ouvertes.fr/tel-01288568},
year = {2016}
}
@article{Dunham2012,
abstract = {The human genome encodes the blueprint of life, but the function of the vast majority of its nearly three billion bases is unknown. The Encyclopedia of DNA Elements (ENCODE) project has systematically mapped regions of transcription, transcription factor association, chromatin structure and histone modification. These data enabled us to assign biochemical functions for 80{\%} of the genome, in particular outside of the well-studied protein-coding regions. Many discovered candidate regulatory elements are physically associated with one another and with expressed genes, providing new insights into the mechanisms of gene regulation. The newly identified elements also show a statistical correspondence to sequence variants linked to human disease, and can thereby guide interpretation of this variation. Overall, the project provides new insights into the organization and regulation of our genes and genome, and is an expansive resource of functional annotations for biomedical research.},
author = {Dunham, Ian and Kundaje, Anshul and Aldred, Shelley F. and Collins, Patrick J. and Davis, Carrie A. and Doyle, Francis and Epstein, Charles B. and Frietze, Seth and Harrow, Jennifer and Kaul, Rajinder and Khatun, Jainab and Lajoie, Bryan R. and Landt, Stephen G. and Lee, Bum Kyu and Pauli, Florencia and Rosenbloom, Kate R. and Sabo, Peter and Safi, Alexias and Sanyal, Amartya and Shoresh, Noam and Simon, Jeremy M. and Song, Lingyun and Trinklein, Nathan D. and Altshuler, Robert C. and Birney, Ewan and Brown, James B. and Cheng, Chao and Djebali, Sarah and Dong, Xianjun and Ernst, Jason and Furey, Terrence S. and Gerstein, Mark and Giardine, Belinda and Greven, Melissa and Hardison, Ross C. and Harris, Robert S. and Herrero, Javier and Hoffman, Michael M. and Iyer, Sowmya and Kellis, Manolis and Kheradpour, Pouya and Lassmann, Timo and Li, Qunhua and Lin, Xinying and Marinov, Georgi K. and Merkel, Angelika and Mortazavi, Ali and Parker, Stephen C.J. and Reddy, Timothy E. and Rozowsky, Joel and Schlesinger, Felix and Thurman, Robert E. and Wang, Jie and Ward, Lucas D. and Whitfield, Troy W. and Wilder, Steven P. and Wu, Weisheng and Xi, Hualin S. and Yip, Kevin Y. and Zhuang, Jiali and Bernstein, Bradley E. and Green, Eric D. and Gunter, Chris and Snyder, Michael and Pazin, Michael J. and Lowdon, Rebecca F. and Dillon, Laura A.L. and Adams, Leslie B. and Kelly, Caroline J. and Zhang, Julia and Wexler, Judith R. and Good, Peter J. and Feingold, Elise A. and Crawford, Gregory E. and Dekker, Job and Elnitski, Laura and Farnham, Peggy J. and Giddings, Morgan C. and Gingeras, Thomas R. and Guig{\'{o}}, Roderic and Hubbard, Timothy J. and Kent, W. James and Lieb, Jason D. and Margulies, Elliott H. and Myers, Richard M. and Stamatoyannopoulos, John A. and Tenenbaum, Scott A. and Weng, Zhiping and White, Kevin P. and Wold, Barbara and Yu, Yanbao and Wrobel, John and Risk, Brian A. and Gunawardena, Harsha P. and Kuiper, Heather C. and Maier, Christopher W. and Xie, Ling and Chen, Xian and Mikkelsen, Tarjei S. and Gillespie, Shawn and Goren, Alon and Ram, Oren and Zhang, Xiaolan and Wang, Li and Issner, Robbyn and Coyne, Michael J. and Durham, Timothy and Ku, Manching and Truong, Thanh and Eaton, Matthew L. and Dobin, Alex and Tanzer, Andrea and Lagarde, Julien and Lin, Wei and Xue, Chenghai and Williams, Brian A. and Zaleski, Chris and R{\"{o}}der, Maik and Kokocinski, Felix and Abdelhamid, Rehab F. and Alioto, Tyler and Antoshechkin, Igor and Baer, Michael T. and Batut, Philippe and Bell, Ian and Bell, Kimberly and Chakrabortty, Sudipto and Chrast, Jacqueline and Curado, Joao and Derrien, Thomas and Drenkow, Jorg and Dumais, Erica and Dumais, Jackie and Duttagupta, Radha and Fastuca, Megan and Fejes-Toth, Kata and Ferreira, Pedro and Foissac, Sylvain and Fullwood, Melissa J. and Gao, Hui and Gonzalez, David and Gordon, Assaf and Howald, C{\'{e}}dric and Jha, Sonali and Johnson, Rory and Kapranov, Philipp and King, Brandon and Kingswood, Colin and Li, Guoliang and Luo, Oscar J. and Park, Eddie and Preall, Jonathan B. and Presaud, Kimberly and Ribeca, Paolo and Robyr, Daniel and Ruan, Xiaoan and Sammeth, Michael and Sandhu, Kuljeet Singh and Schaeffer, Lorain and See, Lei Hoon and Shahab, Atif and Skancke, Jorgen and Suzuki, Ana Maria and Takahashi, Hazuki and Tilgner, Hagen and Trout, Diane and Walters, Nathalie and Wang, Huaien and Hayashizaki, Yoshihide and Reymond, Alexandre and Antonarakis, Stylianos E. and Hannon, Gregory J. and Ruan, Yijun and Carninci, Piero and Sloan, Cricket A. and Learned, Katrina and Malladi, Venkat S. and Wong, Matthew C. and Barber, Galt P. and Cline, Melissa S. and Dreszer, Timothy R. and Heitner, Steven G. and Karolchik, Donna and Kirkup, Vanessa M. and Meyer, Laurence R. and Long, Jeffrey C. and Maddren, Morgan and Raney, Brian J. and Grasfeder, Linda L. and Giresi, Paul G. and Battenhouse, Anna and Sheffield, Nathan C. and Showers, Kimberly A. and London, Darin and Bhinge, Akshay A. and Shestak, Christopher and Schaner, Matthew R. and Kim, Seul Ki and Zhang, Zhuzhu Z. and Mieczkowski, Piotr A. and Mieczkowska, Joanna O. and Liu, Zheng and McDaniell, Ryan M. and Ni, Yunyun and Rashid, Naim U. and Kim, Min Jae and Adar, Sheera and Zhang, Zhancheng and Wang, Tianyuan and Winter, Deborah and Keefe, Damian and Iyer, Vishwanath R. and Zheng, Meizhen and Wang, Ping and Gertz, Jason and Vielmetter, Jost and Partridge, E. Christopher and Varley, Katherine E. and Gasper, Clarke and Bansal, Anita and Pepke, Shirley and Jain, Preti and Amrhein, Henry and Bowling, Kevin M. and Anaya, Michael and Cross, Marie K. and Muratet, Michael A. and Newberry, Kimberly M. and McCue, Kenneth and Nesmith, Amy S. and Fisher-Aylor, Katherine I. and Pusey, Barbara and DeSalvo, Gilberto and Parker, Stephanie L. and Balasubramanian, Sreeram and Davis, Nicholas S. and Meadows, Sarah K. and Eggleston, Tracy and Newberry, J. Scott and Levy, Shawn E. and Absher, Devin M. and Wong, Wing H. and Blow, Matthew J. and Visel, Axel and Pennachio, Len A. and Petrykowska, Hanna M. and Abyzov, Alexej and Aken, Bronwen and Barrell, Daniel and Barson, Gemma and Berry, Andrew and Bignell, Alexandra and Boychenko, Veronika and Bussotti, Giovanni and Davidson, Claire and Despacio-Reyes, Gloria and Diekhans, Mark and Ezkurdia, Iakes and Frankish, Adam and Gilbert, James and Gonzalez, Jose Manuel and Griffiths, Ed and Harte, Rachel and Hendrix, David A. and Hunt, Toby and Jungreis, Irwin and Kay, Mike and Khurana, Ekta and Leng, Jing and Lin, Michael F. and Loveland, Jane and Lu, Zhi and Manthravadi, Deepa and Mariotti, Marco and Mudge, Jonathan and Mukherjee, Gaurab and Notredame, Cedric and Pei, Baikang and Rodriguez, Jose Manuel and Saunders, Gary and Sboner, Andrea and Searle, Stephen and Sisu, Cristina and Snow, Catherine and Steward, Charlie and Tapanari, Electra and Tress, Michael L. and {Van Baren}, Marijke J. and Washietl, Stefan and Wilming, Laurens and Zadissa, Amonida and Zhang, Zhengdong and Brent, Michael and Haussler, David and Valencia, Alfonso and Addleman, Nick and Alexander, Roger P. and Auerbach, Raymond K. and Balasubramanian, Suganthi and Bettinger, Keith and Bhardwaj, Nitin and Boyle, Alan P. and Cao, Alina R. and Cayting, Philip and Charos, Alexandra and Cheng, Yong and Eastman, Catharine and Euskirchen, Ghia and Fleming, Joseph D. and Grubert, Fabian and Habegger, Lukas and Hariharan, Manoj and Harmanci, Arif and Iyengar, Sushma and Jin, Victor X. and Karczewski, Konrad J. and Kasowski, Maya and Lacroute, Phil and Lam, Hugo and Lamarre-Vincent, Nathan and Lian, Jin and Lindahl-Allen, Marianne and Min, Renqiang and Miotto, Benoit and Monahan, Hannah and Moqtaderi, Zarmik and Mu, Xinmeng J. and O'Geen, Henriette and Ouyang, Zhengqing and Patacsil, Dorrelyn and Raha, Debasish and Ramirez, Lucia and Reed, Brian and Shi, Minyi and Slifer, Teri and Witt, Heather and Wu, Linfeng and Xu, Xiaoqin and Yan, Koon Kiu and Yang, Xinqiong and Struhl, Kevin and Weissman, Sherman M. and Penalva, Luiz O. and Karmakar, Subhradip and Bhanvadia, Raj R. and Choudhury, Alina and Domanus, Marc and Ma, Lijia and Moran, Jennifer and Victorsen, Alec and Auer, Thomas and Centanin, Lazaro and Eichenlaub, Michael and Gruhl, Franziska and Heermann, Stephan and Hoeckendorf, Burkhard and Inoue, Daigo and Kellner, Tanja and Kirchmaier, Stephan and Mueller, Claudia and Reinhardt, Robert and Schertel, Lea and Schneider, Stephanie and Sinn, Rebecca and Wittbrodt, Beate and Wittbrodt, Jochen and Jain, Gaurav and Balasundaram, Gayathri and Bates, Daniel L. and Byron, Rachel and Canfield, Theresa K. and Diegel, Morgan J. and Dunn, Douglas and Ebersol, Abigail K. and Frum, Tristan and Garg, Kavita and Gist, Erica and Hansen, R. Scott and Boatman, Lisa and Haugen, Eric and Humbert, Richard and Johnson, Audra K. and Johnson, Ericka M. and Kutyavin, Tattyana V. and Lee, Kristen and Lotakis, Dimitra and Maurano, Matthew T. and Neph, Shane J. and Neri, Fiedencio V. and Nguyen, Eric D. and Qu, Hongzhu and Reynolds, Alex P. and Roach, Vaughn and Rynes, Eric and Sanchez, Minerva E. and Sandstrom, Richard S. and Shafer, Anthony O. and Stergachis, Andrew B. and Thomas, Sean and Vernot, Benjamin and Vierstra, Jeff and Vong, Shinny and Wang, Hao and Weaver, Molly A. and Yan, Yongqi and Zhang, Miaohua and Akey, Joshua M. and Bender, Michael and Dorschner, Michael O. and Groudine, Mark and MacCoss, Michael J. and Navas, Patrick and Stamatoyannopoulos, George and Beal, Kathryn and Brazma, Alvis and Flicek, Paul and Johnson, Nathan and Lukk, Margus and Luscombe, Nicholas M. and Sobral, Daniel and Vaquerizas, Juan M. and Batzoglou, Serafim and Sidow, Arend and Hussami, Nadine and Kyriazopoulou-Panagiotopoulou, Sofia and Libbrecht, Max W. and Schaub, Marc A. and Miller, Webb and Bickel, Peter J. and Banfai, Balazs and Boley, Nathan P. and Huang, Haiyan and Li, Jingyi Jessica and Noble, William Stafford and Bilmes, Jeffrey A. and Buske, Orion J. and Sahu, Avinash D. and Kharchenko, Peter V. and Park, Peter J. and Baker, Dannon and Taylor, James and Lochovsky, Lucas},
doi = {10.1038/nature11247},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Dunham et al. - 2012 - An integrated encyclopedia of DNA elements in the human genome.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {enhancer,epigenetics,genetics},
mendeley-tags = {enhancer,epigenetics,genetics},
number = {7414},
pages = {57--74},
title = {{An integrated encyclopedia of DNA elements in the human genome}},
volume = {489},
year = {2012}
}
@article{VetD13,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23359524{\}}{\{}23359524{\}}},
author = {van der Sluis, Sophie and Posthuma, Danielle and Dolan, Conor V},
journal = {PLoS Genetics},
keywords = {multiple phenotypes},
mendeley-tags = {multiple phenotypes},
number = {1},
pages = {e1003235},
publisher = {Public Library of Science},
title = {{TATES: efficient multivariate genotype-phenotype analysis for genome-wide association studies}},
volume = {9},
year = {2013}
}
@article{Hicks2018,
abstract = {Until recently, high-throughput gene expression technology, such asRNA-Sequencing (RNA-seq) required hundreds of thousands of cells to produce reliable measurements. Recent technical advances permit genome-wide gene expression measurement at the single-cell level. Single-cell RNA-Seq (scRNA-seq) is the most widely used and numerous publications are based on data produced with this technology. However, RN A-seq and scRNA-seq data are markedly different. In particular, unlike RNA-seq, the majority ofreported expression levels in scRNA-seq are zeros, which could be either biologically-driven, genes not expressing RNA at the time of measurement, or technically-driven, genes expressing RNA, but not at a sufficient level to be detected by sequencing technology. Another difference is that the proportion of genes reporting the expression level to be zero varies substantially across single cells compared to RNA-seq samples. However, it remains unclear to what extent this cell-to-cell variation is being driven by technical rather than biological variation. Furthermore, while systematic errors, including batch effects, have been widely reported as a major challenge in high-throughput technologies, these issues have received minimal attention in published studies based on scRNA-seq technology. Here, we use an assessment experiment to examine data from published studies and demonstrate that systematic errors can explain a substantial percentage of observed cell-to-cell expression variability. Specifically, we present evidence that some of these reported zeros are driven by technical variation by demonstrating that scRNA-seq produces more zeros than expected and that this bias is greater for lower expressed genes. In addition, this missing data problem is exacerbated by the fact that this technical variation varies cell-to-cell. Then, we show how this technical cell-to-cell variability can be confused with novel biological results. Finally, we demonstrate and discuss how batch-effects and confounded experiments can intensify the problem.},
author = {Hicks, Stephanie C. and Townes, F. William and Teng, Mingxiang and Irizarry, Rafael A.},
doi = {10.1093/biostatistics/kxx053},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biostatistics/Hicks et al. - 2018 - Missing data and technical variability in single-cell RNA-sequencing experiments.pdf:pdf},
issn = {14684357},
journal = {Biostatistics},
keywords = {Censoring,Confounding.,Genomics,Missing not at random (MNAR),Single-cell RNA-Sequencing,single cell},
mendeley-tags = {single cell},
number = {4},
pages = {562--578},
title = {{Missing data and technical variability in single-cell RNA-sequencing experiments}},
volume = {19},
year = {2018}
}
@article{SetA05,
annote = {16251467},
author = {Schaffner, S F and Foo, C and Gabriel, S and Reich, D and Daly, M J and Altshuler, D},
journal = {Genome Res.},
keywords = {genetics},
mendeley-tags = {genetics},
month = {nov},
pages = {1576--1583},
title = {{{\{}C{\}}alibrating a coalescent simulation of human genome sequence variation}},
volume = {15},
year = {2005}
}
@article{Gier2020,
abstract = {CRISPR-based genetic screening has revolutionized cancer drug target discovery, yet reliable, multiplex gene editing to reveal synergies between gene targets remains a major challenge. Here, we present a simple and robust CRISPR-Cas12a-based approach for combinatorial genetic screening in cancer cells. By engineering the CRISPR-AsCas12a system with key modifications to the Cas protein and its CRISPR RNA (crRNA), we can achieve high efficiency combinatorial genetic screening. We demonstrate the performance of our optimized AsCas12a (opAsCas12a) through double knockout screening against epigenetic regulators. This screen reveals synthetic sick interactions between Brd9{\&}Jmjd6, Kat6a{\&}Jmjd6, and Brpf1{\&}Jmjd6 in leukemia cells.},
author = {Gier, Rodrigo A. and Budinich, Krista A. and Evitt, Niklaus H. and Cao, Zhendong and Freilich, Elizabeth S. and Chen, Qingzhou and Qi, Jun and Lan, Yemin and Kohli, Rahul M. and Shi, Junwei},
doi = {10.1038/s41467-020-17209-1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Gier et al. - 2020 - High-performance CRISPR-Cas12a genome editing for combinatorial genetic screening.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
keywords = {CRISPR,to-read},
mendeley-tags = {CRISPR,to-read},
number = {1},
pages = {1--9},
pmid = {32661245},
publisher = {Springer US},
title = {{High-performance CRISPR-Cas12a genome editing for combinatorial genetic screening}},
url = {http://dx.doi.org/10.1038/s41467-020-17209-1},
volume = {11},
year = {2020}
}
@article{Hoadley1971,
author = {Hoadley, Bruce},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Mathematical Statistics/Hoadley - 1971 - Asymptotic Properties of Maximum Likelihood Estimators for the Independent Not Identically Distributed Case.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {6},
pages = {1977--1991},
title = {{Asymptotic Properties of Maximum Likelihood Estimators for the Independent Not Identically Distributed Case}},
volume = {42},
year = {1971}
}
@article{Lee2020,
abstract = {Advances in single-cell isolation and barcoding technologies offer unprecedented opportunities to profile DNA, mRNA, and proteins at a single-cell resolution. Recently, bulk multiomics analyses, such as multidimensional genomic and proteogenomic analyses, have proven beneficial for obtaining a comprehensive understanding of cellular events. This benefit has facilitated the development of single-cell multiomics analysis, which enables cell type-specific gene regulation to be examined. The cardinal features of single-cell multiomics analysis include (1) technologies for single-cell isolation, barcoding, and sequencing to measure multiple types of molecules from individual cells and (2) the integrative analysis of molecules to characterize cell types and their functions regarding pathophysiological processes based on molecular signatures. Here, we summarize the technologies for single-cell multiomics analyses (mRNA-genome, mRNA-DNA methylation, mRNA-chromatin accessibility, and mRNA-protein) as well as the methods for the integrative analysis of single-cell multiomics data.},
author = {Lee, Jeongwoo and Hyeon, Do Young and Hwang, Daehee},
doi = {10.1038/s12276-020-0420-2},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Experimental and Molecular Medicine/Lee, Hyeon, Hwang - 2020 - Single-cell multiomics technologies and data analysis methods.pdf:pdf},
issn = {20926413},
journal = {Experimental and Molecular Medicine},
keywords = {multi-omics,single cell},
mendeley-tags = {multi-omics,single cell},
number = {9},
pages = {1428--1442},
pmid = {32929225},
publisher = {Springer US},
title = {{Single-cell multiomics: technologies and data analysis methods}},
url = {http://dx.doi.org/10.1038/s12276-020-0420-2},
volume = {52},
year = {2020}
}
@article{M15,
annote = {$\backslash$href{\{}http://www.nature.com/nmeth/journal/v12/n8/full/nmeth.3487.html{\}}{\{}doi:10.1038/nmeth.3487{\}}},
author = {Marx, V},
journal = {Nature Methods},
month = {jul},
pages = {711--714},
title = {{{\{}H{\}}uman phenotyping on a population scale}},
volume = {12},
year = {2015}
}
@article{Wissink2019,
abstract = {The programmes that direct an organism's development and maintenance are encoded in its genome. Decoding of this information begins with regulated transcription of genomic DNA into RNA. Although transcription and its control can be tracked indirectly by measuring stable RNAs, it is only by directly measuring nascent RNAs that the immediate regulatory changes in response to developmental, environmental, disease and metabolic signals are revealed. Multiple complementary methods have been developed to quantitatively track nascent transcription genome-wide at nucleotide resolution, all of which have contributed novel insights into the mechanisms of gene regulation and transcription-coupled RNA processing. Here we critically evaluate the array of strategies used for investigating nascent transcription and discuss the recent conceptual advances they have provided.},
author = {Wissink, Erin M and Vihervaara, Anniina and Tippens, Nathaniel D and Lis, John T},
doi = {10.1038/s41576-019-0159-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Reviews Genetics/Wissink et al. - 2019 - Nascent RNA analyses tracking transcription and its regulation.pdf:pdf},
journal = {Nature Reviews Genetics},
keywords = {Kathryn,PRO-seq,enhancer},
mendeley-tags = {Kathryn,PRO-seq,enhancer},
title = {{Nascent RNA analyses: tracking transcription and its regulation}},
url = {www.nature.com/nrg},
year = {2019}
}
@article{S10,
abstract = {Measures of genomic similarity are the basis of many statistical analytic methods. We review the mathematical and statistical basis of similarity methods, particularly based on kernel methods. A kernel function converts information for a pair of subjects to a quantitative value representing either similarity (larger values meaning more similar) or distance (smaller values meaning more similar), with the requirement that it must create a positive semidefinite matrix when applied to all pairs of subjects. This review emphasizes the wide range of statistical methods and software that can be used when similarity is based on kernel methods, such as nonparametric regression, linear mixed models and generalized linear mixed models, hierarchical models, score statistics, and support vector machines. The mathematical rigor for these methods is summarized, as is the mathematical framework for making kernels. This review provides a framework to move from intuitive and heuristic approaches to define genomic similarities to more rigorous methods that can take advantage of powerful statistical modeling and existing software. A companion paper reviews novel approaches to creating kernels that might be useful for genomic analyses, providing insights with examples [1].},
annote = {20610906},
author = {Schaid, D J},
doi = {10.1159/000312641},
journal = {Hum Hered},
number = {2},
pages = {109--131},
title = {{Genomic Similarity and Kernel Methods I: Advancements by Building on Mathematical and Statistical Foundations}},
url = {http://www.hubmed.org/display.cgi?uids=20610906},
volume = {70},
year = {2010}
}
@article{Delaigle2011a,
abstract = {Student's t-statistic is finding applications today that were never envisaged when it was introduced more than a century ago. Many of these applications rely on properties, e.g. robustness against heavy-tailed sampling distributions, that were not explicitly considered until relatively recently. We explore these features of the t-statistic in the context of its application to very high dimensional problems, including feature selection and ranking, the simultaneous testing of many different hypotheses and sparse, high dimensional signal detection. Robustness properties of the t-ratio are highlighted, and it is established that those properties are preserved under applications of the bootstrap. In particular, bootstrap methods correct for skewness and therefore lead to second-order accuracy, even in the extreme tails. Indeed, it is shown that the bootstrap and also the more popular but less accurate t-distribution and normal approximations are more effective in the tails than towards the middle of the distribution. These properties motivate new methods, e.g. bootstrap-based techniques for signal detection, that confine attention to the significant tail of a statistic. {\textcopyright} 2011 Royal Statistical Society.},
archivePrefix = {arXiv},
arxivId = {1001.3886},
author = {Delaigle, Aurore and Hall, Peter and Jin, Jiashun},
doi = {10.1111/j.1467-9868.2010.00761.x},
eprint = {1001.3886},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society. Series B Statistical Methodology/Delaigle, Hall, Jin - 2011 - Robustness and accuracy of methods for high dimensional data analysis based on Student's t-statistic.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Bootstrap,Central limit theorem,Classification,Dimension reduction,Higher criticism,Large deviation probability,Moderate deviation probability,Ranking,Second-order accuracy,Skewness,Tail probability,Variable selection,knockoffs,t-test},
mendeley-tags = {knockoffs,t-test},
number = {3},
pages = {283--301},
title = {{Robustness and accuracy of methods for high dimensional data analysis based on Student's t-statistic}},
volume = {73},
year = {2011}
}
@article{Shah2013,
abstract = {Stability selection was recently introduced by Meinshausen and B{\"{u}}hlmann as a very general technique designed to improve the performance of a variable selection algorithm. It is based on aggregating the results of applying a selection procedure to subsamples of the data. We introduce a variant, called complementary pairs stability selection, and derive bounds both on the expected number of variables included by complementary pairs stability selection that have low selection probability under the original procedure, and on the expected number of high selection probability variables that are excluded. These results require no (e.g. exchangeability) assumptions on the underlying model or on the quality of the original selection procedure. Under reasonable shape restrictions, the bounds can be further tightened, yielding improved error control, and therefore increasing the applicability of the me},
author = {Shah, Rajen D and Samworth, Richard J},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society Series B (Statistical Methodology)/Shah, Samworth - 2013 - Variable selection with error control another look at stability selection.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {high-dimensional regression,stability selection,to-read},
mendeley-tags = {high-dimensional regression,stability selection,to-read},
number = {1},
pages = {55--80},
title = {{Variable selection with error control: another look at stability selection}},
volume = {75},
year = {2013}
}
@article{Emery2019,
abstract = {Barber and Candes recently introduced a feature selection method called knockoff+ that controls the false discovery rate (FDR) among the selected features in the classical linear regression problem. Knockoff+ uses the competition between the original features and artificially created knockoff features to control the FDR [1]. We generalize Barber and Candes' knockoff construction to generate multiple knockoffs and use those in conjunction with a recently developed general framework for multiple competition-based FDR control [9]. We prove that using our initial multiple-knockoff construction the combined procedure rigorously controls the FDR in the finite sample setting. Because this construction has a somewhat limited utility we introduce a heuristic we call "batching" which significantly improves the power of our multiple-knockoff procedures. Finally, we combine the batched knockoffs with a new context-dependent resampling scheme that replaces the generic resampling scheme used in the general multiple-competition setup. We show using simulations that the resulting "multi-knockoff-select" procedure empirically controls the FDR in the finite setting of the variable selection problem while often delivering substantially more power than knockoff+.},
archivePrefix = {arXiv},
arxivId = {1911.09442},
author = {Emery, Kristen and Keich, Uri},
eprint = {1911.09442},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Emery, Keich - 2019 - Controlling the FDR in variable selection via multiple knockoffs.pdf:pdf},
pages = {1--42},
title = {{Controlling the FDR in variable selection via multiple knockoffs}},
url = {http://arxiv.org/abs/1911.09442},
year = {2019}
}
@article{GLC2013,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/24097068{\}}{\{}24097068{\}}},
author = {{$\backslash$Global Lipids Genetics Consortium}},
journal = {Nature Genetics},
keywords = {applied,genetics},
mendeley-tags = {applied,genetics},
number = {11},
pages = {1274--1283},
title = {{Discovery and refinement of loci associated with lipid levels}},
volume = {45},
year = {2013}
}
@article{JM16,
author = {Javanmard, A and Montanari, A},
journal = {The Annals of Statistics},
keywords = {FDR,Multiple testing,online multiple testing},
mendeley-tags = {FDR,Multiple testing,online multiple testing},
number = {2},
title = {{Online rules for control of false discovery rate and false discovery exceedance}},
volume = {46},
year = {2017}
}
@article{Athey2018,
author = {Athey, Susan and Eckles, Dean and Imbens, Guido W},
doi = {10.1080/01621459.2016.1241178},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Athey, Eckles, Imbens - 2018 - Exact p -Values for Network Interference.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Fisher exact p-values,Interactions,Randomization inference,SUTVA,Spillovers,causality,fisher exact p -values,inference,interactions,interference,randomization,spillovers,sutva},
mendeley-tags = {causality,interference},
number = {521},
pages = {230--240},
publisher = {Taylor {\&} Francis},
title = {{Exact p -Values for Network Interference}},
url = {https://doi.org/10.1080/01621459.2016.1241178},
volume = {113},
year = {2018}
}
@article{Cramer2018,
abstract = {This is a translation of Harald Cram$\backslash$'er's article, 'On a new limit theorem in probability theory', published in French in 1938 and deriving what is considered by mathematicians to be the first large deviation result. My hope is that this translation will help disseminate this historically important work, 80 years after its publication.},
archivePrefix = {arXiv},
arxivId = {1802.05988},
author = {Cram{\'{e}}r, Harald and Touchette, Hugo},
eprint = {1802.05988},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Cram{\'{e}}r, Touchette - 2018 - On a new limit theorem in probability theory (Translation of 'Sur un nouveau th'eor`eme-limite de la th'eori.pdf:pdf},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
pages = {895--913},
title = {{On a new limit theorem in probability theory (Translation of 'Sur un nouveau th$\backslash$'eor$\backslash$`eme-limite de la th$\backslash$'eorie des probabilit$\backslash$'es')}},
url = {http://arxiv.org/abs/1802.05988},
volume = {II},
year = {2018}
}
@article{Isci2014,
abstract = {Motivation: Reverse engineering GI networks from experimental data is a challenging task due to the complex nature of the networks and the noise inherent in the data. One way to overcome these hurdles would be incorporating the vast amounts of external biological knowledge when building interaction networks. We propose a framework where GI networks are learned from experimental data using Bayesian networks (BNs) and the incorporation of external knowledge is also done via a BN that we call Bayesian Network Prior (BNP). BNP depicts the relation between various evidence types that contribute to the event ‘gene interaction' and is used to calculate the probability of a candidate graph (G) in the structure learning process.$\backslash$nResults: Our simulation results on synthetic, simulated and real biological data show that the proposed approach can identify the underlying interaction network with high accuracy even when the prior information is distorted and outperforms existing methods.$\backslash$nAvailability: Accompanying BNP software package is freely available for academic use at http://bioe.bilgi.edu.tr/BNP.$\backslash$nContact: hasan.otu@bilgi.edu.tr$\backslash$nSupplementary Information: Supplementary data are available at Bioinformatics online.},
author = {Isci, Senol and Dogan, Haluk and Ozturk, Cengizhan and Otu, Hasan H.},
doi = {10.1093/bioinformatics/btt643},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Isci et al. - 2014 - Bayesian network prior Network analysis of biological data using external knowledge.pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
keywords = {Kathryn,networks},
mendeley-tags = {Kathryn,networks},
number = {6},
pages = {860--867},
title = {{Bayesian network prior: Network analysis of biological data using external knowledge}},
url = {http://bioe.bilgi.edu.tr/BNP.},
volume = {30},
year = {2014}
}
@article{LetC16,
author = {Lu, Xiangfeng and Huang, Jianfeng and Mo, Zengnan and He, Jiang and Wang, Laiyuan and Yang, Xueli and Tan, Aihua and Chen, Shufeng and Chen, Jing and Gu, C Charles and Others},
journal = {Circulation: Cardiovascular Genetics},
number = {1},
pages = {37--44},
publisher = {Am Heart Assoc},
title = {{Genetic Susceptibility to Lipid Levels and Lipid Change Over Time and Risk of Incident Hyperlipidemia in Chinese Populations}},
volume = {9},
year = {2016}
}
@article{Hill2018,
abstract = {Several groups recently coupled CRISPR perturbations and single-cell RNA-seq for pooled genetic screens. We demonstrate that vector designs of these studies are susceptible to {\^{a}} 1/450{\%} swapping of guide RNA-barcode associations because of lentiviral template switching. We optimized a published alternative, CROP-seq, in which the guide RNA also serves as the barcode, and here confirm that this strategy performs robustly and doubled the rate at which guides are assigned to cells to 94{\%}.},
author = {Hill, Andrew J. and McFaline-Figueroa, Jos{\'{e}} L. and Starita, Lea M. and Gasperini, Molly J. and Matreyek, Kenneth A. and Packer, Jonathan and Jackson, Dana and Shendure, Jay and Trapnell, Cole},
doi = {10.1038/nmeth.4604},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Hill et al. - 2018 - On the design of CRISPR-based single-cell molecular screens.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Hill et al. - 2018 - On the design of CRISPR-based single-cell molecular screens.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {4},
pages = {271--274},
publisher = {Nature Publishing Group},
title = {{On the design of CRISPR-based single-cell molecular screens}},
volume = {15},
year = {2018}
}
@article{VGE15,
archivePrefix = {arXiv},
arxivId = {stat.AP/1512.02306},
author = {Valente, A and Ginsburg, G and Engelhardt, B.{\~{}}E},
eprint = {1512.02306},
journal = {arXiv},
keywords = {Quantitative Biology - Genomics,Statistics - Applications,Statistics - Machine Learning,multiple phenotypes,unpublished},
mendeley-tags = {multiple phenotypes,unpublished},
month = {dec},
primaryClass = {stat.AP},
title = {{Nonparametric Reduced-Rank Regression for Multi-SNP, Multi-Trait Association Mapping}},
year = {2015}
}
@article{Fiaux2019,
abstract = {CRISPR regulatory screens are a powerful technology for discovering sequences that control gene expression, however, a lack of analysis methods limits their effectiveness. In addition, method performance is difficult to assess due to an absence of datasets where the identities of true regulatory sequences are known. To address these problems, we developed an analysis method, RELICS, and a simulation framework, CRSsim, for CRISPR regulatory screens. RELICS detects regulatory elements by modeling guide counts across multiple pools representing different conditions or expression levels and CRSsim generates realistic datasets where the ground truth is known. We used CRSsim to generate 4320 datasets representing 144 scenarios with different characteristics. We compared analysis methods on these datasets and found that RELICS has the best performance under most conditions. We applied RELICS to 8 published datasets for 15 genes and identify previously-validated elements as well as multiple putative elements that were missed by other methods.},
author = {Fiaux, Patrick C and Chen, Hsiuyi and Graham, McVicker},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Fiaux, Chen, Graham - 2019 - Discovering functional sequences with RELICS, an analysis method for CRISPR regulatory screens.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
title = {{Discovering functional sequences with RELICS, an analysis method for CRISPR regulatory screens}},
year = {2019}
}
@article{Jung2019,
abstract = {A large number of putative cis-regulatory sequences have been annotated in the human genome, but the genes they control remain poorly defined. To bridge this gap, we generate maps of long-range chromatin interactions centered on 18,943 well-annotated promoters for protein-coding genes in 27 human cell/tissue types. We use this information to infer the target genes of 70,329 candidate regulatory elements and suggest potential regulatory function for 27,325 noncoding sequence variants associated with 2,117 physiological traits and diseases. Integrative analysis of these promotercentered interactome maps reveals widespread enhancerlike promoters involved in gene regulation and common molecular pathways underlying distinct groups of human traits and diseases.},
author = {Jung, Inkyung and Schmitt, Anthony and Diao, Yarui and Lee, Andrew J and Liu, Tristin and Yang, Dongchan and Tan, Catherine and Eom, Junghyun and Chan, Marilynn and Chee, Sora and Chiang, Zachary and Kim, Changyoun and Masliah, Eliezer and Barr, Cathy L and Li, Bin and Kuan, Samantha and Kim, Dongsup and Ren, Bing},
doi = {10.1038/s41588-019-0494-8},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Jung et al. - 2019 - A compendium of promoter-centered long-range chromatin interactions in the human genome.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Jung et al. - 2019 - A compendium of promoter-centered long-range chromatin interactions in the human genome(2).pdf:pdf},
issn = {1546-1718},
journal = {Nature Genetics},
keywords = {HI-C,Kathryn,gene-enhancer,to-read},
mendeley-tags = {HI-C,Kathryn,gene-enhancer,to-read},
publisher = {Springer US},
title = {{A compendium of promoter-centered long-range chromatin interactions in the human genome}},
url = {http://dx.doi.org/10.1038/s41588-019-0494-8},
year = {2019}
}
@article{Hu2016,
abstract = {Background: Single-cell transcriptome and single-cell methylome technologies have become powerful tools to study RNA and DNA methylation profiles of single cells at a genome-wide scale. A major challenge has been to understand the direct correlation of DNA methylation and gene expression within single-cells. Due to large cell-to-cell variability and the lack of direct measurements of transcriptome and methylome of the same cell, the association is still unclear. Results: Here, we describe a novel method (scMT-seq) that simultaneously profiles both DNA methylome and transcriptome from the same cell. In sensory neurons, we consistently identify transcriptome and methylome heterogeneity among single cells but the majority of the expression variance is not explained by proximal promoter methylation, with the exception of genes that do not contain CpG islands. By contrast, gene body methylation is positively associated with gene expression for only those genes that contain a CpG island promoter. Furthermore, using single nucleotide polymorphism patterns from our hybrid mouse model, we also find positive correlation of allelic gene body methylation with allelic expression. Conclusions: Our method can be used to detect transcriptome, methylome, and single nucleotide polymorphism information within single cells to dissect the mechanisms of epigenetic gene regulation.},
author = {Hu, Youjin and Huang, Kevin and An, Qin and Du, Guizhen and Hu, Ganlu and Xue, Jinfeng and Zhu, Xianmin and Wang, Cun Yu and Xue, Zhigang and Fan, Guoping},
doi = {10.1186/s13059-016-0950-z},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Hu et al. - 2016 - Simultaneous profiling of transcriptome and DNA methylome from a single cell.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Dorsal root ganglion,Gene regulation,Sensory neurons,Single-cell methylome,Single-cell transcriptome,multi-omics},
mendeley-tags = {multi-omics},
number = {1},
pages = {1--11},
pmid = {27150361},
publisher = {Genome Biology},
title = {{Simultaneous profiling of transcriptome and DNA methylome from a single cell}},
url = {http://dx.doi.org/10.1186/s13059-016-0950-z},
volume = {17},
year = {2016}
}
@article{Carroll1984,
abstract = {We consider binary regression models when some of the predictors are measured with error. For normal measurement errors, structural maximum likelihood estimates are considered. We show that if the measurement error is large, the usual estimate of the probability of the event in question can be substantially in error, especially for high risk groups. In the situation of large measurement error, we investigate a conditional maximum likelihood estimator and its properties. {\textcopyright} 1984 Biometrika Trust.},
author = {Carroll, Raymond J. and Spiegelman, Clifford H. and Lan, K. K.Gordon and Bailey, Kent T. and Abbott, Robert D.},
doi = {10.1093/biomet/71.1.19},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Carroll et al. - 1984 - On errors-in-variables for binary regression models.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {Functional model,Logistic regression,Measurement error,Probit regression,Structural model,error-in-variables},
mendeley-tags = {error-in-variables},
number = {1},
pages = {19--25},
title = {{On errors-in-variables for binary regression models}},
volume = {71},
year = {1984}
}
@article{Wang2019g,
abstract = {Single-cell RNA sequencing (scRNA-seq) data are noisy and sparse. Here, we show that transfer learning across datasets remarkably improves data quality. By coupling a deep autoencoder with a Bayesian model, SAVER-X extracts transferable gene−gene relationships across data from different labs, varying conditions and divergent species, to denoise new target datasets.},
author = {Wang, Jingshu and Agarwal, Divyansh and Huang, Mo and Hu, Gang and Zhou, Zilu and Ye, Chengzhong and Zhang, Nancy R.},
doi = {10.1038/s41592-019-0537-1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Wang et al. - 2019 - Data denoising with transfer learning in single-cell transcriptomics.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {single cell},
mendeley-tags = {single cell},
number = {9},
pages = {875--878},
pmid = {31471617},
publisher = {Springer US},
title = {{Data denoising with transfer learning in single-cell transcriptomics}},
url = {http://dx.doi.org/10.1038/s41592-019-0537-1},
volume = {16},
year = {2019}
}
@article{Miao2018a,
abstract = {Summary: The excessive amount of zeros in single-cell RNA-seq (scRNA-seq) data includes 'real' zeros due to the on-off nature of gene transcription in single cells and 'dropout' zeros due to technical reasons. Existing differential expression (DE) analysis methods cannot distinguish these two types of zeros. We developed an R package DEsingle which employed Zero-Inflated Negative Binomial model to estimate the proportion of real and dropout zeros and to define and detect three types of DE genes in scRNA-seq data with higher accuracy. Availability and implementation: The R package DEsingle is freely available at Bioconductor (https://bioconductor.org/packages/DEsingle). Supplementary information: Supplementary data are available at Bioinformatics online.},
author = {Miao, Zhun and Deng, Ke and Wang, Xiaowo and Zhang, Xuegong},
doi = {10.1093/bioinformatics/bty332},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics (Oxford, England)/Miao et al. - 2018 - DEsingle for detecting three types of differential expression in single-cell RNA-seq data.pdf:pdf},
issn = {13674811},
journal = {Bioinformatics (Oxford, England)},
keywords = {differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {18},
pages = {3223--3224},
pmid = {29688277},
title = {{DEsingle for detecting three types of differential expression in single-cell RNA-seq data}},
volume = {34},
year = {2018}
}
@article{LetR16,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/27168765{\}}{\{}27168765{\}}},
author = {Li, R and Dudek, S M and Kim, D and Hall, M A and Bradford, Y and Peissig, P L and Brilliant, M H and Linneman, J G and McCarty, C A and Bao, L and Ritchie, M D},
journal = {BioData Min},
keywords = {genetics,networks},
mendeley-tags = {genetics,networks},
pages = {18},
title = {{{\{}I{\}}dentification of genetic interaction networks via an evolutionary algorithm evolved {\{}B{\}}ayesian network}},
volume = {9},
year = {2016}
}
@article{YetV13,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23756893{\}}{\{}23756893{\}}},
author = {Yang, J and Lee, S H and Goddard, M E and Visscher, P M},
journal = {Methods Mol. Biol.},
keywords = {genetics,linear mixed models},
mendeley-tags = {genetics,linear mixed models},
pages = {215--236},
title = {{{\{}G{\}}enome-wide complex trait analysis ({\{}G{\}}{\{}C{\}}{\{}T{\}}{\{}A{\}}): methods, data analyses, and interpretations}},
volume = {1019},
year = {2013}
}
@article{SWM08,
abstract = {The availability of cost-effective, high-throughput genotyping technologies has generated a tremendous amount of interest in genetic association studies. This interest has led to the belief that one could possibly test thousands to millions of representative polymorphic sites on the genome for association with a trait or disease in order to identify the few sites that may be of relevance to the expression of that trait or disease. The choice of which polymorphic sites are "representative" and to be interrogated in such studies is problematic and has involved considerations of the putative functional significance of the sites as well as the linkage disequilibrium relationships between variations at those sites and other neighboring sites. We consider an obvious alternative to genotyping-based strategies and settings for association studies for which decisions about which variations to interrogate are obviated. Essentially, we anticipate a time when cost-effective, high-throughput DNA sequencing technologies are available and researchers will have actual sequence information on the individuals under study rather than information about what variations they possess at a few well-chosen polymorphic genomic sites. We consider Multivariate Distance Matrix Regression analysis to evaluate associations between DNA sequence information and quantitative traits such as blood pressure and cholesterol level. We evaluate the potential of the method in a few (albeit contrived) settings via simulation studies. Ultimately, we show that the procedure has promise and argue that consideration of DNA sequence-based association data should usher in a new era in genetic association study designs and methodologies.},
annote = {18358322},
author = {Schork, N J and Wessel, J and Malo, N},
doi = {10.1016/S0065-2660(07)00409-9},
journal = {Adv Genet},
pages = {195--217},
title = {{DNA sequence-based phenotypic association analysis}},
url = {http://www.hubmed.org/display.cgi?uids=18358322},
volume = {60},
year = {2008}
}
@article{SetA11,
author = {Schwartzman, Armin and Gavrilov, Yulia and Adler, Robert J},
journal = {The Annals of Statistics},
keywords = {Multiple testing,spatial data},
mendeley-tags = {Multiple testing,spatial data},
number = {6},
pages = {3290},
publisher = {NIH Public Access},
title = {{Multiple testing of local maxima for detection of peaks in 1D}},
volume = {39},
year = {2011}
}
@article{Edwards2015,
abstract = {Epidemiologists often use the potential outcomes framework to cast causal inference as a missing data problem. Here, we demonstrate how bias due to measurement error can be described in terms of potential outcomes and considered in concert with bias from other sources. In addition, we illustrate how acknowledging the uncertainty that arises due to measurement error increases the amount of missing information in causal inference. We use a simple example to show that estimating the average treatment effect requires the investigator to perform a series of hidden imputations based on strong assumptions.},
author = {Edwards, Jessie K. and Cole, Stephen R. and Westreich, Daniel},
doi = {10.1093/ije/dyu272},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/International Journal of Epidemiology/Edwards, Cole, Westreich - 2015 - All your data are always missing Incorporating bias due to measurement error into the potential outcom.pdf:pdf},
issn = {14643685},
journal = {International Journal of Epidemiology},
keywords = {Bias (Epidemiology),Causal inference,HIV,Missing data,causality,missing data},
mendeley-tags = {causality,missing data},
number = {4},
pages = {1452--1459},
title = {{All your data are always missing: Incorporating bias due to measurement error into the potential outcomes framework}},
volume = {44},
year = {2015}
}
@article{Goeman2014,
abstract = {This paper presents an overview of the current state of the art in multiple testing in genomics data from a user's perspective. We describe methods for familywise error control, false discovery rate control and false discovery proportion estimation and confidence, both conceptually and practically, and explain when to use which type of error rate. We elaborate on the assumptions underlying the methods and discuss pitfalls in the interpretation of results. In our discussion, we take into account the exploratory nature of genomics experiments, looking at selection of genes before or after testing, and at the role of validation experiments.},
author = {Goeman, Jelle J. and Solari, Aldo},
doi = {10.1002/sim.6082},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics in Medicine/Goeman, Solari - 2014 - Multiple hypothesis testing in genomics.pdf:pdf},
issn = {10970258},
journal = {Statistics in Medicine},
keywords = {Bonferroni,FDR,False discovery proportion,False discovery rate,Familywise error rate},
number = {11},
pages = {1946--1978},
title = {{Multiple hypothesis testing in genomics}},
volume = {33},
year = {2014}
}
@article{Liley2018,
abstract = {A common statistical procedure throughout the biomedical sciences is the high-dimensional association study, in which a large number of null hypotheses are tested against a trait of interest. These analyses can generally be strengthened by incorporating an informative covariate, often a set of p-values for tests against some related 'conditional' trait. One method to incorporate such a covariate estimates a quantity called the conditional false discovery rate (cFDR) for each observation. The cFDR is the posterior probability of association given p-value thresholds for both the principal and conditional trait, and can be used quantify evidence that the observation is associated with the principal trait. The cFDR-based method is powerful and intuitive, but the two-dimensional nature of its construction means it is difficult to control the overall false- discovery rate (FDR), and existing attempts to do so are over-conservative. We propose a new method, based on identifying maps from the unit square to the unit interval defined by the estimated cFDR, and splitting observations so that each map is independent of the observations it is used to test. This allows theoretical FDR control at arbitrarily low or high numbers of hypotheses and improves power over the existing method. We demonstrate the new method on two genome-wide association studies in autoimmune disease. This method improves the power of the cFDR while maintaining rigorous FDR control, allowing it to be used in the discovery phase of 'omics' studies with the same confidence as the Benjamini-Hochberg procedure and improving its applicability to different data types.},
author = {Liley, James and Wallace, Chris},
doi = {10.1101/414318},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Liley, Wallace - 2018 - Accurate error control in high dimensional association testing using conditional false discovery rates.pdf:pdf},
journal = {bioRxiv},
pages = {414318},
title = {{Accurate error control in high dimensional association testing using conditional false discovery rates}},
url = {https://www.biorxiv.org/content/early/2018/09/12/414318},
year = {2018}
}
@article{Keurentjes2006,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/16751770{\}}{\{}16751770{\}}},
author = {Keurentjes, J J and Fu, J and {De Vos}, C H and Lommen, A and Hall, R D and Bino, R J and van der Plas, L H and Jansen, R C and Vreugdenhil, D and Koornneef, M},
journal = {Nature Genetics},
number = {7},
pages = {842--849},
title = {{The genetics of plant metabolism}},
volume = {38},
year = {2006}
}
@article{SetS19,
annote = {$\backslash$href{\{}https://www.biorxiv.org/content/10.1101/631390v2{\}}{\{}https://www.biorxiv.org/content/10.1101/631390v2{\}}},
author = {Sesia, Matteo and Katsevich, Eugene and Bates, Stephen and Cand{\`{e}}s, Emmanuel and Sabatti, Chiara},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Sesia et al. - 2020 - Multi-resolution localization of causal variants across the genome.pdf:pdf},
journal = {Nature Communications},
keywords = {GWAS,groups,knockoffs,model-X,unpublished},
mendeley-tags = {GWAS,groups,knockoffs,model-X,unpublished},
pages = {1093},
title = {{Multi-resolution localization of causal variants across the genome}},
volume = {11},
year = {2020}
}
@article{Klein2018,
abstract = {Enhancers control the spatiotemporal expression of genes and are essential for encoding differentiation and development. Since their discovery more than three decades ago, researchers have largely studied enhancers removed from their genomic context. The recent adaptation of CRISPR/Cas9 to genome editing in higher organisms now allows researchers to perturb and test these elements in their genomic context, through both mutation and epigenetic modulation. In this Perspective, we discuss recent advances in scanning noncoding regions of the genome for enhancer activity using CRISPR-based tools.},
author = {Klein, Jason C. and Chen, Wei and Gasperini, Molly and Shendure, Jay},
doi = {10.1021/acschembio.7b00778},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/ACS Chemical Biology/Klein et al. - 2018 - Identifying Novel Enhancer Elements with CRISPR-Based Screens.pdf:pdf},
issn = {15548937},
journal = {ACS Chemical Biology},
number = {2},
pages = {326--332},
title = {{Identifying Novel Enhancer Elements with CRISPR-Based Screens}},
volume = {13},
year = {2018}
}
@article{Lang1986,
author = {Lang, Robert},
doi = {10.1007/BF01202504},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Archiv der Mathematik/Lang - 1986 - A note on the measurability of convex sets.pdf:pdf},
issn = {0003889X},
journal = {Archiv der Mathematik},
number = {1},
pages = {90--92},
title = {{A note on the measurability of convex sets}},
volume = {47},
year = {1986}
}
@article{Frangakis2002a,
abstract = {Many scientific problems require that treatment comparisons be adjusted for posttreatment variables, but the estimands underlying standard methods are not causal effects. To address this deficiency, we propose a general framework for comparing treatments adjusting for posttreatment variables that yields principal effects based on principal stratification. Principal stratification with respect to a posttreatment variable is a cross-classification of subjects defined by the joint potential values of that posttreatment variable under each of the treatments being compared. Principal effects are causal effects within a principal stratum. The key property of principal strata is that they are not affected by treatment assignment and therefore can be used just as any pretreatment covariate, such as age category. As a result, the central property of our principal effects is that they are always causal effects and do not suffer from the complications of standard posttreatment-adjusted estimands. We discuss briefly that such principal causal effects are the link between three recent applications with adjustment for posttreatment variables: (i) treatment noncompliance, (ii) missing outcomes (dropout) following treatment noncompliance, and (iii) censoring by death. We then attack the problem of surrogate or biomarker endpoints, where we show, using principal causal effects, that all current definitions of surrogacy, even when perfectly true, do not generally have the desired interpretation as causal effects of treatment on outcome. We go on to formulate estimands based on principal stratification and principal causal effects and show their superiority.},
author = {Frangakis, C. E. and Rubin, D. B.},
doi = {10.1111/j.0006-341X.2002.00021.x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrics/Frangakis, Rubin - 2002 - Principal stratification in causal inference.pdf:pdf},
issn = {0006341X},
journal = {Biometrics},
keywords = {Biomarker,Causal inference,Censoring by death,Missing data,Posttreatment variable,Principal stratification,Quality of life,Rubin causal model,Surrogate,causality,missing data},
mendeley-tags = {causality,missing data},
number = {1},
pages = {21--29},
title = {{Principal stratification in causal inference}},
volume = {58},
year = {2002}
}
@article{Foster2016a,
abstract = {We consider the problem of using permutation-based methods to test for treatment–covariate interactions from randomized clinical trial data. Testing for interactions is common in the field of personalized medicine, as subgroups with enhanced treatment effects arise when treatment-by-covariate interactions exist. Asymptotic tests can often be performed for simple models, but in many cases, more complex methods are used to identify subgroups, and non-standard test statistics proposed, and asymptotic results may be difficult to obtain. In such cases, it is natural to consider permutation-based tests, which shuffle selected parts of the data in order to remove one or more associations of interest; however, in the case of interactions, it is generally not possible to remove only the associations of interest by simple permutations of the data. We propose a number of alternative permutation-based methods, designed to remove only the associations of interest, but preserving other associations. These methods estimate the interaction term in a model, then create data that “looks like” the original data except that the interaction term has been permuted. The proposed methods are shown to outperform traditional permutation methods in a simulation study. In addition, the proposed methods are illustrated using data from a randomized clinical trial of patients with hypertension.},
author = {Foster, Jared C. and Nan, Bin and Shen, Lei and Kaciroti, Niko and Taylor, Jeremy M.G.},
doi = {10.1007/s12561-015-9125-9},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics in Biosciences/Foster et al. - 2016 - Permutation Testing for Treatment–Covariate Interactions and Subgroup Identification.pdf:pdf},
isbn = {1256101591},
issn = {18671772},
journal = {Statistics in Biosciences},
keywords = {Permutation tests,Personalized medicine,Subgroup analysis,Treatment–covariate interactions,interactions},
mendeley-tags = {interactions},
number = {1},
pages = {77--98},
publisher = {Springer US},
title = {{Permutation Testing for Treatment–Covariate Interactions and Subgroup Identification}},
url = {http://dx.doi.org/10.1007/s12561-015-9125-9},
volume = {8},
year = {2016}
}
@book{WY93,
author = {Westfall, Peter and Young, S. Stanley},
edition = {First},
keywords = {FWER,Multiple testing,canonical,resampling},
mendeley-tags = {FWER,Multiple testing,canonical,resampling},
publisher = {Wiley},
title = {{Resampling-Based Multiple Testing: Examples and Methods for p-Value Adjustment}},
year = {1993}
}
@article{He2011,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21036813{\}}{\{}21036813{\}}},
author = {Qianchuan, Q He and Lin, D.-Y.},
journal = {Bioinformatics},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
number = {1},
pages = {1--8},
title = {{A variable selection method for genome-wide association studies}},
volume = {27},
year = {2011}
}
@article{Basse2019,
author = {Basse, G. W. and Feller, A. and Toulis, P.},
doi = {10.1093/biomet/asy072},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Basse, Feller, Toulis - 2019 - Randomization tests of causal effects under interference.pdf:pdf},
journal = {Biometrika},
keywords = {causality,interference,randomization},
mendeley-tags = {causality,interference,randomization},
number = {2},
pages = {487--494},
title = {{Randomization tests of causal effects under interference}},
volume = {106},
year = {2019}
}
@article{Adamson2016,
abstract = {Functional genomics efforts face tradeoffs between number of perturbations examined and complexity of phenotypes measured. We bridge this gap with Perturb-seq, which combines droplet-based single-cell RNA-seq with a strategy for barcoding CRISPR-mediated perturbations, allowing many perturbations to be profiled in pooled format. We applied Perturb-seq to dissect the mammalian unfolded protein response (UPR) using single and combinatorial CRISPR perturbations. Two genome-scale CRISPR interference (CRISPRi) screens identified genes whose repression perturbs ER homeostasis. Subjecting ∼100 hits to Perturb-seq enabled high-precision functional clustering of genes. Single-cell analyses decoupled the three UPR branches, revealed bifurcated UPR branch activation among cells subject to the same perturbation, and uncovered differential activation of the branches across hits, including an isolated feedback loop between the translocon and IRE1$\alpha$. These studies provide insight into how the three sensors of ER homeostasis monitor distinct types of stress and highlight the ability of Perturb-seq to dissect complex cellular responses.},
author = {Adamson, Britt and Norman, Thomas M. and Jost, Marco and Cho, Min Y. and Nu{\~{n}}ez, James K. and Chen, Yuwen and Villalta, Jacqueline E. and Gilbert, Luke A. and Horlbeck, Max A. and Hein, Marco Y. and Pak, Ryan A. and Gray, Andrew N. and Gross, Carol A. and Dixit, Atray and Parnas, Oren and Regev, Aviv and Weissman, Jonathan S.},
doi = {10.1016/j.cell.2016.11.048},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Adamson et al. - 2016 - A Multiplexed Single-Cell CRISPR Screening Platform Enables Systematic Dissection of the Unfolded Protein Respon.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {CRIPSRi,CRISPR,Kathryn,Single-cell RNA-seq,cell-to-cell heterogeneity,genome-scale screening,single-cell genomics,unfolded protein response},
mendeley-tags = {CRISPR,Kathryn},
month = {dec},
number = {7},
pages = {1867--1882.e21},
publisher = {Cell Press},
title = {{A Multiplexed Single-Cell CRISPR Screening Platform Enables Systematic Dissection of the Unfolded Protein Response}},
volume = {167},
year = {2016}
}
@article{Yurko2020,
abstract = {To correct for a large number of hypothesis tests, most researchers rely on simple multiple testing corrections. Yet, new methodologies of selective inference could potentially improve power while retaining statistical guarantees, especially those that enable exploration of test statistics using auxiliary information (covariates) to weight hypothesis tests for association. We explore one such method, adaptive p-value thresholding ([Lei {\&} Fithian 2018][1], AdaPT), in the framework of genome-wide association studies (GWAS) and gene expression/coexpression studies, with particular emphasis on schizophrenia (SCZ). Selected SCZ GWAS association p-values play the role of the primary data for AdaPT; SNPs are selected because they are gene expression quantitative trait loci (eQTLs). This natural pairing of SNPs and genes allow us to map the following covariate values to these pairs: GWAS statistics from genetically-correlated bipolar disorder, the effect size of SNP genotypes on gene expression, and gene-gene coexpression, captured by subnetwork (module) membership. In all 24 covariates per SNP/gene pair were included in the AdaPT analysis using flexible gradient boosted trees. We demonstrate a substantial increase in power to detect SCZ associations using gene expression information from the developing human prefontal cortex ([Werling et al. 2019][2]). We interpret these results in light of recent theories about the polygenic nature of SCZ. Importantly, our entire process for identifying enrichment and creating features with independent complementary data sources can be implemented in many different high-throughput settings to ultimately improve power. [1]: {\#}ref-16 [2]: {\#}ref-31},
author = {Yurko, Ronald and G'Sell, Max and Roeder, Kathryn and Devlin, Bernie},
doi = {10.1101/806471},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences/Yurko et al. - 2020 - A selective inference approach for FDR control using multi-omics covariates yields insights into disease risk.pdf:pdf},
isbn = {1918862117},
journal = {Proceedings of the National Academy of Sciences},
keywords = {GWAS,Multiple testing,adaptive data analysis},
mendeley-tags = {GWAS,Multiple testing,adaptive data analysis},
title = {{A selective inference approach for FDR control using multi-omics covariates yields insights into disease risk}},
url = {https://www.biorxiv.org/content/10.1101/806471v2},
year = {2020}
}
@book{KT81,
author = {Karlin, Samuel and Taylor, Howard E},
publisher = {Elsevier},
title = {{A second course in stochastic processes}},
year = {1981}
}
@article{Agarwal2020,
abstract = {Single cell sequencing technologies are transforming biomedical research. However, due to the inherent nature of the data, single cell RNA sequencing analysis poses new computational and statistical challenges. We begin with a survey of a selection of topics in this field, with a gentle introduction to the biology and a more detailed exploration of the technical noise. We consider in detail the problem of single cell data denoising, sometimes referred to as "imputation" in the relevant literature. We discuss why this is not a typical statistical imputation problem, and review current approaches to this problem. We then explore why the use of denoised values in downstream analyses invites novel statistical insights, and how denois-ing uncertainty should be accounted for to yield valid statistical inference. The utilization of denoised or imputed matrices in statistical inference is not unique to single cell genomics, and arises in many other fields. We describe the challenges in this type of analysis, discuss some preliminary solutions, and highlight unresolved issues.},
author = {Agarwal, Divyansh and Wang, Jingshu and Zhang, Nancy R.},
doi = {10.1214/19-sts7560},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistical Science/Agarwal, Wang, Zhang - 2020 - Data Denoising and Post-Denoising Corrections in Single Cell RNA Sequencing.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {RNA sequencing,Single cell biology,and phrases,deep learning,empirical Bayes,empirical bayes,imputation,post-denoising inference,rna sequencing,single cell,single cell biology},
mendeley-tags = {single cell},
number = {1},
pages = {112--128},
title = {{Data Denoising and Post-Denoising Corrections in Single Cell RNA Sequencing}},
volume = {35},
year = {2020}
}
@article{Branson2019,
author = {Branson, Zach and Miratrix, Luke W},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Causal Inference/Branson, Miratrix - 2019 - Randomization Tests that Condition on Non-Categorical Covariate Balance.pdf:pdf},
journal = {Journal of Causal Inference},
keywords = {1 after randomization,and control groups on,average,causality,conditional inference,considered the,covariate adjustment,distributions of the treatment,gold standard,ization balances the covariate,of statistical inference because,random-,randomization,randomized experiments are often,statistical power,to adjust,to adjust or not,validity,which limits con-},
mendeley-tags = {causality,randomization},
number = {1},
title = {{Randomization Tests that Condition on Non-Categorical Covariate Balance}},
volume = {7},
year = {2019}
}
@article{HetM05,
author = {Hamosh, Ada and Scott, Alan F and Amberger, Joanna S and Bocchini, Carol A and McKusick, Victor A},
journal = {Nucleic Acids Research},
number = {suppl 1},
pages = {D514----D517},
publisher = {Oxford Univ Press},
title = {{Online Mendelian Inheritance in Man (OMIM), a knowledgebase of human genes and genetic disorders}},
volume = {33},
year = {2005}
}
@article{MZ10,
abstract = {Genome-wide association (GWA) studies have proved to be extremely successful in identifying novel common polymorphisms contributing effects to the genetic component underlying complex traits. Nevertheless, one source of, as yet, undiscovered genetic determinants of complex traits are those mediated through the effects of rare variants. With the increasing availability of large-scale re-sequencing data for rare variant discovery, we have developed a novel statistical method for the detection of complex trait associations with these loci, based on searching for accumulations of minor alleles within the same functional unit. We have undertaken simulations to evaluate strategies for the identification of rare variant associations in population-based genetic studies when data are available from re-sequencing discovery efforts or from commercially available GWA chips. Our results demonstrate that methods based on accumulations of rare variants discovered through re-sequencing offer substantially greater power than conventional analysis of GWA data, and thus provide an exciting opportunity for future discovery of genetic determinants of complex traits.},
annote = {19810025},
author = {Morris, A P and Zeggini, E},
doi = {10.1002/gepi.20450},
journal = {Genetic Epidemiology},
keywords = {genetics,rare variants},
mendeley-tags = {genetics,rare variants},
number = {2},
pages = {188--193},
title = {{An evaluation of statistical approaches to rare variant analysis in genetic association studies}},
url = {http://www.hubmed.org/display.cgi?uids=19810025},
volume = {34},
year = {2010}
}
@article{Berrett2019,
abstract = {We propose a general new method, the conditional permutation test, for testing the conditional independence of variables X and Y given a potentially high-dimensional random vector Z that may contain confounding factors. The proposed test permutes entries of X non-uniformly, so as to respect the existing dependence between X and Z and thus account for the presence of these con-founders. Like the conditional randomization test of Cand{\`{e}}s et al. [7], our test relies on the availability of an approximation to the distribution of X|Z-while Cand{\`{e}}s et al. [7]'s test uses this estimate to draw new X values, for our test we use this approximation to design an appropriate non-uniform distribution on permutations of the X values already seen in the true data. We provide an efficient Markov Chain Monte Carlo sampler for the implementation of our method, and establish bounds on the Type I error in terms of the error in the approximation of the conditional distribution of X|Z, finding that, for the worst case test statistic, the inflation in Type I error of the conditional permutation test is no larger than that of the conditional randomization test. We validate these theoretical results with experiments on simulated data and on the Capital Bikeshare data set.},
author = {Berrett, Thomas B and Wang, Yi and {Foygel Barber}, Rina and Samworth, Richard J},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society. Series B Statistical Methodology/Berrett et al. - 2020 - The conditional permutation test for independence while controlling for confounders.pdf:pdf},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {conditional permutation test,high-dimensional regression,multiple testing,resampling,unpublished},
mendeley-tags = {conditional permutation test,high-dimensional regression,multiple testing,resampling,unpublished},
number = {1},
pages = {175--197},
title = {{The conditional permutation test for independence while controlling for confounders}},
volume = {82},
year = {2020}
}
@article{2010arXiv1009.0306L,
archivePrefix = {arXiv},
arxivId = {cs.LG/1009.0306},
author = {Liu, J and Ye, J},
eprint = {1009.0306},
journal = {arXiv},
keywords = {Computer Science - Learning,Lasso,groups,high-dimensional regression,unpublished},
mendeley-tags = {Lasso,groups,high-dimensional regression,unpublished},
month = {sep},
primaryClass = {cs.LG},
title = {{Fast Overlapping Group Lasso}},
year = {2010}
}
@article{Rao2017,
abstract = {The human genome folds to create thousands of intervals, called “contact domains,” that exhibit enhanced contact frequency within themselves. “Loop domains” form because of tethering between two loci—almost always bound by CTCF and cohesin—lying on the same chromosome. “Compartment domains” form when genomic intervals with similar histone marks co-segregate. Here, we explore the effects of degrading cohesin. All loop domains are eliminated, but neither compartment domains nor histone marks are affected. Loss of loop domains does not lead to widespread ectopic gene activation but does affect a significant minority of active genes. In particular, cohesin loss causes superenhancers to co-localize, forming hundreds of links within and across chromosomes and affecting the regulation of nearby genes. We then restore cohesin and monitor the re-formation of each loop. Although re-formation rates vary greatly, many megabase-sized loops recovered in under an hour, consistent with a model where loop extrusion is rapid. Mapping the nucleome in 4D during cohesin loss and recovery reveals that cohesin degradation eliminates loop domains but has only modest transcriptional consequences.},
author = {Rao, Suhas S.P. and Huang, Su Chen and {Glenn St Hilaire}, Brian and Engreitz, Jesse M. and Perez, Elizabeth M. and Kieffer-Kwon, Kyong Rim and Sanborn, Adrian L. and Johnstone, Sarah E. and Bascom, Gavin D. and Bochkov, Ivan D. and Huang, Xingfan and Shamim, Muhammad S. and Shin, Jaeweon and Turner, Douglass and Ye, Ziyi and Omer, Arina D. and Robinson, James T. and Schlick, Tamar and Bernstein, Bradley E. and Casellas, Rafael and Lander, Eric S. and Aiden, Erez Lieberman},
doi = {10.1016/j.cell.2017.09.026},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Rao et al. - 2017 - Cohesin Loss Eliminates All Loop Domains.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {4D Nucleome,CTCF,HI-C,Hi-C,Kathryn,chromatin loops,cohesion,gene regulation,gene-enhancer,genetics,genome architecture,loop extrusion,nuclear compartments,superenhancers},
mendeley-tags = {HI-C,Kathryn,gene-enhancer,genetics},
number = {2},
pages = {305--320.e24},
publisher = {Elsevier Inc.},
title = {{Cohesin Loss Eliminates All Loop Domains}},
url = {https://doi.org/10.1016/j.cell.2017.09.026},
volume = {171},
year = {2017}
}
@article{CS11,
author = {Carbonetto, P and Stephens, M},
journal = {Bayesian Analysis},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
pages = {1--42},
title = {{Scalable variational inference for Bayesian variable selection, and its accuracy in genetic association studies}},
volume = {6},
year = {2011}
}
@book{VanderWeele2015,
author = {VanderWeele, Tyler},
publisher = {Oxford University Press},
title = {{Explanation in causal inference: methods for mediation and interaction}},
year = {2015}
}
@article{ZetR11,
author = {Zeeberg, Barry R and Liu, Hongfang and Kahn, Ari B and Ehler, Martin and Rajapakse, Vinodh N and Bonner, Robert F and Brown, Jacob D and Brooks, Brian P and Larionov, Vladimir L and Reinhold, William and Others},
journal = {BMC bioinformatics},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
number = {1},
pages = {52},
publisher = {BioMed Central},
title = {{RedundancyMiner: De-replication of redundant GO categories in microarray and proteomics analysis}},
volume = {12},
year = {2011}
}
@article{Fishilevich2017,
abstract = {A major challenge in understanding gene regulation is the unequivocal identification of enhancer elements and uncovering their connections to genes. We present GeneHancer, a novel database of human enhancers and their inferred target genes, in the framework of GeneCards. First, we integrated a total of 434 000 reported enhancers from four different genome-wide databases: the Encyclopedia of DNA Elements (ENCODE), the Ensembl regulatory build, the functional annotation of the mammalian genome (FANTOM) project and the VISTA Enhancer Browser. Employing an integration algorithm that aims to re-move redundancy, GeneHancer portrays 285 000 integrated candidate enhancers (cover-ing 12.4{\%} of the genome), 94 000 of which are derived from more than one source, and each assigned an annotation-derived confidence score. GeneHancer subsequently links enhancers to genes, using: tissue co-expression correlation between genes and enhancer RNAs, as well as enhancer-targeted transcription factor genes; expression quantitative trait loci for variants within enhancers; and capture Hi-C, a promoter-specific genome con-formation assay. The individual scores based on each of these four methods, along with gene–enhancer genomic distances, form the basis for GeneHancer's combinatorial likelihood-based scores for enhancer–gene pairing. Finally, we define 'elite' enhancer– gene relations reflecting both a high-likelihood enhancer definition and a strong enhan-cer–gene association. GeneHancer predictions are fully integrated in the widely used GeneCards Suite, whereby candidate enhancers and their annotations are displayed on every relevant GeneCard. This assists in the mapping of non-coding variants to enhancers, and via the linked genes, forms a basis for variant–phenotype interpretation of whole-genome se-quences in health and disease.},
author = {Fishilevich, Simon and Nudel, Ron and Rappaport, Noa and Hadar, Rotem and Plaschkes, Inbar and {Iny Stein}, Tsippi and Rosen, Naomi and Kohn, Asher and Twik, Michal and Safran, Marilyn and Lancet, Doron and Cohen, Dana},
doi = {10.1093/database/bax028},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Database the journal of biological databases and curation/Fishilevich et al. - 2017 - GeneHancer genome-wide integration of enhancers and target genes in GeneCards.pdf:pdf},
issn = {17580463},
journal = {Database : the journal of biological databases and curation},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
pages = {1--17},
title = {{GeneHancer: genome-wide integration of enhancers and target genes in GeneCards}},
volume = {2017},
year = {2017}
}
@article{BY01,
author = {Benjamini, Yoav and Yekutieli, Daniel},
journal = {The Annals of Statistics},
keywords = {FDR,Multiple testing,canonical,correlation},
mendeley-tags = {FDR,Multiple testing,canonical,correlation},
number = {4},
pages = {1165--1188},
title = {{The control of the false discovery rate in multiple testing under dependency}},
volume = {29},
year = {2001}
}
@article{Xie2018,
abstract = {Simultaneously detecting CRISPR-based perturbations and induced transcriptional changes in the same cell is a powerful approach to unraveling genome function. Several lentiviral approaches have been developed, some of which rely on the detection of distally located genetic barcodes as an indirect proxy of sgRNA identity. Since barcodes are often several kilobases from their corresponding sgRNAs, viral recombination-mediated swapping of barcodes and sgRNAs is feasible. Using a self-circularization-based sgRNA-barcode library preparation protocol, we estimate the recombination rate to be {\~{}}50{\%} and we trace this phenomenon to the pooled viral packaging step. Recombination is random, and decreases the signal-to-noise ratio of the assay. Our results suggest that alternative approaches can increase the throughput and sensitivity of single-cell perturbation assays.},
author = {Xie, Shiqi and Cooley, Anne and Armendariz, Daniel and Zhou, Pei and Hon, Gary C.},
doi = {10.1371/journal.pone.0198635},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/PLoS ONE/Xie et al. - 2018 - Frequent sgRNA-barcode recombination in single-cell perturbation assays.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
month = {jun},
number = {6},
publisher = {Public Library of Science},
title = {{Frequent sgRNA-barcode recombination in single-cell perturbation assays}},
volume = {13},
year = {2018}
}
@article{Pushalkar,
author = {Pushalkar, Smruti and Ji, Xiaojie and Li, Yihong and Estilo, Cherry and Yegnanarayana, Ramanathan and Singh, Bhuvanesh and Li, Xin and Saxena, Deepak},
journal = {BMC Microbiology},
keywords = {microbiome},
mendeley-tags = {microbiome},
number = {1},
pages = {144},
title = {{Comparison of oral microbiota in tumor and non-tumor tissues of patients with oral squamous cell carcinoma}},
volume = {12},
year = {2012}
}
@article{Patron2019,
abstract = {To date more than 3700 genome-wide association studies (GWAS) have been published that look at the genetic contributions of single nucleotide polymorphisms (SNPs) to human conditions or human phenotypes. Through these studies many highly significant SNPs have been identified for hundreds of diseases or medical conditions. However, the extent to which GWAS-identified SNPs or combinations of SNP biomarkers can predict disease risk is not well known. One of the most commonly used approaches to assess the performance of predictive biomarkers is to determine the area under the receiver-operator characteristic curve (AUROC). We have developed an R package called G-WIZ to generate ROC curves and calculate the AUROC using summary-level GWAS data. We first tested the performance of G-WIZ by using AUROC values derived from patient-level SNP data, as well as literature-reported AUROC values. We found that G-WIZ predicts the AUROC with {\textless}3{\%} error. Next, we used the summary level GWAS data from GWAS Central to determine the ROC curves and AUROC values for 569 different GWA studies spanning 219 different conditions. Using these data we found a small number of GWA studies with SNP-derived risk predictors that have very high AUROCs ({\textgreater}0.75). On the other hand, the average GWA study produces a multi-SNP risk predictor with an AUROC of 0.55. Detailed AUROC comparisons indicate that most SNP-derived risk predictions are not as good as clinically based disease risk predictors. All our calculations (ROC curves, AUROCs, explained heritability) are in a publicly accessible database called GWAS-ROCS (http://gwasrocs.ca). The G-WIZ code is freely available for download at https://github.com/jonaspatronjp/GWIZ-Rscript/.},
author = {Patron, Jonas and Cayuela, Arnau Serra and Han, Beomsoo and Li, Carin and Wishart, David Scott},
doi = {10.1101/701086},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Patron et al. - 2019 - Assessing the performance of genome-wide association studies for predicting disease risk.pdf:pdf},
journal = {bioRxiv},
pages = {701086},
title = {{Assessing the performance of genome-wide association studies for predicting disease risk}},
url = {https://www.biorxiv.org/content/10.1101/701086v2.abstract?{\%}3Fcollection=},
year = {2019}
}
@article{LetM14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/24995987{\}}{\{}24995987{\}}},
author = {Li, Y and Calvo, S E and Gutman, R and Liu, J S and Mootha, V K},
journal = {Cell},
month = {jul},
number = {1},
pages = {213--225},
title = {{{\{}E{\}}xpansion of biological pathways based on evolutionary inference}},
volume = {158},
year = {2014}
}
@article{KF00,
author = {Knight, Keith and Fu, Wenjiang},
journal = {The Annals of Statistics},
keywords = {high-dimensional regression,lasso},
mendeley-tags = {high-dimensional regression,lasso},
pages = {1356--1378},
publisher = {JSTOR},
title = {{Asymptotics for lasso-type estimators}},
year = {2000}
}
@book{VanderLaan2003,
address = {New York},
author = {van der Laan, Mark J. and Robins, James M.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/van der Laan, Robins - 2003 - Unified methods for censored longitudinal data and causality.pdf:pdf},
isbn = {1-4419-0319-8},
publisher = {Springer-Verlag},
title = {{Unified methods for censored longitudinal data and causality}},
year = {2003}
}
@article{lei17star,
abstract = {We propose a general framework based on $\backslash$textit{\{}selectively traversed accumulation rules{\}} (STAR) for interactive "human-in-the-loop" multiple testing with generic structural constraints on the rejection set. STAR combines accumulation tests from ordered multiple testing with data-carving ideas from post-selection inference, allowing for highly flexible adaptation to generic structural information. Given independent {\$}p{\$}-values for each of {\$}n{\$} null hypotheses, STAR defines an iterative protocol for gradually pruning a candidate rejection set, beginning with {\$}\backslashmathcal{\{}R{\}}{\_}0 = [n]{\$} and shrinking with each step. At step {\$}t{\$}, the analyst estimates the false discovery proportion (FDP) of the current rejection set {\$}\backslashmathcal{\{}R{\}}{\_}t{\$}, and halts and rejects every {\$}H{\_}i{\$} with {\$}i \backslashin \backslashmathcal{\{}R{\}}{\_}t{\$} if {\$}\backslashmathrm{\{}FDP{\}}{\_}t \backslashleq \backslashalpha{\$}. Otherwise, the analyst may shrink the rejection set to {\$}\backslashmathcal{\{}R{\}}{\_}{\{}t+1{\}}\backslashsubseteq \backslashmathcal{\{}R{\}}{\_}t{\$} however she wants, provided the choice depends only on partially masked {\$}p{\$}-values {\$}g(p{\_}i){\$} for {\$}i\backslashin \backslashmathcal{\{}R{\}}{\_}t{\$}, as well as unmasked {\$}p{\$}-values {\$}p{\_}i{\$} for {\$}i\backslashnotin \backslashmathcal{\{}R{\}}{\_}t{\$}. Typically, the choice will be based on eliminating the "least promising" hypothesis from {\$}\backslashmathcal{\{}R{\}}{\_}t{\$}, after estimating a model from the observable data. By restricting the information available to the analyst, our iterative protocol guarantees exact false discovery rate (FDR) control at level {\$}\backslashalpha{\$} in finite samples, for any data-adaptive update rule the analyst may choose. We suggest heuristic update rules for a variety of applications with complex structural constraints, show that STAR performs well for problems ranging from convex region detection and bump-hunting to FDR control on trees and DAGs, and show how to extend STAR to regression problems where knockoff statistics are available in lieu of {\$}p{\$}-values.},
archivePrefix = {arXiv},
arxivId = {1710.02776},
author = {Lei, Lihua and Ramdas, Aaditya and Fithian, William},
eprint = {1710.02776},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Lei, Ramdas, Fithian - 2020 - A general interactive framework for false discovery rate control under structural constraints.pdf:pdf},
journal = {Biometrika},
keywords = {FDR,Multiple testing,structured multiple testing},
mendeley-tags = {FDR,Multiple testing,structured multiple testing},
title = {{A general interactive framework for false discovery rate control under structural constraints}},
url = {http://arxiv.org/abs/1710.02776},
year = {2020}
}
@article{Pimentel2015,
abstract = {Every newly trained surgeon performs her first unsupervised operation. How do the health outcomes of her patients compare with the patients of experienced surgeons? Using data from 498 hospitals, we compare 1252 pairs comprised of a new surgeon and an experienced surgeon working at the same hospital. We introduce a new form of matching that matches patients of each new surgeon to patients of an otherwise similar experienced surgeon at the same hospital, perfectly balancing 176 surgical procedures and closely balancing a total of 2.9 million categories of patients; additionally, the individual patient pairs are as close as possible. A new goal for matching is introduced, called “refined covariate balance,” in which a sequence of nested, ever more refined, nominal covariates is balanced as closely as possible, emphasizing the first or coarsest covariate in that sequence. A new algorithm for matching is proposed and the main new results prove that the algorithm finds the closest match in terms of the total within-pair covariate distances among all matches that achieve refined covariate balance. Unlike previous approaches to forcing balance on covariates, the new algorithm creates multiple paths to a match in a network, where paths that introduce imbalances are penalized and hence avoided to the extent possible. The algorithm exploits a sparse network to quickly optimize a match that is about two orders of magnitude larger than is typical in statistical matching problems, thereby permitting much more extensive use of fine and near-fine balance constraints. The match was constructed in a few minutes using a network optimization algorithm implemented in R. An R package called rcbalance implementing the method is available from CRAN.},
author = {Pimentel, Samuel D. and Kelz, Rachel R. and Silber, Jeffrey H. and Rosenbaum, Paul R.},
doi = {10.1080/01621459.2014.997879},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Pimentel et al. - 2015 - Large, Sparse Optimal Matching With Refined Covariate Balance in an Observational Study of the Health Outcomes.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Fine balance,Network optimization,Optimal matching,Sparse networks,causality,matching,observational studies},
mendeley-tags = {causality,matching,observational studies},
number = {510},
pages = {515--527},
title = {{Large, Sparse Optimal Matching With Refined Covariate Balance in an Observational Study of the Health Outcomes Produced by New Surgeons}},
volume = {110},
year = {2015}
}
@article{Park2021,
abstract = {Finding a causal gene from case-control studies is a classic and fundamental problem in genomics. To date, we still ask which genes are differentially regulated by a disease with single-cell sequencing data, but in a cell-type-specific way. Here, we present a causal inference framework that effectively adjusts confounding effects, not requiring prior knowledge of control genes or cells. We demonstrate that our causal inference algorithm substantially improves statistical power in simulations and real-world data analysis of 70k brain cells, collected for dissecting Alzheimer's disease (AD) mechanisms. We identified that 377 causal genes are differentially regulated by the disease in various brain cell types, including highly-relevant AD genes with a proper cell type annotation, such as DGKD in neurons, SNCA in microglia, PIAS in oligodendrocyte progenitor cells, and FGFR2 in astrocytes. Causal genes in different cell types also enrich distinctive pathways, highlighting multiple components of the disease progressions.Competing Interest StatementThe authors have declared no competing interest.Funding StatementThis work was supported by NIH grants U01NS110453, U24-HG009446, and U01-RFA-HG009088 (MK). We also acknowledge generous supports from the BC Cancer Foundation, Project ID 1NSRG048 (YPP).Author DeclarationsI confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.YesThe details of the IRB/oversight body that provided approval or exemption for the research described are given below:The results published here are in whole or in part based on data obtained from the AD Knowledge Portal (https://adknowledgeportal.synapse.org). Study data were provided by the Rush Alzheimer{\&}{\#}039;s Disease Center, Rush University Medical Center, Chicago. Data collection was supported through funding by NIA grants RF1AG57473 (single nucleus RNAseq) and the Illinois Department of Public Health (ROSMAP). The Religious Orders Study and Rush Memory and Aging Project were approved by an IRB of Rush University Medical Center.All necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived.YesI understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).YesI have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.YesContact Yongjin Park (ypp{\{}at{\}}stat.ubc.ca) for the questions on analysis Scripts (https://github.com/YPARK/cocoa{\_}paper). C++ programs are publicly available at GitHub (http://github.com/ypark/mmutil). https://github.com/YPARK/cocoa{\_}paper http://github.com/ypark/mmutil},
author = {Park, Yongjin and Kellis, Manolis},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/medRxiv/Park, Kellis - 2021 - Counterfactual inference for single-cell gene expression analysis.pdf:pdf},
journal = {medRxiv},
pages = {2021.01.21.21249765},
title = {{Counterfactual inference for single-cell gene expression analysis}},
url = {http://medrxiv.org/content/early/2021/01/26/2021.01.21.21249765.abstract},
year = {2021}
}
@article{GCTA,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21167468{\}}{\{}21167468{\}}},
author = {Yang, J and Lee, S H and Goddard, M E and Visscher, P M},
journal = {American Journal of Human Genetics},
keywords = {GWAS,linear mixed models},
mendeley-tags = {GWAS,linear mixed models},
number = {1},
pages = {76--82},
title = {{{\{}GCTA{\}}: a tool for genome-wide complex trait analysis}},
volume = {88},
year = {2011}
}
@article{Reese2019,
abstract = {When the number of features exponentially outnumbers the number of samples, feature screening plays a pivotal role in reducing the dimension of the feature space and developing models based on such data. While most extant feature screening approaches are only applicable to data having univariate response, we propose a new method (GenCorr) that admits a multivariate response. Such an approach allows us to more appropriately model multiple responses as a single unit, rather than as unrelated entities, which avails more robust analyses in relation to complex traits embedded in the covariance structure of multiple responses. The GenCorr framework allows for the screening of both marginal as well as interactive features. It is demonstrated that GenCorr possesses the desirable property of strong sure screening. In the marginal case, we examine the superior numerical performance of GenCorr in comparison to two current methods for multivariate marginal screening via an assortment of empirical simulations. We also present several simulations inspecting GenCorr's performance in multivariate interaction screening. A culminating real data analysis demonstrates the performance of our method on GWAS data.},
archivePrefix = {arXiv},
arxivId = {1911.06955},
author = {Reese, Randall},
eprint = {1911.06955},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Reese - 2019 - Marginal and Interactive Feature Screening of Ultra-high Dimensional Feature Spaces with Multivariate Response.pdf:pdf},
title = {{Marginal and Interactive Feature Screening of Ultra-high Dimensional Feature Spaces with Multivariate Response}},
url = {http://arxiv.org/abs/1911.06955},
year = {2019}
}
@article{Toshiyuki2003,
abstract = {Explanations for the risks associated with premarital and nonmarital chabitation (e.g., higher Fates of breakup and divorce, lower relationship satisfaction, and greater risk for violent interaction) have focused on levels of conventionality, including attitudes about commitment to the institution of marriage. However, relatively little attention has been paid to the role of interpersonal, not institutional, commitment. In a national random sample (United States), Premarital and nonmarital cohabitation were associated with lower levels of interpersonal commitment to partners, suggesting links to further understanding of risk in these relationships. Premarital cohabitation was particularly associated with less committed and less religious males. Prior findings associating cohabitation with lower levels of happiness and religiosity, and higher levels of negative interaction (for men) were replicated.},
author = {Toshiyuki, Shiraki and Kondo, Shinji and Katayama, Shintaro and Waki, Kazunori and Kasukawa, Takeya and Kawaji, Hideya and Kodzius, Rimantas and Watahiki, Akira and Nakamura, Mari and Arakawa, Takahiro and Fukuda, Shiro and Sasaki, Daisuke and Podhajska, Anna and Harbers, Matthias and Kawai, Jun and Carninci, Piero and {Hayashizaki Yoshihide}},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences/Toshiyuki et al. - 2003 - Cap analysis gene expression for high-throughput analysis of transcriptional starting point and identification.pdf:pdf},
isbn = {0192-513X},
issn = {0192-513X},
journal = {Proceedings of the National Academy of Sciences},
keywords = {CAGE},
mendeley-tags = {CAGE},
number = {26},
pages = {15776--15781},
title = {{Cap analysis gene expression for high-throughput analysis of transcriptional starting point and identification of promoter usage}},
url = {https://search.proquest.com/docview/1891697797},
volume = {100},
year = {2003}
}
@article{BN95,
annote = {7607457},
author = {Balding, D J and Nichols, R A},
journal = {Genetica},
keywords = {genetics},
mendeley-tags = {genetics},
pages = {3--12},
title = {{{\{}A{\}} method for quantifying differentiation between populations at multi-allelic loci and its implications for investigating identity and paternity}},
volume = {96},
year = {1995}
}
@article{Peterson2017,
abstract = {We present a tool to measure gene and protein expression levels in single cells with DNA-labeled antibodies and droplet microfluidics. Using the RNA expression and protein sequencing assay (REAP-seq), we quantified proteins with 82 barcoded antibodies and {\textgreater}20,000 genes in a single workflow. We used REAP-seq to assess the costimulatory effects of a CD27 agonist on human CD8 + lymphocytes and to identify and characterize an unknown cell type.},
author = {Peterson, Vanessa M. and Zhang, Kelvin Xi and Kumar, Namit and Wong, Jerelyn and Li, Lixia and Wilson, Douglas C. and Moore, Renee and Mcclanahan, Terrill K. and Sadekova, Svetlana and Klappenbach, Joel A.},
doi = {10.1038/nbt.3973},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Peterson et al. - 2017 - Multiplexed quantification of proteins and transcripts in single cells.pdf:pdf},
issn = {15461696},
journal = {Nature Biotechnology},
keywords = {multi-omics},
mendeley-tags = {multi-omics},
number = {10},
pages = {936--939},
pmid = {28854175},
title = {{Multiplexed quantification of proteins and transcripts in single cells}},
volume = {35},
year = {2017}
}
@article{Hirano2004,
author = {Hirano, Keisuke and Imbens, Guido W.},
doi = {10.1002/0470090456.ch7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Applied Bayesian Modeling and Causal Inference from Incomplete-Data Perspectives/Hirano, Imbens - 2004 - The Propensity Score with Continuous Treatments.pdf:pdf},
isbn = {9780470090459},
journal = {Applied Bayesian Modeling and Causal Inference from Incomplete-Data Perspectives},
keywords = {Asymptotic standard errors,Binary treatment case,Conventional regression estimates,Dose-response function,Generalized propensity score (GPS),Marginal structural model (MSM),Propensity score methodology,Weak unconfoundedness,causality},
mendeley-tags = {causality},
pages = {73--84},
title = {{The Propensity Score with Continuous Treatments}},
year = {2004}
}
@article{Wu2013,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23676674{\}}{\{}23676674{\}}},
author = {Wu, L and Candille, S I and Choi, Y and Xie, D and Jiang, L and Li-Pook-Than, J and Tang, H and Snyder, M},
journal = {Nature},
keywords = {gene regulation},
mendeley-tags = {gene regulation},
number = {7456},
pages = {79--82},
title = {{Variation and genetic control of protein abundance in humans}},
volume = {499},
year = {2013}
}
@article{Canver2019a,
author = {Canver, Matthew C and Tripathi, Pratibha and Olshansky, Moshe and Turner, Stephen J and Orkin, Stuart H and Bullen, Michael J and Lessard, Samuel and Kumar, Yogesh and Pinello, Luca},
doi = {10.1101/851683},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Canver et al. - 2019 - A saturating mutagenesis CRISPR-Cas9 mediated functional genomic screen identifies.pdf:pdf},
journal = {bioRxiv},
title = {{A saturating mutagenesis CRISPR-Cas9 mediated functional genomic screen identifies}},
year = {2019}
}
@article{G66,
author = {Gower, J C},
issn = {0006-3444},
journal = {Biometrika},
pages = {325--338},
title = {{Some distance properties of latent root and vector methods used in multivariate analysis}},
volume = {53},
year = {1966}
}
@article{Efron2002,
author = {Efron, B and Tibshirani, R},
journal = {Genetic Epidemiology},
keywords = {FDR,empirical Bayes},
mendeley-tags = {FDR,empirical Bayes},
number = {1},
pages = {70--86},
title = {{Empirical Bayes methods and false discovery rates for microarrays}},
volume = {23},
year = {2002}
}
@inproceedings{GetW15,
author = {Gossmann, Alexej and Cao, Shaolong and Wang, Yu-Ping},
booktitle = {Proceedings of the 6th ACM Conference on Bioinformatics, Computational Biology and Health Informatics},
keywords = {groups,high-dimensional regression},
mendeley-tags = {groups,high-dimensional regression},
organization = {ACM},
pages = {232--240},
title = {{Identification of significant genetic variants via SLOPE, and its extension to group SLOPE}},
year = {2015}
}
@article{F18,
author = {Fisher, R A},
journal = {Trans. Roy. Soc. Edinb.},
keywords = {canonical},
mendeley-tags = {canonical},
pages = {399--433},
title = {{The correlation between relatives on the supposition of Mendelian inheritance}},
volume = {52},
year = {1918}
}
@article{Li2012,
abstract = {Higher-order chromosomal organization for transcription regulation is poorly understood in eukaryotes. Using genome-wide Chromatin Interaction Analysis with Paired-End-Tag sequencing (ChIA-PET), we mapped long-range chromatin interactions associated with RNA polymerase II in human cells and uncovered widespread promoter-centered intragenic, extragenic, and intergenic interactions. These interactions further aggregated into higher-order clusters, wherein proximal and distal genes were engaged through promoter-promoter interactions. Most genes with promoter-promoter interactions were active and transcribed cooperatively, and some interacting promoters could influence each other implying combinatorial complexity of transcriptional controls. Comparative analyses of different cell lines showed that cell-specific chromatin interactions could provide structural frameworks for cell-specific transcription, and suggested significant enrichment of enhancer-promoter interactions for cell-specific functions. Furthermore, genetically-identified disease-associated noncoding elements were found to be spatially engaged with corresponding genes through long-range interactions. Overall, our study provides insights into transcription regulation by three-dimensional chromatin interactions for both housekeeping and cell-specific genes in human cells. {\textcopyright} 2012 Elsevier Inc.},
author = {Li, Guoliang and Ruan, Xiaoan and Auerbach, Raymond K. and Sandhu, Kuljeet Singh and Zheng, Meizhen and Wang, Ping and Poh, Huay Mei and Goh, Yufen and Lim, Joanne and Zhang, Jingyao and Sim, Hui Shan and Peh, Su Qin and Mulawadi, Fabianus Hendriyan and Ong, Chin Thing and Orlov, Yuriy L. and Hong, Shuzhen and Zhang, Zhizhuo and Landt, Steve and Raha, Debasish and Euskirchen, Ghia and Wei, Chia Lin and Ge, Weihong and Wang, Huaien and Davis, Carrie and Fisher-Aylor, Katherine I. and Mortazavi, Ali and Gerstein, Mark and Gingeras, Thomas and Wold, Barbara and Sun, Yi and Fullwood, Melissa J. and Cheung, Edwin and Liu, Edison and Sung, Wing Kin and Snyder, Michael and Ruan, Yijun},
doi = {10.1016/j.cell.2011.12.014},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Li et al. - 2012 - Extensive promoter-centered chromatin interactions provide a topological basis for transcription regulation.pdf:pdf},
issn = {00928674},
journal = {Cell},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {1-2},
pages = {84--98},
publisher = {Elsevier Inc.},
title = {{Extensive promoter-centered chromatin interactions provide a topological basis for transcription regulation}},
url = {http://dx.doi.org/10.1016/j.cell.2011.12.014},
volume = {148},
year = {2012}
}
@article{AE89,
abstract = {The robust method for detecting linkage developed by Haseman and Elston [The investigation of linkage between a quantitative trait and a marker locus. Behav Genet 2:3-19, 1972] for data from sib pairs is extended to any type of noninbred relative pair. The regression of the squared relative-pair trait difference on the estimated proportion of genes identical by descent (i.b.d.) at a marker locus is shown to depend upon the recombination fraction between the two loci; the regression coefficient is negative if the trait and marker loci are linked. A test for linkage based on data from any informative type of relative pair can thus be obtained by testing that this regression coefficient is less than zero. Formulae for the asymptotic power of such tests for linkage based upon independent relative pairs are developed. Results are also given for the special case in which the proportion of genes shared i.b.d. for relative pairs is known. Finally, a general algorithm is described that will incorporate all available pedigree data to calculate an estimate of the proportion of genes that a relative pair shares i.b.d. at a marker locus.},
annote = {2721929},
author = {Amos, C I and Elston, R C},
doi = {10.1002/gepi.1370060205},
journal = {Genetic Epidemiology},
keywords = {genetics},
mendeley-tags = {genetics},
number = {2},
pages = {349--360},
title = {{Robust methods for the detection of genetic linkage for quantitative data from pedigrees}},
url = {http://www.hubmed.org/display.cgi?uids=2721929},
volume = {6},
year = {1989}
}
@incollection{S13,
author = {Sabatti, C},
booktitle = {Advances in Statistical Bioinformatics},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
pages = {188--208},
publisher = {Cambridge University Press},
title = {{Multivariate linear models for {\{}G{\}}{\{}W{\}}{\{}A{\}}{\{}S{\}}}},
year = {2013}
}
@article{KSM18,
archivePrefix = {arXiv},
arxivId = {1809.01792},
author = {Katsevich, Eugene and Sabatti, Chiara and Bogomolov, Marina},
eprint = {1809.01792},
journal = {arXiv},
keywords = {FDR,unpublished},
mendeley-tags = {FDR,unpublished},
title = {{Filtering the rejection set while preserving false discovery rate control}},
year = {2018}
}
@article{Kimmel2006a,
author = {Kimmel, Gad and Shamir, Ron},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Human Genetics/Kimmel, Shamir - 2006 - A Fast Method for Computing High-Significance Disease Association in Large Population-Based Studies.pdf:pdf},
journal = {Journal of Human Genetics},
keywords = {Monte Carlo,Multiple testing},
mendeley-tags = {Monte Carlo,Multiple testing},
number = {September},
pages = {481--492},
title = {{A Fast Method for Computing High-Significance Disease Association in Large Population-Based Studies}},
volume = {79},
year = {2006}
}
@article{PetF16,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26712028{\}}{\{}26712028{\}}},
author = {Pagani, L and {St Clair}, P A and Teshiba, T M and Service, S K and Fears, S C and Araya, C and Araya, X and Bejarano, J and Ramirez, M and Castrillon, G and Gomez-Makhinson, J and Lopez, M C and Montoya, G and Montoya, C P and Aldana, I and Navarro, L and Freimer, D G and Safaie, B and Keung, L W and Greenspan, K and Chou, K and Escobar, J I and Ospina-Duque, J and Kremeyer, B and Ruiz-Linares, A and Cantor, R M and Lopez-Jaramillo, C and Macaya, G and Molina, J and Reus, V I and Sabatti, C and Bearden, C E and Takahashi, J S and Freimer, N B},
journal = {Proceedings of the National Academy of Sciences},
month = {feb},
number = {6},
pages = {E754----761},
title = {{{\{}G{\}}enetic contributions to circadian activity rhythm and sleep pattern phenotypes in pedigrees segregating for severe bipolar disorder}},
volume = {113},
year = {2016}
}
@article{Frangieh2020,
author = {Frangieh, Chris J and Melms, Johannes C and Thakore, Pratiksha I and Geiger-Schuller, Kathryn R and Ho, Patricia and Luoma, Adrienne M and Cleary, Brian and Malu, Shruti and Cuoco, Michael and Zhao, Maryann and Rogava, Meri and Hovey, Lila and Rotem, Asaf and Bernatche, Chantale and Wucherpfennig, Kai W. and Johnson, Bruce E. and Rozenblatt-Rosen, Orit and Schadendorf, Dirk and Regev, Aviv and Izar, Benjamin},
journal = {bioRxiv},
keywords = {CRISPR,single cell},
mendeley-tags = {CRISPR,single cell},
title = {{Multi-modal pooled Perturb-CITE-Seq screens in patient models define novel mechanisms of cancer immune evasion}},
url = {doi: https://doi.org/10.1101/2020.09.01.267211},
year = {2020}
}
@incollection{Robins1992a,
address = {Boston},
author = {Robins, James M. and Rotnitzky, Andrea},
booktitle = {AIDS epidemiology},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/AIDS epidemiology/Robins, Rotnitzky - 1992 - Recovery of information and adjustment for dependent censoring using surrogate markers.pdf:pdf},
pages = {297--331},
publisher = {Birkh{\"{a}}user},
title = {{Recovery of information and adjustment for dependent censoring using surrogate markers}},
year = {1992}
}
@article{Du2017,
abstract = {We describe a combinatorial CRISPR interference (CRISPRi) screening platform for mapping genetic interactions in mammalian cells. We targeted 107 chromatin-regulation factors in human cells with pools of either single or double single guide RNAs (sgRNAs) to downregulate individual genes or gene pairs, respectively. Relative enrichment analysis of individual sgRNAs or sgRNA pairs allowed for quantitative characterization of genetic interactions, and comparison with protein-protein-interaction data revealed a functional map of chromatin regulation.},
author = {Du, Dan and Roguev, Assen and Gordon, David E. and Chen, Meng and Chen, Si Han and Shales, Michael and Shen, John Paul and Ideker, Trey and Mali, Prashant and Qi, Lei S. and Krogan, Nevan J.},
doi = {10.1038/nmeth.4286},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Du et al. - 2017 - Genetic interaction mapping in mammalian cells using CRISPR interference.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {CRISPR,interactions},
mendeley-tags = {CRISPR,interactions},
number = {6},
pages = {577--580},
title = {{Genetic interaction mapping in mammalian cells using CRISPR interference}},
volume = {14},
year = {2017}
}
@article{Meinshaunsen2010,
author = {Meinshausen, Nicolai and Buhlmann, Peter},
doi = {10.1007/978-3-662-44185-5_989},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society Series B (Statistical Methodology)/Meinshausen, Buhlmann - 2010 - Stability selection.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {Multiple testing,high dimensional data,high-dimensional regression,resampling,stability selection,structure estimation,to-read},
mendeley-tags = {Multiple testing,high-dimensional regression,stability selection,to-read},
pages = {417--473},
title = {{Stability selection}},
volume = {72},
year = {2010}
}
@article{HetB082,
abstract = {Testing one SNP at a time does not fully realise the potential of genome-wide association studies to identify multiple causal variants, which is a plausible scenario for many complex diseases. We show that simultaneous analysis of the entire set of SNPs from a genome-wide study to identify the subset that best predicts disease outcome is now feasible, thanks to developments in stochastic search methods. We used a Bayesian-inspired penalised maximum likelihood approach in which every SNP can be considered for additive, dominant, and recessive contributions to disease risk. Posterior mode estimates were obtained for regression coefficients that were each assigned a prior with a sharp mode at zero. A non-zero coefficient estimate was interpreted as corresponding to a significant SNP. We investigated two prior distributions and show that the normal-exponential-gamma prior leads to improved SNP selection in comparison with single-SNP tests. We also derived an explicit approximation for type-I error that avoids the need to use permutation procedures. As well as genome-wide analyses, our method is well-suited to fine mapping with very dense SNP sets obtained from re-sequencing and/or imputation. It can accommodate quantitative as well as case-control phenotypes, covariate adjustment, and can be extended to search for interactions. Here, we demonstrate the power and empirical type-I error of our approach using simulated case-control data sets of up to 500 K SNPs, a real genome-wide data set of 300 K SNPs, and a sequence-based dataset, each of which can be analysed in a few hours on a desktop workstation.},
annote = {18654633},
author = {Hoggart, C J and Whittaker, J C and {De Iorio}, M and Balding, D J},
doi = {10.1371/journal.pgen.1000130},
journal = {PLoS Genetics},
number = {7},
title = {{Simultaneous analysis of all SNPs in genome-wide and re-sequencing association studies}},
url = {http://www.hubmed.org/display.cgi?uids=18654633},
volume = {4},
year = {2008}
}
@article{LB17,
author = {Li, Ang and Barber, Rina Foygel},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Li, Barber - 2017 - Accumulation tests for FDR control in ordered hypothesis testing.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Li, Barber - 2017 - Accumulation tests for FDR control in ordered hypothesis testing(2).pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {FDR,Multiple testing,ordered testing},
mendeley-tags = {FDR,Multiple testing,ordered testing},
number = {518},
pages = {837--849},
publisher = {Taylor {\&} Francis},
title = {{Accumulation tests for FDR control in ordered hypothesis testing}},
volume = {112},
year = {2017}
}
@article{Loh2015,
abstract = {Linear mixed models are a powerful statistical tool for identifying genetic associations and avoiding confounding. However, existing methods are computationally intractable in large cohorts and may not optimize power. All existing methods require time cost O(MN 2) (where N is the number of samples and M is the number of SNPs) and implicitly assume an infinitesimal genetic architecture in which effect sizes are normally distributed, which can limit power. Here we present a far more efficient mixed-model association method, BOLT-LMM, which requires only a small number of O(MN) time iterations and increases power by modeling more realistic, non-infinitesimal genetic architectures via a Bayesian mixture prior on marker effect sizes. We applied BOLT-LMM to 9 quantitative traits in 23,294 samples from the Women's Genome Health Study (WGHS) and observed significant increases in power, consistent with simulations. Theory and simulations show that the boost in power increases with cohort size, making BOLT-LMM appealing for genome-wide association studies in large cohorts.},
author = {Loh, Po Ru and Tucker, George and Bulik-Sullivan, Brendan K. and Vilhj{\'{a}}lmsson, Bjarni J. and Finucane, Hilary K. and Salem, Rany M. and Chasman, Daniel I. and Ridker, Paul M. and Neale, Benjamin M. and Berger, Bonnie and Patterson, Nick and Price, Alkes L.},
doi = {10.1038/ng.3190},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Loh et al. - 2015 - Efficient Bayesian mixed-model analysis increases association power in large cohorts.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
number = {3},
pages = {284--290},
publisher = {Nature Publishing Group},
title = {{Efficient Bayesian mixed-model analysis increases association power in large cohorts}},
volume = {47},
year = {2015}
}
@article{Goeman2010,
abstract = {Closed testing and partitioning are recognized as fundamental principles of familywise error control. In this paper, we argue that sequential rejection can be considered equally fundamental as a general principle of multiple testing. We present a general sequentially rejective multiple testing procedure and show that many well-known familywise error controlling methods can be constructed as special cases of this procedure, among which are the procedures of Holm, Shaffer and Hochberg, parallel and serial gatekeeping procedures, modern procedures for multiple testing in graphs, resampling-based multiple testing procedures and even the closed testing and partitioning procedures themselves. We also give a general proof that sequentially rejective multiple testing procedures strongly control the familywise error if they fulfill simple criteria of monotonicity of the critical values and a limited form of weak familywise error control in each single step. The sequential rejection principle gives a novel theoretical perspective on many well-known multiple testing procedures, emphasizing the sequential aspect. Its main practical usefulness is for the development of multiple testing procedures for null hypotheses, possibly logically related, that are structured in a graph. We illustrate this by presenting a uniform improvement of a recently published procedure.},
author = {Goeman, Jelle J. and Solari, Aldo},
doi = {10.1214/10-AOS829},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Goeman, Solari - 2010 - The sequential rejection principle of familywise error control.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {FWER,Familywise error rate,Graph,Multiple testing,to-read},
mendeley-tags = {FWER,Multiple testing,to-read},
number = {6},
pages = {3782--3810},
title = {{The sequential rejection principle of familywise error control}},
volume = {38},
year = {2010}
}
@article{EK12,
author = {Ernst, Jason and Kellis, Manolis},
journal = {Nature Methods},
keywords = {epigenetics,genetics},
mendeley-tags = {epigenetics,genetics},
number = {3},
pages = {215--216},
publisher = {Nature Research},
title = {{Chrom{\{}HMM{\}}: automating chromatin-state discovery and characterization}},
volume = {9},
year = {2012}
}
@article{MetB10,
author = {McLean, C Y and Bristor, D and Hiller, M and Clarke, S L and Schaar, B T and Lowe, C B and Wenger, A M and Bejerano, G},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/McLean et al. - 2010 - GREAT improves functional interpretation of cis-regulatory regions.pdf:pdf},
journal = {Nature Biotechnology},
keywords = {Gene Ontology,enrichment analysis,epigenetics,genetics},
mendeley-tags = {Gene Ontology,enrichment analysis,epigenetics,genetics},
month = {may},
number = {5},
pages = {495--501},
title = {{GREAT improves functional interpretation of cis-regulatory regions}},
url = {https://www.nature.com/articles/nbt.1630},
volume = {28},
year = {2010}
}
@article{OetC12,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/22567092{\}}{\{}22567092{\}}},
author = {O'Reilly, Paul F and Hoggart, Clive J and Pomyen, Yotsawat and Calboli, Federico C F and Elliott, Paul and Jarvelin, Marjo-Riitta and Coin, Lachlan J M},
journal = {PloS one},
keywords = {multiple phenotypes},
mendeley-tags = {multiple phenotypes},
number = {5},
pages = {e34861},
publisher = {Public Library of Science},
title = {{MultiPhen: joint model of multiple phenotypes can increase discovery in GWAS}},
volume = {7},
year = {2012}
}
@article{Dohler2017,
abstract = {To find interesting items in genome-wide association studies or next generation sequencing data, a crucial point is to design powerful false discovery rate (FDR) controlling procedures that suitably combine discrete tests (typically binomial or Fisher tests). In particular, recent research has been striving for appropriate modifications of the classical Benjamini-Hochberg (BH) step-up procedure that accommodate discreteness. However, despite an important number of attempts, these procedures did not come with theoretical guarantees. The present paper contributes to fill the gap: it presents new modifications of the BH procedure that incorporate the discrete structure of the data and provably control the FDR for any fixed number of null hypotheses (under independence). Markedly, our FDR controlling methodology allows to incorporate simultaneously the discreteness and the quantity of signal of the data (corresponding therefore to a so-called {\$}\backslashpi\backslash{\_}0{\$}-adaptive procedure). The power advantage of the new methods is demonstrated in a numerical experiment and for some appropriate real data sets.},
archivePrefix = {arXiv},
arxivId = {1706.08250},
author = {D{\"{o}}hler, Sebastian and Durand, Guillermo and Roquain, Etienne},
eprint = {1706.08250},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/D{\"{o}}hler, Durand, Roquain - 2017 - Improving the Benjamini-Hochberg Procedure for Discrete Tests.pdf:pdf},
journal = {arXiv},
keywords = {adaptive procedure,an important focus has,and phrases,been given to methods,control,controlling the false discovery,data,discrete hypothesis testing,false discovery rate,fdr,find significant items in,massive and complex,multiple testing procedures are,now routinely used to,rate,step-down algorithm,step-up algorithm,type i error rate},
title = {{Improving the Benjamini-Hochberg Procedure for Discrete Tests}},
url = {http://arxiv.org/abs/1706.08250},
year = {2017}
}
@article{Soon2013,
abstract = {Advances in genome sequencing have progressed at a rapid pace, with increased throughput accompanied by plunging costs. But these advances go far beyond faster and cheaper. High-throughput sequencing technologies are now routinely being applied to a wide range of important topics in biology and medicine, often allowing researchers to address important biological questions that were not possible before. In this review, we discuss these innovative new approaches-including ever finer analyses of transcriptome dynamics, genome structure and genomic variation-and provide an overview of the new insights into complex biological systems catalyzed by these technologies. We also assess the impact of genotyping, genome sequencing and personal omics profiling on medical applications, including diagnosis and disease monitoring. Finally, we review recent developments in single-cell sequencing, and conclude with a discussion of possible future advances and obstacles for sequencing in biology and health. {\textcopyright} 2013 EMBO and Macmillan Publishers Limited.},
author = {Soon, Wendy Weijia and Hariharan, Manoj and Snyder, Michael P.},
doi = {10.1038/msb.2012.61},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Molecular Systems Biology/Soon, Hariharan, Snyder - 2013 - High-throughput sequencing for biology and medicine.pdf:pdf},
issn = {17444292},
journal = {Molecular Systems Biology},
keywords = {biology,high-throughput,medicine,sequencing,technologies},
number = {640},
pages = {1--14},
pmid = {23340846},
publisher = {Nature Publishing Group},
title = {{High-throughput sequencing for biology and medicine}},
volume = {9},
year = {2013}
}
@article{Buenrostro2013,
abstract = {We describe an assay for transposase-accessible chromatin using sequencing (ATAC-seq), based on direct in vitro transposition of sequencing adaptors into native chromatin, as a rapid and sensitive method for integrative epigenomic analysis. ATAC-seq captures open chromatin sites using a simple two-step protocol with 500-50,000 cells and reveals the interplay between genomic locations of open chromatin, DNA-binding proteins, individual nucleosomes and chromatin compaction at nucleotide resolution. We discovered classes of DNA-binding factors that strictly avoided, could tolerate or tended to overlap with nucleosomes. Using ATAC-seq maps of human CD4+ T cells from a proband obtained on consecutive days, we demonstrated the feasibility of analyzing an individual's epigenome on a timescale compatible with clinical decision-making. {\textcopyright} 2013 Nature America, Inc.},
author = {Buenrostro, Jason D. and Giresi, Paul G. and Zaba, Lisa C. and Chang, Howard Y. and Greenleaf, William J.},
doi = {10.1038/nmeth.2688},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Buenrostro et al. - 2013 - Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding.pdf:pdf},
issn = {15487091},
journal = {Nature Methods},
number = {12},
pages = {1213--1218},
pmid = {24097267},
title = {{Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position}},
volume = {10},
year = {2013}
}
@article{Carleton2017,
abstract = {Multiple regulatory regions have the potential to regulate a single gene, yet how these elements combine to affect gene expression remains unclear. To uncover the combinatorial relationships between enhancers, we developed Enhancer-interference (Enhancer-i), a CRISPR interference-based approach that uses 2 different repressive domains, KRAB and SID, to prevent enhancer activation simultaneously at multiple regulatory regions. We applied Enhancer-i to promoter-distal estrogen receptor $\alpha$ binding sites (ERBS), which cluster around estradiol-responsive genes and therefore may collaborate to regulate gene expression. Targeting individual sites revealed predominant ERBS that are completely required for the transcriptional response, indicating a lack of redundancy. Simultaneous interference of different ERBS combinations identified supportive ERBS that contribute only when predominant sites are active. Using mathematical modeling, we find strong evidence for collaboration between predominant and supportive ERBS. Overall, our findings expose a complex functional hierarchy of enhancers, where multiple loci bound by the same transcription factor combine to fine-tune the expression of target genes. Carleton et al. have developed a CRISPR-based technique, Enhancer-i, which enables simultaneous deactivation of multiple enhancers and allows for the functional dissection of how enhancers work together to regulate gene expression. They used Enhancer-i to identify estrogen receptor $\alpha$ bound enhancers required for the transcriptional response to estrogens and discovered that specific combinations of enhancers collaborate to produce the estrogen response.},
author = {Carleton, Julia B. and Berrett, Kristofer C. and Gertz, Jason},
doi = {10.1016/j.cels.2017.08.011},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell Systems/Carleton, Berrett, Gertz - 2017 - Multiplex Enhancer Interference Reveals Collaborative Control of Gene Regulation by Estrogen Receptor.pdf:pdf},
issn = {24054720},
journal = {Cell Systems},
keywords = {CRISPR/Cas9,Kathryn,enhancer,enhancer interference,estrogen receptor alpha,gene regulation,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {4},
pages = {333--344.e5},
title = {{Multiplex Enhancer Interference Reveals Collaborative Control of Gene Regulation by Estrogen Receptor $\alpha$-Bound Enhancers}},
volume = {5},
year = {2017}
}
@article{pmid25951947,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25951947{\}}{\{}25951947{\}}},
author = {Dehman, A and Ambroise, C and Neuvial, P},
journal = {BMC Bioinformatics},
keywords = {GWAS,variable selection},
mendeley-tags = {GWAS,variable selection},
pages = {148},
title = {{{\{}P{\}}erformance of a blockwise approach in variable selection using linkage disequilibrium information}},
volume = {16},
year = {2015}
}
@inproceedings{Zhang2019,
abstract = {Monte Carlo (MC) permutation test is considered the gold standard for statistical hypothesis testing, especially when standard parametric assumptions are not clear or likely to fail. However, in modern data science settings where a large number of hypothesis tests need to be performed simultaneously , it is rarely used due to its prohibitive computational cost. In genome-wide association studies, for example, the number of hypothesis tests m is around 10 6 while the number of MC samples n for each test could be greater than 10 8 , totaling more than nm=10 14 samples. In this paper , we propose Adaptive MC multiple Testing (AMT) to estimate MC p-values and control false discovery rate in multiple testing. The algorithm outputs the same result as the standard full MC approach with high probability while requiring only˜Oonly˜ only˜O(√ nm) samples. This sample complexity is shown to be optimal. On a Parkinson GWAS dataset, the algorithm reduces the running time from 2 months for full MC to an hour. The AMT algorithm is derived based on the theory of multi-armed bandits.},
author = {Zhang, Martin J and Zou, James and Tse, David},
booktitle = {ICML},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/ICML/Zhang, Zou, Tse - 2019 - Adaptive Monte Carlo Multiple Testing via Multi-Armed Bandits.pdf:pdf},
keywords = {GWAS,Monte Carlo,Multiple hypothesis testing,Multiple testing,multi-armed bandits,permutation test},
mendeley-tags = {GWAS,Monte Carlo,Multiple testing,multi-armed bandits,permutation test},
title = {{Adaptive Monte Carlo Multiple Testing via Multi-Armed Bandits}},
year = {2019}
}
@article{WetJ07,
annote = {17536212},
author = {Wang, Y and Fang, Y and Jin, M},
journal = {Hum. Hered.},
pages = {182--191},
title = {{{\{}A{\}} ridge penalized principal-components approach based on heritability for high-dimensional data}},
volume = {64},
year = {2007}
}
@article{VetP08,
abstract = {Recent studies of the HapMap lymphoblastoid cell lines have identified large numbers of quantitative trait loci for gene expression (eQTLs). Reanalyzing these data using a novel Bayesian hierarchical model, we were able to create a surprisingly high-resolution map of the typical locations of sites that affect mRNA levels in cis. Strikingly, we found a strong enrichment of eQTLs in the 250 bp just upstream of the transcription end site (TES), in addition to an enrichment around the transcription start site (TSS). Most eQTLs lie either within genes or close to genes; for example, we estimate that only 5{\%} of eQTLs lie more than 20 kb upstream of the TSS. After controlling for position effects, SNPs in exons are approximately 2-fold more likely than SNPs in introns to be eQTLs. Our results suggest an important role for mRNA stability in determining steady-state mRNA levels, and highlight the potential of eQTL mapping as a high-resolution tool for studying the determinants of gene regulation.},
annote = {18846210},
author = {Veyrieras, Jean-Baptiste and Kudaravalli, Sridhar and Kim, Su Yeon and Dermitzakis, Emmanouil T and Gilad, Yoav and Stephens, Matthew and Pritchard, Jonathan K},
journal = {PLoS Genetics},
pages = {e1000214--e1000214},
title = {{{\{}High-resolution{\}} Mapping of {\{}expression-QTLs{\}} Yields Insight into Human gene Regulation}},
volume = {4},
year = {2008}
}
@article{Tibshirani2013,
author = {Tibshirani, Ryan J},
doi = {10.1214/13-EJS815},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Electronic Journal of Statistics/Tibshirani - 2013 - The lasso problem and uniqueness.pdf:pdf},
journal = {Electronic Journal of Statistics},
keywords = {62J07,90C46Lasso,LARS,and phrases,high-dimensional,lars,lasso,received august 2012,uniqueness},
pages = {1456--1490},
title = {{The lasso problem and uniqueness}},
volume = {7},
year = {2013}
}
@article{Hong2008,
author = {Hong, Joung Woo and Hendrix, David A. and Levine, Michael S.},
doi = {10.1126/science.1160631},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Hong, Hendrix, Levine - 2008 - Shadow enhancers as a source of evolutionary novelty.pdf:pdf},
issn = {00368075},
journal = {Science},
keywords = {enhancer},
mendeley-tags = {enhancer},
month = {sep},
number = {5894},
pages = {1314},
title = {{Shadow enhancers as a source of evolutionary novelty}},
volume = {321},
year = {2008}
}
@article{Anderson1986a,
author = {Janssen, Arnold},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Janssen - 1986 - Asymptotic properties of Neyman-Pearson tests for infinite Kullback-Leibler information.pdf:pdf},
journal = {Annals of Statistics},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {3},
pages = {1068--1079},
title = {{Asymptotic properties of Neyman-Pearson tests for infinite Kullback-Leibler information}},
volume = {14},
year = {1986}
}
@article{Howard2019b,
abstract = {Consider the problem of sequentially estimating quantiles of any distribution over a complete, fully-ordered set, based on a stream of i.i.d. observations. We propose new, theoretically sound and practically tight confidence sequences for quantiles, that is, sequences of confidence intervals which are valid uniformly over time. We give two methods for tracking a fixed quantile and two methods for tracking all quantiles simultaneously. Specifically, we provide explicit expressions with small constants for intervals whose widths shrink at the fastest possible t −1 log log t rate, as determined by the law of the iterated logarithm (LIL). As a byproduct, we give a non-asymptotic concentration inequality for the empirical distribution function which holds uniformly over time with the LIL rate, thus strengthening Smirnov's asymptotic empirical process LIL, and extending the famed Dvoretzky-Kiefer-Wolfowitz (DKW) inequality to hold uniformly over all sample sizes while only being about twice as wide in practice. This inequality directly yields sequential analogues of the one-and two-sample Kolmogorov-Smirnov tests, and a test of stochastic dominance. We apply our results to the problem of selecting an arm with an approximately best quantile in a multi-armed bandit framework, proving a state-of-the-art sample complexity bound for a novel allocation strategy. Simulations demonstrate that our method stops with fewer samples than existing methods by a factor of five to fifty. Finally, we show how to compute confidence sequences for the difference between quantiles of two arms in an A/B test, along with corresponding always-valid p-values.},
archivePrefix = {arXiv},
arxivId = {1906.09712v1},
author = {Howard, Steven R and Ramdas, Aaditya},
eprint = {1906.09712v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Howard, Ramdas - 2019 - Sequential estimation of quantiles with applications to AB-testing and best-arm identification.pdf:pdf},
journal = {arXiv},
keywords = {inequalities,sequential analysis,to-skim},
mendeley-tags = {inequalities,sequential analysis,to-skim},
title = {{Sequential estimation of quantiles with applications to A/B-testing and best-arm identification}},
year = {2019}
}
@article{Imbens2011,
author = {Imbens, Guido W . and Rubin, Donald B .},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Imbens, Rubin - 2011 - Bayesian Inference for Causal Effects in Randomized Experiments with Noncompliance.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {causality,missing data},
mendeley-tags = {causality,missing data},
number = {1},
pages = {305--327},
title = {{Bayesian Inference for Causal Effects in Randomized Experiments with Noncompliance}},
volume = {25},
year = {2011}
}
@article{Zrnic2018,
abstract = {We consider the problem of asynchronous online testing, aimed at providing control of the false discovery rate (FDR) during a continual stream of data collection and testing, where each test may be a sequential test that can start and stop at arbitrary times. This setting increasingly characterizes real-world applications in science and industry, where teams of researchers across large organizations may conduct tests of hypotheses in a decentralized manner. The overlap in time and space also tends to induce dependencies among test statistics, a challenge for classical methodology, which either assumes (overly optimistically) independence or (overly pessimistically) arbitrary dependence between test statistics. We present a general framework that addresses both of these issues via a unified computational abstraction that we refer to as "conflict sets." We show how this framework yields algorithms with formal FDR guarantees under a more intermediate, local notion of dependence. We illustrate these algorithms in simulation experiments, comparing to existing algorithms for online FDR control.},
archivePrefix = {arXiv},
arxivId = {1812.05068v1},
author = {Zrnic, Tijana and Ramdas, Aaditya and Jordan, Michael I},
eprint = {1812.05068v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Zrnic, Ramdas, Jordan - 2018 - Asynchronous Online Testing of Multiple Hypotheses.pdf:pdf},
journal = {arXiv},
keywords = {Multiple testing,online multiple testing},
mendeley-tags = {Multiple testing,online multiple testing},
title = {{Asynchronous Online Testing of Multiple Hypotheses}},
year = {2018}
}
@article{HetB08,
abstract = {The problem of multiple testing is an important aspect of genome-wide association studies, and will become more important as marker densities increase. The problem has been tackled with permutation and false discovery rate procedures and with Bayes factors, but each approach faces difficulties that we briefly review. In the current context of multiple studies on different genotyping platforms, we argue for the use of truly genome-wide significance thresholds, based on all polymorphisms whether or not typed in the study. We approximate genome-wide significance thresholds in contemporary West African, East Asian and European populations by simulating sequence data, based on all polymorphisms as well as for a range of single nucleotide polymorphism (SNP) selection criteria. Overall we find that significance thresholds vary by a factor of {\textgreater}20 over the SNP selection criteria and statistical tests that we consider and can be highly dependent on sample size. We compare our results for sequence data to those derived by the HapMap Consortium and find notable differences which may be due to the small sample sizes used in the HapMap estimate.},
annote = {18200594},
author = {Hoggart, C J and Clark, T G and {De Iorio}, M and Whittaker, J C and Balding, D J},
doi = {10.1002/gepi.20292},
journal = {Genetic Epidemiology},
number = {2},
pages = {179--185},
title = {{Genome-wide significance for dense SNP and resequencing data}},
url = {http://www.hubmed.org/display.cgi?uids=18200594},
volume = {32},
year = {2008}
}
@article{abraham2012sparsnp,
author = {Abraham, G and Kowalczyk, A and Zobel, J and Inouye, M},
journal = {BMC bioinformatics},
keywords = {GWAS,software},
mendeley-tags = {GWAS,software},
number = {1},
pages = {88},
publisher = {BioMed Central},
title = {{SparSNP: Fast and memory-efficient analysis of all SNPs for phenotype prediction}},
volume = {13},
year = {2012}
}
@article{Barber2019,
abstract = {We extend conformal prediction methodology beyond the case of exchangeable data. In particular, we show that a weighted version of conformal prediction can be used to compute distribution-free prediction intervals for problems in which the test and training covariate distributions differ, but the likelihood ratio between these two distributions is known-or, in practice, can be estimated accurately with access to a large set of unlabeled data (test covariate points). Our weighted extension of conformal prediction also applies more generally, to settings in which the data satisfies a certain weighted notion of exchangeability. We discuss other potential applications of our new conformal methodology, including latent variable and missing data problems.},
archivePrefix = {arXiv},
arxivId = {1904.06019v2},
author = {Barber, Rina Foygel and Cand{\`{e}}s, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
eprint = {1904.06019v2},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Barber et al. - 2019 - Conformal Prediction Under Covariate Shift.pdf:pdf},
journal = {arXiv},
keywords = {conformal prediction,to-skim,unpublished},
mendeley-tags = {conformal prediction,to-skim,unpublished},
title = {{Conformal Prediction Under Covariate Shift}},
url = {http://www.alrw.net},
year = {2019}
}
@article{Korthauer2016,
abstract = {The ability to quantify cellular heterogeneity is a major advantage of single-cell technologies. However, statistical methods often treat cellular heterogeneity as a nuisance. We present a novel method to characterize differences in expression in the presence of distinct expression states within and among biological conditions. We demonstrate that this framework can detect differential expression patterns under a wide range of settings. Compared to existing approaches, this method has higher power to detect subtle differences in gene expression distributions that are more complex than a mean shift, and can characterize those differences. The freely available R package scDD implements the approach.},
author = {Korthauer, Keegan D. and Chu, Li Fang and Newton, Michael A. and Li, Yuan and Thomson, James and Stewart, Ron and Kendziorski, Christina},
doi = {10.1186/s13059-016-1077-y},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Korthauer et al. - 2016 - A statistical approach for identifying differential distributions in single-cell RNA-seq experiments.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Cellular heterogeneity,Differential expression,Mixture modeling,Single-cell RNA-seq,differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {1},
pages = {1--15},
pmid = {27782827},
publisher = {Genome Biology},
title = {{A statistical approach for identifying differential distributions in single-cell RNA-seq experiments}},
url = {http://dx.doi.org/10.1186/s13059-016-1077-y},
volume = {17},
year = {2016}
}
@article{MR3012522,
author = {Kim, Seyoung and Xing, Eric P},
doi = {10.1214/12-AOAS549},
issn = {1932-6157},
journal = {The Annals of Applied Statistics},
keywords = {gene expression,high-dimensional regression},
mendeley-tags = {gene expression,high-dimensional regression},
number = {3},
pages = {1095--1117},
title = {{Tree-guided group lasso for multi-response regression with structured sparsity, With an application to {\{}EQTL{\}} mapping}},
url = {http://dx.doi.org/10.1214/12-AOAS549},
volume = {6},
year = {2012}
}
@article{Romano,
abstract = {Conformal prediction is a technique for constructing prediction intervals that attain valid coverage in finite samples, without making distributional assumptions. Despite this appeal, existing conformal methods can be unnecessarily conservative because they form intervals of constant or weakly varying length across the input space. In this paper we propose a new method that is fully adaptive to het-eroscedasticity. It combines conformal prediction with classical quantile regression, inheriting the advantages of both. We establish a theoretical guarantee of valid coverage, supplemented by extensive experiments on popular regression datasets. We compare the efficiency of conformalized quantile regression to other conformal methods, showing that our method tends to produce shorter intervals.},
archivePrefix = {arXiv},
arxivId = {1905.03222v1},
author = {Romano, Yaniv and Patterson, Evan and Cand{\`{e}}s, Emmanuel J},
eprint = {1905.03222v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Romano, Patterson, Cand{\`{e}}s - 2019 - Conformalized Quantile Regression.pdf:pdf},
journal = {arXiv},
keywords = {conformal prediction,to-skim,unpublished},
mendeley-tags = {conformal prediction,to-skim,unpublished},
title = {{Conformalized Quantile Regression}},
url = {https://github.com/yromano/cqr.},
year = {2019}
}
@article{BetG09,
abstract = {Summary: We have developed ClueGO, an easy to use Cytoscape plug-in that strongly improves biological interpretation of large lists of genes. ClueGO integrates Gene Ontology (GO) terms as well as KEGG/BioCarta pathways and creates a functionally organized GO/pathway term network. It can analyze one or compare two lists of genes and comprehensively visualizes functionally grouped terms. A one-click update option allows ClueGO to automatically download the most recent GO/KEGG release at any time. ClueGO provides an intuitive representation of the analysis results and can be optionally used in conjunction with the GOlorize plug-in. Availability: http://www.ici.upmc.fr/cluego/cluegoDownload.shtml Contact: jerome.galon@crc.jussieu.fr Supplementary information: Supplementary data are available at Bioinformatics online.},
author = {Galon, Jerome and Bindea, Gabriela and Mlecnik, Bernhard and Hackl, Hubert and Charoentong, Pornpimol and Tosolini, Marie and Kirilovsky, Amos and Fridman, Wolf-Herman and Pages, Franck and Trajanoski, Zlatko},
doi = {10.1093/bioinformatics/btp101},
journal = {Bioinformatics},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
number = {8},
pages = {1091--1093},
publisher = {Oxford University Press},
title = {{ClueGO: a Cytoscape plug-in to decipher functionally grouped gene ontology and pathway annotation networks}},
url = {http://bioinformatics.oxfordjournals.org/cgi/content/abstract/25/8/1091{\%}5Cnhttp://bioinformatics.oxfordjournals.org/cgi/content/abstract/btp101},
volume = {25},
year = {2009}
}
@book{Fisher1935,
address = {Edinburgh},
author = {Fisher, Ronald},
publisher = {Oliver and Boyd},
title = {{The Design of Experiments}},
year = {1935}
}
@book{FellerV1,
address = {New York},
author = {Feller, William},
edition = {Third},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Feller - 1968 - An Introduction to Probability Theory and Its Applications.pdf:pdf},
publisher = {John Wiley {\&} Sons Inc.},
title = {{An Introduction to Probability Theory and Its Applications}},
year = {1968}
}
@article{Canaj2019,
abstract = {CRISPR/Cas technologies have transformed our ability to add functionality to the genome by knock- in of payload via homology-directed repair (HDR). However, a systematic and quantitative profiling of the knock-in integration landscape is still lacking. Here, we present a framework based on long- read sequencing and an integrated computational pipeline (knock-knock) to analyze knock-in repair outcomes across a wide range of experimental parameters. Our data uncover complex repair profiles, with perfect HDR often accounting for a minority of payload integration events, and reveal markedly distinct mis-integration patterns between cell-types or forms of HDR templates used. Our analysis demonstrates that the two sides of a given double-strand break can be repaired by separate pathways and identifies a major role for sequence micro-homology in driving donor mis-integration. Altogether, our comprehensive framework paves the way for investigating repair mechanisms, monitoring accuracy, and optimizing the precision of genome engineering.},
author = {Canaj, Hera and Hussmann, Jeffrey A and Li, Han and Beckman, Kyle A and Goodrich, Leeanne and {Cho, Nathan}, H and Li, Yucheng J and Santos, Daniel A and McGeever, Aaron and Stewart, Edna M and Pessino, Veronica and Mandegar, Mohammad A and Huang, Cindy and Gan, Li and Panning, Barbara and Huang, Bo and Weissman, Jonathan S and Leonetti, Manuel D},
doi = {10.1101/841098},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Canaj et al. - 2019 - Deep profiling reveals substantial heterogeneity of integration outcomes in CRISPR knock-in experiments.pdf:pdf},
journal = {bioRxiv},
title = {{Deep profiling reveals substantial heterogeneity of integration outcomes in CRISPR knock-in experiments}},
year = {2019}
}
@article{SetF06,
abstract = {The genome-wide distribution of linkage disequilibrium (LD) determines the strategy for selecting markers for association studies, but it varies between populations. We assayed LD in large samples (200 individuals) from each of 11 well-described population isolates and an outbred European-derived sample, using SNP markers spaced across chromosome 22. Most isolates show substantially higher levels of LD than the outbred sample and many fewer regions of very low LD (termed 'holes'). Young isolates known to have had relatively few founders show particularly extensive LD with very few holes; these populations offer substantial advantages for genome-wide association mapping.},
annote = {16582909},
author = {Service, S and DeYoung, J and Karayiorgou, M and Roos, J L and Pretorious, H and Bedoya, G and Ospina, J and Ruiz-Linares, A and Macedo, A and Palha, J A and Heutink, P and Aulchenko, Y and Oostra, B and van Duijn, C and Jarvelin, M R and Varilo, T and Peddle, L and Rahman, P and Piras, G and Monne, M and Murray, S and Galver, L and Peltonen, L and Sabatti, C and Collins, A and Freimer, N},
doi = {10.1038/ng1770},
journal = {Nature Genetics},
number = {5},
pages = {556--560},
title = {{Magnitude and distribution of linkage disequilibrium in population isolates and implications for genome-wide association studies}},
url = {http://www.hubmed.org/display.cgi?uids=16582909},
volume = {38},
year = {2006}
}
@article{FastQTL,
annote = {doi:10.1093/bioinformatics/btv722},
author = {Ongen, H and Buil, A and Brown, A B and Dermitzakis, E T and Delaneau, O},
journal = {Bioinformatics},
keywords = {multiple phenotypes},
mendeley-tags = {multiple phenotypes},
number = {10},
pages = {1479--1485},
title = {{Fast and efficient {\{}QTL{\}} mapper for thousands of molecular phenotypes}},
volume = {32},
year = {2015}
}
@article{Stein2010,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/20171287{\}}{\{}20171287{\}}},
author = {Stein, J L and Hua, X and Lee, S and Ho, A J and Leow, A D and Toga, A W and Saykin, A J and Shen, L and Foroud, T and Pankratz, N and Others},
journal = {Neuroimage},
keywords = {GWAS,spatial data},
mendeley-tags = {GWAS,spatial data},
number = {3},
pages = {1160--1174},
title = {{Voxelwise genome-wide association study ($\backslash$Mbox{\{}vGWAS{\}})}},
volume = {53},
year = {2010}
}
@article{FS08,
author = {Foster, D P and Stine, R A},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {2},
pages = {429--444},
publisher = {Wiley Online Library},
title = {alpha-investing: a procedure for sequential control of expected false discoveries},
volume = {70},
year = {2008}
}
@article{Buja2019,
author = {Buja, Andreas and Brown, Lawrence and Kuchibhotla, Arun Kumar and Berk, Richard and George, Edward and Zhao, Linda},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistical Science/Buja et al. - 2019 - Models as Approximations II A Model-Free Theory of Parametric.pdf:pdf},
journal = {Statistical Science},
keywords = {Ancillarity of regressors,ancillarity of regressors,bagging,bootstrap,metrics,misspecification,sandwich estimator},
number = {4},
pages = {545--565},
title = {{Models as Approximations II : A Model-Free Theory of Parametric}},
volume = {34},
year = {2019}
}
@article{DetM16,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26901065{\}}{\{}26901065{\}}},
author = {Dahl, A and Iotchkova, V and Baud, A and Johansson, A and Gyllensten, U and Soranzo, N and Mott, R and Kranis, A and Marchini, J},
journal = {Nature Genetics},
keywords = {multiple phenotypes,phasing},
mendeley-tags = {multiple phenotypes,phasing},
month = {feb},
title = {{{\{}A{\}} multiple-phenotype imputation method for genetic studies}},
year = {2016}
}
@article{Miao2018,
abstract = {We consider a causal effect that is confounded by an unobserved variable, but for which observed proxy variables of the confounder are available. We show that with at least two independent proxy variables satisfying a certain rank condition, the causal effect can be nonparametrically identified, even if the measurement error mechanism, i.e., the conditional distribution of the proxies given the confounder, may not be identified. Our result generalizes the identification strategy of Kuroki and Pearl (2014), which rests on identification of the measurement error mechanism. When only one proxy for the confounder is available, or when the required rank condition is not met, we develop a strategy for testing the null hypothesis of no causal effect.},
archivePrefix = {arXiv},
arxivId = {1609.08816},
author = {Miao, Wang and Geng, Zhi and {Tchetgen Tchetgen}, Eric J.},
doi = {10.1093/biomet/asy038},
eprint = {1609.08816},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Miao, Geng, Tchetgen Tchetgen - 2018 - Identifying causal effects with proxy variables of an unmeasured confounder.pdf:pdf},
issn = {14643510},
journal = {Biometrika},
keywords = {Confounder,Identification,Measurement error,Negative control,Proxy.,causality,missing data},
mendeley-tags = {causality,missing data},
number = {4},
pages = {987--993},
title = {{Identifying causal effects with proxy variables of an unmeasured confounder}},
volume = {105},
year = {2018}
}
@article{Rothenhausler2019,
abstract = {Estimating causal parameters from observational data is notoriously difficult. Popular approaches such as regression adjustment or the instrumental variables approach only work under relatively strong assumptions and are prone to mistakes. Furthermore, causal parameters can exhibit conservative predictive performance which can limit their usefulness in practice. Causal parameters can be written as the solution to a minimax risk problem, where the maximum is taken over a range of interventional (or perturbed) distributions. This motivates anchor regression , a method that makes use of exogeneous variables to solve a relaxation of the "causal" minimax problem. The procedure naturally provides an interpolation between the solution to ordinary least squares and two-stage least squares, but also has predictive guarantees if the instrumental variables assumptions are violated. We derive guarantees of the proposed procedure for predictive performance under perturbations for the population case and for high-dimensional data. An additional characterization of the procedure is given in terms of quantiles: If the data follow a Gaussian distribution , the method minimizes quantiles of the conditional mean squared error. If anchor regression and least squares provide the same answer ("anchor stability"), the relationship between targets and predictors is unconfounded and the coefficients have a causal interpretation. Furthermore, we show under which conditions anchor regression satisfies replicability among different experiments. Anchor regression is shown empirically to improve replicability and protect against distributional shifts.},
archivePrefix = {arXiv},
arxivId = {1801.06229v3},
author = {Rothenh{\"{a}}usler, Dominik and Meinshausen, Nicolai and B{\"{u}}hlmann, Peter and Peters, Jonas},
eprint = {1801.06229v3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Rothenh{\"{a}}usler et al. - 2019 - Anchor regression heterogeneous data meet causality.pdf:pdf},
isbn = {1801.06229v3},
journal = {arXiv},
keywords = {causality,to-skim,unpublished},
mendeley-tags = {causality,to-skim,unpublished},
title = {{Anchor regression: heterogeneous data meet causality}},
year = {2019}
}
@article{PetC09,
abstract = {In recent years, ontologies have become a mainstream topic in biomedical research. When biological entities are described using a common schema, such as an ontology, they can be compared by means of their annotations. This type of comparison is called semantic similarity, since it assesses the degree of relatedness between two entities by the similarity in meaning of their annotations. The application of semantic similarity to biomedical ontologies is recent; nevertheless, several studies have been published in the last few years describing and evaluating diverse approaches. Semantic similarity has become a valuable tool for validating the results drawn from biomedical studies such as gene clustering, gene expression data analysis, prediction and validation of molecular interactions, and disease gene prioritization. We review semantic similarity measures applied to biomedical ontologies and propose their classification according to the strategies they employ: node-based versus edge-based and pairwise versus groupwise. We also present comparative assessment studies and discuss the implications of their results. We survey the existing implementations of semantic similarity measures, and we describe examples of applications to biomedical research. This will clarify how biomedical researchers can benefit from semantic similarity measures and help them choose the approach most suitable for their studies.Biomedical ontologies are evolving toward increased coverage, formality, and integration, and their use for annotation is increasingly becoming a focus of both effort by biomedical experts and application of automated annotation procedures to create corpora of higher quality and completeness than are currently available. Given that semantic similarity measures are directly dependent on these evolutions, we can expect to see them gaining more relevance and even becoming as essential as sequence similarity is today in biomedical research.},
author = {Pesquita, Catia and Faria, Daniel and Falc{\~{a}}o, Andr{\'{e}} O. and Lord, Phillip and Couto, Francisco M.},
doi = {10.1371/journal.pcbi.1000443},
issn = {1553734X},
journal = {PLoS Computational Biology},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
number = {7},
pages = {e1000443},
publisher = {Public Library of Science},
title = {{Semantic similarity in biomedical ontologies}},
volume = {5},
year = {2009}
}
@article{Mora2015,
abstract = {Enhancer-promoter regulation is a fundamental mechanism underlying differential transcriptional regulation. Spatial chromatin organization brings remote enhancers in contact with target promoters in cis to regulate gene expression. There is considerable evidence for promoter-enhancer interactions (PEIs). In the recent years, genome-wide analyses have identified signatures and mapped novel enhancers; however, being able to precisely identify their target gene(s) requires massive biological and bioinformatics efforts. In this review, we give a short overview of the chromatin landscape and transcriptional regulation. We discuss some key concepts and problems related to chromatin interaction detection technologies, and emerging knowledge from genome-wide chromatin interaction data sets. Then, we critically review different types of bioinformatics analysis methods and tools related to representation and visualization of PEI data, raw data processing and PEI prediction. Lastly, we provide specific examples of how PEIs have been used to elucidate a functional role of non-coding single-nucleotide polymorphisms. The topic is at the forefront of epigenetic research, and by highlighting some future bioinformatics challenges in the field, this review provides a comprehensive background for future PEI studies.},
author = {Mora, Antonio and Sandve, Geir Kjetil and Gabrielsen, Odd Stokke and Eskeland, Ragnhild},
doi = {10.1093/bib/bbv097},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Briefings in Bioinformatics/Mora et al. - 2015 - In the loop promoter–enhancer interactions and bioinformatics.pdf:pdf},
issn = {1467-5463},
journal = {Briefings in Bioinformatics},
keywords = {Kathryn,chromatin loops,chromosome conformation capture,ctcf,enhancer,enhancer interactions,enhancer prediction,gene regulation,gene-enhancer,genetics,histone modifications,promoter,snps,transcription factories},
mendeley-tags = {Kathryn,enhancer,gene regulation,gene-enhancer,genetics},
number = {July 2015},
pages = {bbv097},
title = {{In the loop: promoter–enhancer interactions and bioinformatics}},
volume = {17},
year = {2015}
}
@article{T10,
annote = {20686565},
author = {Teslovich, T M and Musunuru, K and Smith, A V and Edmondson, A C and Stylianou, I M and Koseki, M and Pirruccello, J P and Ripatti, S and Chasman, D I and Willer, C J and Johansen, C T and Fouchier, S W and Isaacs, A and Peloso, G M and Barbalic, M and Ricketts, S L and Bis, J C and Aulchenko, Y S and Thorleifsson, G and Feitosa, M F and Chambers, J and Orho-Melander, M and Melander, O and Johnson, T and Li, X and Guo, X and Li, M and {Shin Cho}, Y and {Jin Go}, M and {Jin Kim}, Y and Lee, J Y and Park, T and Kim, K and Sim, X and {Twee-Hee Ong}, R and Croteau-Chonka, D C and Lange, L A and Smith, J D and Song, K and {Hua Zhao}, J and Yuan, X and Luan, J and Lamina, C and Ziegler, A and Zhang, W and Zee, R Y and Wright, A F and Witteman, J C and Wilson, J F and Willemsen, G and Wichmann, H E and Whitfield, J B and Waterworth, D M and Wareham, N J and Waeber, G and Vollenweider, P and Voight, B F and Vitart, V and Uitterlinden, A G and Uda, M and Tuomilehto, J and Thompson, J R and Tanaka, T and Surakka, I and Stringham, H M and Spector, T D and Soranzo, N and Smit, J H and Sinisalo, J and Silander, K and Sijbrands, E J and Scuteri, A and Scott, J and Schlessinger, D and Sanna, S and Salomaa, V and Saharinen, J and Sabatti, C and Ruokonen, A and Rudan, I and Rose, L M and Roberts, R and Rieder, M and Psaty, B M and Pramstaller, P P and Pichler, I and Perola, M and Penninx, B W and Pedersen, N L and Pattaro, C and Parker, A N and Pare, G and Oostra, B A and O'Donnell, C J and Nieminen, M S and Nickerson, D A and Montgomery, G W and Meitinger, T and McPherson, R and McCarthy, M I and McArdle, W and Masson, D and Martin, N G and Marroni, F and Mangino, M and Magnusson, P K and Lucas, G and Luben, R and Loos, R J and Lokki, M L and Lettre, G and Langenberg, C and Launer, L J and Lakatta, E G and Laaksonen, R and Kyvik, K O and Kronenberg, F and Konig, I R and Khaw, K T and Kaprio, J and Kaplan, L M and Johansson, A and Jarvelin, M R and Janssens, A C and Ingelsson, E and Igl, W and {Kees Hovingh}, G and Hottenga, J J and Hofman, A and Hicks, A A and Hengstenberg, C and Heid, I M and Hayward, C and Havulinna, A S and Hastie, N D and Harris, T B and Haritunians, T and Hall, A S and Gyllensten, U and Guiducci, C and Groop, L C and Gonzalez, E and Gieger, C and Freimer, N B and Ferrucci, L and Erdmann, J and Elliott, P and Ejebe, K G and Doring, A and Dominiczak, A F and Demissie, S and Deloukas, P and de Geus, E J and de Faire, U and Crawford, G and Collins, F S and Chen, Y D and Caulfield, M J and Campbell, H and Burtt, N P and Bonnycastle, L L and Boomsma, D I and Boekholdt, S M and Bergman, R N and Barroso, I and Bandinelli, S and Ballantyne, C M and Assimes, T L and Quertermous, T and Altshuler, D and Seielstad, M and Wong, T Y and Tai, E S and Feranil, A B and Kuzawa, C W and Adair, L S and Taylor, H A and Borecki, I B and Gabriel, S B and Wilson, J G and Holm, H and Thorsteinsdottir, U and Gudnason, V and Krauss, R M and Mohlke, K L and Ordovas, J M and Munroe, P B and Kooner, J S and Tall, A R and Hegele, R A and Kastelein, J J and Schadt, E E and Rotter, J I and Boerwinkle, E and Strachan, D P and Mooser, V and Stefansson, K and Reilly, M P and Samani, N J and Schunkert, H and Cupples, L A and Sandhu, M S and Ridker, P M and Rader, D J and van Duijn, C M and Peltonen, L and Abecasis, G R and Boehnke, M and Kathiresan, S},
journal = {Nature},
month = {aug},
pages = {707--713},
title = {{Biological, clinical and population relevance of 95 loci for blood lipids}},
volume = {466},
year = {2010}
}
@article{Barber2020,
author = {Barber, Rina Foygel and Janson, Lucas},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Barber, Janson - 2020 - Testing goodness-of-fit and conditional independence with approximate co-sufficient sampling.pdf:pdf},
journal = {arXiv},
keywords = {approximate sufficiency,co-sufficiency,conditional independence testing,conditional ran-,conditional randomization test,domization test,goodness-of-fit test,high-dimensional inference,high-dimensional regression,model-X,model-x},
mendeley-tags = {conditional randomization test,high-dimensional regression,model-X},
title = {{Testing goodness-of-fit and conditional independence with approximate co-sufficient sampling}},
year = {2020}
}
@article{Tian2019,
abstract = {Major internet companies routinely perform tens of thousands of A/B tests each year. Such large-scale sequential experimentation has resulted in a recent spurt of new algorithms that can provably control the false discovery rate (FDR) in a fully online fashion. However, current state-of-the-art adaptive algorithms can suffer from a significant loss in power if null p-values are conservative (stochastically larger than the uniform distribution), a situation that occurs frequently in practice. In this work, we introduce a new adaptive discarding method called ADDIS that provably controls the FDR and achieves the best of both worlds: it enjoys appreciable power increase over all existing methods if nulls are conservative (the practical case), and rarely loses power if nulls are exactly uniformly distributed (the ideal case). We provide several practical insights on robust choices of tuning parameters, and extend the idea to asynchronous and offline settings as well.},
archivePrefix = {arXiv},
arxivId = {1905.11465v2},
author = {Tian, Jinjin and Ramdas, Aaditya},
eprint = {1905.11465v2},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Tian, Ramdas - 2019 - ADDIS an adaptive discarding algorithm for online FDR control with conservative nulls.pdf:pdf},
journal = {arXiv},
keywords = {FDR,online multiple testing,to-read,unpublished},
mendeley-tags = {FDR,online multiple testing,to-read,unpublished},
title = {{ADDIS: an adaptive discarding algorithm for online FDR control with conservative nulls}},
year = {2019}
}
@article{CLS06,
abstract = {Defining measures of linkage disequilibrium (LD) that have good small sample properties and are applicable to multiallelic markers poses some challenges. The potential of volume measures in this context has been noted before, but their use has been hampered by computational challenges.We design a sequential importance sampling algorithm to evaluate volume measures on I x J tables. The algorithm is implemented in a C routine as a complement to exhaustive enumeration. We make the C code available as open source. We achieve fast and accurate evaluation of volume measures in two dimensional tables.Applying our code to simulated and real datasets reinforces the belief that volume measures are a very useful tool for LD evaluation: they are not inflated in small samples, their definition encompasses multiallelic markers, and they can be computed with appreciable speed.},
annote = {17112381},
author = {Chen, Y and Lin, C H and Sabatti, C},
doi = {10.1186/1471-2156-7-54},
journal = {BMC Genet},
pages = {54},
title = {{Volume measures for linkage disequilibrium}},
url = {http://www.hubmed.org/display.cgi?uids=17112381},
volume = {7},
year = {2006}
}
@article{Chernozhukov2013,
author = {Chernozhukov, Victor and Chetverikov, Denis and Kato, Kengo},
doi = {10.1214/13-AOS1161},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Chernozhukov, Chetverikov, Kato - 2013 - Gaussian approximations and multiplier bootstrap for maxima of sums of high-dimensional random.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Chernozhukov, Chetverikov, Kato - 2013 - Gaussian approximations and multiplier bootstrap for maxima of sums of high-dimensional rand(2).pdf:pdf},
journal = {The Annals of Statistics},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {6},
pages = {2786--2819},
title = {{Gaussian approximations and multiplier bootstrap for maxima of sums of high-dimensional random vectors}},
volume = {41},
year = {2013}
}
@article{Tansey2019,
abstract = {We consider the problem of multiple hypothesis testing when there is a logical nested structure to the hypotheses. When one hypothesis is nested inside another, the outer hypothesis must be false if the inner hypothesis is false. We model the nested structure as a directed acyclic graph, including chain and tree graphs as special cases. Each node in the graph is a hypothesis and rejecting a node requires also rejecting all of its ancestors. We propose a general framework for adjusting node-level test statistics using the known logical constraints. Within this framework, we study a smoothing procedure that recursively merges each node with all of its descendants to form a more powerful statistic. We prove two classical merging strategies can be used with existing selection procedures to control the familywise error rate, false discovery exceedance rate, or false discovery rate, so long as the original test statistics are independent under the null. When the null statistics are not independent but are derived from positively-correlated normal observations, we prove control for all three error rates when the smoothing method is arithmetic averaging of the observations. Simulations and an application to a real biology dataset demonstrate that smoothing leads to substantial power gains.},
archivePrefix = {arXiv},
arxivId = {1911.09200},
author = {Tansey, Wesley and Loper, Jackson H. and Lei, Lihua and Fithian, William},
eprint = {1911.09200},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Tansey et al. - 2019 - Smoothed Nested Testing on Directed Acyclic Graphs.pdf:pdf},
pages = {1--19},
title = {{Smoothed Nested Testing on Directed Acyclic Graphs}},
url = {http://arxiv.org/abs/1911.09200},
year = {2019}
}
@article{Cao2019a,
abstract = {To the Editor-Assigning enhancers to target genes remains an important question in understanding gene regulation. The availability of genome-organization data from experiments such as high-throughput chromosome-conformation capture (Hi-C) 1 and chromatin interaction analysis with paired-end tags (ChIA-PET) 2 remains limited. Development of computational methods to predict enhancer-promoter interactions could thus extend the availability of such data to new cell types. TargetFinder 3 is a machine-learning method that predicts enhancer-promoter interactions on the basis of functional-genomic data, such as that from chromatin immunoprecipitation coupled with high-throughput sequencing (ChIP-seq) of histone modifications or transcription factors, and DNase I hypersensitive site sequencing (DNase-seq). This method introduced the interesting idea that the functional-genomic signatures in the intervening regions (windows) between enhancer-promoter pairs are predictive of enhancer-promoter interactions. The success of TargetFinder in predicting enhancer-promoter interactions and recent advances in the prediction of transcription-factor-binding sites from DNA sequences 4,5 led us to investigate the possibility of using sequence features in window regions to predict enhancer-promoter interactions. We downloaded TargetFinder's enhancer/ promoter/window (E/P/W) datasets, which consist of enhancer-promoter pairs in six cell lines, and obtained the window regions of the enhancer-promoter pairs from the six datasets. For each enhancer-promoter pair, we obtained the occurrence of each of 79 non-redundant transcription-factor motifs 6 within its window region and used the sum of the matching scores of all occurrences of each motif as a feature value. We trained a gradient-tree-boosting model for each cell type by using the same parameters used by TargetFinder. Interestingly, through tenfold cross-validation with shuffling, the models were able to achieve F 1 scores ranging from 0.78 to 0.9 in the six cell types (Fig. 1), values comparable to the reported TargetFinder performance 3. To ensure that the occurrence of these exact transcription-factor motifs in the window regions is predictive of enhancer-promoter interaction, we shuffled the position weights of the 79 motifs and determined the performance when using these shuffled motifs. We checked the shuffled motifs against the JASPAR motif database 7 to ensure that they did not resemble known transcription-factor-binding motifs. The same processing, same model and same parameters used for the 79 transcription-factor-binding motifs were used for the shuffled motifs. Unexpectedly, when tenfold cross-validation with shuffling was used, the models trained and tested with shuffled motifs also achieved F 1 scores ranging from 0.77 to 0.9 (Fig. 1). These results led us to examine the TargetFinder datasets with their original functional-genomic features. In the TargetFinder datasets, most of the positive enhancer-promoter pairs had highly overlapping window regions with at least another positive enhancer-promoter pair in the same dataset (Fig. 2a). For example, approximately 53-76{\%} of positive samples had windows that overlapped with the windows of other positive samples at a 99{\%} reciprocal-overlapping-fraction cutoff, whereas only {\textless}0.16{\%} of positive samples had windows overlapping with windows of negative samples at this threshold (Fig. 2b). The mean absolute differences between the features in window regions of overlapping samples were smaller than the difference between two randomly selected positive samples (Fig. 2c) and decreased as the overlapping fraction increased. The high similarity between window features of positive samples is likely to inflate the cross-validation results when the samples are randomly split into training and test sets. To break the dependence between samples in training and test sets, we used a chromosome-split strategy to split samples such that all samples on the same chromosome were either all in the training or all in the test set. The chromosome-split strategy randomly sampled combinations of chromosomes for inclusion in test sets, such that the positive-to-negative ratios in the training and test sets were similar, and the proportion of samples in the test set was around a specified number. The training and evaluation procedures were repeated several times by using different chromosome combinations as test sets to decrease the influence of genomic differences between chromosomes on the performance. We re-evaluated TargetFinder on the basis of the chromosome-split strategy, by using the original TargetFinder functional-genomic features in the E/P/W datasets with the same parameters. The performance of the models at their last iterations as well as at their best iterations is reported. When chromosome-split training and test datasets were used, the models achieved F 1 scores ranging from 0.013 to 0.098 at the best iterations (Fig. 2d), whereas a classifier that randomly classified a sample as positive or negative had a baseline F 1 score of 0.087 when the positive-to-negative ratio was 1:20. The areas under the precision-recall curves (auPRC) in chromosome-split evaluation were higher than those achievable by a random classifier but much lower than those achieved through cross-validation with shuffling (Fig. 2e). These results suggest that the reported high performance of TargetFinder should be attributed to highly similar samples being split into training and test sets rather Real Shuffled 0.81 0.82 K562 Real Shuffled 0.78 0.78 GM12878 Real Shuffled Performance (F 1) 0.87 0.87 HeLa-S3 Real Shuffled 0.78 0.78 HUVEC Real Shuffled 0.80 0.82 IMR90 Real Shuffled 0.90 0.89 NHEK 0 0.5 1.0 0 0.5 1.0 0 0.5 1.0 Fig. 1 | The performance of using occurrences of real and shuffled motifs in window regions to predict enhancer-promoter interactions by using TargetFinder datasets. Cell lines are indicated above each graph.},
author = {Cao, Fan and Fullwood, Melissa J},
doi = {10.1038/s41588-019-0434-7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Cao, Fullwood - 2019 - Inflated performance measures in enhancer–promoter interaction-prediction methods.pdf:pdf},
journal = {Nature Genetics},
keywords = {Kathryn,enhancer,gene-enhancer},
mendeley-tags = {Kathryn,enhancer,gene-enhancer},
title = {{Inflated performance measures in enhancer–promoter interaction-prediction methods}},
url = {https://doi.org/10.1038/s41588-019-0434-7.},
year = {2019}
}
@article{Bates2021a,
abstract = {To communicate instance-wise uncertainty for prediction tasks, we show how to generate set-valued predictions for black-box predictors that control the expected loss on future test points at a user-specified level. Our approach provides explicit finite-sample guarantees for any dataset by using a holdout set to calibrate the size of the prediction sets. This framework enables simple, distribution-free, rigorous error control for many tasks, and we demonstrate it in five large-scale machine learning problems: (1) classification problems where some mistakes are more costly than others; (2) multi-label classification, where each observation has multiple associated labels; (3) classification problems where the labels have a hierarchical structure; (4) image segmentation, where we wish to predict a set of pixels containing an object of interest; and (5) protein structure prediction. Lastly, we discuss extensions to uncertainty quantification for ranking, metric learning and distributionally robust learning.},
archivePrefix = {arXiv},
arxivId = {2101.02703},
author = {Bates, Stephen and Angelopoulos, Anastasios and Lei, Lihua and Malik, Jitendra and Jordan, Michael I.},
eprint = {2101.02703},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Bates et al. - 2021 - Distribution-Free, Risk-Controlling Prediction Sets.pdf:pdf},
journal = {arXiv},
keywords = {conformal prediction},
mendeley-tags = {conformal prediction},
title = {{Distribution-Free, Risk-Controlling Prediction Sets}},
url = {http://arxiv.org/abs/2101.02703},
year = {2021}
}
@article{BetL05,
abstract = {The application of factor analysis to human genetics has the potential to discover the coordinated control of multiple traits by common environment, common polygenes, or a single major gene. Classical factor analysis explains the covariation among the components of a random vector by approximating the vector by a linear transformation of a small number of uncorrelated factors. In the current paper we show how factor analysis dovetails with the classical variance decompositions of biometrical genetics. To explore the relationships between related quantitative variables, and avoid complicated positive definiteness constraints, we employ Cholesky and factor analytic decompositions. We derive an ECM algorithm and a competing quasi-Newton algorithm for estimating parameters by maximum likelihood and propose tactics for selecting initial parameter values. We also show how parameter asymptotic standard errors under these parameterizations propagate to asymptotic standard errors of the underlying variance components. Our genetic analysis program Mendel, which now incorporates the program Fisher, has performed well on a variety of data sets. We illustrate our methods, algorithms, and models on two data sets: a bivariate quantitative genetic example using total finger ridge count data and a multivariate linkage example using insulin resistance data.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/16138917{\}}{\{}16138917{\}}},
author = {Bauman, L E and Almasy, L and Blangero, J and Duggirala, R and Sinsheimer, J S and Lange, K},
journal = {Annals of Human Genetics},
pages = {590--611},
title = {{{\{}Fishing{\}} for Pleiotropic {\{}QTLs{\}} in a Polygenic sea}},
volume = {69},
year = {2005}
}
@article{Zhao2018,
abstract = {In the evaluation of treatment effects, it is of major policy interest to know if the treatment is beneficial for some and harmful for others, a phenomenon known as qualitative interaction. We formulate this question as a multiple testing problem with many conservative null p-values, in which the classical multiple testing methods may lose power substantially. We propose a simple technique-conditioning-to improve the power. A crucial assumption we need is uniform conservativeness, meaning for any conservative p-value p, the conditional distribution (p/$\tau$) | p ≤ $\tau$ is stochastically larger than the uniform distribution on (0, 1) for any $\tau$. We show this property holds for one-sided tests in a one-dimensional exponential family (e.g., testing for qualitative interaction) as well as testing |$\mu$| ≤ $\eta$ using a statistic Y ∼ N($\mu$, 1) (e.g., testing for practical importance with threshold $\eta$). We propose an adaptive method to select the threshold $\tau$. Our theoretical and simulation results suggest that the proposed tests gain significant power when many p-values are uniformly conservative and lose little power when no p-value is uniformly conservative. We apply our method to two educational intervention datasets. Supplementary materials for this article are available online.},
author = {Zhao, Qingyuan and Small, Dylan S and Su, Weijie},
doi = {10.1080/01621459.2018.1497499},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Zhao, Small, Su - 2018 - Multiple Testing When Many p-Values are Uniformly Conservative, with Application to Testing Qualitative Interac.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Global null,Meta-analysis,Multiple testing,Multisite study,Selective inference,Treatment effect heterogeneity,Uniform conditional stochastic order},
mendeley-tags = {Multiple testing},
title = {{Multiple Testing When Many p-Values are Uniformly Conservative, with Application to Testing Qualitative Interaction in Educational Interventions}},
url = {https://amstat.tandfonline.com/action/journalInformation?journalCode=uasa20},
year = {2018}
}
@article{DetD11,
abstract = {Recent advances in sequencing technology make it possible to comprehensively catalog genetic variation in population samples, creating a foundation for understanding human disease, ancestry and evolution. The amounts of raw data produced are prodigious, and many computational steps are required to translate this output into high-quality variant calls. We present a unified analytic framework to discover and genotype variation among multiple samples simultaneously that achieves sensitive and specific results across five sequencing technologies and three distinct, canonical experimental designs. Our process includes (i) initial read mapping; (ii) local realignment around indels; (iii) base quality score recalibration; (iv) SNP discovery and genotyping to find all potential variants; and (v) machine learning to separate true segregating variation from machine artifacts common to next-generation sequencing technologies. We here discuss the application of these tools, instantiated in the Genome Analysis Toolkit, to deep whole-genome, whole-exome capture and multi-sample low-pass ({\^{a}}ˆ¼4{\~{A}}—) 1000 Genomes Project datasets.},
annote = {21478889},
author = {Depristo, Mark A and Banks, Eric and Poplin, Ryan and Garimella, Kiran V and Maguire, Jared R and Hartl, Christopher and Philippakis, Anthony A and {Del Angel}, Guillermo and Rivas, Manuel A and Hanna, Matt and McKenna, Aaron and Fennell, Tim J and Kernytsky, Andrew M and Sivachenko, Andrey Y and Cibulskis, Kristian and Gabriel, Stacey B and Altshuler, David and Daly, Mark J},
journal = {Nature Genetics},
pages = {491--498},
title = {{{\{}A{\}} Framework for Variation Discovery and Genotyping Using Next-generation {\{}DNA{\}} Sequencing data}},
volume = {43},
year = {2011}
}
@article{Reid2018,
abstract = {Applied statistical problems often come with prespecified groupings to predictors. It is natural to test for the presence of simultaneous group-wide signal for groups in isolation, or for multiple groups together. Current tests for the presence of such signals include the classical F-test or a t-test on unsupervised group prototypes (either group centroids or first principal components). In this article, we propose test statistics that aim for power improvements over these classical approaches. In particular, we first create group prototypes , with reference to the response, and then test with likelihood ratio statistics incorporating only these prototypes. We propose a model, called the "prototype model, " which naturally models this two-step procedure. Furthermore, we introduce an inferential schema detailing the unique considerations for different combinations of prototype formation and univariate/multivariate testing models. The prototype model also suggests new applications to estimation and prediction. Prototype formation often relies on variable selection , which invalidates classical Gaussian test theory. We use recent advances in selective inference to account for selection in the prototyping step and retain test validity. Simulation experiments suggest that our testing procedure enjoys more power than do classical approaches. Supplementary materials for this article are available online.},
author = {Reid, Stephen and Taylor, Jonathan and Tibshirani, Robert},
doi = {10.1080/01621459.2016.1246368},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Reid, Taylor, Tibshirani - 2018 - A General Framework for Estimation and Inference From Clusters of Features.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Hypothesis testing,Likelihood ratio statistics,Selective inference,correlation,high-dimensional regression},
mendeley-tags = {correlation,high-dimensional regression},
pages = {280--293},
title = {{A General Framework for Estimation and Inference From Clusters of Features}},
url = {https://amstat.tandfonline.com/action/journalInformation?journalCode=uasa20https://doi.org/./..},
volume = {113},
year = {2018}
}
@article{SRB07,
author = {Sz{\'{e}}kely, G{\'{a}}bor J and Rizzo, Maria L and Bakirov, Nail K},
doi = {10.1214/009053607000000505},
issn = {0090-5364},
journal = {The Annals of Statistics},
number = {6},
pages = {2769--2794},
title = {{Measuring and testing dependence by correlation of distances}},
url = {http://dx.doi.org/10.1214/009053607000000505},
volume = {35},
year = {2007}
}
@article{Rubin1977,
author = {Rubin, Donald B.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Educational Statistics/Rubin - 1977 - Assignment to Treatment Group on the Basis of a Covariate.pdf:pdf},
journal = {Journal of Educational Statistics},
keywords = {average treatment effects,causal inference,causality,covariance adjustment,experimental design,non-randomized studies,observational studies,treatment assignment},
mendeley-tags = {causality},
number = {1},
pages = {1--26},
title = {{Assignment to Treatment Group on the Basis of a Covariate}},
volume = {2},
year = {1977}
}
@article{Lafzi2018,
author = {Lafzi, Atefeh and Moutinho, Catia and Picelli, Simone and Heyn, Holger},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Protocols/Lafzi et al. - 2018 - Tutorial guidelines for the experimental design of single-cell RNA sequencing studies.pdf:pdf},
journal = {Nature Protocols},
keywords = {single cell},
mendeley-tags = {single cell},
pages = {2742--2757},
title = {{Tutorial: guidelines for the experimental design of single-cell RNA sequencing studies}},
volume = {13},
year = {2018}
}
@article{Moreau2017,
abstract = {Sparse coding is a core building block in many data analysis and machine learning pipelines. Typically it is solved by relying on generic optimization techniques, such as the Iterative Soft Thresholding Algorithm and its accelerated version (ISTA, FISTA). These methods are optimal in the class of first-order methods for non-smooth, convex functions. However , they do not exploit the particular structure of the problem at hand nor the input data distribution. An acceleration using neural networks, coined LISTA, was proposed in Gregor and Le Cun (2010), which showed empirically that one could achieve high quality estimates with few iterations by modifying the parameters of the proximal splitting appropriately. In this paper we study the reasons for such acceleration. Our mathematical analysis reveals that it is related to a specific matrix factorization of the Gram kernel of the dictionary, which attempts to nearly diagonalise the kernel with a basis that produces a small perturbation of the 1 ball. When this factorization succeeds, we prove that the resulting splitting algorithm enjoys an improved convergence bound with respect to the non-adaptive version. Moreover, our analysis also shows that conditions for acceleration occur mostly at the beginning of the iterative process, consistent with numerical experiments. We further validate our analysis by showing that on dictionaries where this factorization does not exist, adaptive acceleration fails.},
archivePrefix = {arXiv},
arxivId = {1706.01338v1},
author = {Moreau, Thomas and Bruna, Joan},
eprint = {1706.01338v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Moreau, Bruna - 2017 - Understanding the Learned Iterative Soft Thresholding Algorithm with matrix factorization.pdf:pdf},
journal = {arXiv},
keywords = {deep learning,optimization,to-skim,unpublished},
mendeley-tags = {deep learning,optimization,to-skim,unpublished},
title = {{Understanding the Learned Iterative Soft Thresholding Algorithm with matrix factorization}},
year = {2017}
}
@article{BetS10,
abstract = {The limitations of genome-wide association (GWA) studies that focus on the phenotypic influence of common genetic variants have motivated human geneticists to consider the contribution of rare variants to phenotypic expression. The increasing availability of high-throughput sequencing technologies has enabled studies of rare variants but these methods will not be sufficient for their success as appropriate analytical methods are also needed. We consider data analysis approaches to testing associations between a phenotype and collections of rare variants in a defined genomic region or set of regions. Ultimately, although a wide variety of analytical approaches exist, more work is needed to refine them and determine their properties and power in different contexts.},
annote = {20940738},
author = {Bansal, V and Libiger, O and Torkamani, A and Schork, N J},
doi = {10.1038/nrg2867},
journal = {Nature Reviews Genetics},
keywords = {genetics,rare variants},
mendeley-tags = {genetics,rare variants},
number = {11},
pages = {773--785},
title = {{Statistical analysis strategies for association studies involving rare variants}},
url = {http://www.hubmed.org/display.cgi?uids=20940738},
volume = {11},
year = {2010}
}
@article{T96,
author = {Tibshirani, Robert},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {Lasso,canonical,high-dimensional regression},
mendeley-tags = {Lasso,canonical,high-dimensional regression},
number = {1},
pages = {267--288},
publisher = {JSTOR},
title = {{Regression shrinkage and selection via the lasso}},
volume = {58},
year = {1996}
}
@article{Dobriban2018,
abstract = {Researchers in data-rich disciplines-think of computational genomics and observational cosmology-often wish to mine large bodies of P-values looking for significant effects, while controlling the false discovery rate or family-wise error rate. Increasingly, researchers also wish to prioritize certain hypotheses , for example, those thought to have larger effect sizes, by upweighting, and to impose constraints on the underlying mining, such as monotonicity along a certain sequence. We introduce Princessp, a princi-pled method for performing weighted multiple testing by constrained convex optimization. Our method elegantly allows one to prioritize certain hypotheses through upweighting and to discount others through downweighting, while constraining the underlying weights involved in the mining process. When the P-values derive from monotone likelihood ratio families such as the Gaussian means model, the new method allows exact solution of an important optimal weighting problem previously thought to be non-convex and computationally infeasible. Our method scales to massive data set sizes. We illustrate the applications of Princessp on a series of standard genomics data sets and offer comparisons with several previous 'standard' methods. Princessp offers both ease of operation and the ability to scale to extremely large problem sizes. The method is available as open-source software from github.com/dobriban/pvalue{\_}weighting{\_}matlab (accessed 11 October 2017).},
author = {Dobriban, Edgar},
doi = {10.1093/imaiai/iax013},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Information and Inference/Dobriban - 2018 - Weighted mining of massive collections of P-values by convex optimization.pdf:pdf},
journal = {Information and Inference},
keywords = {Multiple testing,P-value weighting,genome-wide association studies,large-scale inference,mining of P-values,multiple testing,weighted multiple testing},
mendeley-tags = {Multiple testing,weighted multiple testing},
pages = {251--275},
title = {{Weighted mining of massive collections of P-values by convex optimization}},
url = {https://academic.oup.com/imaiai/article-abstract/7/2/251/4711136},
volume = {7},
year = {2018}
}
@article{Heesen2015,
abstract = {Inequalities are key tools to prove FDR control of a multiple test. The present paper studies upper and lower bounds for the FDR under various dependence structures of p-values, namely independence, reverse martingale dependence and positive regression dependence on the subset (PRDS) of true null hypotheses. The inequalities are based on exact finite sample formulas which are also of interest for independent uniformly distributed p-values under the null. As applications the asymptotic worst case FDR of step up and step down tests coming from an non-decreasing rejection curve is established. In addition, new step up tests are established and necessary conditions for the FDR control are discussed. The reverse martingale models yield sharper FDR results than the PRDS models. Already in certain multivariate normal dependence models the familywise error rate of the Benjamini Hochberg step up test can be different from the desired level $\alpha$. The second part of the paper is devoted to adaptive step up tests under dependence. The well-known Storey estimator is modified so that the corresponding step up test has finite sample control for various block wise dependent p-values. These results may be applied to dependent genome data. Within each chromosome the p-values may be reverse martingale dependent while the chromosomes are independent.},
author = {Heesen, Philipp and Janssen, Arnold},
doi = {10.1214/15-EJS1016},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Electronic Journal of Statistics/Heesen, Janssen - 2015 - Inequalities for the false discovery rate (FDR) under dependence.pdf:pdf},
issn = {19357524},
journal = {Electronic Journal of Statistics},
keywords = {Adaptive benjamini hochberg methods,Blockwise dependence,False discovery rate (FDR),Inequalities,Multiple hypotheses testing,P-values,PRDS,Reverse martingale dependence,Storey test},
pages = {679--716},
title = {{Inequalities for the false discovery rate (FDR) under dependence}},
volume = {9},
year = {2015}
}
@article{Buzkova2016,
abstract = {To obtain statistical inference about interaction hypotheses without making strong distributional assumptions, permutation tests based on permuting the outcomes are often being used. It was shown that in continuous and binary data these tests might not be even approximately valid and parametric bootstrap was suggested as a viable alternative, outperforming such permutation tests. We describe an alternative permutation test, permuting the null hypothesis residuals rather than the outcome. Using simulations, we compare accuracy across the permutation tests and parametric bootstrap, studying continuous, binary, and additionally count data. Finally, we address power.},
author = {Buzkova, Petra},
doi = {10.1515/em-2015-0010},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Epidemiologic Methods/Buzkova - 2016 - Interaction Testing Residuals-Based Permutations and Parametric Bootstrap in Continuous, Count, and Binary Data.pdf:pdf},
issn = {2161962X},
journal = {Epidemiologic Methods},
keywords = {bootstrap,interaction testing,interactions,parametric bootstrap,permutation,permutation methods},
mendeley-tags = {bootstrap,interactions,permutation},
number = {1},
pages = {119--128},
title = {{Interaction Testing: Residuals-Based Permutations and Parametric Bootstrap in Continuous, Count, and Binary Data}},
volume = {5},
year = {2016}
}
@phdthesis{Roquain2015,
author = {Roquain, Etienne},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Roquain - 2015 - Contributions to multiple testing theory for high-dimensional data.pdf:pdf},
keywords = {Multiple testing},
mendeley-tags = {Multiple testing},
title = {{Contributions to multiple testing theory for high-dimensional data}},
url = {https://tel.archives-ouvertes.fr/tel-01203305},
year = {2015}
}
@article{Colmegna2004,
author = {Colmegna, Ines and Cuchacovich, Raquel and Espinoza, Luis R.},
doi = {10.1128/CMR.17.2.348},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Clinical Microbiology Reviews/Colmegna, Cuchacovich, Espinoza - 2004 - HLA-B27-Associated Reactive Arthritis Pathogenetic and Clinical Considerations.pdf:pdf},
journal = {Clinical Microbiology Reviews},
number = {2},
pages = {348--369},
title = {{HLA-B27-Associated Reactive Arthritis: Pathogenetic and Clinical Considerations}},
volume = {17},
year = {2004}
}
@article{LetM10,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/20105321{\}}{\{}20105321{\}}},
author = {Logsdon, B A and Hoffman, G E and Mezey, J G},
journal = {BMC Bioinformatics},
pages = {58},
title = {{{\{}A{\}} variational {\{}B{\}}ayes algorithm for fast and accurate multiple locus genome-wide association analysis}},
volume = {11},
year = {2010}
}
@article{XetK14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/24905018{\}}{\{}24905018{\}}},
author = {Xing, E P and Curtis, R E and Schoenherr, G and Lee, S and Yin, J and Puniyani, K and Wu, W and Kinnaird, P},
journal = {PLoS ONE},
number = {6},
pages = {e97524},
title = {{{\{}G{\}}{\{}W{\}}{\{}A{\}}{\{}S{\}} in a box: statistical and visual analytics of structured associations via {\{}G{\}}en{\{}A{\}}{\{}M{\}}ap}},
volume = {9},
year = {2014}
}
@article{Bates2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2002.09644v1},
author = {Bates, Stephen and Sesia, Matteo and Sabatti, Chiara and Candes, Emmanuel},
eprint = {arXiv:2002.09644v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Bates et al. - 2020 - Causal Inference in Genetic Trio Studies.pdf:pdf},
journal = {arXiv},
keywords = {causal discovery,conditional independence,false discovery rate,family-based association test,fbat,fdr,genome-,gwas,tdt,transmission disequilibrium test,trio,wide association study},
title = {{Causal Inference in Genetic Trio Studies}},
year = {2020}
}
@article{Wiens2005,
abstract = {In testing multiple hypotheses, control of the familywise error rate is often considered. We develop a procedure called the "fallback procedure" to control the familywise error rate when multiple primary hypotheses are tested. With the fallback procedure, the Type I error rate (alpha) is partitioned among the various hypotheses of interest. Unlike the standard Bonferroni adjustment, however, testing hypotheses proceeds in an order determined a priori. As long as hypotheses are rejected, the Type I error rate can be accumulated, making tests of later hypotheses more powerful than under the Bonferroni procedure. Unlike the fixed sequence test, the fallback test allows consideration of all hypotheses even if one or more hypotheses are not rejected early in the process, thereby avoiding a common concern about the fixed sequence procedure. We develop properties of the fallback procedure, including control of the familywise error rate for an arbitrary number of hypotheses via illustrating the procedure as a closed testing procedure, as well as making the test more powerful via alpha exhaustion. We compare it to other procedures for controlling familywise error rates, finding that the fallback procedure is a viable alternative to the fixed sequence procedure when there is some doubt about the power for the first hypothesis. These results expand on the previously developed properties of the fallback procedure (Wiens, 2003). Several examples are discussed to illustrate the relative advantages of the fallback procedure.},
author = {Wiens, Brian L. and Dmitrienko, Alexei},
doi = {10.1080/10543400500265660},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Biopharmaceutical Statistics/Wiens, Dmitrienko - 2005 - The fallback procedure for evaluating a single family of hypotheses.pdf:pdf},
isbn = {1054340050026},
issn = {10543406},
journal = {Journal of Biopharmaceutical Statistics},
keywords = {Bonferroni,Closed testing,Familywise error rate,Power,Type I error rate},
number = {6},
pages = {929--942},
title = {{The fallback procedure for evaluating a single family of hypotheses}},
volume = {15},
year = {2005}
}
@article{Katsevich2020,
abstract = {While traditional multiple testing procedures prohibit adaptive analysis choices made by users, Goeman and Solari (2011) proposed a simultaneous inference framework that allows users such flexibil- ity while preserving high-probability bounds on the false discovery proportion (FDP) of the chosen set. In this paper, we propose a new class of such simultaneous FDP bounds, tailored for nested sequences of rejection sets. While most existing simultaneous FDP bounds are based on closed testing using global null tests based on sorted p- values, we additionally consider the setting where side information can be leveraged to boost power, the variable selection setting where knockoff statistics can be used to order variables, and the online set- ting where decisions about rejections must be made as data arrives. Our finite-sample, closed form bounds are based on repurposing the FDP estimates from false discovery rate (FDR) controlling proce- dures designed for each of the above settings. These results establish a novel connection between the parallel literatures of simultaneous FDP bounds and FDR control methods, and use proof techniques employing martingales and filtrations that are new to both these lit- eratures. We demonstrate the utility of our results by augmenting a recent},
archivePrefix = {arXiv},
arxivId = {1803.06790},
author = {Katsevich, Eugene and Ramdas, Aaditya},
eprint = {1803.06790},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics, to appear/Katsevich, Ramdas - 2020 - Simultaneous high-probability bounds on the false discovery proportion in structured, regression, and online.pdf:pdf},
journal = {The Annals of Statistics, to appear},
title = {{Simultaneous high-probability bounds on the false discovery proportion in structured, regression, and online settings}},
year = {2020}
}
@article{Anderson2001,
abstract = {Several approximate permutation tests have been proposed for tests of partial regression coefficients in a linear model based on sample partial correlations. This paper begins with an explanation and notation for an exact test. It then compares the distributions of the test statistics under the various permutation methods proposed, and shows that the partial correlations under permutation are asymptotically jointly normal with means 0 and variances 1. The method of Freedman {\&} Lane (1983) is found to have asymptotic correlation 1 with the exact test, and the other methods are found to have smaller correlations with this test. Under local alternatives the critical values of all the approximate permutation tests converge to the same constant, so they all have the same asymptotic power. Simulations demonstrate these theoretical results.},
author = {Anderson, Marti J. and Robinson, John},
doi = {10.1111/1467-842X.00156},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Australian and New Zealand Journal of Statistics/Anderson, Robinson - 2001 - Permutation tests for linear models.pdf:pdf},
issn = {13691473},
journal = {Australian and New Zealand Journal of Statistics},
keywords = {Asymptotics,Partial correlations,Power,Resampling,permutation test},
mendeley-tags = {permutation test},
number = {1},
pages = {75--88},
title = {{Permutation tests for linear models}},
volume = {43},
year = {2001}
}
@article{Klann2017,
abstract = {Large genome-mapping consortia and thousands of genome-wide association studies have identified non-protein-coding elements in the genome as having a central role in various biological processes. However, decoding the functions of the millions of putative regulatory elements discovered in these studies remains challenging. CRISPR-Cas9-based epigenome editing technologies have enabled precise perturbation of the activity of specific regulatory elements. Here we describe CRISPR-Cas9-based epigenomic regulatory element screening (CERES) for improved high-throughput screening of regulatory element activity in the native genomic context. Using dCas9 KRAB repressor and dCas9 p300 activator constructs and lentiviral single guide RNA libraries to target DNase I hypersensitive sites surrounding a gene of interest, we carried out both loss-A nd gain-of-function screens to identify regulatory elements for the $\beta$-globin and HER2 loci in human cells. CERES readily identified known and previously unidentified regulatory elements, some of which were dependent on cell type or direction of perturbation. This technology allows the high-throughput functional annotation of putative regulatory elements in their native chromosomal context.},
author = {Klann, Tyler S. and Black, Joshua B. and Chellappan, Malathi and Safi, Alexias and Song, Lingyun and Hilton, Isaac B. and Crawford, Gregory E. and Reddy, Timothy E. and Gersbach, Charles A.},
doi = {10.1038/nbt.3853},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Klann et al. - 2017 - CRISPR-Cas9 epigenome editing enables high-throughput screening for functional regulatory elements in the human ge.pdf:pdf},
issn = {15461696},
journal = {Nature Biotechnology},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
number = {6},
pages = {561--568},
pmid = {28369033},
title = {{CRISPR-Cas9 epigenome editing enables high-throughput screening for functional regulatory elements in the human genome}},
volume = {35},
year = {2017}
}
@article{Mahat2016,
abstract = {{\textcopyright} 2016 Nature America, Inc. We provide a protocol for precision nuclear run-on sequencing (PRO-seq) and its variant, PRO-cap, which map the location of active RNA polymerases (PRO-seq) or transcription start sites (TSSs) (PRO-cap) genome-wide at high resolution. The density of RNA polymerases at a particular genomic locus directly reflects the level of nascent transcription at that region. Nuclei are isolated from cells and, under nuclear run-on conditions, transcriptionally engaged RNA polymerases incorporate one or, at most, a few biotin-labeled nucleotide triphosphates (biotin-NTPs) into the 3' end of nascent RNA. The biotin-labeled nascent RNA is used to prepare sequencing libraries, which are sequenced from the 3' end to provide high-resolution positional information for the RNA polymerases. PRO-seq provides much higher sensitivity than ChIP-seq, and it generates a much larger fraction of usable sequence reads than ChIP-seq or NET-seq (native elongating transcript sequencing). Similarly to NET-seq, PRO-seq maps the RNA polymerase at up to base-pair resolution with strand specificity, but unlike NET-seq it does not require immunoprecipitation. With the protocol provided here, PRO-seq (or PRO-cap) libraries for high-throughput sequencing can be generated in 4-5 working days. The method has been applied to human, mouse, Drosophila melanogaster and Caenorhabditis elegans cells and, with slight modifications, to yeast.},
author = {Mahat, Dig Bijay and Kwak, Hojoong and Booth, Gregory T. and Jonkers, Iris H. and Danko, Charles G. and Patel, Ravi K. and Waters, Colin T. and Munson, Katie and Core, Leighton J. and Lis, John T.},
doi = {10.1038/nprot.2016.086},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Protocols/Mahat et al. - 2016 - Base-pair-resolution genome-wide mapping of active RNA polymerases using precision nuclear run-on (PRO-seq).pdf:pdf},
issn = {17502799},
journal = {Nature Protocols},
keywords = {Kathryn},
mendeley-tags = {Kathryn},
number = {8},
pages = {1455--1476},
title = {{Base-pair-resolution genome-wide mapping of active RNA polymerases using precision nuclear run-on (PRO-seq)}},
volume = {11},
year = {2016}
}
@article{WetS09,
abstract = {Illumina genotyping arrays provide information on DNA copy number. Current methodology for their analysis assumes linkage equilibrium across adjacent markers. This is unrealistic, given the markers high density, and can result in reduced specificity. Another limitation of current methods is that they cannot be directly applied to the analysis of multiple samples with the goal of detecting copy number polymorphisms and their association with traits of interest.We propose a new Hidden Markov Model for Illumina genotype data, that takes into account linkage disequilibrium between adjacent loci. Our framework also allows for location specific deletion/duplication rates. When multiple samples are available, we describe a methodology for their analysis that simultaneously reconstructs the copy number states in each sample and identifies genomic locations with increased variability in copy number in the population. This approach can be extended to test association between copy number variants and a disease trait.We show that taking into account linkage disequilibrium between adjacent markers can increase the specificity of a HMM in reconstructing copy number variants, especially single copy deletions. Our multisample approach is computationally practical and can increase the power of association studies.},
annote = {19339782},
author = {Wang, H and Veldink, J H and Blauw, H and van den Berg, L H and Ophoff, R A and Sabatti, C},
doi = {10.1159/000210445},
journal = {Hum Hered},
number = {1},
pages = {1--22},
title = {{Markov Models for inferring copy number variations from genotype data on Illumina platforms}},
url = {http://www.hubmed.org/display.cgi?uids=19339782},
volume = {68},
year = {2009}
}
@article{Sanjana2016,
abstract = {The noncoding genome affects gene regulation and disease, yet we lack tools for rapid identification and manipulation of noncoding elements.We developed a CRISPR screen using {\~{}}18,000 single guide RNAs targeting {\textgreater}700 kilobases surrounding the genes NF1, NF2, and CUL3, which are involved in BRAF inhibitor resistance in melanoma.We find that noncoding locations that modulate drug resistance also harbor predictive hallmarks of noncoding function.With a subset of regions at the CUL3 locus, we demonstrate that engineered mutations alter transcription factor occupancy and long-range and local epigenetic environments, implicating these sites in gene regulation and chemotherapeutic resistance. Through our expansion of the potential of pooled CRISPR screens, we provide tools for genomic discovery and for elucidating biologically relevant mechanisms of gene regulation.},
author = {Sanjana, Neville and Wright, Jason and Zheng, Kaijie and Shalem, Ophir and Fontanillas, Pierre and Joung, Julia and Cheng, Christine and Regev, Aviv and Zhang, Feng},
doi = {10.1126/science.aaf8325},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Sanjana et al. - 2016 - High-resolution interrogation of functional elements in the noncoding genome.pdf:pdf},
isbn = {4907749082},
issn = {10959203},
journal = {Science},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {6307},
pages = {1545--1549},
title = {{High-resolution interrogation of functional elements in the noncoding genome}},
url = {http://science.sciencemag.org/},
volume = {353},
year = {2016}
}
@article{LS09,
abstract = {Recently, a genomic distance-based regression for multilocus associations was proposed (Wessel and Schork [2006] Am. J. Hum. Genet. 79:792-806) in which either locus or haplotype scoring can be used to measure genetic distance. Although it allows various measures of genomic similarity and simultaneous analyses of multiple phenotypes, its power relative to other methods for case-control analyses is not well known. We compare the power of traditional methods with this new distance-based approach, for both locus-scoring and haplotype-scoring strategies. We discuss the relative power of these association methods with respect to five properties: (1) the marker informativity; (2) the number of markers; (3) the causal allele frequency; (4) the preponderance of the most common high-risk haplotype; (5) the correlation between the causal single-nucleotide polymorphism (SNP) and its flanking markers. We found that locus-based logistic regression and the global score test for haplotypes suffered from power loss when many markers were included in the analyses, due to many degrees of freedom. In contrast, the distance-based approach was not as vulnerable to more markers or more haplotypes. A genotype counting measure was more sensitive to the marker informativity and the correlation between the causal SNP and its flanking markers. After examining the impact of the five properties on power, we found that on average, the genomic distance-based regression that uses a matching measure for diplotypes was the most powerful and robust method among the seven methods we compared.},
annote = {18814307},
author = {Lin, W Y and Schaid, D J},
doi = {10.1002/gepi.20364},
journal = {Genetic Epidemiology},
number = {3},
pages = {183--197},
title = {{Power comparisons between similarity-based multilocus association methods, logistic regression, and score tests for haplotypes}},
url = {http://www.hubmed.org/display.cgi?uids=18814307},
volume = {33},
year = {2009}
}
@article{LetS04,
author = {Lange, K and Cantor, R. and Horvath, S. and Perola, M and Sabatti, C. and Sinsheimer, J. and Sobel, E},
journal = {American Journal of Human Genetics},
keywords = {genetics,software},
mendeley-tags = {genetics,software},
pages = {504},
title = {{Mendel version 4.0: A complete package for the exact genetic analysis of discrete traits in pedigree and population data sets}},
volume = {69 (supple},
year = {2001}
}
@article{Howard2019a,
abstract = {A confidence sequence is a sequence of confidence intervals that is uniformly valid over an unbounded time horizon. In this paper, we develop confidence sequences whose widths go to zero, with non-asymptotic coverage guarantees under nonparametric conditions. Our technique draws a connection between the classical Cram{\'{e}}r-Chernoff method for exponential concentration bounds, the law of the iterated logarithm (LIL), and the sequential probability ratio test-our confidence sequences extend the first to time-uniform concentration bounds; provide tight, non-asymptotic characterizations of the second; and generalize the third to nonparametric settings, including sub-Gaussian and Bernstein conditions, self-normalized processes, and matrix martingales. We illustrate the generality of our proof techniques by deriving an empirical-Bernstein bound growing at a LIL rate, as well as a novel upper LIL for the maximum eigenvalue of a sum of random matrices. Finally, we apply our methods to covariance matrix estimation and to estimation of sample average treatment effect under the Neyman-Rubin potential outcomes model.},
archivePrefix = {arXiv},
arxivId = {1810.08240v3},
author = {Howard, Steven R and Ramdas, Aaditya and Mcauliffe, Jon and Sekhon, Jasjeet},
eprint = {1810.08240v3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Howard et al. - 2019 - Uniform, nonparametric, non-asymptotic confidence sequences.pdf:pdf},
journal = {arXiv},
keywords = {inequalities,sequential analysis,to-skim},
mendeley-tags = {inequalities,sequential analysis,to-skim},
title = {{Uniform, nonparametric, non-asymptotic confidence sequences}},
year = {2019}
}
@article{Wheeler,
author = {Wheeler, Emily C and Vu, Anthony Q and Einstein, Jaclyn M and Disalvo, Matthew and Ahmed, Noorsher and Nostrand, Eric L Van and Shishkin, Alexander A and Jin, Wenhao and Allbritton, Nancy L and Yeo, Gene W},
doi = {10.1038/s41592-020-0826-8},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Wheeler et al. - Unknown - Pooled CRISPR screens with imaging on microraft arrays reveals stress granule-regulatory factors.pdf:pdf},
issn = {1548-7105},
journal = {Nature Methods},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
publisher = {Springer US},
title = {{Pooled CRISPR screens with imaging on microraft arrays reveals stress granule-regulatory factors}},
url = {http://dx.doi.org/10.1038/s41592-020-0826-8}
}
@article{g2013false,
author = {G'Sell, M G and Wager, S and Chouldechova, A and Tibshirani, R},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {2},
pages = {423--444},
publisher = {Wiley Online Library},
title = {{Sequential selection procedures and false discovery rate control}},
volume = {78},
year = {2016}
}
@article{CV15,
author = {Collins, Francis S and Varmus, Harold},
journal = {New England Journal of Medicine},
number = {9},
pages = {793--795},
publisher = {Mass Medical Soc},
title = {{A new initiative on precision medicine}},
volume = {372},
year = {2015}
}
@article{Sandve2011,
abstract = {Motivation: In molecular biology, as in many other scientific fields, the scale of analyses is ever increasing. Often, complex Monte Carlo simulation is required, sometimes within a large-scale multiple testing setting. The resulting computational costs may be prohibitively high. Results: We here present MCFDR, a simple, novel algorithm for false discovery rate (FDR) modulated sequential Monte Carlo (MC) multiple hypothesis testing. The algorithm iterates between adding MC samples across tests and calculating intermediate FDR values for the collection of tests. MC sampling is stopped either by sequential MC or based on a threshold on FDR. An essential property of the algorithm is that it limits the total number of MC samples whatever the number of true null hypotheses. We show on both real and simulated data that the proposed algorithm provides large gains in computational efficiency. Availability: MCFDR is implemented in the Genomic HyperBrowser (http://hyperbrowser.uio.no/mcfdr), a web-based system for genome analysis. All input data and results are available and can be reproduced through a Galaxy Pages document at:},
author = {Sandve, Geir Kjetil and Ferkingstad, Egil and Nyg{\aa}rd, St{\aa}le and Bateman, Alex},
doi = {10.1093/bioinformatics/btr568},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Sandve et al. - 2011 - Sequential Monte Carlo multiple testing.pdf:pdf},
journal = {Bioinformatics},
keywords = {FDR,Monte Carlo,multiple testing},
mendeley-tags = {FDR,Monte Carlo,multiple testing},
number = {23},
pages = {3235--3241},
title = {{Sequential Monte Carlo multiple testing}},
url = {http://hyperbrowser.uio.no/mcfdr/u/sandve/p/mcfdr.},
volume = {27},
year = {2011}
}
@article{SusanWorkflow,
author = {Callahan, B J and Sankaran, K and Fukuyama, J A and McMurdie, P J and Holmes, S P},
doi = {10.12688/f1000research.8986.2},
journal = {F1000Research},
number = {1492},
title = {{Bioconductor Workflow for Microbiome Data Analysis: from raw reads to community analyses [version 2; referees: 3 approved]}},
volume = {5},
year = {2016}
}
@article{Wang2018d,
abstract = {Single-cell RNA sequencing (scRNA-seq) enables the quantifica tion of each gene's expression distribution across cells, thu allowing the assessment of the dispersion, nonzero fraction, and other aspects of its distribution beyond the mean. These sta tistical characterizations of the gene expression distribution are critical for understanding expression variation and for selecting marker genes for population heterogeneity. However, scRNA-seq data are noisy, with each cell typically sequenced at low cov erage, thus making it difficult to infer properties of the gene expression distribution from raw counts. Based on a reexamina tion of nine public datasets, we propose a simple technical noise model for scRNA-seq data with unique molecular identifiers (UMI) We develop deconvolution of single-cell expression distribution (DESCEND), a method that deconvolves the true cross-cell gene expression distribution from observed scRNA-seq counts, lead ing to improved estimates of properties of the distribution such as dispersion and nonzero fraction. DESCEND can adjust for cell level covariates such as cell size, cell cycle, and batch effects DESCEND's noise model and estimation accuracy are further eval uated through comparisons to RNA FISH data, through data split ting and simulations and through its effectiveness in removing known batch effects. We demonstrate how DESCEND can clarify and improve downstream analyses such as finding differentially expressed genes, identifying cell types, and selecting differentia tion markers.},
author = {Wang, Jingshu and Huang, Mo and Torre, Eduardo and Dueck, Hannah and Shaffer, Sydney and Murray, John and Raj, Arjun and Li, Mingyao and Zhang, Nancy R.},
doi = {10.1073/pnas.1721085115},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/Wang et al. - 2018 - Gene expression distribution deconvolution in single-cell RNA sequencing.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Differential expression,Gini coefficient,Highly variable gene,RNA sequencing,Single-cell transcriptomics,single cell},
mendeley-tags = {single cell},
number = {28},
pages = {E6437--E6446},
pmid = {29946020},
title = {{Gene expression distribution deconvolution in single-cell RNA sequencing}},
volume = {115},
year = {2018}
}
@article{Philippou1973,
author = {Philippou, A. N. and Roussas, G. G},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Philippou, Roussas - 1973 - Asymptotic distribution of the likelihood function in the independent not identically distributed case.pdf:pdf},
journal = {Annals of Statistics},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {3},
pages = {454--471},
title = {{Asymptotic distribution of the likelihood function in the independent not identically distributed case}},
volume = {1},
year = {1973}
}
@article{Simon2015,
abstract = {To date testing interactions in high dimensions is a challenging task. Existing methods often have issues with sensitivity to modeling assumptions and heavily asymptotic nominal p-values. To help alleviate these issues, we propose a permutation-based method for testing marginal interactions with a binary response. Our method searches for pairwise correlations that differ between classes. In this article, we compare our method on real and simulated data to the standard approach of running many pairwise logistic models. On simulated data our method finds more significant interactions at a lower false discovery rate (especially in the presence of main effects). On real genomic data, although there is no gold standard, our method finds apparent signal and tells a believable story, while logistic regression does not. We also give asymptotic consistency results under not too restrictive assumptions. Supplementary materials for this article are available online.},
author = {Simon, Noah and Tibshirani, Robert},
doi = {10.1080/01621459.2014.993079},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Simon, Tibshirani - 2015 - A Permutation Approach to Testing Interactions for Binary Response by Comparing Correlations Between Classes.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Correlation,False discovery rate,High dimensional,Logistic regression,interactions},
mendeley-tags = {interactions},
number = {512},
pages = {1707--1716},
title = {{A Permutation Approach to Testing Interactions for Binary Response by Comparing Correlations Between Classes}},
volume = {110},
year = {2015}
}
@article{SetB07,
abstract = {Genome-wide association (GWA) studies require genotyping hundreds of thousands of markers on thousands of subjects, and are expensive at current genotyping costs. To conserve resources, many GWA studies are adopting a staged design in which a proportion of the available samples are genotyped on all markers in stage 1, and a proportion of these markers are genotyped on the remaining samples in stage 2. We describe a strategy for designing cost-effective two-stage GWA studies. Our strategy preserves much of the power of the corresponding one-stage design and minimizes the genotyping cost of the study while allowing for differences in per genotyping cost between stages 1 and 2. We show that the ratio of stage 2 to stage 1 per genotype cost can strongly influence both the optimal design and the genotyping cost of the study. Increasing the stage 2 per genotype cost shifts more of the genotyping and study cost to stage 1, and increases the cost of the study. This higher cost can be partially mitigated by adopting a design with reduced power while preserving the false positive rate or by increasing the false positive rate while preserving power. For example, reducing the power preserved in the two-stage design from 99 to 95{\%} that of the one-stage design decreases the two-stage study cost by approximately 15{\%}. Alternatively, the same cost savings can be had by relaxing the false positive rate by 2.5-fold, for example from 1/300,000 to 2.5/300,000, while retaining the same power.},
annote = {17549752},
author = {Skol, Andrew D and Scott, Laura J and Abecasis, Gon{\c{c}}alo R and Boehnke, Michael},
journal = {Genetic Epidemiology},
pages = {776--788},
title = {{{\{}Optimal{\}} Designs for Two-stage Genome-wide Association Studies}},
volume = {31},
year = {2007}
}
@article{Mandozzi2016,
abstract = {We propose a general, modular method for significance testing of groups (or clusters) of variables in a high-dimensional linear model. In presence of high correlations among the covariables, due to serious problems of identifiability, it is indispensable to focus on detecting groups of variables rather than singletons. We propose an inference method which allows to build in hierarchical structures. It relies on repeated sample splitting and sequential rejection, and we prove that it asymptotically controls the familywise error rate. It can be implemented on any collection of clusters and leads to improved power in comparison to more standard non-sequential rejection methods. We complement the theoretical analysis with empirical results for simulated and real data.},
author = {Mandozzi, Jacopo and B{\"{u}}hlmann, Peter},
doi = {10.1515/ijb-2015-0008},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/International Journal of Biostatistics/Mandozzi, B{\"{u}}hlmann - 2016 - A Sequential Rejection Testing Method for High-Dimensional Regression with Correlated Variables.pdf:pdf},
journal = {International Journal of Biostatistics},
keywords = {correlation,familywise error rate,hierarchical clustering,high-dimensional regression,high-dimensional variable selection,inheritance procedure,lasso,linear model,minimal true detection,multiple testing,sample splitting,sequential rejection principle,singleton true detection,to-skim},
mendeley-tags = {correlation,high-dimensional regression,to-skim},
number = {1},
pages = {79--95},
title = {{A Sequential Rejection Testing Method for High-Dimensional Regression with Correlated Variables}},
volume = {12},
year = {2016}
}
@article{XB11,
abstract = {Quantitative traits (QT) are an important focus of human genetic studies both because of interest in the traits themselves and because of their role as risk factors for many human diseases. For large-scale QT association studies including genome-wide association studies, investigators usually focus on genetic loci showing significant evidence for SNP-QT association, and genetic effect size tends to be overestimated as a consequence of the winner's curse. In this paper, we study the impact of the winner's curse on QT association studies in which the genetic effect size is parameterized as the slope in a linear regression model. We demonstrate by analytical calculation that the overestimation in the regression slope estimate decreases as power increases. To reduce the ascertainment bias, we propose a three-parameter maximum likelihood method and then simplify this to a one-parameter method by excluding nuisance parameters. We show that both methods reduce the bias when power to detect association is low or moderate, and that the one-parameter model generally results in smaller variance in the estimate.},
annote = {21284035},
author = {Xiao, Rui and Boehnke, Michael},
journal = {Genetic Epidemiology},
pages = {133--138},
title = {{{\{}Quantifying{\}} and Correcting for the Winner's Curse in Quantitative-trait Association Studies}},
volume = {35},
year = {2011}
}
@article{Li2020,
author = {Li, Yunxiao and Hu, Yi-Juan and Satten, Glen A.},
doi = {10.1080/01621459.2020.1799811},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Li, Hu, Satten - 2020 - A Bottom-up Approach to Testing Hypotheses That Have a Branching Tree Dependence Structure, with Error Rate Cont.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {driver nodes,false discovery,false selection rate,hierarchical multiple testing,microbiome,multiple testing,rate},
mendeley-tags = {hierarchical multiple testing},
number = {0},
pages = {1--35},
publisher = {Taylor {\&} Francis},
title = {{A Bottom-up Approach to Testing Hypotheses That Have a Branching Tree Dependence Structure, with Error Rate Control}},
volume = {0},
year = {2020}
}
@article{CetZ14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25393678{\}}{\{}25393678{\}}},
author = {Chung, D and Yang, C and Li, C and Gelernter, J and Zhao, H},
doi = {10.1371/journal.pgen.1004787},
journal = {PLoS Genetics},
month = {nov},
number = {11},
pages = {e1004787},
title = {{{\{}GPA{\}}: a statistical approach to prioritizing {\{}GWAS{\}} results by integrating pleiotropy and annotation}},
volume = {10},
year = {2014}
}
@article{Pfister2019,
abstract = {We consider regression in which one predicts a response {\$}Y{\$} with a set of predictors {\$}X{\$} across different experiments or environments. This is a common setup in many data-driven scientific fields and we argue that statistical inference can benefit from an analysis that takes into account the distributional changes across environments. In particular, it is useful to distinguish between stable and unstable predictors, i.e., predictors which have a fixed or a changing functional dependence on the response, respectively. We introduce stabilized regression which explicitly enforces stability and thus improves generalization performance to previously unseen environments. Our work is motivated by an application in systems biology. Using multiomic data, we demonstrate how hypothesis generation about gene function can benefit from stabilized regression. We believe that a similar line of arguments for exploiting heterogeneity in data can be powerful for many other applications as well. We draw a theoretical connection between multi-environment regression and causal models, which allows to graphically characterize stable versus unstable functional dependence on the response. Formally, we introduce the notion of a stable blanket which is a subset of the predictors that lies between the direct causal predictors and the Markov blanket. We prove that this set is optimal in the sense that a regression based on these predictors minimizes the mean squared prediction error given that the resulting regression generalizes to unseen new environments.},
archivePrefix = {arXiv},
arxivId = {1911.01850},
author = {Pfister, Niklas and Williams, Evan G. and Peters, Jonas and Aebersold, Ruedi and B{\"{u}}hlmann, Peter},
eprint = {1911.01850},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Pfister et al. - 2019 - Stabilizing Variable Selection and Regression.pdf:pdf},
pages = {1--43},
title = {{Stabilizing Variable Selection and Regression}},
url = {http://arxiv.org/abs/1911.01850},
year = {2019}
}
@article{2015arXiv150504073W,
archivePrefix = {arXiv},
arxivId = {cs.LG/1505.04073},
author = {Wang, J and Ye, J},
eprint = {1505.04073},
journal = {arXiv},
keywords = {Computer Science - Learning,multiple phenotypes,unpublished},
mendeley-tags = {multiple phenotypes,unpublished},
month = {may},
primaryClass = {cs.LG},
title = {{Safe Screening for Multi-Task Feature Learning with Multiple Data Matrices}},
year = {2015}
}
@article{Gleser1987,
author = {Gleser, Leon Jay and Carroll, Raymond J. and Gallo, Paul P.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Gleser, Carroll, Gallo - 1987 - The limiting distribution of least squares in an errors-in-variables regression model.pdf:pdf},
issn = {0091-1798},
journal = {Annals of Statistics},
keywords = {error-in-variables},
mendeley-tags = {error-in-variables},
number = {1},
pages = {220--233},
title = {{The limiting distribution of least squares in an errors-in-variables regression model}},
url = {http://projecteuclid.org/euclid.aop/1176996548},
volume = {15},
year = {1987}
}
@article{HE72,
annote = {4157472},
author = {Haseman, J K and Elston, R C},
journal = {Behav Genet},
number = {1},
pages = {3--19},
title = {{The investigation of linkage between a quantitative trait and a marker locus}},
url = {http://www.hubmed.org/display.cgi?uids=4157472},
volume = {2},
year = {1972}
}
@article{Roquain2011,
abstract = {In a context of multiple hypothesis testing, we provide several new exact calculations related to the false discovery proportion (FDP) of step-up and step-down procedures. For step-up procedures, we show that the number of erroneous rejections conditionally on the rejection number is simply a bino-mial variable, which leads to explicit computations of the c.d.f., the sth moment and the mean of the FDP, the latter corresponding to the false discovery rate (FDR). For step-down procedures, we derive what is to our knowledge the first explicit formula for the FDR valid for any alternative c.d.f. of the p-values. We also derive explicit computations of the power for both step-up and step-down procedures. These formulas are "explicit" in the sense that they only involve the parameters of the model and the c.d.f. of the order statistics of i.i.d. uniform variables. The p-values are assumed either independent or coming from an equicorrelated multivariate normal model and an additional mixture model for the true/false hypotheses is used. Our approach is then used to investigate new results which are of interest in their own right, related to least/most favorable configurations for the FDR and the variance of the FDP.},
author = {Roquain, Etienne and Villers, Fanny},
doi = {10.1214/10-AOS847},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Roquain, Villers - 2011 - EXACT CALCULATIONS FOR FALSE DISCOVERY PROPORTION WITH APPLICATION TO LEAST FAVORABLE CONFIGURATIONS 1.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {60C05,62G10,62J15,FDR,False discovery rate,Multiple testing,equicorrelated multivariate normal distribution,false discovery proportion,least favorable configuration,multiple testing,power,step-down,step-up,to-skim},
mendeley-tags = {FDR,Multiple testing,to-skim},
number = {1},
pages = {584--612},
title = {{EXACT CALCULATIONS FOR FALSE DISCOVERY PROPORTION WITH APPLICATION TO LEAST FAVORABLE CONFIGURATIONS 1}},
volume = {39},
year = {2011}
}
@article{Katsevich2020c,
author = {Katsevich, Eugene and Barry, Timothy and Roeder, Kathryn},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Katsevich, Barry, Roeder - 2020 - Conditional resampling improves calibration in single cell CRISPR screen analysis.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,gene-enhancer},
mendeley-tags = {CRISPR,gene-enhancer},
title = {{Conditional resampling improves calibration in single cell CRISPR screen analysis}},
url = {https://www.biorxiv.org/content/10.1101/2020.08.13.250092v2},
year = {2020}
}
@article{HetE09,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/19213738{\}}{\{}19213738{\}}},
author = {Heller, R and Manduchi, E and Grant, G R and Ewens, W J},
journal = {Bioinformatics},
keywords = {gene expression,genetics},
mendeley-tags = {gene expression,genetics},
month = {apr},
number = {8},
pages = {1019--1025},
title = {{{\{}A{\}} flexible two-stage procedure for identifying gene sets that are differentially expressed}},
volume = {25},
year = {2009}
}
@article{Che2014,
abstract = {BACKGROUND: Permutation testing is a robust and popular approach for significance testing in genomic research, which has the broad advantage of estimating significance non-parametrically, thereby safe guarding against inflated type I error rates. However, the computational efficiency remains a challenging issue that limits its wide application, particularly in genome-wide association studies (GWAS). Because of this, adaptive permutation strategies can be employed to make permutation approaches feasible. While these approaches have been used in practice, there is little research into the statistical properties of these approaches, and little guidance into the proper application of such a strategy for accurate p-value estimation at the GWAS level.$\backslash$n$\backslash$nMETHODS: In this work, we advocate an adaptive permutation procedure that is statistically valid as well as computationally feasible in GWAS. We perform extensive simulation experiments to evaluate the robustness of the approach to violations of modeling assumptions and compare the power of the adaptive approach versus standard approaches. We also evaluate the parameter choices in implementing the adaptive permutation approach to provide guidance on proper implementation in real studies. Additionally, we provide an example of the application of adaptive permutation testing on real data.$\backslash$n$\backslash$nRESULTS: The results provide sufficient evidence that the adaptive test is robust to violations of modeling assumptions. In addition, even when modeling assumptions are correct, the power achieved by adaptive permutation is identical to the parametric approach over a range of significance thresholds and effect sizes under the alternative. A framework for proper implementation of the adaptive procedure is also generated.$\backslash$n$\backslash$nCONCLUSIONS: While the adaptive permutation approach presented here is not novel, the current study provides evidence of the validity of the approach, and importantly provides guidance on the proper implementation of such a strategy. Additionally, tools are made available to aid investigators in implementing these approaches.},
author = {Che, Ronglin and Jack, John R. and Motsinger-Reif, Alison A. and Brown, Chad C.},
doi = {10.1186/1756-0381-7-9},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BioData Mining/Che et al. - 2014 - An adaptive permutation approach for genome-wide association study Evaluation and recommendations for use.pdf:pdf},
issn = {17560381},
journal = {BioData Mining},
keywords = {Monte Carlo,Multiple testing},
mendeley-tags = {Monte Carlo,Multiple testing},
number = {1},
pages = {1--13},
title = {{An adaptive permutation approach for genome-wide association study: Evaluation and recommendations for use}},
volume = {7},
year = {2014}
}
@article{Doudna2014,
abstract = {The advent of facile genome engineering using the bacterial RNA-guided CRISPR-Cas9 system in animals and plants is transforming biology. We review the history of CRISPR (clustered regularly interspaced palindromic repeat) biology from its initial discovery through the elucidation of the CRISPR-Cas9 enzyme mechanism, which has set the stage for remarkable developments using this technology to modify, regulate, or mark genomic loci in a wide variety of cells and organisms from all three domains of life. These results highlight a new era in which genomic manipulation is no longer a bottleneck to experiments, paving the way toward fundamental discoveries in biology, with applications in all branches of biotechnology, as well as strategies for human therapeutics.},
author = {Doudna, Jennifer A. and Charpentier, Emmanuelle},
doi = {10.1126/science.1258096},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Doudna, Charpentier - 2014 - The new frontier of genome engineering with CRISPR-Cas9.pdf:pdf},
issn = {10959203},
journal = {Science},
number = {6213},
pmid = {25430774},
title = {{The new frontier of genome engineering with CRISPR-Cas9}},
volume = {346},
year = {2014}
}
@techreport{Mukherjee2008,
abstract = {Recent years have seen much interest in the study of systems characterized by multiple interacting components. A class of statistical models called graphical models, in which graphs are used to represent probabilistic relationships between variables, provides a framework for formal inference regarding such systems. In many settings, the object of inference is the network structure itself. This problem of "network inference" is well known to be a challenging one. However, in scientific settings there is very often existing information regarding network connectivity. A natural idea then is to take account of such information during inference. This article addresses the question of incorporating prior information into network inference. We focus on directed models called Bayesian networks, and use Markov chain Monte Carlo to draw samples from posterior distributions over network structures. We introduce prior distributions on graphs capable of capturing information regarding network features including edges, classes of edges, degree distributions, and sparsity. We illustrate our approach in the context of systems biology, applying our methods to network inference in cancer signaling.},
author = {Mukherjee, S. and Speed, T. P.},
booktitle = {Proceedings of the National Academy of Sciences},
doi = {10.1073/pnas.0802272105},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences/Mukherjee, Speed - 2008 - Network inference using informative priors.pdf:pdf},
issn = {0027-8424},
keywords = {Kathryn,networks},
mendeley-tags = {Kathryn,networks},
number = {38},
pages = {14313--14318},
title = {{Network inference using informative priors}},
url = {www.pnas.orgcgidoi10.1073pnas.0802272105},
volume = {105},
year = {2008}
}
@article{LL08lasso,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/18310618{\}}{\{}18310618{\}}},
author = {Li, C and Li, H},
journal = {Bioinformatics},
keywords = {FDR,networks},
mendeley-tags = {FDR,networks},
month = {may},
number = {9},
pages = {1175--1182},
title = {{{\{}N{\}}etwork-constrained regularization and variable selection for analysis of genomic data}},
volume = {24},
year = {2008}
}
@article{Yekutieli2019,
abstract = {Bayesian modeling is now ubiquitous in problems of large-scale inference even when frequentist criteria are in mind for evaluating the performance of a procedure. By far most popular in literature of the past decade and a half are empirical Bayes methods, that have shown in practice to improve significantly over strictly-frequentist competitors in many different problems. As an alternative to empirical Bayes methods, in this paper we propose hierarchical Bayes modeling for large-scale problems, and address two separate points that, in our opinion, deserve more attention. The first is nonparametric "deconvolution" methods that are applicable also outside the sequence model. The second point is the adequacy of Bayesian modeling for situations where the parameters are by assumption deterministic. We provide partial answers to both: first, we demonstrate how our methodology applies in the analysis of a logistic regression model. Second, we appeal to Robbins's compound decision theory and provide an extension, to give formal justification for the Bayesian approach in the sequence case.},
archivePrefix = {arXiv},
arxivId = {1908.08444v1},
author = {Yekutieli, Daniel and Weinstein, Asaf},
eprint = {1908.08444v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Yekutieli, Weinstein - 2019 - Hierarchical Bayes Modeling for Large-Scale Inference.pdf:pdf},
journal = {arXiv},
keywords = {empirical Bayes},
mendeley-tags = {empirical Bayes},
title = {{Hierarchical Bayes Modeling for Large-Scale Inference}},
year = {2019}
}
@article{PetS16BP,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/27176483{\}}{\{}27176483{\}}},
author = {Peterson, C B and Service, S K and Jasinska, A J and Gao, F and Zelaya, I and Teshiba, T M and Bearden, C E and Cantor, R M and Reus, V I and Macaya, G and Lopez-Jaramillo, C and Bogomolov, M and Benjamini, Y and Eskin, E and Coppola, G and Freimer, N B and Sabatti, C},
journal = {PLoS Genetics},
keywords = {eQTL,genetics},
mendeley-tags = {eQTL,genetics},
month = {may},
number = {5},
pages = {e1006046},
title = {{{\{}C{\}}haracterization of {\{}E{\}}xpression {\{}Q{\}}uantitative {\{}T{\}}rait {\{}L{\}}oci in {\{}P{\}}edigrees from {\{}C{\}}olombia and {\{}C{\}}osta {\{}R{\}}ica {\{}A{\}}scertained for {\{}B{\}}ipolar {\{}D{\}}isorder}},
volume = {12},
year = {2016}
}
@article{Chen2020,
abstract = {Various methods of combining individual p-values into one p-value are widely used in many areas of statistical applications. We say that a combining method is valid for arbitrary dependence (VAD) if it does not require any assumption on the dependence structure of the p-values, whereas it is valid for some dependence (VSD) if it requires some specific, perhaps realistic but unjustifiable, dependence structures. The trade-off between validity and efficiency of these methods is studied via analyzing the choices of critical values under different dependence assumptions. We introduce the notions of independence-comonotonicity balance (IC-balance) and the price for validity. In particular, IC-balanced methods always produce an identical critical value for independent and perfectly positively dependent p-values, thus showing insensitivity to dependence assumptions. We show that, among two very general classes of merging methods commonly used in practice, the Cauchy combination method and the Simes method are the only IC-balanced ones. Simulation studies and a real data analysis are conducted to analyze the sizes and powers of various combining methods in the presence of weak and strong dependence.},
archivePrefix = {arXiv},
arxivId = {2007.12366},
author = {Chen, Yuyu and Liu, Peng and Tan, Ken Seng and Wang, Ruodu},
eprint = {2007.12366},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Chen et al. - 2020 - Trade-off between validity and efficiency of merging p-values under arbitrary dependence.pdf:pdf},
journal = {arXiv},
keywords = {efficiency,global testing,hypothesis testing,multiple hypothesis testing,validity},
mendeley-tags = {global testing},
title = {{Trade-off between validity and efficiency of merging p-values under arbitrary dependence}},
url = {http://arxiv.org/abs/2007.12366},
year = {2020}
}
@article{Hu2018,
abstract = {The current paradigm of genomic studies of complex diseases is association and correlation analysis. Despite significant progress in dissecting the genetic architecture of complex diseases by genome-wide association studies (GWAS), the identified genetic variants by GWAS can only explain a small proportion of the heritability of complex diseases. A large fraction of genetic variants is still hidden. Association analysis has limited power to unravel mechanisms of complex diseases. It is time to shift the paradigm of genomic analysis from association analysis to causal inference. Causal inference is an essential component for the discovery of mechanism of diseases. This paper will review the major platforms of the genomic analysis in the past and discuss the perspectives of causal inference as a general framework of genomic analysis. In genomic data analysis, we usually consider four types of associations: association of discrete variables (DNA variation) with continuous variables (phenotypes and gene expressions), association of continuous variables (expressions, methylations, and imaging signals) with continuous variables (gene expressions, imaging signals, phenotypes, and physiological traits), association of discrete variables (DNA variation) with binary trait (disease status) and association of continuous variables (gene expressions, methylations, phenotypes, and imaging signals) with binary trait (disease status). In this paper, we will review algorithmic information theory as a general framework for causal discovery and the recent development of statistical methods for causal inference on discrete data, and discuss the possibility of extending the association analysis of discrete variable with disease to the causal analysis for discrete variable and disease.},
author = {Hu, Pengfei and Jiao, Rong and Jin, Li and Xiong, Momiao},
doi = {10.3389/fgene.2018.00238},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Frontiers in Genetics/Hu et al. - 2018 - Application of causal inference to genomic analysis Advances in methodology.pdf:pdf},
issn = {16648021},
journal = {Frontiers in Genetics},
keywords = {Additive noise models for discrete variables,Association analysis,CRISPR,Causal inference,Entropy,Genomic analysis,causality},
mendeley-tags = {CRISPR,causality},
number = {JUL},
title = {{Application of causal inference to genomic analysis: Advances in methodology}},
volume = {9},
year = {2018}
}
@article{Jiang2015,
abstract = {A number of recent studies have investigated the role of de novo mutations in various neurodevelopmental and neuropsychiatric disorders. These studies attempt to implicate causal genes by looking for an excess load of de novo mutations within those genes. Current statistical methods for assessing this excess are based on the implicit assumption that all qualifying mutations in a gene contribute equally to disease. However, it is well established that different mutations can have radically different effects on the ultimate protein product and, as a result, on disease risk. Here, we propose a method, fitDNM, that incorporates functional information in a test of excess de novo mutational load. Specifically, we derive score statistics from a retrospective likelihood that incorporates the probability of a mutation being damaging to gene function. We show that, under the null, the resulting test statistic is distributed as a weighted sum of Poisson random variables and we implement a saddlepoint approximation of this distribution to obtain accurate p values. Using simulation, we have shown that our method outperforms current methods in terms of statistical power while maintaining validity. We have applied this approach to four de novo mutation datasets of neurodevelopmental and neuropsychiatric disorders: autism spectrum disorder, epileptic encephalopathy, schizophrenia, and severe intellectual disability. Our approach also implicates genes that have been implicated by existing methods. Furthermore, our approach provides strong statistical evidence supporting two potentially causal genes: SUV420H1 in autism spectrum disorder and TRIO in a combined analysis of the four neurodevelopmental and neuropsychiatric disorders investigated here.},
author = {Jiang, Yu and Han, Yujun and Petrovski, Slav{\'{e}} and Owzar, Kouros and Goldstein, David B. and Allen, Andrew S.},
doi = {10.1016/j.ajhg.2015.06.013},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Human Genetics/Jiang et al. - 2015 - Incorporating Functional Information in Tests of Excess De Novo Mutational Load.pdf:pdf},
issn = {15376605},
journal = {American Journal of Human Genetics},
keywords = {Kathryn,autism,de novo mutations,psychiatric genomics,whole exome sequencing},
mendeley-tags = {Kathryn,autism,de novo mutations,psychiatric genomics,whole exome sequencing},
number = {2},
pages = {272--283},
title = {{Incorporating Functional Information in Tests of Excess De Novo Mutational Load}},
volume = {97},
year = {2015}
}
@article{Ma2018,
abstract = {High-dimensional logistic regression is widely used in analyzing data with binary outcomes. In this paper, global testing and large-scale multiple testing for the regression coefficients are considered in both single- and two-regression settings. A test statistic for testing the global null hypothesis is constructed using a generalized low-dimensional projection for bias correction and its asymptotic null distribution is derived. A lower bound for the global testing is established, which shows that the proposed test is asymptotically minimax optimal. For testing the individual coefficients simultaneously, multiple testing procedures are proposed and shown to control the false discovery rate (FDR) and falsely discovered variables (FDV) asymptotically. Simulation studies are carried out to examine the numerical performance of the proposed tests and their superiority over existing methods. The testing procedures are also illustrated by analyzing a data set of a metabolomics study that investigates the association between fecal metabolites and pediatric Crohn's disease and the effects of treatment on such associations.},
archivePrefix = {arXiv},
arxivId = {1805.06970},
author = {Ma, Rong and Cai, T. Tony and Li, Hongzhe},
eprint = {1805.06970},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Ma, Cai, Li - 2018 - Global and Simultaneous Hypothesis Testing for High-Dimensional Logistic Regression Models.pdf:pdf},
keywords = {false discovery rate,global testing,large-scale multiple testing,minimax lower},
title = {{Global and Simultaneous Hypothesis Testing for High-Dimensional Logistic Regression Models}},
url = {http://arxiv.org/abs/1805.06970},
year = {2018}
}
@article{Cao2017,
abstract = {We propose a new method for determining the target genes of transcriptional enhancers in specific cells and tissues. It combines global trends across many samples and sample-specific information, and considers the joint effect of multiple enhancers. Our method outperforms existing methods when predicting the target genes of enhancers in unseen samples, as evaluated by independent experimental data. Requiring few types of input data, we are able to apply our method to reconstruct the enhancer-target networks in 935 samples of human primary cells, tissues and cell lines, which constitute by far the largest set of enhancer-target networks. The similarity of these networks from different samples closely follows their cell and tissue lineages. We discover three major co-regulation modes of enhancers and find defense-related genes often simultaneously regulated by multiple enhancers bound by different transcription factors. We also identify differentially methylated enhancers in hepatocellular carcinoma (HCC) and experimentally confirm their altered regulation of HCC-related genes. Enhancers are bound by transcription factors and interact with the promoters of their target genes through DNA looping 1. Because enhancers can be far away from the genes they regulate and can be either upstream or downstream of them 1,2 , determining enhancer targets is difficult. Direct DNA contacts obtained from Hi-C 3 , chromatin interaction analysis by paired-end tag sequencing (ChIA-PET) 4 or similar experiments would provide valuable information, but thus far these data are only available for a few human cell types 3,5-11. As a result, previous studies have attempted to computationally infer enhancer targets 12-18. Limited by the availability of epigenomic and other data required by these methods, they have only been applied to a small number of human cell types. To study general properties of enhancer-mediated gene regulation, here we reconstruct and analyze active enhancer-target networks in 935 samples, covering a major fraction of human cell and tissue types. The method we employ only requires several types of input data, making it easily applicable to many samples. It combines both global trends across all samples and sample-specific information, and considers the joint effect of multiple enhancers on the same target genes. Our method is more accurate than existing methods in predicting enhancer targets in unseen samples. We are also able to experimentally confirm some of our predictions in HCC samples.},
author = {Cao, Qin and Anyansi, Christine and Hu, Xihao and Xu, Liangliang and Xiong, Lei and Tang, Wenshu and {S Mok}, Myth T and Cheng, Chao and Fan, Xiaodan and Gerstein, Mark and {L Cheng}, Alfred S and Yip, Kevin Y},
doi = {10.1038/ng.3950},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Cao et al. - 2017 - Reconstruction of enhancer-target networks in 935 samples of human primary cells, tissues and cell lines.pdf:pdf},
journal = {Nature Genetics},
keywords = {Kathryn,gene-enhancer,genetics,to-read},
mendeley-tags = {Kathryn,gene-enhancer,genetics,to-read},
number = {10},
pages = {1428--1436},
title = {{Reconstruction of enhancer-target networks in 935 samples of human primary cells, tissues and cell lines}},
volume = {49},
year = {2017}
}
@article{RetD05,
abstract = {A goal of association analysis is to determine whether variation in a particular candidate region or gene is associated with liability to complex disease. To evaluate such candidates, ubiquitous Single Nucleotide Polymorphisms (SNPs) are useful. It is critical, however, to select a set of SNPs that are in substantial linkage disequilibrium (LD) with all other polymorphisms in the region. Whether there is an ideal statistical framework to test such a set of 'tag SNPs' for association is unknown. Compared to tests for association based on frequencies of haplotypes, recent evidence suggests tests for association based on linear combinations of the tag SNPs (Hotelling T(2) test) are more powerful. Following this logical progression, we wondered if single-locus tests would prove generally more powerful than the regression-based tests? We answer this question by investigating four inferential procedures: the maximum of a series of test statistics corrected for multiple testing by the Bonferroni procedure, T(B), or by permutation of case-control status, T(P); a procedure that tests the maximum of a smoothed curve fitted to the series of of test statistics, T(S); and the Hotelling T(2) procedure, which we call T(R). These procedures are evaluated by simulating data like that from human populations, including realistic levels of LD and realistic effects of alleles conferring liability to disease. We find that power depends on the correlation structure of SNPs within a gene, the density of tag SNPs, and the placement of the liability allele. The clearest pattern emerges between power and the number of SNPs selected. When a large fraction of the SNPs within a gene are tested, and multiple SNPs are highly correlated with the liability allele, T(S) has better power. Using a SNP selection scheme that optimizes power but also requires a substantial number of SNPs to be genotyped (roughly 10-20 SNPs per gene), power of T(P) is generally superior to that for the other procedures, including T(R). Finally, when a SNP selection procedure that targets a minimal number of SNPs per gene is applied, the average performances of T(P) and T(R) are indistinguishable.},
annote = {15637715},
author = {Roeder, K and Bacanu, S A and Sonpar, V and Zhang, X and Devlin, B},
doi = {10.1002/gepi.20050},
journal = {Genetic Epidemiology},
number = {3},
pages = {207--219},
title = {{Analysis of single-locus tests to detect gene/disease associations}},
url = {http://www.hubmed.org/display.cgi?uids=15637715},
volume = {28},
year = {2005}
}
@article{Cao2019,
author = {Cao, Qin and Yip, Kevin Y},
doi = {10.1038/s41588-019-0452-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Cao, Yip - 2019 - Reply to ‘Inflated performance measures in enhancer–promoter interaction-prediction methods'.pdf:pdf},
isbn = {4158801904525},
journal = {Nature Genetics},
keywords = {Kathryn,enhancer,gene-enhancer},
mendeley-tags = {Kathryn,enhancer,gene-enhancer},
title = {{Reply to ‘Inflated performance measures in enhancer–promoter interaction-prediction methods'}},
url = {https://doi.org/10.1038/s41588-019-0452-5.},
year = {2019}
}
@article{ZetL12,
annote = {22223662},
author = {Zuk, O and Hechter, E and Sunyaev, S R and Lander, E S},
journal = {Proceedings of the National Academy of Sciences},
month = {jan},
pages = {1193--1198},
title = {{{\{}T{\}}he mystery of missing heritability: {\{}G{\}}enetic interactions create phantom heritability}},
volume = {109},
year = {2012}
}
@article{Jeng2019,
abstract = {This article addresses the challenge of efficiently capturing a high proportion of true signals for subsequent data analyses when sample sizes are relatively limited with respect to data dimension. We propose the signal missing rate (SMR) as a new measure for false-negative control to account for the variability of false-negative proportion. Novel data-adaptive procedures are developed to control SMR without incurring many unnecessary false positives under dependence. We justify the efficiency and adaptivity of the proposed methods via theory and simulation. The proposed methods are applied to GWAS on human height to effectively remove irrelevant single nucleotide polymorphisms (SNPs) while retaining a high proportion of relevant SNPs for subsequent polygenic analysis.},
author = {Jeng, X Jessie and Zhang, Teng and Tzeng, Jung-Ying},
doi = {10.1080/01621459.2018.1518236},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Jeng, Zhang, Tzeng - 2019 - Efficient Signal Inclusion With Genomic Applications.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Dimension reduction,False-negative control,False-positive control,Multiple testing,Ultrahigh dimension,Variable screening,genetics},
mendeley-tags = {Multiple testing,genetics},
title = {{Efficient Signal Inclusion With Genomic Applications}},
url = {https://www.tandfonline.com/action/journalInformation?journalCode=uasa20},
year = {2019}
}
@article{Doench2018,
abstract = {The rapid development of CRISPR-based gene manipulation has enabled various approaches for high-throughput functional genomics. This Review guides users through the practicalities of CRISPR-based functional genomics screens, including study design options, best-practice approaches, pitfalls to avoid and data analysis strategies.},
author = {Doench, John G.},
doi = {10.1038/nrg.2017.97},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Reviews Genetics/Doench - 2018 - Am I ready for CRISPR A user's guide to genetic screens.pdf:pdf},
issn = {14710064},
journal = {Nature Reviews Genetics},
keywords = {CRISPR,Kathryn,gene-enhancer,genetics},
mendeley-tags = {CRISPR,Kathryn,gene-enhancer,genetics},
number = {2},
pages = {67--80},
publisher = {Nature Publishing Group},
title = {{Am I ready for CRISPR? A user's guide to genetic screens}},
url = {http://dx.doi.org/10.1038/nrg.2017.97},
volume = {19},
year = {2018}
}
@article{Storey2003,
author = {Storey, J D},
journal = {The Annals of Statistics},
keywords = {FDR,Multiple testing,canonical,pFDR,q-value},
mendeley-tags = {FDR,Multiple testing,canonical,pFDR,q-value},
number = {6},
pages = {2013--2035},
title = {{The positive false discovery rate: a Bayesian interpretation and the {\$}q{\$}-Value}},
volume = {31},
year = {2003}
}
@article{Weinstein2017,
abstract = {Knockoffs is a new framework for controlling the false discovery rate (FDR) in multiple hypothesis testing problems involving complex statistical models. While there has been great emphasis on Type-I error control, Type-II errors have been far less studied. In this paper we analyze the false negative rate or, equivalently, the power of a knockoff procedure associated with the Lasso solution path under an i.i.d. Gaussian design, and find that knockoffs asymptotically achieve close to optimal power with respect to an omniscient oracle. Furthermore, we demonstrate that for sparse signals, performing model selection via knockoff filtering achieves nearly ideal prediction errors as compared to a Lasso oracle equipped with full knowledge of the distribution of the unknown regression coefficients. The i.i.d. Gaussian design is adopted to leverage results concerning the empirical distribution of the Lasso estimates, which makes power calculation possible for both knockoff and oracle procedures.},
archivePrefix = {arXiv},
arxivId = {1712.06465},
author = {Weinstein, Asaf and Barber, Rina and Candes, Emmanuel},
eprint = {1712.06465},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Weinstein, Barber, Candes - 2017 - A power analysis for knockoffs under Gaussian designs.pdf:pdf},
journal = {arXiv},
title = {{A power analysis for knockoffs under Gaussian designs}},
url = {http://arxiv.org/abs/1712.06465},
year = {2017}
}
@article{1993,
author = {Papalexi, Efthymia and Mimitou, Eleni and Butler, Andrew W. and Foster, Samantha and Bracken, Bernadette and III, William M. Mauck and Wessels, Hans-Hermann and Yeung, Bertrand Z. and Smibert, Peter and Satija, Rahul},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Papalexi et al. - 2020 - Characterizing the molecular regulation of inhibitory immune checkpoints with multi-modal single- cell scree(2).pdf:pdf},
issn = {0300-9165},
journal = {bioRxiv},
keywords = {CRISPR,ECCITE-seq,single cell},
mendeley-tags = {CRISPR,ECCITE-seq,single cell},
title = {{Characterizing the molecular regulation of inhibitory immune checkpoints with multi-modal single- cell screens}},
year = {2020}
}
@article{Harris2016,
abstract = {We consider the problem of selective inference after solving a (randomized) convex statistical learning program in the form of a penalized or constrained loss function. Our first main result is a change-of-measure formula that describes many conditional sampling problems of interest in selective inference. Our approach is model-agnostic in the sense that users may provide their own statistical model for inference, we simply provide the modification of each distribution in the model after the selection. Our second main result describes the geometric structure in the Jacobian appearing in the change of measure, drawing connections to curvature measures appearing in Weyl-Steiner volume-of-tubes formulae. This Jacobian is necessary for problems in which the convex penalty is not polyhedral, with the prototypical example being group LASSO or the nuclear norm. We derive explicit formulae for the Jacobian of the group LASSO. To illustrate the generality of our method, we consider many examples throughout, varying both the penalty or constraint in the statistical learning problem as well as the loss function, also considering selective inference after solving multiple statistical learning programs. Penalties considered include LASSO, forward stepwise, stagewise algorithms, marginal screening and generalized LASSO. Loss functions considered include squared-error, logistic, and log-det for covariance matrix estimation. Having described the appropriate distribution we wish to sample from through our first two results, we outline a framework for sampling using a projected Langevin sampler in the (commonly occuring) case that the distribution is log-concave.},
archivePrefix = {arXiv},
arxivId = {1609.05609v1},
author = {Harris, Xiaoying Tian and Panigrahi, Snigdha and Markovic, Jelena and Bi, Nan and Taylor, Jonathan},
eprint = {1609.05609v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Harris et al. - 2016 - Selective sampling after solving a convex problem.pdf:pdf},
journal = {arXiv},
keywords = {post-selection inference,unpublished},
mendeley-tags = {post-selection inference,unpublished},
title = {{Selective sampling after solving a convex problem}},
year = {2016}
}
@article{MetT17,
author = {Markovic, Jelena and Xia, Lucy and Taylor, Jonathan},
journal = {arXiv},
keywords = {post-selection inference,unpublished},
mendeley-tags = {post-selection inference,unpublished},
title = {{Adaptive p-values after cross-validation}},
year = {2017}
}
@article{AK10,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21104890{\}}{\{}21104890{\}}},
author = {Ayers, K L and Cordell, H J},
journal = {Genetic Epidemiology},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
month = {dec},
number = {8},
pages = {879--891},
title = {{SNP selection in genome-wide and candidate gene studies via penalized logistic regression}},
volume = {34},
year = {2010}
}
@article{Sheffield2013,
abstract = {Regulatory elements recruit transcription factors that modulate gene expression distinctly across cell types, but the relationships among these remains elusive. To address this, we analyzed matched DNase-seq and gene expression data for 112 human samples representing 72 cell types. We first defined more than 1800 clusters of DNase I hypersensitive sites (DHSs) with similar tissue specificity of DNase-seq signal patterns. We then used these to uncover distinct associations between DHSs and promoters, CpG islands, conserved elements, and transcription factor motif enrichment. Motif analysis within clusters identified known and novel motifs in cell-type-specific and ubiquitous regulatory elements and supports a role for AP-1 regulating open chromatin. We developed a classifier that accurately predicts cell-type lineage based on only 43 DHSs and evaluated the tissue of origin for cancer cell types. A similar classifier identified three sex-specific loci on the X chromosome, including the XIST lincRNA locus. By correlating DNase I signal and gene expression, we predicted regulated genes for more than 500K DHSs. Finally, we introduce a web resource to enable researchers to use these results to explore these regulatory patterns and better understand how expression is modulated within and across human cell types.},
author = {Sheffield, Nathan C. and Thurman, Robert E. and Song, Lingyun and Safi, Alexias and Stamatoyannopoulos, John A. and Lenhard, Boris and Crawford, Gregory E. and Furey, Terrence S.},
doi = {10.1101/gr.152140.112},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Research/Sheffield et al. - 2013 - Patterns of regulatory activity across diverse human cell types predict tissue identity, transcription factor.pdf:pdf},
issn = {10889051},
journal = {Genome Research},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {5},
pages = {777--788},
title = {{Patterns of regulatory activity across diverse human cell types predict tissue identity, transcription factor binding, and long-range interactions}},
volume = {23},
year = {2013}
}
@article{Javanmard2018a,
abstract = {Performing statistical inference in high-dimensional models is challenging because of the lack of precise information on the distribution of high-dimensional regularized estimators. Here, we consider linear regression in the high-dimensional regime p n and the Lasso estimator: we would like to perform inference on the parameter vector $\theta$∗ ∈ Rp. Important progress has been achieved in computing confidence intervals and p-values for single coordinates $\theta$i∗, i ∈ {\{}1, . . ., p{\}}. A key role in these new inferential methods is played by a certain debiased estimator $\theta$d. Earlier work establishes that, under suitable assumptions on the design matrix, the coordinates of $\theta$d are asymptotically Gaussian provided the true parameters vector $\theta$∗ is s0-sparse with s0 = o(n/log p). The condition s0 = o(n/log p) is considerably stronger than the one for consistent estimation, namely s0 = o(n/log p). In this paper, we consider Gaussian designs with known or unknown population covariance. When the covariance is known, we prove that the debiased estimator is asymptotically Gaussian under the nearly optimal condition s0 = o(n/(log p)2). The same conclusion holds if the population covariance is unknown but can be estimated sufficiently well. For intermediate regimes, we describe the trade-off between sparsity in the coefficients $\theta$∗, and sparsity in the inverse covariance of the design. We further discuss several applications of our results beyond high-dimensional inference. In particular, we propose a thresholded Lasso estimator that is minimax optimal up to a factor 1 + on(1) for i.i.d. Gaussian designs.},
archivePrefix = {arXiv},
arxivId = {1508.02757},
author = {Javanmard, Adel and Montanari, Andrea},
doi = {10.1214/17-AOS1630},
eprint = {1508.02757},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Javanmard, Montanari - 2018 - Debiasing the lasso Optimal sample size for Gaussian designs.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bias,Confidence intervals,High-dimensional regression,Hypothesis testing,Lasso,Sample size,Variance},
number = {6A},
pages = {2593--2622},
title = {{Debiasing the lasso: Optimal sample size for Gaussian designs}},
volume = {46},
year = {2018}
}
@article{Ebrahimpoor2019,
abstract = {Studying sets of genomic features is increasingly popular in genomics, proteomics and metabolomics since analyzing at set level not only creates a natural connection to biological knowledge but also offers more statistical power. Currently, there are two gene-set testing approaches, self-contained and competitive, both of which have their advantages and disadvantages, but neither offers the final solution. We introduce simultaneous enrichment analysis (SEA), a new approach for analysis of feature sets in genomics and other omics based on a new unified null hypothesis, which includes the self-contained and competitive null hypotheses as special cases. We employ closed testing using Simes tests to test this new hypothesis. For every feature set, the proportion of active features is estimated, and a confidence bound is provided. Also, for every unified null hypotheses, a {\$}P{\$}-value is calculated, which is adjusted for family-wise error rate. SEA does not need to assume that the features are independent. Moreover, users are allowed to choose the feature set(s) of interest after observing the data. We develop a novel pipeline and apply it on RNA-seq data of dystrophin-deficient mdx mice, showcasing the flexibility of the method. Finally, the power properties of the method are evaluated through simulation studies.},
author = {Ebrahimpoor, Mitra and Spitali, Pietro and Hettne, Kristina and Tsonaka, Roula and Goeman, Jelle},
doi = {10.1093/bib/bbz074},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Briefings in Bioinformatics/Ebrahimpoor et al. - 2019 - Simultaneous Enrichment Analysis of all Possible Gene-sets Unifying Self-Contained and Competitive Methods.pdf:pdf},
journal = {Briefings in Bioinformatics},
keywords = {Gene Ontology,Multiple testing,closed testing,competitive approach,genetics,gwas,multiple pathways,pathway analysis,self-contained approach,simultaneous inference,to-read},
mendeley-tags = {Gene Ontology,Multiple testing,closed testing,genetics,simultaneous inference,to-read},
number = {May},
pages = {1--11},
title = {{Simultaneous Enrichment Analysis of all Possible Gene-sets: Unifying Self-Contained and Competitive Methods}},
volume = {00},
year = {2019}
}
@article{Ignatiadis2019,
abstract = {In an empirical Bayes analysis, we use data from repeated sampling to imitate inferences made by an oracle Bayesian with extensive knowledge of the data-generating distribution. Existing results provide a comprehensive characterization of when and why empirical Bayes point estimates accurately recover oracle Bayes behavior. Here, we develop confidence intervals that provide asymptotic frequentist coverage of empirical Bayes estimands. Our intervals include an honest assessment of bias even in situations where empirical Bayes point estimates may converge very slowly. Applied to multiple testing situations, our approach provides flexible and practical confidence statements about the local false sign rate.},
archivePrefix = {arXiv},
arxivId = {1902.02774v1},
author = {Ignatiadis, Nikolaos and Wager, Stefan},
eprint = {1902.02774v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Ignatiadis, Wager - 2019 - Bias-Aware Confidence Intervals for Empirical Bayes Analysis.pdf:pdf},
journal = {arXiv},
keywords = {confidence intervals,empirical Bayes,to-skim,unpublished},
mendeley-tags = {confidence intervals,empirical Bayes,to-skim,unpublished},
title = {{Bias-Aware Confidence Intervals for Empirical Bayes Analysis}},
year = {2019}
}
@inproceedings{robbins1954one,
author = {Robbins, H},
booktitle = {The Annals of Mathematical Statistics},
keywords = {Empirical process,canonical},
mendeley-tags = {Empirical process,canonical},
number = {2},
pages = {409},
title = {{A one-sided confidence interval for an unknown distribution function}},
volume = {25},
year = {1954}
}
@inproceedings{RetR13,
author = {Rao, Nikhil and Cox, Christopher and Nowak, Rob and Rogers, Timothy T},
booktitle = {Advances in neural information processing systems},
keywords = {Lasso,multiple phenotypes},
mendeley-tags = {Lasso,multiple phenotypes},
pages = {2202--2210},
title = {{Sparse overlapping sets lasso for multitask learning and its application to {\{}fMRI{\}} analysis}},
year = {2013}
}
@article{SetS11,
author = {Supek, Fran and Bo{\v{s}}njak, Matko and {\v{S}}kunca, Nives and {\v{S}}muc, Tomislav},
journal = {PloS one},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
number = {7},
pages = {e21800},
publisher = {Public Library of Science},
title = {{REVIGO summarizes and visualizes long lists of gene ontology terms}},
volume = {6},
year = {2011}
}
@article{RetL11,
annote = {22174245},
author = {Reshef, D N and Reshef, Y A and Finucane, H K and Grossman, S R and McVean, G and Turnbaugh, P J and Lander, E S and Mitzenmacher, M and Sabeti, P C},
journal = {Science},
month = {dec},
pages = {1518--1524},
title = {{{\{}D{\}}etecting novel associations in large data sets}},
volume = {334},
year = {2011}
}
@book{EfronBook,
annote = {Empirical Bayes methods for estimation, testing, and
prediction},
author = {Efron, B},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Efron - 2010 - Large-scale inference.pdf:pdf},
keywords = {canonical,empirical Bayes},
mendeley-tags = {canonical,empirical Bayes},
publisher = {Cambridge University Press, Cambridge},
series = {Institute of Mathematical Statistics (IMS) Monographs},
title = {{Large-scale inference}},
volume = {1},
year = {2010}
}
@article{Mimitou2019,
abstract = {Multimodal single-cell assays provide high-resolution snapshots of complex cell populations, but are mostly limited to transcriptome plus an additional modality. Here, we describe expanded CRISPR-compatible cellular indexing of transcriptomes and epitopes by sequencing (ECCITE-seq) for the high-throughput characterization of at least five modalities of information from each single cell. We demonstrate application of ECCITE-seq to multimodal CRISPR screens with robust direct single-guide RNA capture and to clonotype-aware multimodal phenotyping of cancer samples.},
author = {Mimitou, Eleni P. and Cheng, Anthony and Montalbano, Antonino and Hao, Stephanie and Stoeckius, Marlon and Legut, Mateusz and Roush, Timothy and Herrera, Alberto and Papalexi, Efthymia and Ouyang, Zhengqing and Satija, Rahul and Sanjana, Neville E. and Koralov, Sergei B. and Smibert, Peter},
doi = {10.1038/s41592-019-0392-0},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Mimitou et al. - 2019 - Multiplexed detection of proteins, transcriptomes, clonotypes and CRISPR perturbations in single cells.pdf:pdf},
isbn = {4159201903},
issn = {15487105},
journal = {Nature Methods},
keywords = {CRISPR,single cell},
mendeley-tags = {CRISPR,single cell},
number = {5},
pages = {409--412},
pmid = {31011186},
publisher = {Springer US},
title = {{Multiplexed detection of proteins, transcriptomes, clonotypes and CRISPR perturbations in single cells}},
volume = {16},
year = {2019}
}
@article{Janssen2007,
author = {Janssen, Arnold and V{\"{o}}lker, Dominik},
doi = {10.1524/stnd.2007.25.1.41},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics {\&} Decisions/Janssen, V{\"{o}}lker - 2007 - Most powerful conditional tests.pdf:pdf},
issn = {0721-2631},
journal = {Statistics {\&} Decisions},
pages = {41--62},
title = {{Most powerful conditional tests}},
volume = {25},
year = {2007}
}
@article{Kichaev2019,
abstract = {Functional genomics data has the potential to increase GWAS power by identifying SNPs that have a higher prior probability of association. Here, we introduce a method that leverages polygenic functional enrichment to incorporate coding, conserved, regulatory, and LD-related genomic annotations into association analyses. We show via simulations with real genotypes that the method, functionally informed novel discovery of risk loci (FINDOR), correctly controls the false-positive rate at null loci and attains a 9{\%}–38{\%} increase in the number of independent associations detected at causal loci, depending on trait polygenicity and sample size. We applied FINDOR to 27 independent complex traits and diseases from the interim UK Biobank release (average N = 130K). Averaged across traits, we attained a 13{\%} increase in genome-wide significant loci detected (including a 20{\%} increase for disease traits) compared to unweighted raw p values that do not use functional data. We replicated the additional loci in independent UK Biobank and non-UK Biobank data, yielding a highly statistically significant replication slope (0.66–0.69) in each case. Finally, we applied FINDOR to the full UK Biobank release (average N = 416K), attaining smaller relative improvements (consistent with simulations) but larger absolute improvements, detecting an additional 583 GWAS loci. In conclusion, leveraging functional enrichment using our method robustly increases GWAS power.},
author = {Kichaev, Gleb and Bhatia, Gaurav and Loh, Po Ru and Gazal, Steven and Burch, Kathryn and Freund, Malika K. and Schoech, Armin and Pasaniuc, Bogdan and Price, Alkes L.},
doi = {10.1016/j.ajhg.2018.11.008},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Human Genetics/Kichaev et al. - 2019 - Leveraging Polygenic Functional Enrichment to Improve GWAS Power.pdf:pdf},
issn = {15376605},
journal = {American Journal of Human Genetics},
keywords = {GWAS,complex traits,functional genomics,structured multiple testing},
mendeley-tags = {GWAS,structured multiple testing},
number = {1},
pages = {65--75},
publisher = {ElsevierCompany.},
title = {{Leveraging Polygenic Functional Enrichment to Improve GWAS Power}},
url = {https://doi.org/10.1016/j.ajhg.2018.11.008},
volume = {104},
year = {2019}
}
@article{Lei2020,
abstract = {Evaluating treatment effect heterogeneity widely informs treatment decision making. At the moment, much emphasis is placed on the estimation of the conditional average treatment effect via flexible machine learning algorithms. While these methods enjoy some theoretical appeal in terms of consistency and convergence rates, they generally perform poorly in terms of uncertainty quantification. This is troubling since assessing risk is crucial for reliable decision-making in sensitive and uncertain environments. In this work, we propose a conformal inference-based approach that can produce reliable interval estimates for counterfactuals and individual treatment effects under the potential outcome framework. For completely randomized or stratified randomized experiments with perfect compliance, the intervals have guaranteed average coverage in finite samples regardless of the unknown data generating mechanism. For randomized experiments with ignorable compliance and general observational studies obeying the strong ignorability assumption, the intervals satisfy a doubly robust property which states the following: the average coverage is approximately controlled if either the propensity score or the conditional quantiles of potential outcomes can be estimated accurately. Numerical studies on both synthetic and real datasets empirically demonstrate that existing methods suffer from a significant coverage deficit even in simple models. In contrast, our methods achieve the desired coverage with reasonably short intervals.},
archivePrefix = {arXiv},
arxivId = {2006.06138},
author = {Lei, Lihua and Cand{\`{e}}s, Emmanuel J.},
eprint = {2006.06138},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Lei, Cand{\`{e}}s - 2020 - Conformal Inference of Counterfactuals and Individual Treatment Effects.pdf:pdf},
journal = {arXiv},
keywords = {causality,conformal prediction,to-read},
mendeley-tags = {causality,conformal prediction,to-read},
title = {{Conformal Inference of Counterfactuals and Individual Treatment Effects}},
url = {http://arxiv.org/abs/2006.06138},
year = {2020}
}
@article{Rosenman2018,
archivePrefix = {arXiv},
arxivId = {1804.07863v2},
author = {Rosenman, Evan and Baiocchi, Michael and Banack, Hailey and Owen, Art B.},
eprint = {1804.07863v2},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Rosenman et al. - 2018 - Propensity Score Methods for Merging Observational and Experimental Datasets.pdf:pdf},
journal = {arXiv},
keywords = {causality,to-skim,unpublished},
mendeley-tags = {causality,to-skim,unpublished},
title = {{Propensity Score Methods for Merging Observational and Experimental Datasets}},
year = {2018}
}
@article{BastiaanHolwerda2013,
abstract = {CTCF has it all. The transcription factor binds to tens of thousands of genomic sites, some tissue-specific, others ultra-conserved. It can act as a transcriptional activator, repressor and insulator, and it can pause transcription. CTCF binds at chromatin domain boundaries, at enhancers and gene promoters, and inside gene bodies. It can attract many other transcription factors to chromatin, including tissue-specific transcriptional activators, repressors, cohesin and RNA polymerase II, and it forms chromatin loops. Yet, or perhaps therefore, CTCF's exact function at a given genomic site is unpredictable. It appears to be determined by the associated transcription factors, by the location of the binding site relative to the transcriptional start site of a gene, and by the site's engagement in chromatin loops with other CTCF-binding sites, enhancers or gene promoters. Here, we will discuss genome-wide features of CTCF binding events, as well as locus-specific functions of this remarkable transcription factor.},
author = {{Bastiaan Holwerda}, Sjoerd Johannes and de Laat, Wouter},
doi = {10.1098/rstb.2012.0369},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Philosophical Transactions of the Royal Society B Biological Sciences/Bastiaan Holwerda, de Laat - 2013 - CTCF The protein, the binding partners, the binding sites and their chromatin loops.pdf:pdf},
issn = {14712970},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {CTCF,Chromatin loops,Cohesin,Kathryn,Nuclear organization,Transcription,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {1620},
title = {{CTCF: The protein, the binding partners, the binding sites and their chromatin loops}},
volume = {368},
year = {2013}
}
@article{LN10,
author = {Liang, Kun and Nettleton, Dan},
doi = {10.1198/jasa.2010.tm10195},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Gene Ontology,Multiple testing},
mendeley-tags = {Gene Ontology,Multiple testing},
number = {492},
pages = {1444--1454},
title = {{A hidden {\{}M{\}}arkov model approach to testing multiple hypotheses on a tree-transformed gene ontology graph}},
url = {https://doi.org/10.1198/jasa.2010.tm10195},
volume = {105},
year = {2010}
}
@article{XCS11,
author = {Xu, Lizhen and Craiu, Radu and Sun, Lei},
journal = {The Annals of Applied Statistics},
number = {1},
pages = {201--231},
title = {{Bayesian methods to overcome the winner's curse in genetic studies}},
volume = {5},
year = {2011}
}
@article{Tippens2019a,
abstract = {Distal enhancers remain one of the least understood regulatory elements with pivotal roles in development and disease. We used massively parallel reporter assays to perform functional comparisons of two leading enhancer models and find that gene-distal transcription start sites (TSSs) are robust predictors of enhancer activity with higher resolution and specificity than histone modifications. We show that active enhancer units are precisely delineated by active TSSs, validate that these boundaries are sufficient to capture enhancer function, and confirm that core promoter sequences are required for this activity. Finally, we assay pairs of adjacent units and find that their cumulative activity is best predicted by the strongest unit within the pair. Synthetic fusions of enhancer units demonstrate that adjacency imposes winner-takes-all logic, revealing a simple design for a maximum-activity filter of enhancer unit outputs. Together, our results define fundamental enhancer units and a principle of non-cooperativity between adjacent units.},
author = {Tippens, Nathaniel Dixon and Liang, Jin and Leung, King Y and Ozer, Abdullah and Booth, James G and Lis, John and Yu, Haiyuan},
doi = {10.1101/818849},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Tippens et al. - 2019 - Transcription imparts architecture, function, and logic to enhancer units.pdf:pdf},
journal = {bioRxiv},
pages = {818849},
title = {{Transcription imparts architecture, function, and logic to enhancer units}},
url = {https://www.biorxiv.org/content/10.1101/818849v1},
year = {2019}
}
@article{Bayati2012,
abstract = {We consider the problem of learning a coefficient vector x 0 ∈ ℝ N from noisy linear observation y = Ax 0 + w ∈ ℝ n. In many contexts (ranging from model selection to image processing), it is desirable to construct a sparse estimator x̂. In this case, a popular approach consists in solving an ℓ 1 -penalized least-squares problem known as the LASSO or basis pursuit denoising. For sequences of matrices of increasing dimensions,with independent Gaussian entries, we prove that the normalized risk of the LASSO converges to a limit, and we obtain an explicit expression for this limit. Our result is the first rigorous derivation of an explicit formula for the asymptotic mean square error of the LASSO for random instances. The proof technique is based on the analysis of AMP, a recently developed efficient algorithm, that is inspired from graphical model ideas. Simulations on real data matrices suggest that our results can be relevant in a broad array of practical applications. {\textcopyright} 2006 IEEE.},
archivePrefix = {arXiv},
arxivId = {1008.2581},
author = {Bayati, Mohsen and Montanari, Andrea},
doi = {10.1109/TIT.2011.2174612},
eprint = {1008.2581},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/IEEE Transactions on Information Theory/Bayati, Montanari - 2012 - The LASSO risk for Gaussian matrices(2).pdf:pdf},
issn = {00189448},
journal = {IEEE Transactions on Information Theory},
keywords = {Compressed sensing,graphical models,message passing algorithms,random matrix theory,state evolution,statistical learning},
number = {4},
pages = {1997--2017},
publisher = {IEEE},
title = {{The LASSO risk for Gaussian matrices}},
volume = {58},
year = {2012}
}
@article{Trynka2017,
abstract = {High-resolution maps of enhancer–promoter interactions in rare primary human T cell subsets and coronary artery smooth muscle cells link variants associated with autoimmune and cardiovascular diseases to target genes. This represents an important step forward for mapping genes involved in complex diseases.},
author = {Trynka, Gosia},
doi = {10.1038/ng.3982},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Trynka - 2017 - Enhancers looping to target genes.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {11},
pages = {1564--1565},
publisher = {Nature Publishing Group},
title = {{Enhancers looping to target genes}},
url = {http://dx.doi.org/10.1038/ng.3982},
volume = {49},
year = {2017}
}
@article{LetR01,
abstract = {Haplotype analysis of disease chromosomes can help identify probable historical recombination events and localize disease mutations. Most available analyses use only marginal and pairwise allele frequency information. We have developed a Bayesian framework that utilizes full haplotype information to overcome various complications such as multiple founders, unphased chromosomes, data contamination, and incomplete marker data. A stochastic model is used to describe the dependence structure among several variables characterizing the observed haplotypes, for example, the ancestral haplotypes and their ages, mutation rate, recombination events, and the location of the disease mutation. An efficient Markov chain Monte Carlo algorithm was developed for computing the estimates of the quantities of interest. The method is shown to perform well in both real data sets (cystic fibrosis data and Friedreich ataxia data) and simulated data sets. The program that implements the proposed method, BLADE, as well as the two real datasets, can be obtained from http://www.fas.harvard.edu/$\backslash${\~{}}junliu/TechRept/01folder/diseq{\_}prog.tar.gz.},
annote = {11591648},
author = {Liu, J S and Sabatti, C and Teng, J and Keats, B J and Risch, N},
doi = {10.1101/gr.194801},
journal = {Genome Res},
keywords = {linkage disequilibrium},
mendeley-tags = {linkage disequilibrium},
number = {10},
pages = {1716--1724},
title = {{Bayesian analysis of haplotypes for linkage disequilibrium mapping}},
url = {http://www.hubmed.org/display.cgi?uids=11591648},
volume = {11},
year = {2001}
}
@article{Information2011a,
author = {Efron, Bradley and Hinkley, David V},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Efron, Hinkley - 1978 - Assessing the Accuracy of the Maximum Likelihood Estimator Observed Versus Expected Fisher Information.pdf:pdf},
journal = {Biometrika},
number = {3},
pages = {457--482},
title = {{Assessing the Accuracy of the Maximum Likelihood Estimator: Observed Versus Expected Fisher Information}},
url = {http://www.stat.tamu.edu/{~}suhasini/teaching613/expected{\_}observed{\_}information78.pdf},
volume = {65},
year = {1978}
}
@article{Lei2019,
abstract = {Cross-validation is one of the most popular model and tuning parameter selection methods in statistics and machine learning. Despite its wide applicability, traditional cross-validation methods tend to overfit, due to the ignorance of the uncertainty in the testing sample. We develop a novel statistically principled inference tool based on cross-validation that takes into account the uncertainty in the testing sample. This method outputs a set of highly competitive candidate models containing the optimal one with guaranteed probability. As a consequence, our method can achieve consistent variable selection in a classical linear regression setting, for which existing cross-validation methods require unconventional split ratios. When used for tuning parameter selection, the method can provide an alternative trade-off between prediction accuracy and model interpretability than existing variants of cross-validation. We demonstrate the performance of the proposed method in several simulated and real data examples. Supplemental materials for this article can be found online.},
archivePrefix = {arXiv},
arxivId = {1703.07904},
author = {Lei, Jing},
doi = {10.1080/01621459.2019.1672556},
eprint = {1703.07904},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Lei - 2019 - Cross-Validation With Confidence.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Cross-validation,Hypothesis testing,Model selection,Overfitting,Tuning parameter selection},
number = {0},
pages = {1--53},
publisher = {Taylor {\&} Francis},
title = {{Cross-Validation With Confidence}},
url = {https://doi.org/10.1080/01621459.2019.1672556},
volume = {0},
year = {2019}
}
@article{Visscher2012,
abstract = {The past five years have seen many scientific and biological discoveries made through the experimental design of genome-wide association studies (GWASs). These studies were aimed at detecting variants at genomic loci that are associated with complex traits in the population and, in particular, at detecting associations between common single-nucleotide polymorphisms (SNPs) and common diseases such as heart disease, diabetes, auto-immune diseases, and psychiatric disorders. We start by giving a number of quotes from scientists and journalists about perceived problems with GWASs. We will then briefly give the history of GWASs and focus on the discoveries made through this experimental design, what those discoveries tell us and do not tell us about the genetics and biology of complex traits, and what immediate utility has come out of these studies. Rather than giving an exhaustive review of all reported findings for all diseases and other complex traits, we focus on the results for auto-immune diseases and metabolic diseases. We return to the perceived failure or disappointment about GWASs in the concluding section. {\textcopyright} 2012 The American Society of Human Genetics.},
author = {Visscher, Peter M. and Brown, Matthew A. and McCarthy, Mark I. and Yang, Jian},
doi = {10.1016/j.ajhg.2011.11.029},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Human Genetics/Visscher et al. - 2012 - Five years of GWAS discovery.pdf:pdf},
issn = {00029297},
journal = {American Journal of Human Genetics},
number = {1},
pages = {7--24},
pmid = {22243964},
publisher = {The American Society of Human Genetics},
title = {{Five years of GWAS discovery}},
url = {http://dx.doi.org/10.1016/j.ajhg.2011.11.029},
volume = {90},
year = {2012}
}
@article{WetH10,
annote = {20601685},
author = {Wang, K and Li, M and Hakonarson, H},
journal = {Nucleic Acids Research},
keywords = {functional annotation,genetics},
mendeley-tags = {functional annotation,genetics},
month = {sep},
pages = {e164},
title = {{{\{}A{\}}{\{}N{\}}{\{}N{\}}{\{}O{\}}{\{}V{\}}{\{}A{\}}{\{}R{\}}: functional annotation of genetic variants from high-throughput sequencing data}},
volume = {38},
year = {2010}
}
@techreport{Yu2010,
author = {Yu, Ping},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Yu - 2020 - Least Squares Estimation - Large-Sample Properties.pdf:pdf},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
title = {{Least Squares Estimation - Large-Sample Properties}},
year = {2020}
}
@article{Gandy2017a,
abstract = {Multiple hypothesis testing is widely used to evaluate scientific studies involving statistical tests. However, for many of these tests, p-values are not available and are thus often approximated using Monte Carlo tests such as permutation tests or bootstrap tests. This article presents a simple algorithm based on Thompson Sampling to test multiple hypotheses. It works with arbitrary multiple testing procedures, in particular with step-up and step-down procedures. Its main feature is to sequentially allocate Monte Carlo effort, generating more Monte Carlo samples for tests whose decisions are so far less certain. A simulation study demonstrates that for a low computational effort, the new approach yields a higher power and a higher degree of reproducibility of its results than previously suggested methods.},
author = {Gandy, Axel and Hahn, Georg},
doi = {10.1007/s11222-016-9656-z},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics and Computing/Gandy, Hahn - 2017 - QuickMMCTest quick multiple Monte Carlo testing.pdf:pdf},
issn = {15731375},
journal = {Statistics and Computing},
keywords = {Benjamini–Hochberg procedure,Bonferroni correction,Monte Carlo,Multiple hypothesis testing,Multiple testing,Thompson sampling},
mendeley-tags = {Monte Carlo,Multiple testing},
number = {3},
pages = {823--832},
publisher = {Springer US},
title = {{QuickMMCTest: quick multiple Monte Carlo testing}},
volume = {27},
year = {2017}
}
@article{Angermueller2016,
abstract = {We report scM{\&}T-seq, a method for parallel single-cell genome-wide methylome and transcriptome sequencing that allows for the discovery of associations between transcriptional and epigenetic variation. Profiling of 61 mouse embryonic stem cells confirmed known links between DNA methylation and transcription. Notably, the method revealed previously unrecognized associations between heterogeneously methylated distal regulatory elements and transcription of key pluripotency genes.},
author = {Angermueller, Christof and Clark, Stephen J. and Lee, Heather J. and Macaulay, Iain C. and Teng, Mabel J. and Hu, Tim Xiaoming and Krueger, Felix and Smallwood, S{\'{e}}bastien A. and Ponting, Chris P. and Voet, Thierry and Kelsey, Gavin and Stegle, Oliver and Reik, Wolf},
doi = {10.1038/nmeth.3728},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Angermueller et al. - 2016 - Parallel single-cell sequencing links transcriptional and epigenetic heterogeneity.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {multi-omics},
mendeley-tags = {multi-omics},
number = {3},
pages = {229--232},
pmid = {26752769},
title = {{Parallel single-cell sequencing links transcriptional and epigenetic heterogeneity}},
volume = {13},
year = {2016}
}
@article{amgen,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/22460880{\}}{\{}22460880{\}}},
author = {Begley, C G and Ellis, L M},
journal = {Nature},
month = {mar},
number = {7391},
pages = {531--533},
title = {{{\{}D{\}}rug development: {\{}R{\}}aise standards for preclinical cancer research}},
volume = {483},
year = {2012}
}
@article{Javanmard2018,
abstract = {Performing statistical inference in high-dimensional models is challenging because of the lack of precise information on the distribution of high-dimensional regularized estimators. Here, we consider linear regression in the high-dimensional regime p n and the Lasso estimator: we would like to perform inference on the parameter vector $\theta$ * ∈ R p. Important progress has been achieved in computing confidence intervals and p-values for single coordinates $\theta$ * i , i ∈ {\{}1,. .. , p{\}}. A key role in these new inferential methods is played by a certain debiased estima-tor $\theta$ d. Earlier work establishes that, under suitable assumptions on the design matrix, the coordinates of $\theta$ d are asymptotically Gaussian provided the true parameters vector $\theta$ * is s 0-sparse with s 0 = o(√ n/ log p). The condition s 0 = o(√ n/ log p) is considerably stronger than the one for consistent estimation, namely s 0 = o(n/ log p). In this paper, we consider Gaussian designs with known or unknown population covariance. When the covariance is known, we prove that the debiased estimator is asymptotically Gaussian under the nearly optimal condition s 0 = o(n/(log p) 2). The same conclusion holds if the population covariance is unknown but can be estimated sufficiently well. For intermediate regimes, we describe the trade-off between sparsity in the coefficients $\theta$ * , and sparsity in the inverse covariance of the design. We further discuss several applications of our results beyond high-dimensional inference. In particular, we propose a thresholded Lasso estimator that is minimax optimal up to a factor 1 + o n (1) for i.i.d. Gaussian designs.},
author = {Javanmard, Adel and Montanari, Andrea},
doi = {10.1214/17-AOS1630},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Javanmard, Montanari - 2018 - DEBIASING THE LASSO OPTIMAL SAMPLE SIZE FOR GAUSSIAN DESIGNS.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {Lasso,Multiple testing,bias and variance,confidence intervals,debiased lasso,high-dimensional regression,hypothesis testing,sample size},
mendeley-tags = {Lasso,Multiple testing,confidence intervals,debiased lasso,high-dimensional regression,sample size},
number = {6A},
pages = {2593--2622},
title = {{DEBIASING THE LASSO: OPTIMAL SAMPLE SIZE FOR GAUSSIAN DESIGNS}},
url = {https://doi.org/10.1214/17-AOS1630},
volume = {46},
year = {2018}
}
@article{LK95,
abstract = {Genetic studies are under way for many complex traits, spurred by the recent feasibility of whole genome scans. Clear guidelines for the interpretation of linkage results are needed to avoid a flood of false positive claims. At the same time, an overly cautious approach runs the risk of causing true hints of linkage to be missed. We address this problem by proposing specific standards designed to maintain rigor while also promoting communication.},
annote = {7581446},
author = {Lander, E and Kruglyak, L},
journal = {Nature Genetics},
pages = {241--247},
title = {{{\{}Genetic{\}} Dissection of Complex Traits: Guidelines for Interpreting and Reporting Linkage Results}},
volume = {11},
year = {1995}
}
@article{Rosenbaum2005,
author = {Rosenbaum, Paul R},
doi = {10.1198/000313005X42831},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The American Statistician/Rosenbaum - 2005 - Heterogeneity and Causality Unit Heterogeneity and Design Sensitivity in Observational Studies.pdf:pdf},
journal = {The American Statistician},
keywords = {causal effect,causality,observational studies,observational study,randomization inference,randomized experiment,s signed rank test,sensitivity analysis,wilcoxon},
mendeley-tags = {causality,observational studies},
number = {2},
pages = {147--152},
title = {{Heterogeneity and Causality: Unit Heterogeneity and Design Sensitivity in Observational Studies}},
volume = {59},
year = {2005}
}
@article{Storey04,
author = {Storey, John D. and Taylor, Jonathan E. and Siegmund, David},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society Series B (Statistical Methodology)/Storey, Taylor, Siegmund - 2004 - Strong control, conservative point estimation and simultaneous conservative consistency of false disco.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,canonical,null proportion adaptivity},
mendeley-tags = {FDR,canonical,null proportion adaptivity},
number = {1},
pages = {187--205},
title = {{Strong control, conservative point estimation and simultaneous conservative consistency of false discovery rates: a unified approach}},
volume = {66},
year = {2004}
}
@article{KetA06,
abstract = {Traditional genetic mapping has largely focused on the identification of loci affecting one, or at most a few, complex traits. Microarrays allow for measurement of thousands of gene expression abundances, themselves complex traits, and a number of recent investigations have considered these measurements as phenotypes in mapping studies. Combining traditional quantitative trait loci (QTL) mapping methods with microarray data is a powerful approach with demonstrated utility in a number of recent biological investigations. These expression quantitative trait loci (eQTL) studies are similar to traditional QTL studies, as a main goal is to identify the genomic locations to which the expression traits are linked. However, eQTL studies probe thousands of expression transcripts; and as a result, standard multi-trait QTL mapping methods, designed to handle at most tens of traits, do not directly apply. One possible approach is to use single-trait QTL mapping methods to analyze each transcript separately. This leads to an increased number of false discoveries, as corrections for multiple tests across transcripts are not made. Similarly, the repeated application, at each marker, of methods for identifying differentially expressed transcripts suffers from multiple tests across markers. Here, we demonstrate the deficiencies of these approaches and propose a mixture over markers (MOM) model that shares information across both markers and transcripts. The utility of all methods is evaluated using simulated data as well as data from an F(2) mouse cross in a study of diabetes. Results from simulation studies indicate that the MOM model is best at controlling false discoveries, without sacrificing power. The MOM model is also the only one capable of finding two genome regions previously shown to be involved in diabetes.},
annote = {16542225},
author = {Kendziorski, C M and Chen, M and Yuan, M and Lan, H and Attie, A D},
journal = {Biometrics},
pages = {19--27},
title = {{{\{}Statistical{\}} Methods for Expression Quantitative Trait loci {\{}(eQTL){\}} Mapping}},
volume = {62},
year = {2006}
}
@article{Romano2019,
abstract = {Conformal prediction is a technique for constructing prediction intervals that attain valid coverage in finite samples, without making distributional assumptions. Despite this appeal, existing conformal methods can be unnecessarily conservative because they form intervals of constant or weakly varying length across the input space. In this paper we propose a new method that is fully adaptive to heteroscedasticity. It combines conformal prediction with classical quantile regression, inheriting the advantages of both. We establish a theoretical guarantee of valid coverage, supplemented by extensive experiments on popular regression datasets. We compare the efficiency of conformalized quantile regression to other conformal methods, showing that our method tends to produce shorter intervals.},
archivePrefix = {arXiv},
arxivId = {1905.03222},
author = {Romano, Yaniv and Patterson, Evan and Cand{\`{e}}s, Emmanuel J.},
eprint = {1905.03222},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Romano, Patterson, Cand{\`{e}}s - 2019 - Conformalized Quantile Regression(2).pdf:pdf},
journal = {arXiv},
keywords = {conformal prediction,to-skim},
mendeley-tags = {conformal prediction,to-skim},
title = {{Conformalized Quantile Regression}},
url = {http://arxiv.org/abs/1905.03222},
year = {2019}
}
@article{Rao2014,
abstract = {We use in situ Hi-C to probe the 3D architecture of genomes, constructing haploid and diploid maps of nine cell types. The densest, in human lymphoblastoid cells, contains 4.9 billion contacts, achieving 1 kb resolution. We find that genomes are partitioned into contact domains (median length, 185 kb), which are associated with distinct patterns of histone marks and segregate into six subcompartments. We identify ∼10,000 loops. These loops frequently link promoters and enhancers, correlate with gene activation, and show conservation across cell types and species. Loop anchors typically occur at domain boundaries and bind CTCF. CTCF sites at loop anchors occur predominantly ({\textgreater}90{\%}) in a convergent orientation, with the asymmetric motifs "facing" one another. The inactive X chromosome splits into two massive domains and contains large loops anchored at CTCF-binding repeats. PaperFlick},
author = {Rao, Suhas S.P. and Huntley, Miriam H. and Durand, Neva C. and Stamenova, Elena K. and Bochkov, Ivan D. and Robinson, James T. and Sanborn, Adrian L. and Machol, Ido and Omer, Arina D. and Lander, Eric S. and Aiden, Erez Lieberman},
doi = {10.1016/j.cell.2014.11.021},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Rao et al. - 2014 - A 3D map of the human genome at kilobase resolution reveals principles of chromatin looping.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {HI-C,Kathryn,gene-enhancer},
mendeley-tags = {HI-C,Kathryn,gene-enhancer},
number = {7},
pages = {1665--1680},
pmid = {25497547},
publisher = {Elsevier Inc.},
title = {{A 3D map of the human genome at kilobase resolution reveals principles of chromatin looping}},
volume = {159},
year = {2014}
}
@article{JM14b,
author = {Javanmard, Adel and Montanari, Andrea},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/IEEE Transactions on Information Theory/Javanmard, Montanari - 2014 - Hypothesis testing in high-dimensional regression under the gaussian random design model Asymptotic theory.pdf:pdf},
journal = {IEEE Transactions on Information Theory},
number = {10},
pages = {6522--6554},
publisher = {IEEE},
title = {{Hypothesis testing in high-dimensional regression under the gaussian random design model: Asymptotic theory}},
volume = {60},
year = {2014}
}
@article{Azriel2019,
abstract = {Consider a high-dimensional linear regression problem, where the number of covariates is larger than the number of observations and the interest is in estimating the conditional variance of the response variable given the covariates. A conditional and an unconditional framework are considered, where conditioning is with respect to the covariates, which are ancillary to the parameter of interest. In recent papers, a consistent estimator was developed in the unconditional framework when the marginal distribution of the covariates is normal with known mean and variance. In the present work, a certain Bayesian hypothesis test is formulated under the conditional framework, and it is shown that the Bayes risk is a constant. This implies that no consistent estimator exists in the conditional framework. However, when the marginal distribution of the covariates is normal, the conditional error of the above consistent estimator converges to zero, with probability converging to one. It follows that even in the conditional setting, information about the marginal distribution of an ancillary statistic may have a significant impact on statistical inference. The practical implication in the context of high-dimensional regression models is that additional observations where only the covariates are given are potentially very useful and should not be ignored. This finding is most relevant to semi-supervised learning problems where covariate information is easy to obtain.},
author = {Azriel, D},
doi = {10.1093/biomet/asz015},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Azriel - 2019 - The conditionality principle in high-dimensional regression.pdf:pdf},
journal = {Biometrika},
keywords = {Ancillary statistic,Conditionality principle,High-dimensional regression,high-dimensional regression,model-X},
mendeley-tags = {high-dimensional regression,model-X},
number = {3},
pages = {702--707},
title = {{The conditionality principle in high-dimensional regression}},
url = {https://academic.oup.com/biomet/article-abstract/106/3/702/5491755},
volume = {106},
year = {2019}
}
@article{LetW11,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21156729{\}}{\{}21156729{\}}},
author = {Li, J and Das, K and Fu, G and Li, R and Wu, R},
journal = {Bioinformatics},
keywords = {GWAS,Lasso},
mendeley-tags = {GWAS,Lasso},
month = {feb},
number = {4},
pages = {516--523},
title = {{{\{}T{\}}he {\{}B{\}}ayesian lasso for genome-wide association studies}},
volume = {27},
year = {2011}
}
@article{AetE00,
author = {Ashburner, Michael and Ball, Catherine A and Blake, Judith A and Botstein, David and Butler, Heather and Cherry, J Michael and Davis, Allan P and Dolinski, Kara and Dwight, Selina S and Eppig, Janan T},
journal = {Nature Genetics},
keywords = {Gene Ontology,canonical,genetics},
mendeley-tags = {Gene Ontology,canonical,genetics},
number = {1},
pages = {25},
publisher = {Nature Publishing Group},
title = {{Gene Ontology: tool for the unification of biology}},
volume = {25},
year = {2000}
}
@article{KetR15,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26092718{\}}{\{}26092718{\}}},
author = {Kvale, M N and Hesselson, S and Hoffmann, T J and Cao, Y and Chan, D and Connell, S and Croen, L A and Dispensa, B P and Eshragh, J and Finn, A and Gollub, J and Iribarren, C and Jorgenson, E and Kushi, L H and Lao, R and Lu, Y and Ludwig, D and Mathauda, G K and McGuire, W B and Mei, G and Miles, S and Mittman, M and Patil, M and Quesenberry, C P and Ranatunga, D and Rowell, S and Sadler, M and Sakoda, L C and Shapero, M and Shen, L and Shenoy, T and Smethurst, D and Somkin, C P and {Van Den Eeden}, S K and Walter, L and Wan, E and Webster, T and Whitmer, R A and Wong, S and Zau, C and Zhan, Y and Schaefer, C and Kwok, P Y and Risch, N},
journal = {Genetics},
month = {aug},
number = {4},
pages = {1051--1060},
title = {{{\{}G{\}}enotyping {\{}I{\}}nformatics and {\{}Q{\}}uality {\{}C{\}}ontrol for 100,000 {\{}S{\}}ubjects in the {\{}G{\}}enetic {\{}E{\}}pidemiology {\{}R{\}}esearch on {\{}A{\}}dult {\{}H{\}}ealth and {\{}A{\}}ging ({\{}G{\}}{\{}E{\}}{\{}R{\}}{\{}A{\}}) {\{}C{\}}ohort}},
volume = {200},
year = {2015}
}
@article{Lu2019,
author = {Lu, Leina and Liu, Xiaoxiao and Huang, Wei-Kai and Giusti-Rodr{\'{i}}guez, Paola and Cui, Jian and Zhang, Shanshan and Xu, Wanying and Wen, Zhexing and Ma, Shufeng and Rosen, Jonathan D and Xu, Zheng and Bartels, Cynthia and Kawaguchi, Riki and Hu, Ming and Scacheri, Peter and Rong, Zhili and Li, Yun and Sullivan, Patrick F and Song, Hongjun and Ming, Guo-Li and Li, Yan and Jin, Fulai},
doi = {10.1101/744540},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/biorXiv/Lu et al. - 2019 - Robust Hi-C chromatin loop maps in human neurogenesis and brain tissues at high-resolution.pdf:pdf},
journal = {biorXiv},
keywords = {HI-C,genetics},
mendeley-tags = {HI-C,genetics},
title = {{Robust Hi-C chromatin loop maps in human neurogenesis and brain tissues at high-resolution}},
url = {http://dx.doi.org/10.1101/744540},
year = {2019}
}
@article{SetP12,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/22138362{\}}{\{}22138362{\}}},
author = {{San Lucas}, F A and Wang, G and Scheet, P and Peng, B},
journal = {Bioinformatics},
month = {feb},
pages = {421--422},
title = {{{\{}I{\}}ntegrated annotation and analysis of genetic variants from next-generation sequencing studies with variant tools}},
volume = {28},
year = {2012}
}
@article{VetZ15,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26430803{\}}{\{}26430803{\}}},
author = {Vilhjalmsson and [...] and Zheng, W},
journal = {American Journal of Human Genetics},
keywords = {genetics,polygenic risk scores},
mendeley-tags = {genetics,polygenic risk scores},
month = {oct},
number = {4},
pages = {576--592},
title = {{{\{}M{\}}odeling {\{}L{\}}inkage {\{}D{\}}isequilibrium {\{}I{\}}ncreases {\{}A{\}}ccuracy of {\{}P{\}}olygenic {\{}R{\}}isk {\{}S{\}}cores}},
volume = {97},
year = {2015}
}
@book{VDV1998,
address = {Cambridge},
author = {van der Vaart, A. W.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Vaart - 1998 - Asymptotic Statistics.pdf:pdf},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
publisher = {Cambridge University Press},
title = {{Asymptotic Statistics}},
year = {1998}
}
@article{ST12,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26257503{\}}{\{}26257503{\}}},
author = {Simon, N and Tibshirani, R},
journal = {Stat Sin},
keywords = {groups,high-dimensional regression},
mendeley-tags = {groups,high-dimensional regression},
month = {jul},
number = {3},
pages = {983--1001},
title = {{Standardization and the group lasso penalty}},
volume = {22},
year = {2012}
}
@article{SH16,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26866487{\}}{\{}26866487{\}}},
author = {Santorico, S A and Hendricks, A E},
journal = {BMC Genet.},
pages = {6},
title = {{{\{}P{\}}rogress in methods for rare variant association}},
volume = {17 Suppl 2},
year = {2016}
}
@article{Howey2019,
abstract = {Mendelian randomization (MR) is an increasingly popular causal inference tool used in genetic epidemiology. But it can have limitations for evaluating simultaneous causal relationships in complex data sets that include, for example, multiple genetic predictors and multiple potential risk factors associated with the same genetic variant. Here we use real and simulated data to investigate Bayesian network analysis (BN) as an alternative approach. A Bayesian network describes the conditional dependencies/ independencies of variables using a graphical model (a directed acyclic graph) and its accompanying joint probability. In real data, we found BN inferred simultaneous causal relationships that confirmed the individual causal relationships suggested by bi-directional MR, while allowing for potential horizontal pleiotropy (that violates MR assumptions). In simulated data, BN with two directional anchors (mimicking genetic instruments) had greater power for a fixed type 1 error than bi-directional MR, while BN with a single directional anchor performed better than or as well as bi-directional MR. Both BN and MR could be adversely affected by violations of their underlying assumptions (such as genetic confounding due to unmeasured horizontal pleiotropy). BN with no directional anchor generated inference that was no better than by chance, emphasizing the importance of directional anchors in BN (as in MR). Under highly pleiotropic simulated scenarios, BN outperformed both MR (and its recent extensions) and two recently-proposed alternative approaches: a multi-SNP mediation intersection-union test (SMUT) and a latent causal variable (LCV) test. We conclude that BN is a useful complementary method to MR for performing causal inference in complex data sets such as those generated from modern “omics” technologiesAuthor summary Mendelian randomization (MR) is a popular method for inferring causal relationships between variables (such as between an intermediate biological factor and a disease outcome). However, MR relies on a number of assumptions that may be hard to verify, and it is not ideally suited to comparing different underlying causal scenarios. Here we propose the use of an alternative method, Bayesian network analysis (BN), as a complementary tool to MR. We use real and simulated data to investigate the performance of MR, BN and several other recently-proposed methods, and find that BN performs as well as, or better than, the other methods, particularly under complex scenarios. We conclude that BN is a useful complementary method to MR for performing causal inference in complex data sets.},
author = {Howey, Richard and Shin, So-Youn and Relton, Caroline and Smith, George Davey and Cordell, Heather J},
doi = {10.1101/639864},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Howey et al. - 2019 - Bayesian network analysis complements Mendelian randomization approaches for exploratory analysis of causal relati.pdf:pdf},
journal = {bioRxiv},
keywords = {Mendelian randomization,to-skim},
mendeley-tags = {Mendelian randomization,to-skim},
title = {{Bayesian network analysis complements Mendelian randomization approaches for exploratory analysis of causal relationships in complex data}},
url = {http://biorxiv.org/content/early/2019/05/15/639864.abstract},
year = {2019}
}
@article{H90,
author = {Helland, I},
journal = {Scandinavian Journal of Statistics},
pages = {97--114},
title = {{Partial Least-Squares Regression and Statistical-Models}},
volume = {17},
year = {1990}
}
@article{Egami2019a,
abstract = {We study causal interaction in factorial experiments, in which several factors, each with multiple levels, are randomized to form a large number of possible treatment combinations. Examples of such experiments include conjoint analysis, which is often used by social scientists to analyze multidimensional preferences in a population. To characterize the structure of causal interaction in factorial experiments, we propose a new causal interaction effect, called the average marginal interaction effect (AMIE). Unlike the conventional interaction effect, the relative magnitude of the AMIE does not depend on the choice of baseline conditions, making its interpretation intuitive even for higher-order interactions. We show that the AMIE can be nonparametrically estimated using ANOVA regression with weighted zero-sum constraints. Because the AMIEs are invariant to the choice of baseline conditions, we directly regularize them by collapsing levels and selecting factors within a penalized ANOVA framework. This regularized estimation procedure reduces false discovery rate and further facilitates interpretation. Finally, we apply the proposed methodology to the conjoint analysis of ethnic voting behavior in Africa and find clear patterns of causal interaction between politicians' ethnicity and their prior records. The proposed methodology is implemented in an open source software package. Supplementary materials for this article, including a standardized description of the materials available for reproducing the work, are available as an online supplement.},
author = {Egami, Naoki and Imai, Kosuke},
doi = {10.1080/01621459.2018.1476246},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Egami, Imai - 2019 - Causal Interaction in Factorial Experiments Application to Conjoint Analysis.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {ANOVA,Causal inference,Heterogenous treatment effects,Interaction effects,Randomized experiments,Regularization,interactions},
mendeley-tags = {interactions},
number = {526},
pages = {529--540},
title = {{Causal Interaction in Factorial Experiments: Application to Conjoint Analysis}},
volume = {114},
year = {2019}
}
@article{MG15,
author = {Meijer, Rosa J. and Goeman, Jelle J.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Briefings in Bioinformatics/Meijer, Goeman - 2015 - Multiple testing of gene sets from Gene Ontology possibilities and pitfalls.pdf:pdf},
journal = {Briefings in Bioinformatics},
keywords = {FWER,Gene Ontology,Multiple testing},
mendeley-tags = {FWER,Gene Ontology,Multiple testing},
number = {5},
pages = {808--818},
publisher = {Oxford University Press},
title = {{Multiple testing of gene sets from Gene Ontology: possibilities and pitfalls}},
volume = {17},
year = {2015}
}
@article{Jia2017,
abstract = {Background: Clustered regularly-interspaced short palindromic repeats (CRISPR) screens are usually implemented in cultured cells to identify genes with critical functions. Although several methods have been developed or adapted to analyze CRISPR screening data, no single specific algorithm has gained popularity. Thus, rigorous procedures are needed to overcome the shortcomings of existing algorithms. Methods: We developed a Permutation-Based Non-Parametric Analysis (PBNPA) algorithm, which computes p-values at the gene level by permuting sgRNA labels, and thus it avoids restrictive distributional assumptions. Although PBNPA is designed to analyze CRISPR data, it can also be applied to analyze genetic screens implemented with siRNAs or shRNAs and drug screens. Results: We compared the performance of PBNPA with competing methods on simulated data as well as on real data. PBNPA outperformed recent methods designed for CRISPR screen analysis, as well as methods used for analyzing other functional genomics screens, in terms of Receiver Operating Characteristics (ROC) curves and False Discovery Rate (FDR) control for simulated data under various settings. Remarkably, the PBNPA algorithm showed better consistency and FDR control on published real data as well. Conclusions: PBNPA yields more consistent and reliable results than its competitors, especially when the data quality is low. R package of PBNPA is available at: https://cran.r-project.org/web/packages/PBNPA/.},
author = {Jia, Gaoxiang and Wang, Xinlei and Xiao, Guanghua},
doi = {10.1186/s12864-017-3938-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Genomics/Jia, Wang, Xiao - 2017 - A permutation-based non-parametric analysis of CRISPR screen data.pdf:pdf},
isbn = {1286401739},
issn = {14712164},
journal = {BMC Genomics},
keywords = {CRISPR,False discovery rate,Functional genomics,Kathryn,Multiple testing,Negative selection,Next generation sequencing,Positive selection,RNA interference,gene-enhancer},
mendeley-tags = {CRISPR,Kathryn,Multiple testing,gene-enhancer},
number = {1},
pages = {1--11},
publisher = {BMC Genomics},
title = {{A permutation-based non-parametric analysis of CRISPR screen data}},
volume = {18},
year = {2017}
}
@article{ZL07,
abstract = {Epistatic interactions among multiple genetic variants in the human genome may be important in determining individual susceptibility to common diseases. Although some existing computational methods for identifying genetic interactions have been effective for small-scale studies, we here propose a method, denoted 'bayesian epistasis association mapping' (BEAM), for genome-wide case-control studies. BEAM treats the disease-associated markers and their interactions via a bayesian partitioning model and computes, via Markov chain Monte Carlo, the posterior probability that each marker set is associated with the disease. Testing this on an age-related macular degeneration genome-wide association data set, we demonstrate that the method is significantly more powerful than existing approaches and that genome-wide case-control epistasis mapping with many thousands of markers is both computationally and statistically feasible.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/17721534{\}}{\{}17721534{\}}},
author = {Zhang, Y and Liu, J S},
doi = {10.1038/ng2110},
journal = {Nature Genetics},
number = {9},
pages = {1167--1173},
title = {{Bayesian inference of epistatic interactions in case-control studies}},
url = {http://www.hubmed.org/display.cgi?uids=17721534},
volume = {39},
year = {2007}
}
@article{HG18,
author = {Hemerik, Jesse and Goeman, Jelle J.},
doi = {10.1111/rssb.12238},
issn = {1369-7412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {Multiple testing,genetics,resampling},
mendeley-tags = {Multiple testing,genetics,resampling},
number = {1},
pages = {137--155},
title = {{False discovery proportion estimation by permutations: confidence for significance analysis of microarrays}},
url = {https://doi.org/10.1111/rssb.12238},
volume = {80},
year = {2018}
}
@article{NL17,
author = {Ning, Yang and Liu, Han},
journal = {The Annals of Statistics},
keywords = {confidence intervals,high-dimensional regression},
mendeley-tags = {confidence intervals,high-dimensional regression},
number = {1},
pages = {158--195},
publisher = {Institute of Mathematical Statistics},
title = {{A general theory of hypothesis tests and confidence regions for sparse high dimensional models}},
volume = {45},
year = {2017}
}
@inproceedings{Kusner2016,
abstract = {Causal inference deals with identifying which random variables “cause” or control other random variables. Recent advances on the topic of causal inference based on tools from statistical estimation and machine learning have resulted in practical algorithms for causal inference. Causal inference has the potential to have significant impact on medical research, prevention and control of diseases, and identifying factors that impact economic changes to name just a few. However, these promising applications for causal inference are often ones that involve sensitive or personal data of users that need to be kept private (e.g., medical records, personal finances, etc). Therefore, there is a need for the development of causal inference methods that preserve data privacy. We study the problem of inferring causality using the current, popular causal inference framework, the additive noise model (ANM) while simultaneously ensuring privacy of the users. Our framework provides differential privacy guarantees for a variety of ANM variants. We run extensive experiments, and demonstrate that our techniques are practical and easy to implement.},
archivePrefix = {arXiv},
arxivId = {1512.05469},
author = {Kusner, Matt J. and Sun, Yu and Sridharan, Karthik and Weinberger, Kilian Q.},
booktitle = {Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, AISTATS 2016},
eprint = {1512.05469},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the 19th International Conference on Artificial Intelligence and Statistics, AISTATS 2016/Kusner et al. - 2016 - Private causal inference.pdf:pdf},
keywords = {causality,error-in-variables,privacy},
mendeley-tags = {causality,error-in-variables,privacy},
pages = {1308--1317},
title = {{Private causal inference}},
volume = {51},
year = {2016}
}
@article{Javanmard2014,
abstract = {Fitting high-dimensional statistical models often requires the use of non-linear parameter estimation procedures. As a consequence, it is generally impossible to obtain an exact characterization of the probability distribution of the parameter estimates. This in turn implies that it is extremely challenging to quantify the uncertainty associated with a certain parameter estimate. Concretely, no commonly accepted procedure exists for computing classical measures of uncertainty and statistical significance as confidence intervals or p-values for these models. We consider here high-dimensional linear regression problem, and propose an efficient algorithm for constructing confidence intervals and p-values. The resulting confidence intervals have nearly optimal size. When testing for the null hypothesis that a certain parameter is vanishing, our method has nearly optimal power. Our approach is based on constructing a 'de-biased' version of regularized M-estimators. The new construction improves over recent work in the field in that it does not assume a special structure on the design matrix. We test our method on synthetic data and a high-throughput genomic data set about riboflavin production rate, made publicly available by B{\"{u}}hlmann et al. (2014).},
author = {Javanmard, Adel and Montanari, Andrea},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Machine Learning Research/Javanmard, Montanari - 2014 - Confidence Intervals and Hypothesis Testing for High-Dimensional Regression(2).pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {LASSO,bias of an estimator,confidence intervals,high-dimensional models,high-dimensional regression,hypothesis testing},
mendeley-tags = {confidence intervals,high-dimensional regression},
pages = {2869--2909},
title = {{Confidence Intervals and Hypothesis Testing for High-Dimensional Regression}},
volume = {15},
year = {2014}
}
@article{AK13,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23836590{\}}{\{}23836590{\}}},
author = {Ayers, K L and Cordell, H J},
journal = {Genetic Epidemiology},
keywords = {genetics,groups,high-dimensional regression,rare variants},
mendeley-tags = {genetics,groups,high-dimensional regression,rare variants},
month = {sep},
number = {6},
pages = {592--602},
title = {{{\{}I{\}}dentification of grouped rare and common variants via penalized logistic regression}},
volume = {37},
year = {2013}
}
@article{S07,
abstract = {We consider the problem of controlling false discoveries in association studies. We assume that the design of the study is adequate so that the "false discoveries" are potentially only because of random chance, not to confounding or other flaws. Under this premise, we review the statistical framework for hypothesis testing and correction for multiple comparisons. We consider in detail the currently accepted strategies in linkage analysis. We then examine the underlying similarities and differences between linkage and association studies and document some of the most recent methodological developments for association mapping.},
annote = {17984547},
author = {Sabatti, C},
journal = {Methods Mol Biol},
pages = {195--211},
title = {{Avoiding false discoveries in association studies}},
url = {http://www.hubmed.org/display.cgi?uids=17984547},
volume = {376},
year = {2007}
}
@article{WetL11,
annote = {21737059},
author = {Wu, M C and Lee, S and Cai, T and Li, Y and Boehnke, M and Lin, X},
journal = {American Journal of Human Genetics},
keywords = {rare variants},
mendeley-tags = {rare variants},
month = {jul},
pages = {82--93},
title = {{{\{}R{\}}are-variant association testing for sequencing data with the sequence kernel association test}},
volume = {89},
year = {2011}
}
@article{DJ04,
author = {Donoho, D and Jin, J},
journal = {The Annals of Statistics},
keywords = {Multiple testing,empirical process},
mendeley-tags = {Multiple testing,empirical process},
pages = {962--994},
title = {{Higher criticism for detecting sparse heterogeneous mixtures}},
volume = {32},
year = {2004}
}
@article{WetL10,
abstract = {GWAS have emerged as popular tools for identifying genetic variants that are associated with disease risk. Standard analysis of a case-control GWAS involves assessing the association between each individual genotyped SNP and disease risk. However, this approach suffers from limited reproducibility and difficulties in detecting multi-SNP and epistatic effects. As an alternative analytical strategy, we propose grouping SNPs together into SNP sets on the basis of proximity to genomic features such as genes or haplotype blocks, then testing the joint effect of each SNP set. Testing of each SNP set proceeds via the logistic kernel-machine-based test, which is based on a statistical framework that allows for flexible modeling of epistatic and nonlinear SNP effects. This flexibility and the ability to naturally adjust for covariate effects are important features of our test that make it appealing in comparison to individual SNP tests and existing multimarker tests. Using simulated data based on the International HapMap Project, we show that SNP-set testing can have improved power over standard individual-SNP analysis under a wide range of settings. In particular, we find that our approach has higher power than individual-SNP analysis when the median correlation between the disease-susceptibility variant and the genotyped SNPs is moderate to high. When the correlation is low, both individual-SNP analysis and the SNP-set analysis tend to have low power. We apply SNP-set analysis to analyze the Cancer Genetic Markers of Susceptibility (CGEMS) breast cancer GWAS discovery-phase data.},
annote = {20560208},
author = {Wu, Michael C and Kraft, Peter and Epstein, Michael P and Taylor, Deanne M and Chanock, Stephen J and Hunter, David J and Lin, Xihong},
journal = {American Journal of Human Genetics},
keywords = {GWAS},
mendeley-tags = {GWAS},
pages = {929--942},
title = {{{\{}Powerful{\}} {\{}SNP-set{\}} Analysis for Case-control Genome-wide Association Studies}},
volume = {86},
year = {2010}
}
@article{Imkeller2019,
abstract = {Pooled CRISPR screens are a powerful tool to probe genotype-phenotype relationships at genome-wide scale. They are based on a library of target-specific guide RNAs (gRNAs) that is applied to a pool of cells, with the aim to induce a single genetic perturbation in each cell. Detection of viability phenotypes depends on statistical comparison of the frequencies of these gRNAs before and after cell proliferation. Here, we report empirical and theoretical evidence for asymmetries in gRNA count ratios, and we show how failure to consider asymmetric null distribution of the data leads to loss of detection power. We present a biology-based, generative probabilistic model to show that the asymmetry is generated during the proliferation phase of the screen and that it is mainly driven by the distribution width of the gRNA library. Based on these observations we develop a statistical test that improves hit detection at reduced experiment size. The method is implemented in the open source package 'gscreend' (submission to Bioconductor pending).},
author = {Imkeller, Katharina and Ambrosi, Giulia and Boutros, Michael and Huber, Wolfgang},
doi = {10.1101/699348},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Imkeller et al. - 2019 - Modelling asymmetric count ratios in CRISPR screens to decrease experiment size and improve phenotype detection.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,Kathryn,Multiple testing},
mendeley-tags = {CRISPR,Kathryn,Multiple testing},
title = {{Modelling asymmetric count ratios in CRISPR screens to decrease experiment size and improve phenotype detection}},
url = {https://www.biorxiv.org/content/10.1101/699348v1},
year = {2019}
}
@article{Vovk2020,
abstract = {This paper proposes general methods for the problem of multiple testing of a single hypothesis, with a standard goal of combining a number of {\$}p{\$}-values without making any assumptions about their dependence structure. A result by R{\"{u}}schendorf (1982) and, independently, Meng (1993) implies that the {\$}p{\$}-values can be combined by scaling up their arithmetic mean by a factor of 2, and no smaller factor is sufficient in general. A similar result by Mattner about the geometric mean replaces 2 by e. Based on more recent developments in mathematical finance, specifically, robust risk aggregation techniques, we extend these results to generalized means; in particular, we show that {\$}K{\$}{\$}p{\$}-values can be combined by scaling up their harmonic mean by a factor of {\$}\backslashlog K{\$} asymptotically as {\$}K{\$} tends to infinity. This leads to a generalized version of the Bonferroni–Holm procedure. We also explore methods using weighted averages of {\$}p{\$}-values. Finally, we discuss the efficiency of various methods of combining {\$}p{\$}-values and how to choose a suitable method in light of data and prior information.},
archivePrefix = {arXiv},
arxivId = {1212.4966},
author = {Vovk, Vladimir and Wang, Ruodu},
doi = {10.1093/biomet/asaa027},
eprint = {1212.4966},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Vovk, Wang - 2020 - Combining p-values via averaging.pdf:pdf},
issn = {0006-3444},
journal = {Biometrika},
keywords = {global testing},
mendeley-tags = {global testing},
pages = {1--18},
title = {{Combining p-values via averaging}},
year = {2020}
}
@article{Gasperini2020,
abstract = {The human gene catalogue is essentially complete, but we lack an equivalently vetted inventory of bona fide human enhancers. Hundreds of thousands of candidate enhancers have been nominated via biochemical annotations; however, only a handful of these have been validated and confidently linked to their target genes. Here we review emerging technologies for discovering, characterizing and validating human enhancers at scale. We furthermore propose a new framework for operationally defining enhancers that accommodates the heterogeneous and complementary results that are emerging from reporter assays, biochemical measurements and CRISPR screens.},
author = {Gasperini, Molly and Tome, Jacob M. and Shendure, Jay},
doi = {10.1038/s41576-019-0209-0},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Reviews Genetics/Gasperini, Tome, Shendure - 2020 - Towards a comprehensive catalogue of validated and target-linked human enhancers.pdf:pdf},
isbn = {4157601902090},
issn = {1471-0064},
journal = {Nature Reviews Genetics},
keywords = {CRISPR,gene-enhancer},
mendeley-tags = {CRISPR,gene-enhancer},
publisher = {Springer US},
title = {{Towards a comprehensive catalogue of validated and target-linked human enhancers}},
year = {2020}
}
@article{Buzdugan2016,
abstract = {Motivation: Although Genome Wide Association Studies (GWAS) genotype a very large number of single nucleotide polymorphisms (SNPs), the data are often analyzed one SNP at a time. The low predictive power of single SNPs, coupled with the high significance threshold needed to correct for multiple testing, greatly decreases the power of GWAS. Results: We propose a procedure in which all the SNPs are analyzed in a multiple generalized linear model, and we show its use for extremely high-dimensional datasets. Our method yields P-values for assessing significance of single SNPs or groups of SNPs while controlling for all other SNPs and the family wise error rate (FWER). Thus, our method tests whether or not a SNP carries any additional information about the phenotype beyond that available by all the other SNPs. This rules out spurious correlations between phenotypes and SNPs that can arise from marginal methods because the 'spuriously correlated' SNP merely happens to be correlated with the 'truly causal' SNP. In addition , the method offers a data driven approach to identifying and refining groups of SNPs that jointly contain informative signals about the phenotype. We demonstrate the value of our method by applying it to the seven diseases analyzed by the Wellcome Trust Case Control Consortium (WTCCC). We show, in particular, that our method is also capable of finding significant SNPs that were not identified in the original WTCCC study, but were replicated in other independent studies. Availability and implementation: Reproducibility of our research is supported by the open-source Bioconductor package hierGWAS.},
author = {Buzdugan, Laura and Kalisch, Markus and Navarro, Arcadi and Schunk, Daniel and Fehr, Ernst and {B{\"{u}} Hlmann}, Peter and Stegle, Oliver},
doi = {10.1093/bioinformatics/btw128},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Buzdugan et al. - 2016 - Assessing statistical significance in multivariable genome wide association analysis.pdf:pdf},
journal = {Bioinformatics},
keywords = {GWAS,high-dimensional regression,to-skim},
mendeley-tags = {GWAS,high-dimensional regression,to-skim},
number = {13},
pages = {1990--2000},
title = {{Assessing statistical significance in multivariable genome wide association analysis}},
url = {https://academic.oup.com/bioinformatics/article-abstract/32/13/1990/1744010},
volume = {32},
year = {2016}
}
@article{SCPB06,
annote = {16800000},
author = {Sun, L and Craiu, R V and Paterson, A D and Bull, S B},
journal = {Journal of the American Statistical Association},
keywords = {FDR,GWAS},
mendeley-tags = {FDR,GWAS},
pages = {519--530},
title = {{Stratified false discovery control for large-scale hypothesis testing with application to genome-wide association studies}},
volume = {30},
year = {2006}
}
@article{SetF03,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/12646919{\}}{\{}12646919{\}}},
author = {Schadt, E E and Monks, S A and Drake, T A and Lusis, A J and Che, N and Colinayo, V and Ruff, T G and Milligan, S B and Lamb, J R and Cavet, G and Linsley, P S and Mao, M and Stoughton, R B and Friend, S H},
journal = {Nature},
keywords = {gene expression,genetics},
mendeley-tags = {gene expression,genetics},
month = {mar},
number = {6929},
pages = {297--302},
title = {{{\{}G{\}}enetics of gene expression surveyed in maize, mouse and man}},
volume = {422},
year = {2003}
}
@article{GetS14,
abstract = {Regulatory and coding variants are known to be enriched with associations identified by genome-wide association studies (GWASs) of complex disease, but their contributions to trait heritability are currently unknown. We applied variance-component methods to imputed genotype data for 11 common diseases to partition the heritability explained by genotyped SNPs (hg2) across functional categories (while accounting for shared variance due to linkage disequilibrium). Extensive simulations showed that in contrast to current estimates from GWAS summary statistics, the variance-component approach partitions heritability accurately under a wide range of complex-disease architectures. Across the 11 diseases DNaseI hypersensitivity sites (DHSs) from 217 cell types spanned 16{\%} of imputed SNPs (and 24{\%} of genotyped SNPs) but explained an average of 79{\%} (SE = 8{\%}) of hg2 from imputed SNPs (5.1× enrichment; p = 3.7 × 10-17) and 38{\%} (SE = 4{\%}) of hg2 from genotyped SNPs (1.6× enrichment, p = 1.0 × 10 -4). Further enrichment was observed at enhancer DHSs and cell-type-specific DHSs. In contrast, coding variants, which span 1{\%} of the genome, explained {\textless}10{\%} of hg2 despite having the highest enrichment. We replicated these findings but found no significant contribution from rare coding variants in independent schizophrenia cohorts genotyped on GWAS and exome chips. Our results highlight the value of analyzing components of heritability to unravel the functional architecture of common disease.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25439723{\}}{\{}25439723{\}}},
author = {A, Gusev and Sh, Lee and G, Trynka and H, Finucane and Bj, Vilhj{\'{a}}lmsson and H, Xu and C, Zang and S, Ripke and B, Bulik-Sullivan and E, Stahl and Working, Schizophrenia and Consortium, Swe-Scz and Ak, K{\"{a}}hler and Cm, Hultman and Sm, Purcell and Sa, McCarroll and M, Daly and B, Pasaniuc and Pf, Sullivan and Bm, Neale and Nr, Wray and S, Raychaudhuri and Al, Price and Working, Schizophrenia and Consortium, Swe-Scz},
doi = {10.1016/j.ajhg.2014.10.004},
issn = {1537-6605},
journal = {American Journal of Human Genetics},
keywords = {heritability,linear mixed models},
mendeley-tags = {heritability,linear mixed models},
month = {nov},
number = {5},
pages = {535--552},
pmid = {25439723},
title = {{Partitioning Heritability of Regulatory and Cell-Type-Specific Variants across 11 Common Diseases}},
volume = {95},
year = {2014}
}
@article{Janson2016,
author = {Janson, Lucas and Su, Weijie},
doi = {10.1214/16-EJS1129},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Electronic Journal of Statistics/Janson, Su - 2016 - Familywise error rate control via knockoffs.pdf:pdf},
journal = {Electronic Journal of Statistics},
keywords = {62F03,62J05k-familywise error rate,62J15,Lasso,and phrases,ing,k -familywise error rate,knockoffs,lasso,linear regression,multiple test-,multiple testing,negative binomial distribution,received october 2015},
mendeley-tags = {knockoffs},
pages = {960--975},
title = {{Familywise error rate control via knockoffs}},
volume = {10},
year = {2016}
}
@article{Delaigle2011,
abstract = {Student's t-statistic is finding applications today that were never envisaged when it was introduced more than a century ago. Many of these applications rely on properties, e.g. robustness against heavy-tailed sampling distributions, that were not explicitly considered until relatively recently. We explore these features of the t-statistic in the context of its application to very high dimensional problems, including feature selection and ranking, the simultaneous testing of many different hypotheses and sparse, high dimensional signal detection. Robustness properties of the t-ratio are highlighted, and it is established that those properties are preserved under applications of the bootstrap. In particular, bootstrap methods correct for skewness and therefore lead to second-order accuracy, even in the extreme tails. Indeed, it is shown that the bootstrap and also the more popular but less accurate t-distribution and normal approximations are more effective in the tails than towards the middle of the distribution. These properties motivate new methods, e.g. bootstrap-based techniques for signal detection, that confine attention to the significant tail of a statistic. {\textcopyright} 2011 Royal Statistical Society.},
archivePrefix = {arXiv},
arxivId = {1001.3886},
author = {Delaigle, Aurore and Hall, Peter and Jin, Jiashun},
doi = {10.1111/j.1467-9868.2010.00761.x},
eprint = {1001.3886},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society. Series B Statistical Methodology/Delaigle, Hall, Jin - 2011 - Robustness and accuracy of methods for high dimensional data analysis based on Student's t-statistic(2).pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Bootstrap,Central limit theorem,Classification,Dimension reduction,Higher criticism,Large deviation probability,Moderate deviation probability,Multiple testing,Ranking,Second-order accuracy,Skewness,Tail probability,Variable selection,bootstrap},
mendeley-tags = {Multiple testing,bootstrap},
number = {3},
pages = {283--301},
title = {{Robustness and accuracy of methods for high dimensional data analysis based on Student's t-statistic}},
volume = {73},
year = {2011}
}
@article{Janson2017,
abstract = {Consider the following three important problems in statistical inference: constructing confidence intervals for the error of a high dimensional (p{\textgreater}n) regression estimator, the linear regression noise level and the genetic signal-to-noise ratio of a continuous-valued trait (related to the heritability). All three problems turn out to be closely related to the little-studied problem of performing inference on the l2-norm of the signal in high dimensional linear regression. We derive a novel procedure for this, which is asymptotically correct when the covariates are multivariate Gaussian and produces valid confidence intervals in finite samples as well. The procedure, called EigenPrism, is computationally fast and makes no assumptions on coefficient sparsity or knowledge of the noise level.We investigate the width of the EigenPrism confidence intervals, including a comparison with a Bayesian setting in which our interval is just 5{\%} wider than the Bayes credible interval.We are then able to unify the three aforementioned problems by showing that EigenPrism with only minor modifications can make important contributions to all three. We also investigate the robustness of coverage and find that the method applies in practice and in finite samples much more widely than just the case of multivariate Gaussian covariates. Finally, we apply EigenPrism to a genetic data set to estimate the genetic signal-to- noise ratio for a number of continuous phenotypes.},
author = {Janson, Lucas and Barber, Rina Foygel and Candes, Emmanuel},
doi = {10.1111/rssb.12203},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society Series B (Statistical Methodology)/Janson, Barber, Candes - 2017 - EigenPrism inference for high dimensional signal-to-noise ratios.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {eigenprism,heritability,high-dimensional regression,regression error,signal-to-noise ratio,variance},
mendeley-tags = {heritability,high-dimensional regression},
number = {4},
pages = {1037--1065},
title = {{EigenPrism : inference for high dimensional signal-to-noise ratios}},
volume = {79},
year = {2017}
}
@article{Ning2017,
abstract = {We consider the problem of uncertainty assessment for low dimensional components in high dimensional models. Specifically, we propose a novel decorrelated score function to handle the impact of high dimensional nuisance parameters. We consider both hypothesis tests and confidence regions for generic penalized M-estimators. Unlike most existing inferential methods which are tailored for individual models, our method provides a general framework for high dimensional inference and is applicable to a wide variety of applications. In particular, we apply this general framework to study five illustrative examples: linear regression, logistic regression, Poisson regression, Gaussian graphical model and additive hazards model. For hypothesis testing, we develop general theorems to characterize the limiting distributions of the decorrelated score test statistic under both null hypothesis and local alternatives. These results provide asymptotic guarantees on the type I errors and local powers. For confidence region construction, we show that the decorrelated score function can be used to construct point estimators that are asymptotically normal and semiparametrically efficient. We further generalize this framework to handle the settings of misspecified models. Thorough numerical results are provided to back up the developed theory.},
archivePrefix = {arXiv},
arxivId = {1412.8765},
author = {Ning, Yang and Liu, Han},
doi = {10.1214/16-AOS1448},
eprint = {1412.8765},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Ning, Liu - 2017 - A general theory of hypothesis tests and confidence regions for sparse high dimensional models.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Confidence interval,High dimensional inference,Hypothesis test,Model misspecification,Nuisance parameter,Score function,Sparsity},
number = {1},
pages = {158--195},
title = {{A general theory of hypothesis tests and confidence regions for sparse high dimensional models}},
volume = {45},
year = {2017}
}
@article{friedman2010regularization,
author = {Friedman, J and Hastie, T and Tibshirani, R},
journal = {Journal of statistical software},
keywords = {high-dimensional regression},
mendeley-tags = {high-dimensional regression},
number = {1},
pages = {1},
publisher = {NIH Public Access},
title = {{Regularization paths for generalized linear models via coordinate descent}},
volume = {33},
year = {2010}
}
@article{genovese2006exceedance,
author = {Genovese, C R and Wasserman, L},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Genovese, Wasserman - 2006 - Exceedance control of the false discovery proportion.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {FDX,Multiple testing,simultaneous inference},
mendeley-tags = {FDX,Multiple testing,simultaneous inference},
number = {476},
pages = {1408--1417},
publisher = {Taylor {\&} Francis},
title = {{Exceedance control of the false discovery proportion}},
volume = {101},
year = {2006}
}
@article{Wang2018,
abstract = {Background: Enhancers are distal cis-regulatory elements that control gene expression. Despite an increasing appreciation of the importance of enhancers in cellular function and disease, our knowledge of enhancer-regulated transcription is very limited. Nascent RNA sequencing technologies, such as global nuclear run-on sequencing (GRO-seq) and precision run-on sequencing (PRO-seq), not only provide a direct and reliable measurement of enhancer activity, but also allow for quantifying transcription of enhancers and target genes simultaneously, making these technologies extremely useful for exploring enhancer-mediated regulation. Results: Nascent RNA sequencing analysis (NRSA) provides a comprehensive view of enhancer-mediated gene regulation. NRSA not only outperforms existing methods for enhancer identification, but also enables annotation and quantification of active enhancers, and prediction of their target genes. Furthermore, NRSA identifies functionally important enhancers by integrating 1) nascent transcriptional changes in enhancers and their target genes and 2) binding profiles from regulator(s) of interest. Applied to wildtype and histone deacetylase 3 (Hdac3) knockout mouse livers, NRSA showed that HDAC3 regulates RNA polymerase recruitment through both proximal (promoter) and distal (enhancer) regulatory elements. Integrating ChIP-seq with PRO-seq data, NRSA prioritized enhancers based on their potential contribution to mediating HDAC3 regulation. Conclusions: NRSA will greatly facilitate the usage of nascent RNA sequencing techniques and accelerate the study of enhancer-mediated regulation.},
author = {Wang, Jing and Zhao, Yue and Zhou, Xiaofan and Hiebert, Scott W and Liu, Qi and Shyr, Yu},
doi = {10.1186/s12864-018-5016-z},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Genomics/Wang et al. - 2018 - Nascent RNA sequencing analysis provides insights into enhancer-mediated gene regulation.pdf:pdf},
journal = {BMC Genomics},
keywords = {Kathryn,enhancer,gene-enhancer},
mendeley-tags = {Kathryn,enhancer,gene-enhancer},
title = {{Nascent RNA sequencing analysis provides insights into enhancer-mediated gene regulation}},
url = {https://doi.org/10.1186/s12864-018-5016-z},
volume = {19},
year = {2018}
}
@article{Beal2017,
abstract = {Cells exhibit a high degree of variation in levels of gene expression, even within otherwise homogeneous populations. The standard model to describe this variation centres on a gamma distribution driven by stochastic bursts of translation. Stochastic bursting, however, cannot account for the well-established behaviour of strong transcriptional repressors. Instead, it can be shown that the very complexity of the biochemical processes involved in gene expression drives an emergent log-normal distribution of expression levels. Emergent log-normal distributions can account for the observed behaviour of transcriptional repressors, are still compatible with stochastically constrained distributions, and have important implications for both analysis of gene expression data and the engineering of biological organisms. 1},
author = {Beal, Jacob},
doi = {10.1049/enb.2017.0004},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Engineering Biology/Beal - 2017 - Biochemical complexity drives log-normal variation in genetic expression.pdf:pdf},
issn = {2398-6182},
journal = {Engineering Biology},
number = {1},
pages = {55--60},
title = {{Biochemical complexity drives log-normal variation in genetic expression}},
volume = {1},
year = {2017}
}
@article{Lee2016,
abstract = {We develop a general approach to valid inference after model selection. At the core of our framework is a result that characterizes the distribution of a post-selection estimator conditioned on the selection event. We specialize the approach to model selection by the lasso to form valid confidence intervals for the selected coefficients and test whether all relevant variables have been included in the model. 1. Introduction. As a statistical technique, linear regression is both simple and powerful. Not only does it provide estimates of the "effect" of each variable, but it also quantifies the uncertainty in those estimates, allowing inferences to be made about the effects. However, in many applications, a practitioner starts with a large pool of candidate variables, such as genes or demographic features, and does not know a priori which are relevant. This is especially problematic when there are more variables than observations, since then the model is unidentifiable (at least in the setting where the predictors are assumed fixed). In such settings, it is tempting to let the data decide which variables to include in the model. For example, one common approach when the number of variables is not too large is to fit a linear model with all variables included, observe which ones are significant at level $\alpha$, and then refit the linear model with only those variables included. The problem with this is that the p-values can no longer be trusted, since the variables that are selected will tend to be those that are significant. Intuitively, we are "overfitting" to a particular realization of the data. To formalize the problem, consider the standard linear regression setup, where the response y ∈ R n is generated from a multivariate normal distribution:},
author = {Lee, Jason D and Sun, Dennis L and Sun, Yuekai and Taylor, Jonathan E},
doi = {10.1214/15-AOS1371},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Lee et al. - 2016 - EXACT POST-SELECTION INFERENCE, WITH APPLICATION TO THE LASSO.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {62E15,62F03,62J07,Lasso,canonical,confidence interval,hypothesis test,model selection,post-selection inference},
mendeley-tags = {Lasso,canonical,post-selection inference},
number = {3},
pages = {907--927},
title = {{EXACT POST-SELECTION INFERENCE, WITH APPLICATION TO THE LASSO}},
volume = {44},
year = {2016}
}
@article{FST14,
archivePrefix = {arXiv},
arxivId = {math.ST/1410.2597},
author = {Fithian, W and Sun, D and Taylor, J},
eprint = {1410.2597},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Fithian, Sun, Taylor - 2014 - Optimal Inference After Model Selection.pdf:pdf},
journal = {arXiv},
keywords = {Mathematics - Statistics Theory,Statistics - Methodology,post-selection inference,unpublished},
mendeley-tags = {post-selection inference,unpublished},
month = {oct},
primaryClass = {math.ST},
title = {{Optimal Inference After Model Selection}},
year = {2014}
}
@article{DeRubeis2014,
abstract = {The genetic architecture of autism spectrum disorder involves the interplay of common and rare variants and their impact on hundreds of genes. Using exome sequencing, here we show that analysis of rare coding variation in 3,871 autism cases and 9,937 ancestry-matched or parental controls implicates 22 autosomal genes at a false discovery rate (FDR) {\textless} 0.05, plus a set of 107 autosomal genes strongly enriched for those likely to affect risk (FDR {\textless} 0.30). These 107 genes, which show unusual evolutionary constraint against mutations, incur de novo loss-of-function mutations in over 5{\%} of autistic subjects. Many of the genes implicated encode proteins for synaptic formation, transcriptional regulation and chromatin-remodelling pathways. These include voltage-gated ion channels regulating the propagation of action potentials, pacemaking and excitability-transcription coupling, as well as histone-modifying enzymes and chromatin remodellers-most prominently those that mediate post-translational lysine methylation/demethylation modifications of histones.},
author = {{De Rubeis}, Silvia and He, Xin and Goldberg, Arthur P. and Poultney, Christopher S. and Samocha, Kaitlin and Cicek, A. Ercument and Kou, Yan and Liu, Li and Fromer, Menachem and Walker, Susan and Singh, Tarjinder and Klei, Lambertus and Kosmicki, Jack and Fu, Shih Chen and Aleksic, Branko and Biscaldi, Monica and Bolton, Patrick F. and Brownfeld, Jessica M. and Cai, Jinlu and Campbell, Nicholas G. and Carracedo, Angel and Chahrour, Maria H. and Chiocchetti, Andreas G. and Coon, Hilary and Crawford, Emily L. and Crooks, Lucy and Curran, Sarah R. and Dawson, Geraldine and Duketis, Eftichia and Fernandez, Bridget A. and Gallagher, Louise and Geller, Evan and Guter, Stephen J. and Hill, R. Sean and Ionita-Laza, Iuliana and Gonzalez, Patricia Jimenez and Kilpinen, Helena and Klauck, Sabine M. and Kolevzon, Alexander and Lee, Irene and Lei, Jing and Lehtim{\"{a}}ki, Terho and Lin, Chiao Feng and Ma'ayan, Avi and Marshall, Christian R. and McInnes, Alison L. and Neale, Benjamin and Owen, Michael J. and Ozaki, Norio and Parellada, Mara and Parr, Jeremy R. and Purcell, Shaun and Puura, Kaija and Rajagopalan, Deepthi and Rehnstr{\"{o}}m, Karola and Reichenberg, Abraham and Sabo, Aniko and Sachse, Michael and Sanders, Stephan J. and Schafer, Chad and Schulte-R{\"{u}}ther, Martin and Skuse, David and Stevens, Christine and Szatmari, Peter and Tammimies, Kristiina and Valladares, Otto and Voran, Annette and Wang, Li San and Weiss, Lauren A. and Willsey, A. Jeremy and Yu, Timothy W. and Yuen, Ryan K.C. and Cook, Edwin H. and Freitag, Christine M. and Gill, Michael and Hultman, Christina M. and Lehner, Thomas and Palotie, Aarno and Schellenberg, Gerard D. and Sklar, Pamela and State, Matthew W. and Sutcliffe, James S. and Walsh, Christopher A. and Scherer, Stephen W. and Zwick, Michael E. and Barrett, Jeffrey C. and Cutler, David J. and Roeder, Kathryn and Devlin, Bernie and Daly, Mark J. and Buxbaum, Joseph D.},
doi = {10.1038/nature13772},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/De Rubeis et al. - 2014 - Synaptic, transcriptional and chromatin genes disrupted in autism.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {Kathryn,autism,psychiatric genomics,whole exome sequencing},
mendeley-tags = {Kathryn,autism,psychiatric genomics,whole exome sequencing},
number = {7526},
pages = {209--215},
title = {{Synaptic, transcriptional and chromatin genes disrupted in autism}},
volume = {515},
year = {2014}
}
@article{PLINK,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/17701901{\}}{\{}17701901{\}}},
author = {Purcell, S and Neale, B and Todd-Brown, K and Thomas, L and Ferreira, M A and Bender, D and Maller, J and Sklar, P and de Bakker, P I and Daly, M J and Sham, P C},
journal = {American Journal of Human Genetics},
month = {sep},
pages = {559--575},
title = {{{\{}P{\}}{\{}L{\}}{\{}I{\}}{\{}N{\}}{\{}K{\}}: a tool set for whole-genome association and population-based linkage analyses}},
volume = {81},
year = {2007}
}
@article{VetW02,
author = {{Van't Veer}, Laura J. and Dai, Hongyue and {Van De Vijver}, Marc J. and He, Yudong D. and Hart, Augustinus A. M. and Mao, Mao and Peterse, Hans L. and {Van Der Kooy}, Karin and Marton, Matthew J. and Witteveen, Anke T.},
journal = {Nature},
keywords = {genetics},
mendeley-tags = {genetics},
number = {6871},
pages = {530},
publisher = {Nature Publishing Group},
title = {{Gene expression profiling predicts clinical outcome of breast cancer}},
volume = {415},
year = {2002}
}
@article{Bernstein2010,
abstract = {The NIH Roadmap Epigenomics Mapping Consortium aims to produce a public resource of epigenomic maps for stem cells and primary ex vivo tissues selected to represent the normal counterparts of tissues and organ systems frequently involved in human disease.},
author = {Bernstein, Bradley E. and Stamatoyannopoulos, John A. and Costello, Joseph F. and Ren, Bing and Milosavljevic, Aleksandar and Meissner, Alexander and Kellis, Manolis and Marra, Marco A. and Beaudet, Arthur L. and Ecker, Joseph R. and Farnham, Peggy J. and Hirst, Martin and Lander, Eric S. and Mikkelsen, Tarjei S. and Thomson, James A.},
doi = {10.1038/nbt1010-1045},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Bernstein et al. - 2010 - The NIH roadmap epigenomics mapping consortium.pdf:pdf},
issn = {10870156},
journal = {Nature Biotechnology},
keywords = {Kathryn,epigenetics,genetics},
mendeley-tags = {Kathryn,epigenetics,genetics},
number = {10},
pages = {1045--1048},
pmid = {20944595},
publisher = {Nature Publishing Group},
title = {{The NIH roadmap epigenomics mapping consortium}},
volume = {28},
year = {2010}
}
@article{VanderVaart2002,
abstract = {We give an overview and appraisal of the scientific work in theoretical statistics, and its impact, by Lucien Le Cam. The references to Le Cam's papers refer to the Le Cam bibliography. The reference is the first paper for the given year if not stated.},
author = {{Van der Vaart}, Aad},
doi = {10.1214/aos/1028674836},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Van der Vaart - 2002 - The statistical work of Lucien Le Cam.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Comparison of experiments,Contiguity,Deficiency,LAN,Limit experiment,Metric entropy,Sufficiency,asymptotics},
mendeley-tags = {asymptotics},
number = {3},
pages = {631--682},
title = {{The statistical work of Lucien Le Cam}},
volume = {30},
year = {2002}
}
@article{Pearl2009a,
abstract = {This review presents empirical researcherswith recent advances in causal inference, and stresses the paradigmatic shifts that must be undertaken in moving from traditional statistical analysis to causal analysis of multivariate data. Special emphasis is placed on the assumptions that underly all causal inferences, the languages used in formulating those assumptions, the conditional nature of all causal and counterfactual claims, and the methods that have been developed for the assessment of such claims. These advances are illustrated using a general theory of causation based on the Structural Causal Model (SCM) described in Pearl (2000a), which subsumes and unifies other approaches to causation, and provides a coherent mathematical foundation for the analysis of causes and counterfactuals. In particular, the paper surveys the development of mathematical tools for inferring (from a combination of data and assumptions) answers to three types of causal queries: (1) queries about the effects of potential interventions, (also called "causal effects" or "policy evaluation") (2) queries about probabilities of counterfactuals, (including assessment of "regret," "attribution" or "causes of effects") and (3) queries about direct and indirect effects (also known as "mediation"). Finally, the paper defines the formal and conceptual relationships between the structural and potential-outcome frameworks and presents tools for a symbiotic analysis that uses the strong features of both.},
author = {Pearl, Judea},
doi = {10.1214/09-SS057},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics Surveys/Pearl - 2009 - Causal inference in statistics An overview.pdf:pdf},
issn = {19357516},
journal = {Statistics Surveys},
keywords = {Causal effects,Causes of effects,Confounding,Counterfactuals,Graphical methods,Mediation,Policy evaluation,Potential-outcome,Structural equationmodels},
pages = {96--146},
title = {{Causal inference in statistics: An overview}},
volume = {3},
year = {2009}
}
@article{Harrison2012,
abstract = {Importance sampling is a common technique for Monte Carlo approximation, including Monte Carlo approximation of p-values. Here it is shown that a simple correction of the usual importance sampling p-values creates valid p-values, meaning that a hypothesis test created by rejecting the null when the p-value is {\textless}= alpha will also have a type I error rate {\textless}= alpha. This correction uses the importance weight of the original observation, which gives valuable diagnostic information under the null hypothesis. Using the corrected p-values can be crucial for multiple testing and also in problems where evaluating the accuracy of importance sampling approximations is difficult. Inverting the corrected p-values provides a useful way to create Monte Carlo confidence intervals that maintain the nominal significance level and use only a single Monte Carlo sample. Several applications are described, including accelerated multiple testing for a large neurophysiological dataset and exact conditional inference for a logistic regression model with nuisance parameters.},
author = {Harrison, Matthew T.},
doi = {10.1093/biomet/asr079},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Harrison - 2012 - Conservative hypothesis tests and confidence intervals using importance sampling.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {Exact inference,Monte Carlo,Monte Carlo simulation,Multiple testing,Rasch model,p-value,resampling},
mendeley-tags = {Monte Carlo,Multiple testing,resampling},
number = {1},
pages = {57--69},
title = {{Conservative hypothesis tests and confidence intervals using importance sampling}},
volume = {99},
year = {2012}
}
@article{van2004multiple,
author = {van der Laan, M J and Dudoit, S and Pollard, K S},
keywords = {FWER,Multiple testing},
mendeley-tags = {FWER,Multiple testing},
publisher = {bepress},
title = {{Multiple testing. Part III. Procedures for control of the generalized family-wise error rate and proportion of false positives}},
year = {2004}
}
@article{Sarkar2020,
abstract = {How to model and analyze scRNA-seq data has been the subject of considerable confusion and debate. The high proportion of zero counts in a typical scRNA-seq data matrix has garnered particular attention, and lead to widespread but inconsistent use of terminology such as "dropout" and "missing data." Here, we argue that much of this terminology is unhelpful and confusing, and outline simple ways of thinking about models for scRNA-seq data that can help avoid this confusion. The key ideas are: (1) observed scRNA-seq counts reflect both the actual expression level of each gene in each cell and the measurement process, and it is important for models to explicitly distinguish contributions from these two distinct factors; and (2) the measurement process can be adequately described by a simple Poisson model, a claim for which we provide both theoretical and empirical support. We show how these ideas lead to a simple, flexible statistical framework that encompasses a number of commonly used models and analysis methods, and how this framework makes explicit their different assumptions and helps interpret their results. We also illustrate how explicitly separating models for expression and measurement can help address questions of biological interest, such as whether mRNA expression levels are multi-modal among cells.},
author = {Sarkar, Abhishek and Stephens, Matthew},
doi = {10.1101/2020.04.07.030007},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Sarkar, Stephens - 2020 - Separating measurement and expression models clarifies confusion in single cell RNA-seq analysis.pdf:pdf},
journal = {bioRxiv},
keywords = {single cell},
mendeley-tags = {single cell},
title = {{Separating measurement and expression models clarifies confusion in single cell RNA-seq analysis}},
url = {https://doi.org/10.1101/2020.04.07.030007},
year = {2020}
}
@article{WLB07,
abstract = {Published genomewide association (GWA) studies typically analyze and report single-nucleotide polymorphisms (SNPs) and their neighboring genes with the strongest evidence of association (the "most-significant SNPs/genes" approach), while paying little attention to the rest. Borrowing ideas from microarray data analysis, we demonstrate that pathway-based approaches, which jointly consider multiple contributing factors in the same pathway, might complement the most-significant SNPs/genes approach and provide additional insights into interpretation of GWA data on complex diseases.},
author = {Wang, Kai and Li, Mingyao and Bucan, Maja},
doi = {10.1086/522374},
issn = {00029297},
journal = {American Journal of Human Genetics},
month = {dec},
number = {6},
pages = {1278--1283},
title = {{Pathway-Based Approaches for Analysis of Genomewide Association Studies}},
volume = {81},
year = {2007}
}
@article{Clark2018,
abstract = {Parallel single-cell sequencing protocols represent powerful methods for investigating regulatory relationships, including epigenome-transcriptome interactions. Here, we report a single-cell method for parallel chromatin accessibility, DNA methylation and transcriptome profiling. scNMT-seq (single-cell nucleosome, methylation and transcription sequencing) uses a GpC methyltransferase to label open chromatin followed by bisulfite and RNA sequencing. We validate scNMT-seq by applying it to differentiating mouse embryonic stem cells, finding links between all three molecular layers and revealing dynamic coupling between epigenomic layers during differentiation.},
author = {Clark, Stephen J. and Argelaguet, Ricard and Kapourani, Chantriolnt Andreas and Stubbs, Thomas M. and Lee, Heather J. and Alda-Catalinas, Celia and Krueger, Felix and Sanguinetti, Guido and Kelsey, Gavin and Marioni, John C. and Stegle, Oliver and Reik, Wolf},
doi = {10.1038/s41467-018-03149-4},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Clark et al. - 2018 - ScNMT-seq enables joint profiling of chromatin accessibility DNA methylation and transcription in single cells e.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
keywords = {multi-omics,single cell},
mendeley-tags = {multi-omics,single cell},
number = {1},
pages = {1--9},
pmid = {29472610},
publisher = {Springer US},
title = {{ScNMT-seq enables joint profiling of chromatin accessibility DNA methylation and transcription in single cells e}},
url = {http://dx.doi.org/10.1038/s41467-018-03149-4},
volume = {9},
year = {2018}
}
@article{Lause2020,
abstract = {Standard preprocessing of single-cell RNA-seq UMI data includes normalization by sequencing depth to remove this technical variability, and nonlinear transformation to stabilize the variance across genes with different expression levels. Instead, two recent papers propose to use statistical count models for these tasks: Hafemeister and Satija (2019) recommend using Pearson residuals from negative binomial regression, while Townes et al. (2019) recommend fitting a generalized PCA model. Here, we investigate the connection between these approaches theoretically and empirically, and compare their effects on downstream processing. We show that the model of Hafemeister and Satija (2019) produces noisy parameter estimates because it is overspecified (which is why the original paper employs post-hoc regularization). When specified more parsimoniously, it has a simple analytic solution equivalent to the rank-one Poisson GLM-PCA of Townes et al. (2019). Further, our analysis indicates that per-gene overdispersion estimates in Hafemeister and Satija (2019) are biased, and that the data analyzed in that paper are in fact consistent with constant overdispersion parameter across genes. We then use negative control data without biological variability to estimate the technical overdispersion of UMI counts, and find that across several different experimental protocols, the data suggest very moderate overdispersion. Finally, we argue that analytic Pearson residuals (or, equivalently, rank-one GLM-PCA or negative binomial regression after regularization) strongly outperform standard preprocessing for identifying biologically variable genes, and capture more biologically meaningful variation when used for dimensionality reduction, compared to other methods.},
author = {Lause, Jan and Berens, Philipp and Kobak, Dmitry},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Lause, Berens, Kobak - 2020 - Analytic Pearson residuals for normalization of single-cell RNA-seq UMI data.pdf:pdf},
journal = {bioRxiv},
keywords = {single cell},
mendeley-tags = {single cell},
title = {{Analytic Pearson residuals for normalization of single-cell RNA-seq UMI data}},
url = {https://doi.org/10.1101/2020.12.01.405886},
year = {2020}
}
@article{pmid25938221,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25938221{\}}{\{}25938221{\}}},
author = {Li, Y and O'Connor, G T and Dupuis, J and Kolaczyk, E},
journal = {Stat Appl Genet Mol Biol},
keywords = {GWAS,genetics,high-dimensional regression},
mendeley-tags = {GWAS,genetics,high-dimensional regression},
month = {jun},
number = {3},
pages = {265--277},
title = {{{\{}M{\}}odeling gene-covariate interactions in sparse regression with group structure for genome-wide association studies}},
volume = {14},
year = {2015}
}
@article{Benjamini2019,
abstract = {Practical or scientific considerations often lead to selecting a subset of parameters as "important." Inferences about those parameters often are based on the same data used to select them in the first place. That can make the reported uncertainties deceptively optimistic: confidence intervals that ignore selection generally have less than their nominal coverage probability. Controlling the probability that one or more intervals for selected parameters do not cover-the "simultaneous over the selected" (SoS) error rate-is crucial in many scientific problems. Intervals that control the SoS error rate can be constructed in ways that take advantage of knowledge of the selection rule. We construct SoS-controlling confidence intervals for parameters deemed the most "important" k of m shift parameters because they are estimated (by independent estimators) to be the largest. The new intervals improve substantially oveř Sid{\'{a}}k intervals when k is small compared to m, and approach the standard Bonferroni-corrected intervals when k ≈ m. Standard, unadjusted confidence intervals for location parameters have the correct coverage probability for k = 1, m = 2 if, when the true parameters are zero, the estimators are ex-changeable and symmetric.},
archivePrefix = {arXiv},
arxivId = {1906.00505v1},
author = {Benjamini, Yoav and Hechtlinger, Yotam and Stark, Philip B},
eprint = {1906.00505v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Benjamini, Hechtlinger, Stark - 2019 - Confidence Intervals for Selected Parameters(2).pdf:pdf},
journal = {arXiv},
keywords = {Post Selection Inference,Selec-tion of the Maximum,Selective Inference 2,Simultaneous over the Selected,confidence intervals,post-selection inference,to-skim,unpublished},
mendeley-tags = {confidence intervals,post-selection inference,to-skim,unpublished},
title = {{Confidence Intervals for Selected Parameters}},
year = {2019}
}
@article{phyloseq,
author = {McMurdie, Paul J and Holmes, Susan},
journal = {PLoS ONE},
keywords = {microbiome,software},
mendeley-tags = {microbiome,software},
number = {4},
pages = {e61217},
title = {{phyloseq: An {\{}R{\}} Package for reproducible interactive analysis and graphics of microbiome census data}},
volume = {8},
year = {2013}
}
@article{Lin2013,
abstract = {Freedman [Adv. in Appl. Math. 40 (2008) 180-193; Ann. Appl. Stat. 2 (2008) 176-196] critiqued ordinary least squares regression adjustment of estimated treatment effects in randomized experiments, using Neyman's model for randomization inference. Contrary to conventional wisdom, he argued that adjustment can lead to worsened asymptotic precision, invalid measures of precision, and small-sample bias. This paper shows that in sufficiently large samples, those problems are either minor or easily fixed. OLS adjustment cannot hurt asymptotic precision when a full set of treatment-covariate interactions is included. Asymptotically valid confidence intervals can be constructed with the Huber-White sandwich standard error estimator. Checks on the asymptotic approximations are illustrated with data from Angrist, Lang, and Oreopoulos's [Am. Econ. J.: Appl. Econ. 1:1 (2009) 136-163] evaluation of strategies to improve college students' achievement. The strongest reasons to support Freedman's preference for unadjusted estimates are transparency and the dangers of specification search. {\textcopyright} 2013 Institute of Mathematical Statistics.},
archivePrefix = {arXiv},
arxivId = {arXiv:1208.2301v2},
author = {Lin, Winston},
doi = {10.1214/12-AOAS583},
eprint = {arXiv:1208.2301v2},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Applied Statistics/Lin - 2013 - Agnostic notes on regression adjustments to experimental data Reexamining Freedman's critique.pdf:pdf},
issn = {19326157},
journal = {Annals of Applied Statistics},
keywords = {Analysis of covariance,Covariate adjustment,Program evaluation,Randomization inference,Robust standard errors,Sandwich estimator,Social experiments,causality},
mendeley-tags = {causality},
number = {1},
pages = {295--318},
title = {{Agnostic notes on regression adjustments to experimental data: Reexamining Freedman's critique}},
volume = {7},
year = {2013}
}
@article{cross,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23933821{\}}{\{}23933821{\}}},
author = {{Cross Disorder Group of the Psychiatric Genomics Consortium}},
journal = {Nature Genetics},
keywords = {genetics,multiple phenotypes},
mendeley-tags = {genetics,multiple phenotypes},
month = {sep},
number = {9},
pages = {984--994},
title = {{{\{}G{\}}enetic relationship between five psychiatric disorders estimated from genome-wide {\{}S{\}}{\{}N{\}}{\{}P{\}}s}},
volume = {45},
year = {2013}
}
@article{Canver2015,
abstract = {Enhancers, critical determinants of cellular identity, are commonly recognized by correlative chromatin marks and gain-of-function potential, although only loss-of-function studies can demonstrate their requirement in the native genomic context. Previously, we identified an erythroid enhancer of human BCL11A, subject to common genetic variation associated with the fetal haemoglobin level, the mouse orthologue of which is necessary for erythroid BCL11A expression. Here we develop pooled clustered regularly interspaced palindromic repeat (CRISPR)-Cas9 guide RNA libraries to perform in situ saturating mutagenesis of the human and mouse enhancers. This approach reveals critical minimal features and discrete vulnerabilities of these enhancers. Despite conserved function of the composite enhancers, their architecture diverges. The crucial human sequences appear to be primate-specific. Through editing of primary human progenitors and mouse transgenesis, we validate the BCL11A erythroid enhancer as a target for fetal haemoglobin reinduction. The detailed enhancer map will inform therapeutic genome editing, and the screening approach described here is generally applicable to functional interrogation of non-coding genomic elements.},
author = {Canver, Matthew C. and Smith, Elenoe C. and Sher, Falak and Pinello, Luca and Sanjana, Neville E. and Shalem, Ophir and Chen, Diane D. and Schupp, Patrick G. and Vinjamur, Divya S. and Garcia, Sara P. and Luc, Sidinh and Kurita, Ryo and Nakamura, Yukio and Fujiwara, Yuko and Maeda, Takahiro and Yuan, Guo Cheng and Zhang, Feng and Orkin, Stuart H. and Bauer, Daniel E.},
doi = {10.1038/nature15521},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Canver et al. - 2015 - BCL11A enhancer dissection by Cas9-mediated in situ saturating mutagenesis.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {7577},
pages = {192--197},
pmid = {26375006},
title = {{BCL11A enhancer dissection by Cas9-mediated in situ saturating mutagenesis}},
volume = {527},
year = {2015}
}
@article{Liu2020a,
abstract = {Abstract–Combining individual p-values to aggregate multiple small effects has a long-standing interest in statistics, dating back to the classic Fisher's combination test. In modern large-scale data analysis, correlation and sparsity are common features and efficient computation is a necessary requirement for dealing with massive data. To overcome these challenges, we propose a new test that takes advantage of the Cauchy distribution. Our test statistic has a simple form and is defined as a weighted sum of Cauchy transformation of individual p-values. We prove a nonasymptotic result that the tail of the null distribution of our proposed test statistic can be well approximated by a Cauchy distribution under arbitrary dependency structures. Based on this theoretical result, the p-value calculation of our proposed test is not only accurate, but also as simple as the classic z-test or t-test, making our test well suited for analyzing massive data. We further show that the power of the proposed test is asymptotically optimal in a strong sparsity setting. Extensive simulations demonstrate that the proposed test has both strong power against sparse alternatives and a good accuracy with respect to p-value calculations, especially for very small p-values. The proposed test has also been applied to a genome-wide association study of Crohn's disease and compared with several existing tests. Supplementary materials for this article are available online.},
author = {Liu, Yaowu and Xie, Jun},
doi = {10.1080/01621459.2018.1554485},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Liu, Xie - 2020 - Cauchy Combination Test A Powerful Test With Analytic p-Value Calculation Under Arbitrary Dependency Structures.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Cauchy distribution,Correlation matrix,Global hypothesis testing,High-dimensional data,Nonasymptotic approximation,Sparse alternative,global testing},
mendeley-tags = {global testing},
number = {529},
pages = {393--402},
publisher = {Taylor {\&} Francis},
title = {{Cauchy Combination Test: A Powerful Test With Analytic p-Value Calculation Under Arbitrary Dependency Structures}},
url = {https://doi.org/10.1080/01621459.2018.1554485},
volume = {115},
year = {2020}
}
@article{GetV07,
author = {S., Grossmann and S., Bauer and P.N., Robinson and M., Vingron},
journal = {Bioinformatics},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
number = {22},
pages = {3024--3031},
publisher = {Oxford University Press},
title = {{Improved detection of overrepresentation of Gene-Ontology annotations with parent child analysis.}},
volume = {23},
year = {2007}
}
@article{Jaljuli2019,
abstract = {Systematic reviews of interventions are important tools for synthesizing evidence from multiple studies. They serve to increase power and improve precision, in the same way that larger studies can do, but also to establish the consistency of effects and replicability of results across studies which are not identical. In this work we suggest to incorporate replicability analysis tools to quantify the consistency and conflict. These are offered both for the fixed-effect and for the random-effects meta-analyses. We motivate and demonstrate our approach and its implications by examples from systematic reviews from the Cochrane library, and offer a way to incorporate our suggestions in their standard reporting system.},
archivePrefix = {arXiv},
arxivId = {1907.06856},
author = {Jaljuli, Iman and Benjamini, Yoav and Shenhav, Liat and Panagiotou, Orestis and Heller, Ruth},
eprint = {1907.06856},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Jaljuli et al. - 2019 - Quantifying replicability and consistency in systematic reviews.pdf:pdf},
journal = {arXiv},
pages = {1--18},
title = {{Quantifying replicability and consistency in systematic reviews}},
url = {http://arxiv.org/abs/1907.06856},
year = {2019}
}
@article{Vovk2020a,
abstract = {Methods of merging several p-values into a single p-value are important in their own right and widely used in multiple hypothesis testing. This paper is the first to systematically study the admissibility (in Wald's sense) of p-merging functions and their domination structure, without any assumptions on the dependence structure of the input p-values. As a technical tool we use the notion of e-values, which are alternatives to p-values recently promoted by several authors. We obtain several results on the representation of admissible p-merging functions via e-values and on (in)admissibility of existing p-merging functions. By introducing new admissible p-merging functions, we show that some classic merging methods can be strictly improved to enhance power without compromising validity under arbitrary dependence.},
archivePrefix = {arXiv},
arxivId = {2007.14208},
author = {Vovk, Vladimir and Wang, Bin and Wang, Ruodu},
eprint = {2007.14208},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Vovk, Wang, Wang - 2020 - Admissible ways of merging p-values under arbitrary dependence.pdf:pdf},
journal = {arXiv},
keywords = {admissibility,duality,e-values,global testing,multiple hypothesis testing,p-values},
mendeley-tags = {global testing},
pages = {1--34},
title = {{Admissible ways of merging p-values under arbitrary dependence}},
url = {http://arxiv.org/abs/2007.14208},
year = {2020}
}
@article{Nica2011,
author = {Nica, A C and Parts, L and Glass, D and Nisbet, J and Barrett, A and Sekowska, M and Travers, M and Potter, S and Grundberg, E and Others},
journal = {PLoS Genetics},
keywords = {gene regulation,genetics},
mendeley-tags = {gene regulation,genetics},
number = {2},
pages = {e1002003},
title = {{The architecture of gene regulatory variation across multiple human tissues: the {\{}M{\}}u{\{}T{\}}{\{}H{\}}{\{}E{\}}{\{}R{\}} study}},
volume = {7},
year = {2011}
}
@article{Benjamini2019b,
abstract = {Scientists use high-dimensional measurement assays to detect and prioritize regions of strong signal in spatially organized domain. Examples include finding methylation-enriched genomic regions using microarrays, and active cortical areas using brain-imaging. The most common procedure for detecting potential regions is to group neighboring sites where the signal passed a threshold. However, one needs to account for the selection bias induced by this procedure to avoid diminishing effects when generalizing to a population. This article introduces pin-down inference, a model and an inference framework that permit population inference for these detected regions. Pin-down inference provides nonasymptotic point and confidence interval estimators for the mean effect in the region that account for local selection bias. Our estimators accommodate nonstationary covariances that are typical of these data, allowing researchers to better compare regions of different sizes and correlation structures. Inference is provided within a conditional one-parameter exponential family per region, with truncations that match the selection constraints. A secondary screening-and-adjustment step allows pruning the set of detected regions, while controlling the false-coverage rate over the reported regions. We apply the method to genomic regions with differing DNA-methylation rates across tissue. Our method provides superior power compared to other conditional and nonparametric approaches. Supplementary materials for this article are available online.},
author = {Benjamini, Yuval and Taylor, Jonathan and Irizarry, Rafael A.},
doi = {10.1080/01621459.2018.1498347},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Benjamini, Taylor, Irizarry - 2019 - Selection-Corrected Statistical Inference for Region Detection With High-Throughput Assays.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Bump-hunting,Conditional inference,DNA-methylation,Nonstationary process,Selective inference,Spatial statistics},
number = {527},
pages = {1351--1365},
publisher = {Taylor {\&} Francis},
title = {{Selection-Corrected Statistical Inference for Region Detection With High-Throughput Assays}},
url = {https://doi.org/10.1080/01621459.2018.1498347},
volume = {114},
year = {2019}
}
@article{goeman2016simultaneous,
author = {Goeman, J and Meijer, R and Krebs, T and Solari, A},
journal = {arXiv},
keywords = {unpublished},
mendeley-tags = {unpublished},
title = {{Simultaneous Control of All False Discovery Proportions in Large-Scale Multiple Hypothesis Testing}},
year = {2016}
}
@article{Ding2017,
abstract = {Under the potential outcomes framework, causal effects are defined as comparisons between potential outcomes under treatment and control. To infer causal effects from randomized experiments, Neyman proposed to test the null hypothesis of zero average causal effect (Neyman's null), and Fisher proposed to test the null hypothesis of zero individual causal effect (Fisher's null). Although the subtle difference between Neyman's null and Fisher's null has caused a lot of controversies and confusions for both theoretical and practical statisticians, a careful comparison between the two approaches has been lacking in the literature for more than eighty years. We fill this historical gap by making a theoretical comparison between them and highlighting an intriguing paradox that has not been recognized by previous researchers. Logically, Fisher's null implies Neyman's null. It is therefore surprising that, in actual completely randomized experiments, rejection of Neyman's null does not imply rejection of Fisher's null for many realistic situations, including the case with constant causal effect. Furthermore, we show that this paradox also exists in other commonly-used experiments, such as stratified experiments, matched-pair experiments and factorial experiments. Asymptotic analyses, numerical examples and real data examples all support this surprising phenomenon. Besides its historical and theoretical importance, this paradox also leads to useful practical implications for modern researchers.},
archivePrefix = {arXiv},
arxivId = {1402.0142},
author = {Ding, Peng},
doi = {10.1214/16-STS571},
eprint = {1402.0142},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistical Science/Ding - 2017 - A paradox from randomization-based causal inference.pdf:pdf},
issn = {08834237},
journal = {Statistical Science},
keywords = {Average null hypothesis,Fisher randomization test,Potential outcome,Randomized experiment,Repeated sampling property,Sharp null hypothesis,causality,conditional randomization test,permutation test},
mendeley-tags = {causality,conditional randomization test,permutation test},
number = {3},
pages = {331--345},
title = {{A paradox from randomization-based causal inference}},
volume = {32},
year = {2017}
}
@article{ZK12,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/22821350{\}}{\{}22821350{\}}},
author = {Zaitlen, N and Kraft, P},
journal = {Hum. Genet.},
keywords = {GWAS,genetics,heritability},
mendeley-tags = {GWAS,genetics,heritability},
month = {oct},
number = {10},
pages = {1655--1664},
title = {{{\{}H{\}}eritability in the genome-wide association era}},
volume = {131},
year = {2012}
}
@article{Storey02,
author = {Storey, John},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,Multiple testing,pFDR},
mendeley-tags = {FDR,Multiple testing,pFDR},
number = {3},
pages = {479--498},
title = {{A direct approach to false discovery rates}},
volume = {64},
year = {2002}
}
@article{KZI09,
abstract = {Replication helps ensure that a genotype-phenotype association observed in a genome-wide association (GWA) study represents a credible association and is not a chance finding or an artifact due to uncontrolled biases. We discuss prerequisites for exact replication; issues of heterogeneity; advantages and disadvantages of different methods of data synthesis across multiple studies; frequentist vs. Bayesian inferences for replication; and challenges that arise from multi-team collaborations. While consistent replication can greatly improve the credibility of a genotype-phenotype association, it may not eliminate spurious associations due to biases shared by many studies. Conversely, lack of replication in well-powered follow-up studies usually invalidates the initially proposed association, although occasionally it may point to differences in linkage disequilibrium or effect modifiers across studies.},
annote = {20454541},
author = {Kraft, Peter and Zeggini, Eleftheria and Ioannidis, John P A},
journal = {Statistical Science},
keywords = {GWAS},
mendeley-tags = {GWAS},
pages = {561--573},
title = {{{\{}Replication{\}} in Genome-wide Association Studies}},
volume = {24},
year = {2009}
}
@article{Buniello2019,
abstract = {The GWAS Catalog delivers a high-quality curated collection of all published genome-wide association studies enabling investigations to identify causal variants, understand disease mechanisms, and establish targets for novel therapies. The scope of the Catalog has also expanded to targeted and exome arrays with 1000 new associations added for these technologies. As of September 2018, the Catalog contains 5687 GWAS comprising 71673 variant-trait associations from 3567 publications. New content includes 284 full P-value summary statistics datasets for genome-wide and new targeted array studies, representing 6 × 10 9 individual variant-trait statistics. In the last 12 months, the Catalog's user interface was accessed by 1/490000 unique users who viewed {\textgreater}1 million pages. We have improved data access with the release of a new RESTful API to support high-throughput programmatic access, an improved web interface and a new summary statistics database. Summary statistics provision is supported by a new format proposed as a community standard for summary statistics data representation. This format was derived from our experience in standardizing heterogeneous submissions, mapping formats and in harmonizing content. Availability: https://www.ebi.ac.uk/gwas/.},
author = {Buniello, Annalisa and Macarthur, Jacqueline A.L. and Cerezo, Maria and Harris, Laura W. and Hayhurst, James and Malangone, Cinzia and McMahon, Aoife and Morales, Joannella and Mountjoy, Edward and Sollis, Elliot and Suveges, Daniel and Vrousgou, Olga and Whetzel, Patricia L. and Amode, Ridwan and Guillen, Jose A. and Riat, Harpreet S. and Trevanion, Stephen J. and Hall, Peggy and Junkins, Heather and Flicek, Paul and Burdett, Tony and Hindorff, Lucia A. and Cunningham, Fiona and Parkinson, Helen},
doi = {10.1093/nar/gky1120},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nucleic Acids Research/Buniello et al. - 2019 - The NHGRI-EBI GWAS Catalog of published genome-wide association studies, targeted arrays and summary statistics.pdf:pdf},
issn = {13624962},
journal = {Nucleic Acids Research},
keywords = {GWAS},
mendeley-tags = {GWAS},
number = {D1},
pages = {D1005--D1012},
pmid = {30445434},
publisher = {Oxford University Press},
title = {{The NHGRI-EBI GWAS Catalog of published genome-wide association studies, targeted arrays and summary statistics 2019}},
volume = {47},
year = {2019}
}
@article{Balkema1974,
author = {Chernoff, Hermann and Savage, I. Richard},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Mathematical Statistics/Chernoff, Savage - 1957 - Asymptotic normality and efficiency of certain nonparametric test statistics.pdf:pdf},
issn = {0091-1798},
journal = {Annals of Mathematical Statistics},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {4},
pages = {972--994},
title = {{Asymptotic normality and efficiency of certain nonparametric test statistics}},
url = {http://projecteuclid.org/euclid.aop/1176996548},
volume = {29},
year = {1957}
}
@article{Smallwood2014,
abstract = {We report a single-cell bisulfite sequencing (scBSBS-seq) method that can be used to accurately measure DNADNADNA methylation at up to 48.4{\%} of CpG sites. Embryonic stem cells grown in serum or in 2i medium displayed epigenetic heterogeneity, with '2i-like' cells present in serum culture. Integration of 12 individual mouse oocyte datasets largely recapitulated the whole DNADNADNA methylome, which makes scBSBS-seq a versatile tool to explore DNADNADNA methylation in rare cells and heterogeneous populations. {\textcopyright} 2014 Nature America, Inc. All rights reserved.},
author = {Smallwood, S{\'{e}}bastien A. and Lee, Heather J. and Angermueller, Christof and Krueger, Felix and Saadeh, Heba and Peat, Julian and Andrews, Simon R. and Stegle, Oliver and Reik, Wolf and Kelsey, Gavin},
doi = {10.1038/nmeth.3035},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Smallwood et al. - 2014 - Single-cell genome-wide bisulfite sequencing for assessing epigenetic heterogeneity.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
number = {8},
pages = {817--820},
pmid = {25042786},
title = {{Single-cell genome-wide bisulfite sequencing for assessing epigenetic heterogeneity}},
volume = {11},
year = {2014}
}
@article{Wang2019a,
abstract = {Genome-wide association studies (GWAS) have identified more than 100 schizophrenia (SCZ)-associated loci, but using these findings to illuminate disease biology remains a challenge. Here we present integrative risk gene selector (iRIGS), a Bayesian framework that integrates multi-omics data and gene networks to infer risk genes in GWAS loci. By applying iRIGS to SCZ GWAS data, we predicted a set of high-confidence risk genes, most of which are not the nearest genes to the GWAS index variants. High-confidence risk genes account for a significantly enriched heritability, as estimated by stratified linkage disequilibrium score regression. Moreover, high-confidence risk genes are predominantly expressed in brain tissues, especially prenatally, and are enriched for targets of approved drugs, suggesting opportunities to reposition existing drugs for SCZ. Thus, iRIGS can leverage accumulating functional genomics and GWAS data to advance our understanding of SCZ etiology and potential therapeutics.},
author = {Wang, Quan and Chen, Rui},
doi = {10.1038/s41593-019-0382-7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Neuroscience/Wang, Chen - 2019 - A Bayesian framework that integrates multi-omics data and gene networks predicts risk genes from schizophrenia GWAS.pdf:pdf},
isbn = {4159301903827},
journal = {Nature Neuroscience},
keywords = {Kathryn,gene-enhancer,genetics,to-read},
mendeley-tags = {Kathryn,gene-enhancer,genetics,to-read},
pages = {691--699},
title = {{A Bayesian framework that integrates multi-omics data and gene networks predicts risk genes from schizophrenia GWAS data}},
url = {https://doi.org/10.1038/s41593-019-0382-7},
volume = {22},
year = {2019}
}
@article{Huang2018,
abstract = {In single-cell RNA sequencing (scRNA-seq) studies, only a small fraction of the transcripts present in each cell are sequenced. This leads to unreliable quantification of genes with low or moderate expression, which hinders downstream analysis. To address this challenge, we developed SAVER (single-cell analysis via expression recovery), an expression recovery method for unique molecule index (UMI)-based scRNA-seq data that borrows information across genes and cells to provide accurate expression estimates for all genes.},
author = {Huang, Mo and Wang, Jingshu and Torre, Eduardo and Dueck, Hannah and Shaffer, Sydney and Bonasio, Roberto and Murray, John I. and Raj, Arjun and Li, Mingyao and Zhang, Nancy R.},
doi = {10.1038/s41592-018-0033-z},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Huang et al. - 2018 - SAVER Gene expression recovery for single-cell RNA sequencing.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {single cell},
mendeley-tags = {single cell},
number = {7},
pages = {539--542},
pmid = {29941873},
publisher = {Springer US},
title = {{SAVER: Gene expression recovery for single-cell RNA sequencing}},
url = {http://dx.doi.org/10.1038/s41592-018-0033-z},
volume = {15},
year = {2018}
}
@inproceedings{SAFFRON,
author = {Ramdas, Aaditya and Zrnic, Tijana and Wainwright, Martin and Jordan, Michael},
booktitle = {Proceedings of the 35th International Conference on Machine Learning},
keywords = {FDR,Multiple testing,online multiple testing},
mendeley-tags = {FDR,Multiple testing,online multiple testing},
pages = {4286--4294},
title = {{SAFFRON: An adaptive algorithm for online control of the false discovery rate}},
year = {2018}
}
@article{Roquain2019,
abstract = {When performing multiple testing, adjusting the distribution of the null hypotheses is ubiquitous in applications. However, the cost of such an operation remains largely unknown in terms of false discovery proportion (FDP) and true discovery proportion (TDP). We explore this issue in the most classical case where the null hypotheses are Gaussian with an unknown rescaling parameters (mean and variance) and where the Benjamini-Hochberg (BH) procedure is applied after a data-rescaling step. Our main result identifies the following sparsity boundary: an asymptotically optimal rescaling (in some specific sense) exists if and only if the sparsity {\$}k{\$} (number of false nulls) is of order less than {\$}n/\backslashlog(n){\$}, where {\$}n{\$} is the total number of tests. Our proof relies on new non-asymptotic lower bounds on FDP/TDP, which are of independent interest and share similarities with those developed in the minimax robust statistical theory. Further sparsity boundaries are derived for general location models for which the shape of the null distribution is not necessarily Gaussian.},
archivePrefix = {arXiv},
arxivId = {1912.03109},
author = {Roquain, Etienne and Verzelen, Nicolas},
eprint = {1912.03109},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Roquain, Verzelen - 2019 - On using empirical null distribution in Benjamini-Hochberg procedure.pdf:pdf},
journal = {arXiv},
keywords = {and phrases,anomaly detection,false discovery rate,minimax estimator,multiple,robustness,sparsity,testing,true discovery rate,two-point lower bound},
title = {{On using empirical null distribution in Benjamini-Hochberg procedure}},
url = {http://arxiv.org/abs/1912.03109},
year = {2019}
}
@article{MetS12,
author = {Morgan, Xochitl C and Tickle, Timothy L and Sokol, Harry and Gevers, Dirk and Devaney, Kathryn L and Ward, Doyle V and Reyes, Joshua A and Shah, Samir A and LeLeiko, Neal and Snapper, Scott B and Others},
journal = {Genome Biology},
keywords = {microbiome},
mendeley-tags = {microbiome},
number = {9},
pages = {R79},
publisher = {BioMed Central},
title = {{Dysfunction of the intestinal microbiome in inflammatory bowel disease and treatment}},
volume = {13},
year = {2012}
}
@article{Hommel2007,
abstract = {In this paper we present a general testing principle for a class of multiple testing problems based on weighted hypotheses. Under moderate conditions, this principle leads to powerful consonant multiple testing procedures. Furthermore, short-cut versions can be derived, which simplify substantially the implementation and interpretation of the related test procedures. It is shown that many well-known multiple test procedures turn out to be special cases of this general principle. Important examples include gatekeeping procedures, which are often applied in clinical trials when primary and secondary objectives are investigated, and multiple test procedures based on hypotheses which are completely ordered by importance. We illustrate the methodology with two real clinical studies.},
author = {Hommel, Gerhard and Bretz, Frank and Maurer, Willi},
doi = {10.1002/sim},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics in Medicine/Hommel, Bretz, Maurer - 2007 - Powerful short-cuts for multiple testing procedures with special reference to gatekeeping strategies.pdf:pdf},
journal = {Statistics in Medicine},
keywords = {FWER,Multiple testing,closed testing},
mendeley-tags = {FWER,Multiple testing,closed testing},
pages = {4063--4073},
title = {{Powerful short-cuts for multiple testing procedures with special reference to gatekeeping strategies}},
volume = {26},
year = {2007}
}
@article{NetD11,
abstract = {Technological advances make it possible to use high-throughput sequencing as a primary discovery tool of medical genetics, specifically for assaying rare variation. Still this approach faces the analytic challenge that the influence of very rare variants can only be evaluated effectively as a group. A further complication is that any given rare variant could have no effect, could increase risk, or could be protective. We propose here the C-alpha test statistic as a novel approach for testing for the presence of this mixture of effects across a set of rare variants. Unlike existing burden tests, C-alpha, by testing the variance rather than the mean, maintains consistent power when the target set contains both risk and protective variants. Through simulations and analysis of case/control data, we demonstrate good power relative to existing methods that assess the burden of rare variants in individuals.},
annote = {21408211},
author = {Neale, Benjamin M and Rivas, Manuel A and Voight, Benjamin F and Altshuler, David and Devlin, Bernie and Orho-Melander, Marju and Kathiresan, Sekar and Purcell, Shaun M and Roeder, Kathryn and Daly, Mark J},
journal = {PLoS Genetics},
keywords = {rare variants},
mendeley-tags = {rare variants},
pages = {e1001322--e1001322},
title = {{{\{}Testing{\}} for an Unusual Distribution of rare Variants}},
volume = {7},
year = {2011}
}
@article{YetY06,
author = {Benjamini, Yoav and Krieger, Abba M. and Yekutieli, Daniel},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Benjamini, Krieger, Yekutieli - 2006 - Adaptive linear step-up procedures that control the false discovery rate.pdf:pdf},
journal = {Biometrika},
keywords = {FDR,Multiple testing,null proportion adaptivity},
mendeley-tags = {FDR,Multiple testing,null proportion adaptivity},
number = {3},
pages = {491--507},
publisher = {Oxford University Press},
title = {{Adaptive linear step-up procedures that control the false discovery rate}},
volume = {93},
year = {2006}
}
@article{Wang2019,
abstract = {Recent studies have shown that disease-susceptibility variants frequently lie in cell-type-specific enhancer elements. To identify, interpret, and prioritize such risk variants, we must identify the enhancers active in disease-relevant cell types, their upstream transcription factor (TF) binding, and their downstream target genes. To address this need, we built HACER (http://bioinfo.vanderbilt.edu/AE/HACER/), an atlas of Human ACtive Enhancers to interpret Regulatory variants. The HACER atlas catalogues and annotates in-vivo transcribed cell-type-specific enhancers, as well as placing enhancers within transcriptional regulatory networks by integrating ENCODE TF ChIP-Seq and predicted/validated chromatin interaction data. We demonstrate the utility of HACER in (i) offering a mechanistic hypothesis to explain the association of SNP rs614367 with ER-positive breast cancer risk, (ii) exploring tumor-specific enhancers in selective MYC dysregulation and (iii) prioritizing/annotating non-coding regulatory regions targeting CCND1. HACER provides a valuable resource for studies of GWAS, non-coding variants, and enhancer-mediated regulation.},
author = {Wang, Jing and Dai, Xizhen and Berry, Lynne D and Cogan, Joy D and Liu, Qi and Shyr, Yu},
doi = {10.1093/nar/gky864},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nucleic Acids Research/Wang et al. - 2019 - HACER an atlas of human active enhancers to interpret regulatory variants.pdf:pdf},
journal = {Nucleic Acids Research},
keywords = {Kathryn,enhancer,gene-enhancer,to-skim},
mendeley-tags = {Kathryn,enhancer,gene-enhancer,to-skim},
pages = {D106--D112},
title = {{HACER: an atlas of human active enhancers to interpret regulatory variants}},
url = {https://genome.ucsc.edu/cgi-},
volume = {47},
year = {2019}
}
@article{Gasperini2019,
abstract = {Over one million candidate regulatory elements have been identified across the human genome, but nearly all are unvalidated and their target genes uncertain. Approaches based on human genetics are limited in scope to common variants and in resolution by linkage disequilibrium. We present a multiplex, expression quantitative trait locus (eQTL)-inspired framework for mapping enhancer-gene pairs by introducing random combinations of CRISPR/Cas9-mediated perturbations to each of many cells, followed by single-cell RNA sequencing (RNA-seq). Across two experiments, we used dCas9-KRAB to perturb 5,920 candidate enhancers with no strong a priori hypothesis as to their target gene(s), measuring effects by profiling 254,974 single-cell transcriptomes. We identified 664 (470 high-confidence) cis enhancer-gene pairs, which were enriched for specific transcription factors, non-housekeeping status, and genomic and 3D conformational proximity to their target genes. This framework will facilitate the large-scale mapping of enhancer-gene regulatory interactions, a critical yet largely uncharted component of the cis-regulatory landscape of the human genome.},
author = {Gasperini, Molly and Hill, Andrew J. and McFaline-Figueroa, Jos{\'{e}} L. and Martin, Beth and Kim, Seungsoo and Zhang, Melissa D. and Jackson, Dana and Leith, Anh and Schreiber, Jacob and Noble, William S. and Trapnell, Cole and Ahituv, Nadav and Shendure, Jay},
doi = {10.1016/j.cell.2018.11.029},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Gasperini et al. - 2019 - A Genome-wide Framework for Mapping Gene Regulation via Cellular Genetic Screens.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {CRISPR,CRISPRi,Kathryn,RNA-seq,crisprQTL,eQTL,enhancer,gene regulation,genetic screen,human genetics,single cell},
mendeley-tags = {CRISPR,Kathryn},
number = {1-2},
pages = {377--390.e19},
pmid = {30612741},
title = {{A Genome-wide Framework for Mapping Gene Regulation via Cellular Genetic Screens}},
volume = {176},
year = {2019}
}
@article{BR07,
author = {Blanchard, Gilles and Roquain, {\'{E}}tienne},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Machine Learning Research/Blanchard, Roquain - 2009 - Adaptive False Discovery Rate Control under Independence and Dependence.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {FDR,Multiple testing,null proportion adaptivity},
mendeley-tags = {FDR,Multiple testing,null proportion adaptivity},
number = {Dec},
pages = {2837--2871},
title = {{Adaptive False Discovery Rate Control under Independence and Dependence}},
volume = {10},
year = {2009}
}
@article{HetS16,
abstract = {In many genomic applications, hypotheses tests are performed by aggregating test-statistics across units within naturally defined classes for powerful identification of signals. Following class-level testing, it is naturally of interest to identify the lower level units which contain true signals. Testing the individual units within a class without taking into account the fact that the class was selected using an aggregate-level test-statistic, will produce biased inference. We develop a hypothesis testing framework that guarantees control for false positive rates conditional on the fact that the class was selected. Specifically, we develop procedures for calculating unit level p-values that allows rejection of null hypotheses controlling for two types of conditional error rates, one relating to family wise rate and the other relating to false discovery rate. We use simulation studies to illustrate validity and power of the proposed procedure in comparison to several possible alternatives. We illustrate the power of the method in a natural application involving whole-genome expression quantitative trait loci (eQTL) analysis across 17 tissue types using data from The Cancer Genome Atlas (TCGA) Project.},
author = {Heller, Ruth and Chatterjee, Nilanjan and Krieger, Abba and Shi, Jianxin},
doi = {10.1101/058404},
journal = {bioRxiv},
keywords = {post-selection inference,unpublished},
mendeley-tags = {post-selection inference,unpublished},
publisher = {Cold Spring Harbor Labs Journals},
title = {{Post-selection Inference Following Aggregate Level Hypothesis Testing in Large Scale Genomic Data}},
url = {http://biorxiv.org/content/early/2016/06/11/058404},
year = {2016}
}
@article{MB09,
abstract = {Resequencing is an emerging tool for identification of rare disease-associated mutations. Rare mutations are difficult to tag with SNP genotyping, as genotyping studies are designed to detect common variants. However, studies have shown that genetic heterogeneity is a probable scenario for common diseases, in which multiple rare mutations together explain a large proportion of the genetic basis for the disease. Thus, we propose a weighted-sum method to jointly analyse a group of mutations in order to test for groupwise association with disease status. For example, such a group of mutations may result from resequencing a gene. We compare the proposed weighted-sum method to alternative methods and show that it is powerful for identifying disease-associated genes, both on simulated and Encode data. Using the weighted-sum method, a resequencing study can identify a disease-associated gene with an overall population attributable risk (PAR) of 2{\%}, even when each individual mutation has much lower PAR, using 1,000 to 7,000 affected and unaffected individuals, depending on the underlying genetic model. This study thus demonstrates that resequencing studies can identify important genetic associations, provided that specialised analysis methods, such as the weighted-sum method, are used.},
annote = {19214210},
author = {Madsen, B E and Browning, S R},
doi = {10.1371/journal.pgen.1000384},
journal = {PLoS Genetics},
number = {2},
pages = {e1000384--e1000384},
title = {{A groupwise association test for rare mutations using a weighted sum statistic}},
url = {http://www.hubmed.org/display.cgi?uids=19214210},
volume = {5},
year = {2009}
}
@article{ZSE07,
abstract = {We study a two-stage analysis of genetic association for case-control studies. In the first stage, we compare Hardy-Weinberg disequilibrium coefficients between cases and controls and, in the second stage, we apply the Cochran- Armitage trend test. The two analyses are statistically independent when Hardy-Weinberg equilibrium holds in the population, so all the samples are used in both stages. The significance level in the first stage is adaptively determined based on its conditional power. Given the level in the first stage, the level for the second stage analysis is determined with the overall Type I error being asymptotically controlled. For finite sample sizes, a parametric bootstrap method is used to control the overall Type I error rate. This two-stage analysis is often more powerful than the Cochran-Armitage trend test alone for a large association study. The new approach is applied to SNPs from a real study.},
annote = {17310127},
author = {Zheng, Gang and Song, Kijoung and Elston, Robert C},
journal = {Hum Hered},
pages = {175--186},
title = {{{\{}Adaptive{\}} Two-stage Analysis of Genetic Association in Case-control Designs}},
volume = {63},
year = {2007}
}
@article{Vieth2019,
abstract = {The recent rapid spread of single cell RNA sequencing (scRNA-seq) methods has created a large variety of experimental and computational pipelines for which best practices have not yet been established. Here, we use simulations based on five scRNA-seq library protocols in combination with nine realistic differential expression (DE) setups to systematically evaluate three mapping, four imputation, seven normalisation and four differential expression testing approaches resulting in {\~{}}3000 pipelines, allowing us to also assess interactions among pipeline steps. We find that choices of normalisation and library preparation protocols have the biggest impact on scRNA-seq analyses. Specifically, we find that library preparation determines the ability to detect symmetric expression differences, while normalisation dominates pipeline performance in asymmetric DE-setups. Finally, we illustrate the importance of informed choices by showing that a good scRNA-seq pipeline can have the same impact on detecting a biological signal as quadrupling the sample size.},
author = {Vieth, Beate and Parekh, Swati and Ziegenhain, Christoph and Enard, Wolfgang and Hellmann, Ines},
doi = {10.1038/s41467-019-12266-7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Vieth et al. - 2019 - A systematic evaluation of single cell RNA-seq analysis pipelines.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
keywords = {differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {1},
pages = {1--11},
pmid = {31604912},
publisher = {Springer US},
title = {{A systematic evaluation of single cell RNA-seq analysis pipelines}},
url = {http://dx.doi.org/10.1038/s41467-019-12266-7},
volume = {10},
year = {2019}
}
@article{Liu2018a,
abstract = {In this paper, we present a new variable selection method for regression and classification purposes. Our method, called Subsampling Ranking Forward selection (SuRF), is based on LASSO penalised regression, subsampling and forward-selection methods. SuRF offers major advantages over existing variable selection methods in terms of both sparsity of selected models and model inference. We provide an R package that can implement our method for generalized linear models. We apply our method to classification problems from microbiome data, using a novel agglomeration approach to deal with the special tree-like correlation structure of the variables. Existing methods arbitrarily choose a taxonomic level a priori before performing the analysis, whereas by combining SuRF with these aggregated variables, we are able to identify the key biomarkers at the appropriate taxonomic level, as suggested by the data. We present simulations in multiple sparse settings to demonstrate that our approach performs better than several other popularly used existing approaches in recovering the true variables. We apply SuRF to two microbiome data sets: one about prediction of pouchitis and another for identifying samples from two healthy individuals. We find that SuRF can provide a better or comparable prediction with other methods while controlling the false positive rate of variable selection.},
archivePrefix = {arXiv},
arxivId = {arXiv:1909.06439v1},
author = {Liu, Lihui and Gu, Hong and Limbergen, Johan Van and Kenney, Toby},
doi = {10.1111/j.1541-0420.2005.00454.x},
eprint = {arXiv:1909.06439v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Liu et al. - 2019 - SuRF a New Method for Sparse Variable Selection, with Application in Microbiome Data Analysis.pdf:pdf},
journal = {arXiv},
keywords = {forward selection,generalised linear models,lasso,microbiome,stabil-,surf,to-skim,variable selection},
mendeley-tags = {microbiome,to-skim,variable selection},
title = {{SuRF: a New Method for Sparse Variable Selection, with Application in Microbiome Data Analysis}},
year = {2019}
}
@article{Petralia2015,
abstract = {{\textcopyright} The Author 2015. Published by Oxford University Press. Motivation: Gene regulatory network (GRN) inference based on genomic data is one of the most actively pursued computational biological problems. Because different types of biological data usually provide complementary information regarding the underlying GRN, a model that integrates big data of diverse types is expected to increase both the power and accuracy of GRN inference. Towards this goal, we propose a novel algorithm named iRafNet: integrative random forest for gene regulatory network inference. Results: iRafNet is a flexible, unified integrative framework that allows information from heterogeneous data, such as protein-protein interactions, transcription factor (TF)-DNA-binding, gene knock-down, to be jointly considered for GRN inference. Using test data from the DREAM4 and DREAM5 challenges, we demonstrate that iRafNet outperforms the original random forest based network inference algorithm (GENIE3), and is highly comparable to the community learning approach. We apply iRafNet to construct GRN in Saccharomyces cerevisiae and demonstrate that it improves the performance in predicting TF-target gene regulations and provides additional functional insights to the predicted gene regulations.},
author = {Petralia, Francesca and Wang, Pei and Yang, Jialiang and Tu, Zhidong},
doi = {10.1093/bioinformatics/btv268},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Petralia et al. - 2015 - Integrative random forest for gene regulatory network inference.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
keywords = {Kathryn,networks},
mendeley-tags = {Kathryn,networks},
number = {12},
pages = {i197--i205},
title = {{Integrative random forest for gene regulatory network inference}},
url = {http://research.mssm.edu/tulab/software/irafnet.html},
volume = {31},
year = {2015}
}
@article{scott,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/24522887{\}}{\{}24522887{\}}},
author = {Fears, S C and Service, S K and Kremeyer, B and Araya, C and Araya, X and Bejarano, J and Ramirez, M and Castrillon, G and Gomez-Franco, J and Lopez, M C and Montoya, G and Montoya, P and Aldana, I and Teshiba, T M and Abaryan, Z and Al-Sharif, N B and Ericson, M and Jalbrzikowski, M and Luykx, J J and Navarro, L and Tishler, T A and Altshuler, L and Bartzokis, G and Escobar, J and Glahn, D C and Ospina-Duque, J and Risch, N and Ruiz-Linares, A and Thompson, P M and Cantor, R M and Lopez-Jaramillo, C and Macaya, G and Molina, J and Reus, V I and Sabatti, C and Freimer, N B and Bearden, C E},
journal = {JAMA Psychiatry},
month = {apr},
number = {4},
pages = {375--387},
title = {{{\{}M{\}}ultisystem component phenotypes of bipolar disorder for genetic investigations of extended pedigrees}},
volume = {71},
year = {2014}
}
@article{Illig2010,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/20037589{\}}{\{}20037589{\}}},
author = {Illig, T and Gieger, C and Zhai, G and R{\"{o}}misch-Margl, W and Wang-Sattler, R and Prehn, C and Altmaier, E and Kastenm{\"{u}}ller, G and Kato, B S and Mewes, H and Others},
journal = {Nature Genetics},
number = {2},
pages = {137--141},
title = {{A genome-wide perspective of genetic variation in human metabolism}},
volume = {42},
year = {2010}
}
@article{Ibragimov1975,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Ibragimov, I. A. and Khasminskii, R. Z.},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Theory of Probability and its Applications/Ibragimov, Khasminskii - 1975 - Local asymptotic normality for non-identically distributed observations.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
journal = {Theory of Probability and its Applications},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {2},
pages = {246--260},
pmid = {25246403},
title = {{Local asymptotic normality for non-identically distributed observations}},
volume = {20},
year = {1975}
}
@article{Yu2019,
abstract = {Including pairwise interactions between the predictors of a regression model can produce better predicting models. However, to fit such interaction models on typical data sets in biology and other fields can often require solving enormous variable selection problems with billions of interactions. The scale of such problems demands methods that are computationally cheap (both in time and memory) yet still have sound statistical properties. Motivated by these large-scale problem sizes, we adopt a very simple guiding principle: One should prefer a main effect over an interaction if all else is equal. This "reluctance" to interactions, while reminiscent of the hierarchy principle for interactions, is much less restrictive. We design a computationally efficient method built upon this principle and provide theoretical results indicating favorable statistical properties. Empirical results show dramatic computational improvement without sacrificing statistical properties. For example, the proposed method can solve a problem with 10 billion interactions with 5-fold cross-validation in under 7 hours on a single CPU.},
archivePrefix = {arXiv},
arxivId = {1907.08414v1},
author = {Yu, Guo and Bien, Jacob and Tibshirani, Ryan},
eprint = {1907.08414v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Yu, Bien, Tibshirani - 2019 - Reluctant Interaction Modeling.pdf:pdf},
journal = {arXiv},
keywords = {high-dimensional regression,interactions,large-scale interaction modeling,sub-Weibull distribution,variable screening,variable selection},
mendeley-tags = {high-dimensional regression,interactions,variable selection},
title = {{Reluctant Interaction Modeling}},
year = {2019}
}
@article{Holst1980,
author = {Holst, Lars and Rao, J . S .},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Sankhyā The Indian Journal of Statistics, Series A/Holst, Rao - 1980 - Asymptotic Theory for Some Families of Two-Sample Nonparametric Statistics.pdf:pdf},
journal = {Sankhyā: The Indian Journal of Statistics, Series A},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {1},
pages = {19--52},
title = {{Asymptotic Theory for Some Families of Two-Sample Nonparametric Statistics}},
volume = {42},
year = {1980}
}
@techreport{Hafemeister2020,
author = {Hafemeister, Christoph and Satija, Rahul},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Hafemeister, Satija - 2020 - Analyzing scRNA-seq data with the sctransform and offset models.pdf:pdf},
keywords = {single cell},
mendeley-tags = {single cell},
title = {{Analyzing scRNA-seq data with the sctransform and offset models}},
year = {2020}
}
@article{Werling2018,
abstract = {Genomic association studies of common or rare protein-coding variation have established robust statistical approaches to account for multiple testing. Here we present a comparable framework to evaluate rare and de novo noncoding single-nucleotide variants, insertion/deletions, and all classes of structural variation from whole-genome sequencing (WGS). Integrating genomic annotations at the level of nucleotides, genes, and regulatory regions, we define 51,801 annotation categories. Analyses of 519 autism spectrum disorder families did not identify association with any categories after correction for 4,123 effective tests. Without appropriate correction, biologically plausible associations are observed in both cases and controls. Despite excluding previously identified gene-disrupting mutations, coding regions still exhibited the strongest associations. Thus, in autism, the contribution of de novo noncoding variation is probably modest in comparison to that of de novo coding variants. Robust results from future WGS studies will require large cohorts and comprehensive analytical strategies that consider the substantial multiple-testing burden.},
author = {Werling, Donna M. and Brand, Harrison and An, Joon Yong and Stone, Matthew R. and Zhu, Lingxue and Glessner, Joseph T. and Collins, Ryan L. and Dong, Shan and Layer, Ryan M. and Markenscoff-Papadimitriou, Eirene and Farrell, Andrew and Schwartz, Grace B. and Wang, Harold Z. and Currall, Benjamin B. and Zhao, Xuefang and Dea, Jeanselle and Duhn, Clif and Erdman, Carolyn A. and Gilson, Michael C. and Yadav, Rachita and Handsaker, Robert E. and Kashin, Seva and Klei, Lambertus and Mandell, Jeffrey D. and Nowakowski, Tomasz J. and Liu, Yuwen and Pochareddy, Sirisha and Smith, Louw and Walker, Michael F. and Waterman, Matthew J. and He, Xin and Kriegstein, Arnold R. and Rubenstein, John L. and Sestan, Nenad and McCarroll, Steven A. and Neale, Benjamin M. and Coon, Hilary and Willsey, A. Jeremy and Buxbaum, Joseph D. and Daly, Mark J. and State, Matthew W. and Quinlan, Aaron R. and Marth, Gabor T. and Roeder, Kathryn and Devlin, Bernie and Talkowski, Michael E. and Sanders, Stephan J.},
doi = {10.1038/s41588-018-0107-y},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Werling et al. - 2018 - An analytical framework for whole-genome sequence association studies and its implications for autism spectrum d.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Werling et al. - 2018 - An analytical framework for whole-genome sequence association studies and its implications for autism spectru(2).pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {Kathryn,autism,de novo mutations,psychiatric genomics,whole genome sequencing},
mendeley-tags = {Kathryn,autism,de novo mutations,psychiatric genomics,whole genome sequencing},
number = {5},
pages = {727--736},
title = {{An analytical framework for whole-genome sequence association studies and its implications for autism spectrum disorder}},
url = {https://doi.org/10.1038/s41588-018-0107-y},
volume = {50},
year = {2018}
}
@article{FBR15,
author = {{Foygel Barber}, Rina and Ramdas, Aaditya},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,Multiple testing,groups},
mendeley-tags = {FDR,Multiple testing,groups},
number = {4},
pages = {1247--1268},
title = {{The p-filter: multi-layer false discovery rate control for grouped hypotheses}},
volume = {79},
year = {2016}
}
@article{ADB97,
abstract = {Power to detect linkage and localization of a major gene were compared in univariate and bivariate variance components linkage analysis of three related quantitative traits in general pedigrees. Although both methods demonstrated adequate power to detect loci of moderate effect, bivariate analysis improved both power and localization for correlated quantitative traits mapping to the same chromosomal region, regardless of whether co-localization was the result of pleiotropy. Additionally, a test of pleiotropy versus co-incident linkage was shown to have adequate power and a low error rate.},
annote = {9433606},
author = {Almasy, L and Dyer, T D and Blangero, J},
journal = {Genetic Epidemiology},
keywords = {genetics},
mendeley-tags = {genetics},
pages = {953--958},
title = {{{\{}Bivariate{\}} Quantitative Trait Linkage Analysis: Pleiotropy Versus Co-incident Linkages}},
volume = {14},
year = {1997}
}
@article{Weir,
author = {Weir, Tiffany L and Manter, Daniel K and Sheflin, Amy M and Barnett, Brittany A and Heuberger, Adam L and Ryan, Elizabeth P},
journal = {PloS One},
keywords = {microbiome},
mendeley-tags = {microbiome},
number = {8},
pages = {e70803},
title = {{Stool microbiome and metabolome differences between colorectal cancer patients and healthy adults}},
volume = {8},
year = {2013}
}
@article{WetH14,
author = {Welter, Danielle and MacArthur, Jacqueline and Morales, Joannella and Burdett, Tony and Hall, Peggy and Junkins, Heather and Klemm, Alan and Flicek, Paul and Manolio, Teri and Hindorff, Lucia and Others},
journal = {Nucleic Acids Research},
number = {D1},
pages = {D1001----D1006},
publisher = {Oxford Univ Press},
title = {{The {\{}NHGRI{\}} {\{}GWAS{\}} Catalog, a curated resource of {\{}SNP{\}}-trait associations}},
volume = {42},
year = {2014}
}
@article{Shilo2020,
abstract = {Health data are increasingly being generated at a massive scale, at various levels of phenotyping and from different types of resources. Concurrent with recent technological advances in both data-generation infrastructure and data-analysis methodologies, there have been many claims that these events will revolutionize healthcare, but such claims are still a matter of debate. Addressing the potential and challenges of big data in healthcare requires an understanding of the characteristics of the data. Here we characterize various properties of medical data, which we refer to as ‘axes' of data, describe the considerations and tradeoffs taken when such data are generated, and the types of analyses that may achieve the tasks at hand. We then broadly describe the potential and challenges of using big data in healthcare resources, aiming to contribute to the ongoing discussion of the potential of big data resources to advance the understanding of health and disease.},
author = {Shilo, Smadar and Rossman, Hagai and Segal, Eran},
doi = {10.1038/s41591-019-0727-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Medicine/Shilo, Rossman, Segal - 2020 - Axes of a revolution challenges and promises of big data in healthcare.pdf:pdf},
issn = {1546170X},
journal = {Nature Medicine},
keywords = {causality},
mendeley-tags = {causality},
number = {1},
pages = {29--38},
pmid = {31932803},
publisher = {Springer US},
title = {{Axes of a revolution: challenges and promises of big data in healthcare}},
url = {http://dx.doi.org/10.1038/s41591-019-0727-5},
volume = {26},
year = {2020}
}
@inproceedings{CetB09,
author = {Charlesworth, Jac C and Peralta, Juan M and Drigalenko, Eugene and G{\"{o}}ring, Harald H H and Almasy, Laura and Dyer, Thomas D and Blangero, John},
booktitle = {BMC proceedings},
number = {7},
organization = {BioMed Central},
pages = {S92},
title = {{Toward the identification of causal genes in complex diseases: a gene-centric joint test of significance combining genomic and transcriptomic data}},
volume = {3},
year = {2009}
}
@article{Renaux2019,
abstract = {We provide a view on high-dimensional statistical inference for genome-wide association studies (GWAS). It is in part a review but covers also new developments for meta analysis with multiple studies and novel software in terms of an R-package hierinf. Inference and assessment of significance is based on very high-dimensional multivariate (generalized) linear models: in contrast to often used marginal approaches, this provides a step towards more causal-oriented inference.},
archivePrefix = {arXiv},
arxivId = {1805.02988v3},
author = {Renaux, Claude and Buzdugan, Laura and Kalisch, Markus and B{\"{u}}hlmann, Peter},
eprint = {1805.02988v3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Renaux et al. - 2019 - Hierarchical inference for genome-wide association studies a view on methodology with software.pdf:pdf},
journal = {arXiv},
keywords = {GWAS,hierarchical multiple testing,high-dimensional regression,to-skim,unpublished},
mendeley-tags = {GWAS,hierarchical multiple testing,high-dimensional regression,to-skim,unpublished},
title = {{Hierarchical inference for genome-wide association studies: a view on methodology with software}},
year = {2019}
}
@article{GR11,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21685087{\}}{\{}21685087{\}}},
author = {Golan, D and Rosset, S},
journal = {Bioinformatics},
keywords = {GWAS,linear mixed models},
mendeley-tags = {GWAS,linear mixed models},
month = {jul},
number = {13},
pages = {i317----323},
title = {{{\{}A{\}}ccurate estimation of heritability in genome wide studies using random effects models}},
volume = {27},
year = {2011}
}
@article{Burmistrz2020,
abstract = {Clustered Regularly Interspaced Short Palindromic Repeats (CRISPR)–CRISPR-associated (Cas) systems have revolutionized modern molecular biology. Numerous types of these systems have been discovered to date. Many CRISPR–Cas systems have been used as a backbone for the development of potent research tools, with Cas9 being the most widespread. While most of the utilized systems are DNA-targeting, recently more and more attention is being gained by those that target RNA. Their ability to specifically recognize a given RNA sequence in an easily programmable way makes them ideal candidates for developing new research tools. In this review we summarize current knowledge on CRISPR–Cas systems which have been shown to target RNA molecules, that is type III (Csm/Cmr), type VI (Cas13), and type II (Cas9). We also present a list of available technologies based on these systems.},
author = {Burmistrz, Michal and Krakowski, Kamil and Krawczyk-Balska, Agata},
doi = {10.3390/ijms21031122},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/International Journal of Molecular Sciences/Burmistrz, Krakowski, Krawczyk-Balska - 2020 - RNA-targeting CRISPR–cas systems and their applications.pdf:pdf},
issn = {14220067},
journal = {International Journal of Molecular Sciences},
keywords = {CRISPR,Cas,Cas13,Cas9,Cmr,Csm,RNA},
mendeley-tags = {CRISPR},
number = {3},
pmid = {32046217},
title = {{RNA-targeting CRISPR–cas systems and their applications}},
volume = {21},
year = {2020}
}
@article{Liu2018,
abstract = {Analysis of de novo mutations (DNMs) from sequencing data of nuclear families has identified risk genes for many complex diseases, including multiple neurodevelopmental and psychiatric disorders. Most of these efforts have focused on mutations in protein-coding sequences. Evidence from genome-wide association studies (GWASs) strongly suggests that variants important to human diseases often lie in non-coding regions. Extending DNM-based approaches to non-coding sequences is challenging, however, because the functional significance of non-coding mutations is difficult to predict. We propose a statistical framework for analyzing DNMs from whole-genome sequencing (WGS) data. This method, TADA-Annotations (TADA-A), is a major advance of the TADA method we developed earlier for DNM analysis in coding regions. TADA-A is able to incorporate many functional annotations such as conservation and enhancer marks, to learn from data which annotations are informative of pathogenic mutations, and to combine both coding and non-coding mutations at the gene level to detect risk genes. It also supports meta-analysis of multiple DNM studies, while adjusting for study-specific technical effects. We applied TADA-A to WGS data of ∼300 autism-affected family trios across five studies and discovered several autism risk genes. The software is freely available for all research uses.},
author = {Liu, Yuwen and Liang, Yanyu and Cicek, A. Ercument and Li, Zhongshan and Li, Jinchen and Muhle, Rebecca A. and Krenzer, Martina and Mei, Yue and Wang, Yan and Knoblauch, Nicholas and Morrison, Jean and Zhao, Siming and Jiang, Yi and Geller, Evan and Ionita-Laza, Iuliana and Wu, Jinyu and Xia, Kun and Noonan, James P. and Sun, Zhong Sheng and He, Xin},
doi = {10.1016/j.ajhg.2018.03.023},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Human Genetics/Liu et al. - 2018 - A Statistical Framework for Mapping Risk Genes from De Novo Mutations in Whole-Genome-Sequencing Studies.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Human Genetics/Liu et al. - 2018 - A Statistical Framework for Mapping Risk Genes from De Novo Mutations in Whole-Genome-Sequencing Studies(2).pdf:pdf},
issn = {15376605},
journal = {American Journal of Human Genetics},
keywords = {Kathryn,TADA,autism,de novo mutations,epigenomics,noncoding sequences,psychiatric disorders,psychiatric genomics,statistical model,whole genome sequencing},
mendeley-tags = {Kathryn,TADA,autism,de novo mutations,psychiatric genomics,whole genome sequencing},
number = {6},
pages = {1031--1047},
title = {{A Statistical Framework for Mapping Risk Genes from De Novo Mutations in Whole-Genome-Sequencing Studies}},
volume = {102},
year = {2018}
}
@article{benjamini1999step,
author = {Benjamini, Yoav and Liu, Wei},
journal = {Journal of Statistical Planning and Inference},
keywords = {FDR,multiple testing},
mendeley-tags = {FDR,multiple testing},
number = {1},
pages = {163--170},
publisher = {Elsevier},
title = {{A step-down multiple hypotheses testing procedure that controls the false discovery rate under independence}},
volume = {82},
year = {1999}
}
@article{Replogle2020,
abstract = {Single-cell CRISPR screens enable the exploration of mammalian gene function and genetic regulatory networks. However, use of this technology has been limited by reliance on indirect indexing of single-guide RNAs (sgRNAs). Here we present direct-capture Perturb-seq, a versatile screening approach in which expressed sgRNAs are sequenced alongside single-cell transcriptomes. Direct-capture Perturb-seq enables detection of multiple distinct sgRNA sequences from individual cells and thus allows pooled single-cell CRISPR screens to be easily paired with combinatorial perturbation libraries that contain dual-guide expression vectors. We demonstrate the utility of this approach for high-throughput investigations of genetic interactions and, leveraging this ability, dissect epistatic interactions between cholesterol biogenesis and DNA repair. Using direct capture Perturb-seq, we also show that targeting individual genes with multiple sgRNAs per cell improves efficacy of CRISPR interference and activation, facilitating the use of compact, highly active CRISPR libraries for single-cell screens. Last, we show that hybridization-based target enrichment permits sensitive, specific sequencing of informative transcripts from single-cell RNA-seq experiments.},
author = {Replogle, Joseph M. and Norman, Thomas M. and Xu, Albert and Hussmann, Jeffrey A. and Chen, Jin and Cogan, J. Zachery and Meer, Elliott J. and Terry, Jessica M. and Riordan, Daniel P. and Srinivas, Niranjan and Fiddes, Ian T. and Arthur, Joseph G. and Alvarado, Luigi J. and Pfeiffer, Katherine A. and Mikkelsen, Tarjei S. and Weissman, Jonathan S. and Adamson, Britt},
doi = {10.1038/s41587-020-0470-y},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Replogle et al. - 2020 - Combinatorial single-cell CRISPR screens by direct guide RNA capture and targeted sequencing.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Replogle et al. - 2020 - Combinatorial single-cell CRISPR screens by direct guide RNA capture and targeted sequencing(2).pdf:pdf},
issn = {15461696},
journal = {Nature Biotechnology},
keywords = {CRISPR,Kathryn,single cell},
mendeley-tags = {CRISPR,Kathryn,single cell},
pmid = {32231336},
publisher = {Springer US},
title = {{Combinatorial single-cell CRISPR screens by direct guide RNA capture and targeted sequencing}},
year = {2020}
}
@article{Stute2007,
abstract = {In this article we study inference in parametric-nonparametric errors-in-covariables regression models using an empirical likelihood approach based on validation data. It is shown that the asymptotic behavior of the proposed estimator depends on the ratio of the sizes of the primary sample and the validation sample, respectively. Unlike cases without measurement errors, the limit distribution of the estimator is no longer tractable and cannot be used for constructing confidence regions. Monte Carlo approximations are employed to simulate the limit distribution. To increase the coverage accuracy of confidence regions, two adjusted empirical likelihood estimators are recommended, which in the limit have a standard chi-squared distribution. A simulation study is carried out to compare the proposed methods with other existing methods. The new methods outperform the least squares method, and one of them works better than simulation-extrapolation (SIMEX) estimation, even when the restrictive model assumptions needed for SIMEX are satisfied. An application to a real dataset illustrates our new approach. {\textcopyright} 2007 American Statistical Association.},
author = {Stute, Winfried and Xue, Liugen and Zhu, Lixing},
doi = {10.1198/016214506000000816},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Stute, Xue, Zhu - 2007 - Empirical likelihood inference in nonlinear errors-in-covariables models with validation data.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Confidence regions: Empirical likelihood,Errors in covariahles: Nnnpurametric estimation,Validation data,error-in-variables},
mendeley-tags = {error-in-variables},
number = {477},
pages = {332--346},
title = {{Empirical likelihood inference in nonlinear errors-in-covariables models with validation data}},
volume = {102},
year = {2007}
}
@article{Won2016,
abstract = {Three-dimensional physical interactions within chromosomes dynamically regulate gene expression in a tissue-specific manner. However, the 3D organization of chromosomes during human brain development and its role in regulating gene networks dysregulated in neurodevelopmental disorders, such as autism or schizophrenia, are unknown. Here we generate high-resolution 3D maps of chromatin contacts during human corticogenesis, permitting large-scale annotation of previously uncharacterized regulatory relationships relevant to the evolution of human cognition and disease. Our analyses identify hundreds of genes that physically interact with enhancers gained on the human lineage, many of which are under purifying selection and associated with human cognitive function. We integrate chromatin contacts with non-coding variants identified in schizophrenia genome-wide association studies (GWAS), highlighting multiple candidate schizophrenia risk genes and pathways, including transcription factors involved in neurogenesis, and cholinergic signalling molecules, several of which are supported by independent expression quantitative trait loci and gene expression analyses. Genome editing in human neural progenitors suggests that one of these distal schizophrenia GWAS loci regulates FOXG1 expression, supporting its potential role as a schizophrenia risk gene. This work provides a framework for understanding the effect of non-coding regulatory elements on human brain development and the evolution of cognition, and highlights novel mechanisms underlying neuropsychiatric disorders.},
author = {Won, Hyejung and {De La Torre-Ubieta}, Luis and Stein, Jason L. and Parikshak, Neelroop N. and Huang, Jerry and Opland, Carli K. and Gandal, Michael J. and Sutton, Gavin J. and Hormozdiari, Farhad and Lu, Daning and Lee, Changhoon and Eskin, Eleazar and Voineagu, Irina and Ernst, Jason and Geschwind, Daniel H.},
doi = {10.1038/nature19847},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Won et al. - 2016 - Chromosome conformation elucidates regulatory relationships in developing human brain.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {HI-C,Kathryn,gene-enhancer,genetics},
mendeley-tags = {HI-C,Kathryn,gene-enhancer,genetics},
number = {7626},
pages = {523--527},
publisher = {Nature Publishing Group},
title = {{Chromosome conformation elucidates regulatory relationships in developing human brain}},
url = {http://dx.doi.org/10.1038/nature19847},
volume = {538},
year = {2016}
}
@article{Katsevich2020a,
abstract = {For testing conditional independence (CI) of a response {\$}Y{\$} and a predictor {\$}X{\$} given covariates {\$}Z{\$}, the recently introduced model-X (MX) framework has been the subject of active methodological research, especially in the context of MX knockoffs and their successful application to genome-wide association studies. In this paper, we build a theoretical foundation for the MX CI problem, yielding quantitative explanations for empirically observed phenomena and novel insights to guide the design of MX methodology. We focus our analysis on the conditional randomization test (CRT), whose validity conditional on {\$}Y,Z{\$} allows us to view it as a test of a point null hypothesis involving the conditional distribution of {\$}X{\$}. We use the Neyman-Pearson lemma to derive an intuitive most-powerful CRT statistic against a point alternative as well as an analogous result for MX knockoffs. We define MX analogs of {\$}t{\$}- and {\$}F{\$}- tests and derive their power against local semiparametric alternatives using Le Cam's local asymptotic normality theory, explicitly capturing the prediction error of the underlying machine learning procedure. Importantly, all our results hold conditionally on {\$}Y,Z{\$}, almost surely in {\$}Y,Z{\$}. Finally, we define nonparametric notions of effect size and derive consistent estimators inspired by semiparametric statistics. Thus, this work forms explicit, and underexplored, bridges from MX to both classical statistics (testing) and modern causal inference (estimation).},
archivePrefix = {arXiv},
arxivId = {2005.05506},
author = {Katsevich, Eugene and Ramdas, Aaditya},
eprint = {2005.05506},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Katsevich, Ramdas - 2020 - A theoretical treatment of conditional independence testing under Model-X.pdf:pdf},
journal = {arXiv},
title = {{A theoretical treatment of conditional independence testing under Model-X}},
url = {http://arxiv.org/abs/2005.05506},
year = {2020}
}
@article{Tansey2018a,
abstract = {Personalized cancer treatments based on the molecular profile of a patient's tumor are an emerging and exciting class of treatments in oncology. As genomic tumor profiling is becoming more common, targeted treatments to specific molecular alterations are gaining traction. To discover new potential therapeutics that may apply to broad classes of tumors matching some molecular pattern, experimentalists and pharmacologists rely on high-throughput, in-vitro screens of many compounds against many different cell lines. We propose a hierarchical Bayesian model of how cancer cell lines respond to drugs in these experiments and develop a method for fitting the model to real-world high-throughput screening data. Through a case study, the model is shown to capture nontrivial associations between molecular features and drug response, such as requiring both wild type TP53 and overexpression of MDM2 to be sensitive to Nutlin-3(a). In quantitative benchmarks, the model outperforms a standard approach in biology, with {\~{}}20{\%} lower predictive error on held out data. When combined with a conditional randomization testing procedure, the model discovers biomarkers of therapeutic response that recapitulate known biology and suggest new avenues for investigation. All code for the paper is publicly available at https://github.com/tansey/deep-dose-response.},
archivePrefix = {arXiv},
arxivId = {1812.05691},
author = {Tansey, Wesley and Li, Kathy and Zhang, Haoran and Linderman, Scott W. and Rabadan, Raul and Blei, David M. and Wiggins, Chris H.},
eprint = {1812.05691},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Tansey et al. - 2018 - Dose-response modeling in high-throughput cancer drug screenings An end-to-end approach.pdf:pdf},
journal = {arXiv},
pages = {1--24},
title = {{Dose-response modeling in high-throughput cancer drug screenings: An end-to-end approach}},
url = {http://arxiv.org/abs/1812.05691},
year = {2018}
}
@article{LetS13,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23610370{\}}{\{}23610370{\}}},
author = {Lange, K and Papp, J C and Sinsheimer, J S and Sripracha, R and Zhou, H and Sobel, E M},
journal = {Bioinformatics},
keywords = {genetics,software},
mendeley-tags = {genetics,software},
month = {jun},
number = {12},
pages = {1568--1570},
title = {{{\{}M{\}}endel: the {\{}S{\}}wiss army knife of genetic analysis programs}},
volume = {29},
year = {2013}
}
@article{ZetLi10,
abstract = {Studies of the relationship between DNA variation and gene expression variation, often referred to as "expression quantitative trait loci (eQTL) mapping", have been conducted in many species and resulted in many significant findings. Because of the large number of genes and genetic markers in such analyses, it is extremely challenging to discover how a small number of eQTLs interact with each other to affect mRNA expression levels for a set of co-regulated genes. We present a Bayesian method to facilitate the task, in which co-expressed genes mapped to a common set of markers are treated as a module characterized by latent indicator variables. A Markov chain Monte Carlo algorithm is designed to search simultaneously for the module genes and their linked markers. We show by simulations that this method is more powerful for detecting true eQTLs and their target genes than traditional QTL mapping methods. We applied the procedure to a data set consisting of gene expression and genotypes for 112 segregants of S. cerevisiae. Our method identified modules containing genes mapped to previously reported eQTL hot spots, and dissected these large eQTL hot spots into several modules corresponding to possibly different biological functions or primary and secondary responses to regulatory perturbations. In addition, we identified nine modules associated with pairs of eQTLs, of which two have been previously reported. We demonstrated that one of the novel modules containing many daughter-cell expressed genes is regulated by AMN1 and BPH1. In conclusion, the Bayesian partition method which simultaneously considers all traits and all markers is more powerful for detecting both pleiotropic and epistatic effects based on both simulated and empirical data.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/20090830{\}}{\{}20090830{\}}},
author = {Zhang, W and Zhu, J and Schadt, E E and Liu, J S},
doi = {10.1371/journal.pcbi.1000642},
journal = {PLoS Comput Biol},
keywords = {gene expression,genetics},
mendeley-tags = {gene expression,genetics},
number = {1},
title = {{A Bayesian partition method for detecting pleiotropic and epistatic eQTL modules}},
url = {http://www.hubmed.org/display.cgi?uids=20090830},
volume = {6},
year = {2010}
}
@article{Wang2019e,
abstract = {Background: The analysis of single-cell RNA sequencing (scRNAseq) data plays an important role in understanding the intrinsic and extrinsic cellular processes in biological and biomedical research. One significant effort in this area is the detection of differentially expressed (DE) genes. scRNAseq data, however, are highly heterogeneous and have a large number of zero counts, which introduces challenges in detecting DE genes. Addressing these challenges requires employing new approaches beyond the conventional ones, which are based on a nonzero difference in average expression. Several methods have been developed for differential gene expression analysis of scRNAseq data. To provide guidance on choosing an appropriate tool or developing a new one, it is necessary to evaluate and compare the performance of differential gene expression analysis methods for scRNAseq data. Results: In this study, we conducted a comprehensive evaluation of the performance of eleven differential gene expression analysis software tools, which are designed for scRNAseq data or can be applied to them. We used simulated and real data to evaluate the accuracy and precision of detection. Using simulated data, we investigated the effect of sample size on the detection accuracy of the tools. Using real data, we examined the agreement among the tools in identifying DE genes, the run time of the tools, and the biological relevance of the detected DE genes. Conclusions: In general, agreement among the tools in calling DE genes is not high. There is a trade-off between true-positive rates and the precision of calling DE genes. Methods with higher true positive rates tend to show low precision due to their introducing false positives, whereas methods with high precision show low true positive rates due to identifying few DE genes. We observed that current methods designed for scRNAseq data do not tend to show better performance compared to methods designed for bulk RNAseq data. Data multimodality and abundance of zero read counts are the main characteristics of scRNAseq data, which play important roles in the performance of differential gene expression analysis methods and need to be considered in terms of the development of new methods.},
author = {Wang, Tianyu and Li, Boyang and Nelson, Craig E. and Nabavi, Sheida},
doi = {10.1186/s12859-019-2599-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Bioinformatics/Wang et al. - 2019 - Comparative analysis of differential gene expression analysis tools for single-cell RNA sequencing data.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Comparative analysis,Differential gene expression analysis,RNAseq,Single-cell,differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {1},
pages = {1--16},
publisher = {BMC Bioinformatics},
title = {{Comparative analysis of differential gene expression analysis tools for single-cell RNA sequencing data}},
volume = {20},
year = {2019}
}
@article{YetV10,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/20562875{\}}{\{}20562875{\}}},
author = {Yang, J and Benyamin, B and McEvoy, B P and Gordon, S and Henders, A K and Nyholt, D R and Madden, P A and Heath, A C and Martin, N G and Montgomery, G W and Goddard, M E and Visscher, P M},
journal = {Nature Genetics},
keywords = {GWAS},
mendeley-tags = {GWAS},
month = {jul},
pages = {565--569},
title = {{{\{}C{\}}ommon {\{}S{\}}{\{}N{\}}{\{}P{\}}s explain a large proportion of the heritability for human height}},
volume = {42},
year = {2010}
}
@article{Gallagher2018,
abstract = {During the past 12 years, genome-wide association studies (GWASs) have uncovered thousands of genetic variants that influence risk for complex human traits and diseases. Yet functional studies aimed at delineating the causal genetic variants and biological mechanisms underlying the observed statistical associations with disease risk have lagged. In this review, we highlight key advances in the field of functional genomics that may facilitate the derivation of biological meaning post-GWAS. We highlight the evidence suggesting that causal variants underlying disease risk often function through regulatory effects on the expression of target genes and that these expression effects might be modest and cell-type specific. We moreover discuss specific studies as proof-of-principle examples for current statistical, bioinformatic, and empirical bench-based approaches to downstream elucidation of GWAS-identified disease risk loci.},
author = {Gallagher, Michael D. and Chen-Plotkin, Alice S.},
doi = {10.1016/j.ajhg.2018.04.002},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Human Genetics/Gallagher, Chen-Plotkin - 2018 - The Post-GWAS Era From Association to Function.pdf:pdf},
issn = {15376605},
journal = {American Journal of Human Genetics},
keywords = {GWAS},
mendeley-tags = {GWAS},
number = {5},
pages = {717--730},
pmid = {29727686},
publisher = {American Society of Human Genetics},
title = {{The Post-GWAS Era: From Association to Function}},
url = {https://doi.org/10.1016/j.ajhg.2018.04.002},
volume = {102},
year = {2018}
}
@article{Pounds2006,
abstract = {Motivation: Presently available methods that use p-values to estimate or control the false discovery rate (FDR) implicitly assume that p-values are continuously distributed and based on two-sided tests. Therefore, it is difficult to reliably estimate the FDR when p-values are discrete or based on one-sided tests.Results: A simple and robust method to estimate the FDR is proposed. The proposed method does not rely on implicit assumptions that tests are two-sided or yield continuously distributed p-values. The proposed method is proven to be conservative and have desirable large-sample properties. In addition, the proposed method was among the best performers across a series of ‘real data simulations' comparing the performance of five currently available methods.Availability: Libraries of S-plus and R routines to implement the method are freely available from www.stjuderesearch.org/depts/biostatsContact:stanley.pounds@stjude.orgSupplementary information: Supplementary data are avilable at Bioinformatics online.},
author = {Pounds, Stan and Cheng, Cheng},
doi = {10.1093/bioinformatics/btl328},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Pounds, Cheng - 2006 - Robust estimation of the false discovery rate.pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
keywords = {Monte Carlo,Multiple testing,permutation test},
mendeley-tags = {Monte Carlo,Multiple testing,permutation test},
number = {16},
pages = {1979--1987},
title = {{Robust estimation of the false discovery rate}},
volume = {22},
year = {2006}
}
@article{Petralia2016,
abstract = {We focus on characterizing common and different coexpression patterns among RNAs and proteins in breast cancer tumors. To address this problem, we introduce Joint Random Forest (JRF), a novel nonparametric algorithm to simultaneously estimate multiple coexpression networks by effectively borrowing information across protein and gene expression data. The performance of JRF was evaluated through extensive simulation studies using different network topologies and data distribution functions. Advantages of JRF over other algorithms that estimate class-specific networks separately were observed across all simulation settings. JRF also outperformed a competing method based on Gaussian graphic models. We then applied JRF to simultaneously construct gene and protein coexpression networks based on protein and RNAseq data from CPTAC-TCGA breast cancer study. We identified interesting common and differential coexpression patterns among genes and proteins. This information can help to cast light on the potential disease mechanisms of breast cancer.},
author = {Petralia, Francesca and Song, Won Min and Tu, Zhidong and Wang, Pei},
doi = {10.1021/acs.jproteome.5b00925},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Proteome Research/Petralia et al. - 2016 - New Method for Joint Network Analysis Reveals Common and Different Coexpression Patterns among Genes and Protei.pdf:pdf},
issn = {15353907},
journal = {Journal of Proteome Research},
keywords = {Kathryn,networks},
mendeley-tags = {Kathryn,networks},
number = {3},
pages = {743--754},
title = {{New Method for Joint Network Analysis Reveals Common and Different Coexpression Patterns among Genes and Proteins in Breast Cancer}},
url = {https://pubs.acs.org/doi/10.1021/acs.jproteome.5b00925.},
volume = {15},
year = {2016}
}
@article{Wagner2012,
abstract = {Measures of RNA abundance are important for many areas of biology and often obtained from high-throughput RNA sequencing methods such as Illumina sequence data. These measures need to be normalized to remove technical biases inherent in the sequencing approach, most notably the length of the RNA species and the sequencing depth of a sample. These biases are corrected in the widely used reads per kilobase per million reads (RPKM) measure. Here, we argue that the intended meaning of RPKM is a measure of relative molar RNA concentration (rmc) and show that for each set of transcripts the average rmc is a constant, namely the inverse of the number of transcripts mapped. Further, we show that RPKM does not respect this invariance property and thus cannot be an accurate measure of rmc. We propose a slight modification of RPKM that eliminates this inconsistency and call it TPM for transcripts per million. TPM respects the average invariance and eliminates statistical biases inherent in the RPKM measure.},
author = {Wagner, Gunter P. and Koryu, Kin and Lynch, Vincent J.},
doi = {10.1007/s12064-012-0162-3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Theory in Biosciences/Wagner, Koryu, Lynch - 2012 - Measurement of mRNA abundance using RNA-seq data RPKM measure is inconsistent among samples.pdf:pdf},
journal = {Theory in Biosciences},
keywords = {Kathryn,NextGen sequencing,RNA quantification,RNA-seq,RPKM Introduction},
mendeley-tags = {Kathryn,RNA-seq},
pages = {281--285},
title = {{Measurement of mRNA abundance using RNA-seq data: RPKM measure is inconsistent among samples}},
volume = {131},
year = {2012}
}
@inproceedings{NetR09,
author = {Negahban, Sahand and Yu, Bin and Wainwright, Martin J and Ravikumar, Pradeep K},
booktitle = {Advances in Neural Information Processing Systems},
keywords = {high-dimensional regression},
mendeley-tags = {high-dimensional regression},
pages = {1348--1356},
title = {{A unified framework for high-dimensional analysis of {\$} m {\$}-estimators with decomposable regularizers}},
year = {2009}
}
@article{Bentkus2006,
author = {Bentkus, V.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Theory of Probability and its Applications/Bentkus - 2006 - A Lyapunov-type bound in Rd.pdf:pdf},
journal = {Theory of Probability and its Applications},
number = {2},
pages = {311--323},
title = {{A Lyapunov-type bound in Rd}},
volume = {49},
year = {2006}
}
@article{Galvao2015,
abstract = {This article studies identification, estimation, and inference of general unconditional treatment effects models with continuous treatment under the ignorability assumption. We show identification of the parameters of interest, the dose–response functions, under the assumption that selection to treatment is based on observables. We propose a semiparametric two-step estimator, and consider estimation of the dose–response functions through moment restriction models with generalized residual functions that are possibly nonsmooth. This general formulation includes average and quantile treatment effects as special cases. The asymptotic properties of the estimator are derived, namely, uniform consistency, weak convergence, and semiparametric efficiency. We also develop statistical inference procedures and establish the validity of a bootstrap approach to implement these methods in practice. Monte Carlo simulations show that the proposed methods have good finite sample properties. Finally, we apply the proposed methods to estimate the unconditional average and quantile effects of mothers' weight gain and age on birthweight. Supplementary materials for this article are available online.},
author = {Galvao, Antonio F. and Wang, Liang},
doi = {10.1080/01621459.2014.978005},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Galvao, Wang - 2015 - Uniformly Semiparametric Efficient Estimation of Treatment Effects With a Continuous Treatment.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Birthweight,Dose–response function,Ignorability,Semiparametric estimation and inference,causality},
mendeley-tags = {causality},
number = {512},
pages = {1528--1542},
title = {{Uniformly Semiparametric Efficient Estimation of Treatment Effects With a Continuous Treatment}},
volume = {110},
year = {2015}
}
@article{LS00,
author = {Liu, Jun S and Sabatti, Chiara},
doi = {10.1093/biomet/87.2.353},
issn = {0006-3444},
journal = {Biometrika},
keywords = {Monte Carlo},
mendeley-tags = {Monte Carlo},
number = {2},
pages = {353--369},
title = {{Generalised {\{}G{\}}ibbs sampler and multigrid {\{}M{\}}onte {\{}C{\}}arlo for {\{}B{\}}ayesian computation}},
url = {http://dx.doi.org/10.1093/biomet/87.2.353},
volume = {87},
year = {2000}
}
@article{Corradin2014,
abstract = {{\textcopyright} 2014, Le Dily et al. The human genome is segmented into topologically associating domains (TADs), but the role of this conserved organization during transient changes in gene expression is not known. Here we describe the distribution of progestin-induced chromatin modifications and changes in transcriptional activity over TADs in T47D breast cancer cells. Using ChIP-seq (chromatin immunoprecipitation combined with high-throughput sequencing), Hi-C (chromosome capture followed by high-throughput sequencing), and three-dimensional (3D) modeling techniques, we found that the borders of the ∼2000 TADs in these cells are largely maintained after hormone treatment and that up to 20{\%} of the TADs could be considered as discrete regulatory units where the majority of the genes are either transcriptionally activated or repressed in a coordinated fashion. The epigenetic signatures of the TADs are homogeneously modified by hormones in correlation with the transcriptional changes. Hormone-induced changes in gene activity and chromatin remodeling are accompanied by differential structural changes for activated and repressed TADs, as reflected by specific and opposite changes in the strength of intra-TAD interactions within responsive TADs. Indeed, 3D modeling of the Hi-C data suggested that the structure of TADs was modified upon treatment. The differential responses of TADs to progestins and estrogens suggest that TADs could function as “regulons” to enable spatially proximal genes to be coordinately transcribed in response to hormones.},
author = {{Le Dily}, Fran{\c{c}}ois L. and Ba{\`{u}}, Davide and Pohl, Andy and Vicent, Guillermo P. and Serra, Fran{\c{c}}ois and Soronellas, Daniel and Castellano, Giancarlo and Wright, Roni H.G. and Ballare, Cecilia and Filion, Guillaume and Marti-Renom, Marc A. and Beato, Miguel},
doi = {10.1101/gad.241422.114},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genes and Development/Le Dily et al. - 2014 - Distinct structural transitions of chromatin topological domains correlate with coordinated hormone-induced gene.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Genes and Development/Le Dily et al. - 2014 - Distinct structural transitions of chromatin topological domains correlate with coordinated hormone-induced g(2).pdf:pdf},
isbn = {8159368127},
issn = {15495477},
journal = {Genes and Development},
keywords = {Epigenetic landscape,Gene expression,Hi-C,Kathryn,Progesterone receptor,TADs,Three-dimensional structure of the genome,Transcriptional regulation,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {19},
pages = {2151--2162},
title = {{Distinct structural transitions of chromatin topological domains correlate with coordinated hormone-induced gene regulation}},
volume = {28},
year = {2014}
}
@misc{Zhou2019,
abstract = {The vast majority of the mammalian genome consists of DNAs that do not encode protein sequences. For decades, the functional potentials of these noncoding DNAs have remained poorly understood. Large-scale studies, such as the Encyclopedia of DNA Elements project and genome-wide association studies, have suggested that the noncoding genome functions in a wide variety of biological and physiological process [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}1{\textless}/a{\textgreater}]. However, it has been technically challenging to attribute functions to a plethora of noncoding elements in any given biological context, largely due to a lack of convenient high-throughput approaches.
The recently developed clustered regularly interspaced short palindromic repeats (CRISPR)-Cas system enables efficient and precise perturbation of DNA sequences in the genome, thus offering an unprecedented opportunity to associate functions or phenotypes with genetic elements [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}2{\textless}/a{\textgreater}]. Directed by a single-guide RNA (sgRNA) with a region complementary to the target DNA, Cas nuclease cleaves the genomic DNA at the target locus to generate a double-strand DNA break (DSB), which is subsequently repaired through an internal error-prone nonhomologous end-joining (NHEJ) pathway, resulting in an insertion or deletion (indel) that often disrupts gene function [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}3{\textless}/a{\textgreater}]. The CRISPR-Cas system has been further engineered to regulate gene expression at will through the fusion of the catalytically inactive Cas9 (dCas9) with transcriptional activators, repressors or other effectors, enabling transcriptional activation (CRISPR activation, CRISPRa), inhibition (CRISPR interference, CRISPRi) or epigenetic modifications [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}3{\textless}/a{\textgreater}].
Owing to its programmability and multiplexability, the CRISPR-Cas system is especially potent in high-throughput functional genomics. To achieve this, sgRNAs are designed {\textless}em{\textgreater}in silico{\textless}/em{\textgreater} and synthesized as a pool before being cloned into lentiviral vectors to generate a library of viruses for target cell transduction. After phenotypic selection, such as drug resistance/sensitivity or fluorescence-activated cell sorting, candidate genes responsible for the functions of interests are revealed through next-generation sequencing (NGS) analysis of sgRNA barcodes from enriched or depleted cell populations [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}4{\textless}/a{\textgreater}].
Despite the power of pooled CRISPR screening in the dissection of key genes in a variety of biological processes, the majority of such screens hitherto have mainly targeted protein-coding genes. This is because the small indels ({\textless}10 bp) created by NHEJ are unlikely to produce loss-of-function phenotypes on the noncoding elements. Recently, endeavors have been made to probe the noncoding regions in mammalian genome by exploiting customized CRISPR-based screens.
As much as 76{\%} of genomic DNA is transcribed into RNAs, while less than 2{\%} encodes proteins [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}5{\textless}/a{\textgreater}]. Long noncoding RNAs (lncRNAs), which are at least 200 nucleotides in length, are the major subsets of the human transcriptome [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}5{\textless}/a{\textgreater}]. The first high-throughput method to identify functional lncRNAs is through a specially designed CRISPR approach that employs paired gRNAs (pgRNAs) to produce genomic deletions (Fig. {\textless}a class="link link-reveal link-table xref-fig"{\textgreater}1a{\textless}/a{\textgreater}). A pgRNA library comprising 12 472 gRNA pairs specific for 671 human lncRNAs was assembled, and the screening identified 51 lncRNAs that modulate tumor cell growth [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}6{\textless}/a{\textgreater}]. Alternatively, CRISPRi and CRISPRa have been employed to investigate functional lncRNAs by perturbing lncRNA transcription in two opposite directions (Fig. {\textless}a class="link link-reveal link-table xref-fig"{\textgreater}1b{\textless}/a{\textgreater}). Genome-scale CRISPRi screens were performed in seven different cell lines, using an sgRNA library targeting the transcriptional start site (TSS) of 16 401 lncRNAs. This assay revealed that ∼500 lncRNA loci are important for cell growth [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}7{\textless}/a{\textgreater}]. Intriguingly, despite more than 1300 lncRNA genes being expressed in all seven cell lines tested, none of them was identified in all screens, suggesting that lncRNAs exert distinct functions in diverse cellular contexts. Moreover, Joung {\textless}em{\textgreater}et al.{\textless}/em{\textgreater} performed a CRISPRa screen to globally map lncRNA loci relevant to drug resistance. By targeting the TSS of more than 10 000 lncRNA loci, 11 were identified whose overexpression conferred cell resistance to BRAF inhibitors [{\textless}a class="link link-ref link-reveal xref-bibr"{\textgreater}8{\textless}/a{\textgreater}].
Although lncRNA functional screening at a genome-wide scale could be achieved, the CRISPRi and CRISPRa approaches have limitations, mainly owing to their insu

{\textless}p{\textgreater}-Abstract Truncated-{\textless}/p{\textgreater}},
author = {Zhou, Zhuo and Wei, Wensheng},
booktitle = {National Science Review},
doi = {10.1093/nsr/nwy138},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/National Science Review/Zhou, Wei - 2019 - Interrogating the noncoding genome in a high-throughput fashion.pdf:pdf},
issn = {2053714X},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
month = {may},
number = {3},
pages = {397--399},
publisher = {Oxford University Press},
title = {{Interrogating the noncoding genome in a high-throughput fashion}},
volume = {6},
year = {2019}
}
@article{anderson1995inequalities,
author = {Anderson, G D and Barnard, R W and Richards, K C and Vamanamurthy, M K and Vuorinen, M},
journal = {Transactions of the American Mathematical Society},
pages = {1713--1723},
publisher = {JSTOR},
title = {{Inequalities for zero-balanced hypergeometric functions}},
year = {1995}
}
@article{Guo2019,
abstract = {Group inference has been a long-standing question in statistics and the development of high-dimensional group inference is an essential part of statistical methods for analyzing complex data sets, including hierarchical testing, tests of interaction, detection of heterogeneous treatment effects and local heritability. Group inference in regression models can be measured with respect to a weighted quadratic functional of the regression sub-vector corresponding to the group. Asymptotically unbiased estimators of these weighted quadratic functionals are constructed and a procedure using these esti-mator for inference is proposed. We derive its asymptotic Gaussian distribution which allows to construct asymptotically valid confidence intervals and tests which perform well in terms of length or power. The results simultaneously address four challenges encountered in the literature: controlling coverage or type I error even when the variables inside the group are highly correlated, achieving a good power when there are many small coefficients inside the group, computational efficiency even for a large group, and no requirements on the group size. We apply the methodology to several interesting statistical problems and demonstrate its strength and usefulness on simulated and real data.},
archivePrefix = {arXiv},
arxivId = {1909.01503v1},
author = {Guo, Zijian and Renaux, Claude and B{\"{u}}hlmann, Peter and Cai, T Tony},
eprint = {1909.01503v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Guo et al. - 2019 - Group Inference in High Dimensions with Applications to Hierarchical Testing.pdf:pdf},
journal = {arXiv},
keywords = {Detection of Heterogeneous Treatment Effects,Hierarchical Testing,Interaction Test,Local Heritability *,Multiple testing,groups,hierarchical multiple testing,high-dimensional regression},
mendeley-tags = {Multiple testing,groups,hierarchical multiple testing,high-dimensional regression},
title = {{Group Inference in High Dimensions with Applications to Hierarchical Testing}},
year = {2019}
}
@phdthesis{L14,
author = {Lynch, Gavin},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Lynch - 2014 - The Control of the False Discovery Rate Under Structured Hypotheses.pdf:pdf},
keywords = {FDR,structured multiple testing,to-skim},
mendeley-tags = {FDR,structured multiple testing,to-skim},
school = {New Jersey Institute of Technology, Department of Mathematical Sciences},
title = {{The Control of the False Discovery Rate Under Structured Hypotheses}},
year = {2014}
}
@article{Imai2004,
abstract = {In this article we develop the theoretical properties of the propensity function, which is a generalization of the propensity score of Rosenbaum and Rubin. Methods based on the propensity score have long been used for causal inference in observational studies; they are easy to use and can effectively reduce the bias caused by nonrandom treatment assignment. Although treatment regimes need not be binary in practice, the propensity score methods are generally confined to binary treatment scenarios. Two possible exceptions have been suggested for ordinal and categorical treatments. In this article we develop theory and methods that encompass all of these techniques and widen their applicability by allowing for arbitrary treatment regimes. We illustrate our propensity function methods by applying them to two datasets; we estimate the effect of smoking on medical expenditure and the effect of schooling on wages. We also conduct simulation studies to investigate the performance of our methods.},
author = {Imai, Kosuke and {Van Dyk}, David A.},
doi = {10.1198/016214504000001187},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Imai, Van Dyk - 2004 - Causal inference with general treatment regimes Generalizing the propensity score.pdf:pdf},
issn = {01621459},
journal = {Journal of the American Statistical Association},
keywords = {Medical expenditure,Nonrandom treatment assignment,Observational studies,Return to schooling,Subclassification,Treatment effect,causality},
mendeley-tags = {causality},
number = {467},
pages = {854--866},
title = {{Causal inference with general treatment regimes: Generalizing the propensity score}},
volume = {99},
year = {2004}
}
@article{MAGillentineLNBerryRPGoin-KochelMAAliJGeDGuffeyJARosenfeldVHannigPBaderMProudMShinawiBHGraham1ALinSRLalaniJReynoldsMChenTGrebeCGMinardPStankiewiczALBeaudet2017,
abstract = {Chromosome 15q11q13 is among the least stable regions in the genome due to its highly complex genomic architecture. Low copy repeat elements at 15q13.3 facilitate recurrent copy number variants (CNVs), with deletions established as pathogenic and CHRN CHRN A7 implicated as a candidate gene. However, the pathogenicity of duplications of A7 is unclear, as they are also found in reportedly healthy parents and unaffected control individuals. We evaluated 18 children with microduplications involving CHRN A7 identified by clinical chromosome microarray analysis (CMA). Comprehensive phenotyping revealed high prevalence of developmental delay/intellectual disability, autism spectrum disorder, and attention deficit/hyperactivity disorder. As duplications are the most common CNVs identified by clinical CMA, this study provides CHRN A7 anticipatory guidance for those involved with care of affected individuals. Keywords},
author = {{MA Gillentine, LN Berry, RP Goin-Kochel, MA Ali, J Ge, D Guffey, JA Rosenfeld, V Hannig, P Bader, M Proud, M Shinawi, BH Graham1, A Lin, SR Lalani, J Reynolds, M Chen, T Grebe, CG Minard, P Stankiewicz, AL Beaudet}, and CP and Schaaf},
doi = {10.1097/CCM.0b013e31823da96d.Hydrogen},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/J Autism Dev Disord/MA Gillentine, LN Berry, RP Goin-Kochel, MA Ali, J Ge, D Guffey, JA Rosenfeld, V Hannig, P Bader, M Proud, M Shinawi, BH Graham1, A Lin,.pdf:pdf},
journal = {J Autism Dev Disord},
keywords = {Kathryn,applied,enhancer,free radicals,hydrogen,oxidative stress,subarachnoid hemorrhage},
mendeley-tags = {Kathryn,applied,enhancer},
number = {3},
pages = {549--562},
title = {{Large-Scale Discovery of Enhancers from Human Heart Tissue}},
volume = {47},
year = {2017}
}
@article{aharoni2014generalized,
author = {Aharoni, E and Rosset, S},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {4},
pages = {771--794},
publisher = {Wiley Online Library},
title = {{Generalized alpha-investing: definitions, optimality results and application to public databases}},
volume = {76},
year = {2014}
}
@article{TetR15,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25532137{\}}{\{}25532137{\}}},
author = {Tasan, M and Musso, G and Hao, T and Vidal, M and MacRae, C A and Roth, F P},
journal = {Nature Methods},
keywords = {GWAS,networks},
mendeley-tags = {GWAS,networks},
month = {feb},
number = {2},
pages = {154--159},
title = {{{\{}S{\}}electing causal genes from genome-wide association studies via functionally coherent subnetworks}},
volume = {12},
year = {2015}
}
@article{RetS02,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/12202775{\}}{\{}12202775{\}}},
author = {Ramensky, V and Bork, P and Sunyaev, S},
journal = {Nucleic Acids Research},
keywords = {genetics},
mendeley-tags = {genetics},
month = {sep},
pages = {3894--3900},
title = {{Human non-synonymous {\{}S{\}}{\{}N{\}}{\{}P{\}}s: server and survey}},
volume = {30},
year = {2002}
}
@article{DetR10,
abstract = {BACKGROUND: The use of ontologies to control vocabulary and structure annotation has added value to genome-scale data, and contributed to the capture and re-use of knowledge across research domains. Gene Ontology (GO) is widely used to capture detailed expert knowledge in genomic-scale datasets and as a consequence has grown to contain many terms, making it unwieldy for many applications. To increase its ease of manipulation and efficiency of use, subsets called GO slims are often created by collapsing terms upward into more general, high-level terms relevant to a particular context. Creation of a GO slim currently requires manipulation and editing of GO by an expert (or community) familiar with both the ontology and the biological context. Decisions about which terms to include are necessarily subjective, and the creation process itself and subsequent curation are time-consuming and largely manual. RESULTS: Here we present an objective framework for generating customised ontology slims for specific annotated datasets, exploiting information latent in the structure of the ontology graph and in the annotation data. This framework combines ontology engineering approaches, and a data-driven algorithm that draws on graph and information theory. We illustrate this method by application to GO, generating GO slims at different information thresholds, characterising their depth of semantics and demonstrating the resulting gains in statistical power. CONCLUSIONS: Our GO slim creation pipeline is available for use in conjunction with any GO-annotated dataset, and creates dataset-specific, objectively defined slims. This method is fast and scalable for application to other biomedical ontologies.},
author = {Davis, Melissa J. and Sehgal, Muhammad S.B. and Ragan, Mark A.},
doi = {10.1186/1471-2105-11-498},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
number = {1},
pages = {498},
publisher = {BioMed Central},
title = {{Automatic, context-specific generation of Gene Ontology slims}},
volume = {11},
year = {2010}
}
@article{Hemerik2019,
abstract = {When multiple hypotheses are tested, interest is often in ensuring that the proportion of false discoveries is small with high confidence. In this paper, confidence upper bounds for the false discovery proportion are constructed, which are simultaneous over all rejection cutoffs. In particular , this allows the user to select a set of hypotheses post hoc such that the false discovery proportion lies below some constant with high confidence. Our method uses permutations to account for the dependence structure in the data. So far only Meinshausen (2006) has developed an exact, permutation-based and computationally feasible method for obtaining simultaneous false discovery proportion bounds. We propose an exact method which uniformly improves that procedure. Further, we provide a generalization of the method that lets the user select the shape of the simultaneous confidence bounds; this gives the user more freedom in determining the power properties of the method. Interestingly, several existing permutation methods, such as significance analysis of microarrays and the maxT method of Westfall {\&} Young (1993), are obtained as special cases.},
author = {Hemerik, J and Solari, A and Goeman, J J},
doi = {10.1093/biomet/asz021},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Hemerik, Solari, Goeman - 2019 - Permutation-based simultaneous confidence bounds for the false discovery proportion.pdf:pdf},
journal = {Biometrika},
keywords = {Exceedance control,FDX,False discovery proportion,False discovery rate,Monte Carlo,Multiple testing,Post hoc inference,Some key words: Confidence envelope,permutation test,simultaneous inference,to-read},
mendeley-tags = {FDX,Monte Carlo,Multiple testing,permutation test,simultaneous inference,to-read},
number = {3},
pages = {635--649},
title = {{Permutation-based simultaneous confidence bounds for the false discovery proportion}},
url = {https://academic.oup.com/biomet/article-abstract/106/3/635/5527339},
volume = {106},
year = {2019}
}
@article{Ma2015,
abstract = {West Nile virus (WNV) causes an acute neurological infection attended by massive neuronal cell death. However, the mechanism(s) behind the virusinduced cell death is poorly understood. Using a library containing 77,406 sgRNAs targeting 20,121 genes, we performed a genome-wide screen followed by a second screen with a sub-library. Among the genes identified, seven genes, EMC2, EMC3, SEL1L, DERL2, UBE2G2, UBE2J1, and HRD1, stood out as having the strongest phenotype, whose knockout conferred strong protection against WNVinduced cell death with two different WNV strains and in three cell lines. Interestingly, knockout of these genes did not block WNV replication. Thus, these appear to be essential genes that link WNV replication to downstream cell death pathway(s). In addition, the fact that all of these genes belong to the ER-associated protein degradation (ERAD) pathway suggests that this might be the primary driver of WNV-induced cell death.},
author = {Ma, Hongming and Dang, Ying and Wu, Yonggan and Jia, Gengxiang and Anaya, Edgar and Zhang, Junli and Abraham, Sojan and Choi, Jang Gi and Shi, Guojun and Qi, Ling and Manjunath, N. and Wu, Haoquan},
doi = {10.1016/j.celrep.2015.06.049},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell Reports/Ma et al. - 2015 - A CRISPR-based screen identifies genes essential for west-nile-virus-induced cell death.pdf:pdf},
issn = {22111247},
journal = {Cell Reports},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {4},
pages = {673--683},
publisher = {The Authors},
title = {{A CRISPR-based screen identifies genes essential for west-nile-virus-induced cell death}},
url = {http://dx.doi.org/10.1016/j.celrep.2015.06.049},
volume = {12},
year = {2015}
}
@article{Chung2021,
abstract = {Identifying gene regulatory targets of nuclear proteins in tissues remains a challenge. Here we describe intranuclear Cellular Indexing of Transcriptomes and Epitopes (inCITE-seq), a scalable method for measuring multiplexed intranuclear protein levels and the transcriptome in parallel in thousands of cells, enabling joint analysis of TF levels and gene expression in vivo. We apply inCITE-seq to characterize cell state-related changes upon pharmacological induction of neuronal activity in the mouse brain. Modeling gene expression as a linear combination of quantitative protein levels revealed the genome-wide effect of each TF and recovered known targets. Cell type-specific genes associated with each TF were co-expressed as distinct modules that each corresponded to positive or negative TF levels, showing that our approach can disentangle relative contributions of TFs to gene expression and add interpretability to gene networks. InCITE-seq can illuminate how combinations of nuclear proteins shape gene expression in native tissue contexts, with direct applications to solid or frozen tissues and clinical specimens.Competing Interest StatementA.R. is a founder and equity holder of Celsius Therapeutics, an equity holder in Immunitas Therapeutics, and until August 31, 2020 was an SAB member of Syros Pharmaceuticals, Neogene Therapeutics, Asimov and ThermoFisher Scientific. From August 1, 2020, A.R. is an employee of Genentech.},
author = {Chung, Hattie and Parkhurst, Christopher N and Magee, Emma M and Phillips, Devan and Habibi, Ehsan and Chen, Fei and Yeung, Bertrand and Waldman, Julia and Artis, David and Regev, Aviv and Observatory, Klarman Cell and Medicine, Weill Cornell and Diego, San and Medicine, Weill Cornell},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Chung et al. - 2021 - Simultaneous single cell measurements of intranuclear proteins and gene expression.pdf:pdf},
journal = {bioRxiv},
keywords = {multi-omics,single cell},
mendeley-tags = {multi-omics,single cell},
pages = {2021.01.18.427139},
title = {{Simultaneous single cell measurements of intranuclear proteins and gene expression}},
url = {http://biorxiv.org/content/early/2021/01/19/2021.01.18.427139.abstract},
year = {2021}
}
@article{Schwartzman2008,
abstract = {In large scale multiple testing, the use of an empirical null distribution rather than the theoretical null distribution can be critical for correct inference. This paper proposes a "mode matching" method for fitting an empirical null when the theoretical null belongs to any exponential family. Based on the central matching method for z-scores, mode matching estimates the null density by fitting an appropriate exponential family to the histogram of the test statistics by Poisson regression in a region surrounding the mode. The empirical null estimate is then used to estimate local and tail false discovery rate (FDR) for inference. Delta-method covariance formulas and approximate asymptotic bias formulas are provided, as well as simulation studies of the effect of the tuning parameters of the procedure on the bias-variance trade-off. The standard FDR estimates are found to be biased down at the far tails. Correlation between test statistics is taken into account in the covariance estimates , providing a generalization of Efron's "wing function" for exponential families. Applications with $\chi$ 2 statistics are shown in a family-based genome-wide association study from the Framingham Heart Study and an anatomical brain imaging study of dyslexia in children.},
author = {Schwartzman, Armin},
doi = {10.1214/08-AOAS184},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Applied Statistics/Schwartzman - 2008 - EMPIRICAL NULL AND FALSE DISCOVERY RATE INFERENCE FOR EXPONENTIAL FAMILIES.pdf:pdf},
journal = {The Annals of Applied Statistics},
keywords = {Multiple testing,Poisson regression,brain imaging,genome-wide association,mixture model,multiple comparisons,spatial data,to-skim},
mendeley-tags = {Multiple testing,spatial data,to-skim},
number = {4},
pages = {1332--1359},
title = {{EMPIRICAL NULL AND FALSE DISCOVERY RATE INFERENCE FOR EXPONENTIAL FAMILIES}},
volume = {2},
year = {2008}
}
@article{Roeder2009,
author = {Roeder, K and Wasserman, L},
journal = {Statistical Science},
keywords = {GWAS,weighted multiple testing},
mendeley-tags = {GWAS,weighted multiple testing},
number = {4},
pages = {398--413},
title = {{Genome-wide significance levels and weighted hypothesis testing}},
volume = {24},
year = {2009}
}
@article{ZB18,
author = {Zhu, Yinchu and Bradic, Jelena},
journal = {Journal of the American Statistical Association},
keywords = {high-dimensional regression},
mendeley-tags = {high-dimensional regression},
number = {524},
pages = {1583--1600},
publisher = {Taylor {\&} Francis},
title = {{Linear hypothesis testing in dense high-dimensional linear models}},
volume = {113},
year = {2018}
}
@article{meinshausen2006false,
author = {Meinshausen, N},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Scandinavian Journal of Statistics/Meinshausen - 2006 - False discovery control for multiple tests of association under general dependence.pdf:pdf},
journal = {Scandinavian Journal of Statistics},
keywords = {Multiple testing,correlation,resampling,simultaneous inference},
mendeley-tags = {Multiple testing,correlation,resampling,simultaneous inference},
number = {2},
pages = {227--237},
publisher = {Wiley Online Library},
title = {{False discovery control for multiple tests of association under general dependence}},
volume = {33},
year = {2006}
}
@article{Zhang2019a,
abstract = {Conventional multiple testing procedures often assume hypotheses for different features are exchangeable. However, in many scientific applications, additional covariate information regarding the patterns of signals and nulls are available. In this paper, we introduce an FDR control procedure in large-scale inference problem that can incorporate covariate information. We develop a fast algorithm to implement the proposed procedure and prove its asymptotic validity even when the underlying model is misspecified and the p-values are weakly dependent (e.g., strong mixing). Extensive simulations are conducted to study the finite sample performance of the proposed method and we demonstrate that the new approach improves over the state-of-the-art approaches by being flexible, robust, powerful and computationally efficient. We finally apply the method to several omics datasets arising from genomics studies with the aim to identify omics features associated with some clinical and biological phenotypes. We show that the method is overall the most powerful among competing methods, especially when the signal is sparse. The proposed Covariate Adaptive Multiple Testing procedure is implemented in the R package CAMT.},
archivePrefix = {arXiv},
arxivId = {1909.04811},
author = {Zhang, Xianyang and Chen, Jun},
eprint = {1909.04811},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Zhang, Chen - 2019 - Covariate Adaptive False Discovery Rate Control with Applications to Omics-Wide Multiple Testing.pdf:pdf},
journal = {arXiv},
keywords = {Multiple testing,covariates,em-algorithm,false discovery rate,multiple testing,structured multiple testing},
mendeley-tags = {Multiple testing,structured multiple testing},
title = {{Covariate Adaptive False Discovery Rate Control with Applications to Omics-Wide Multiple Testing}},
url = {http://arxiv.org/abs/1909.04811},
year = {2019}
}
@article{Belloni2013,
abstract = {In this article we study post-model selection estimators that apply ordinary least squares (OLS) to the model selected by first-step penalized estimators, typically Lasso. It is well known that Lasso can estimate the nonparametric regression function at nearly the oracle rate, and is thus hard to improve upon. We show that the OLS post-Lasso estimator performs at least as well as Lasso in terms of the rate of convergence, and has the advantage of a smaller bias. Remarkably, this performance occurs even if the Lasso-based model selection "fails" in the sense of missing some components of the "true" regression model. By the "true" model, we mean the best s-dimensional approximation to the nonparametric regression function chosen by the oracle. Furthermore, OLS post-Lasso estimator can perform strictly better than Lasso, in the sense of a strictly faster rate of convergence, if the Lasso-based model selection correctly includes all components of the "true" model as a subset and also achieves sufficient sparsity. In the extreme case, when Lasso perfectly selects the "true" model, the OLS post-Lasso estimator becomes the oracle estimator. An important ingredient in our analysis is a new sparsity bound on the dimension of the model selected by Lasso, which guarantees that this dimension is at most of the same order as the dimension of the "true" model. Our rate results are nonasymptotic and hold in both parametric and nonparametric models. Moreover, our analysis is not limited to the Lasso estimator acting as a selector in the first step, but also applies to any other estimator, for example, various forms of thresholded Lasso, with good rates and good sparsity properties. Our analysis covers both traditional thresholding and a new practical, data-driven thresholding scheme that induces additional sparsity subject to maintaining a certain goodness of fit. The latter scheme has theoretical guarantees similar to those of Lasso or OLS post-Lasso, but it dominates those procedures as well as traditional thresholding in a wide variety of experiments.},
author = {Belloni, Alexandre and Chernozhukov, Victor},
doi = {10.3150/11-BEJ410},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bernoulli/Belloni, Chernozhukov - 2013 - Least squares after model selection in high-dimensional sparse models.pdf:pdf},
journal = {Bernoulli},
keywords = {Lasso,OLS post-Lasso,high-dimensional regression,post-model selection estimators,post-selection inference},
mendeley-tags = {high-dimensional regression,post-selection inference},
number = {2},
pages = {521--547},
title = {{Least squares after model selection in high-dimensional sparse models}},
volume = {19},
year = {2013}
}
@article{Schwartzman2017,
abstract = {Analysis of genome-wide association studies (GWAS) is characterized by a large number of univariate regressions where an outcome, a quantitative trait, is regressed on hundreds of thousands to millions of genomic markers, i.e. single-nucleotide polymorphism (SNP) counts, one marker at a time. Assuming a linear model linking the markers to the outcome, this article proposes an estimator of the heritability of the trait, defined here as the fraction of the variance of the trait explained by the genomic markers in the study. The estimator, called GWAS heritability (GWASH) estimator, is easy to compute, highly interpretable, and is consistent as the number of markers and the sample size increase. More importantly, it can be computed from summary statistics typically reported in GWAS, not requiring access to the original data. The estimator takes full account of the linkage disequilibrium (LD) or correlation between the SNPs in the study through moments of the LD matrix, estimable from auxiliary datasets. Unlike other proposed estimators in the literature, the precision of the estimate is obtainable analytically, allowing for power and sample size calculations for heritability estimates.},
author = {Schwartzman, Armin and Schork, Andrew J. and Zablocki, Rong and Thompson, Wesley K.},
doi = {10.1101/204446},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Schwartzman et al. - 2017 - A simple, consistent estimator of heritability for genome-wide association studies.pdf:pdf},
journal = {bioRxiv},
number = {4},
pages = {204446},
title = {{A simple, consistent estimator of heritability for genome-wide association studies}},
url = {https://www.biorxiv.org/content/10.1101/204446v1.full},
volume = {13},
year = {2017}
}
@article{BetZ13,
author = {Berk, Richard and Brown, Lawrence and Buja, Andreas and Zhang, Kai and Zhao, Linda},
journal = {The Annals of Statistics},
keywords = {Multiple testing,high-dimensional regression,simultaneous inference,to-skim},
mendeley-tags = {Multiple testing,high-dimensional regression,simultaneous inference,to-skim},
number = {2},
pages = {802--837},
publisher = {Institute of Mathematical Statistics},
title = {{Valid post-selection inference}},
volume = {41},
year = {2013}
}
@book{Rosenbaum2002,
address = {New York},
author = {Rosenbaum, Paul R.},
edition = {Second},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Rosenbaum - 2002 - Observational Studies.pdf:pdf},
isbn = {9781461271666},
keywords = {causality,observational studies},
mendeley-tags = {causality,observational studies},
publisher = {Springer-Verlag},
title = {{Observational Studies}},
year = {2002}
}
@article{Lin2020,
author = {Lin, Xueqiu and Chemparathy, Augustine and Russa, Marie La and Daley, Timothy and Qi, Lei S},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annual Review of Biomedical Data Science/Lin et al. - 2020 - Computational Methods for Analysis of Large-Scale CRISPR Screens.pdf:pdf},
journal = {Annual Review of Biomedical Data Science},
keywords = {CRISPR,computational method,crispr screen,gene editing,genetic,genotype,high-throughput,interaction,noncoding element,single-cell},
mendeley-tags = {CRISPR},
pages = {137--162},
title = {{Computational Methods for Analysis of Large-Scale CRISPR Screens}},
volume = {3},
year = {2020}
}
@article{Calderon2020,
abstract = {12 13 Gene regulation occurs through transacting factors (e.g. transcription factors) acting on cis-14 regulatory elements (e.g. enhancers). Massively parallel reporter assays (MPRAs) functionally 15 survey large numbers of cis-regulatory elements for regulatory potential, but do not identify the 16 transacting factors that mediate any observed effects. Here we describe transMPRA-a 17 reporter assay that efficiently combines multiplex CRISPR-mediated perturbation and MPRAs to 18 identify transacting factors that modulate the regulatory activity of specific enhancers. 19 20 Main 21 22 Cells rely on complex gene-regulatory networks in the context of differentiation, development, 23 homeostasis, external signal response, etc 1-4. These networks depend on myriad direct and 24 indirect interactions between transacting factors and cis-regulatory elements, which underlie 25},
author = {Calderon, Diego and Ellis, Andria and Daza, Riza M and Martin, Beth and Tome, Jacob M and Chen, Wei and Chardon, Florence M and Leith, Anh and Lee, Choli and Trapnell, Cole and Shendure, Jay},
doi = {10.1101/2020.09.30.321323},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Calderon et al. - 2020 - TransMPRA A framework for assaying the role of many trans-acting factors at many enhancers 2 3.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
title = {{TransMPRA: A framework for assaying the role of many trans-acting factors at many enhancers 2 3}},
url = {https://doi.org/10.1101/2020.09.30.321323},
year = {2020}
}
@article{Murakawa2016,
abstract = {Enhancers are distal cis-regulatory DNA elements that increase the expression of target genes. Various experimental and computational approaches including chromatin signature profiling have been developed to predict enhancers on a genome-wide scale, although each method has its advantages and disadvantages. Here we overview an emerging method to identify transcribed enhancers at exceedingly high nucleotide resolution based on enhancer RNA transcripts captured by Cap Analysis of Gene Expression (CAGE) technology. We further argue that disease-causative regulatory mutations at enhancers are increasingly recognized, emphasizing the importance of enhancer identification in functional and clinical genomics including, but not limited to, genome-wide association studies (GWASs) and cancer genomics studies. Various experimental and computational approaches have been developed to predict enhancers on a genome-wide scale, although each method has its advantages and disadvantages.Cap analysis of gene expression (CAGE) identifies transcribed enhancers at exceedingly high nucleotide resolution by detecting enhancer RNAs (eRNAs).Disease-associated SNPs and recurrent somatic cancer mutations are identified within enhancers. These variants might alter enhancer activities and contribute to pathogenesis, highlighting the importance of enhancer identification in various clinical settings.},
author = {Murakawa, Yasuhiro and Yoshihara, Masahito and Kawaji, Hideya and Nishikawa, Miki and Zayed, Hatem and Suzuki, Harukazu and Hayashizaki, Yoshihide},
doi = {10.1016/j.tig.2015.11.004},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Trends in Genetics/Murakawa et al. - 2016 - Enhanced Identification of Transcriptional Enhancers Provides Mechanistic Insights into Diseases.pdf:pdf},
issn = {13624555},
journal = {Trends in Genetics},
keywords = {CAGE,ERNA,Enhancer,FANTOM,Kathryn,enhancer},
mendeley-tags = {Kathryn,enhancer},
number = {2},
pages = {76--88},
title = {{Enhanced Identification of Transcriptional Enhancers Provides Mechanistic Insights into Diseases}},
url = {http://dx.doi.org/10.1016/j.tig.2015.11.004},
volume = {32},
year = {2016}
}
@article{ScaledLasso,
author = {N.{\~{}}St{\"{a}}dler and P.{\~{}}B{\"{u}}hlmann and de Geer, S.{\~{}}van},
journal = {Test},
keywords = {high-dimensional regression},
mendeley-tags = {high-dimensional regression},
pages = {209--285},
title = {{\$}\backslashell{\_}1{\$}-penalization for mixture regression models (with discussion)},
volume = {19},
year = {2010}
}
@article{He2014,
abstract = {Enhancer mapping has been greatly facilitated by various genomic marks associated with it. However, little is available in our toolbox to link enhancers with their target promoters, hampering mechanistic understanding of enhancer-promoter (EP) interaction. We develop and characterize multiple genomic features for distinguishing true EP pairs from noninteracting pairs. We integrate these features into a probabilistic predictor for EP interactions. Multiple validation experiments demonstrate a significant improvement over state-of-the-art approaches. Systematic analyses of EP interactions across 12 cell types reveal several global features of EP interactions: (i) a larger fraction of EP interactions are cell type specific than enhancers; (ii) promoters controlled by multiple enhancers have higher tissue specificity, but the regulating enhancers are less conserved; (iii) cohesin plays a role in mediating tissue-specific EP interactions via chromatin looping in a CTCF-independent manner. Our approach presents a systematic and effective strategy to decipher the mechanisms underlying EP communication.},
author = {He, B. and Chen, C. and Teng, L. and Tan, K.},
doi = {10.1073/pnas.1320308111},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences/He et al. - 2014 - Global view of enhancer-promoter interactome in human cells.pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {21},
pages = {E2191--E2199},
title = {{Global view of enhancer-promoter interactome in human cells}},
volume = {111},
year = {2014}
}
@article{dobriban2018flexible,
author = {Dobriban, Edgar},
journal = {arXiv},
keywords = {Multiple testing,closed testing,unpublished},
mendeley-tags = {Multiple testing,closed testing,unpublished},
title = {{Flexible Multiple Testing with the FACT Algorithm}},
year = {2018}
}
@article{LetF17,
author = {Lynch, Gavin and Guo, Wenge and Sarkar, Sanat K and Finner, Helmut},
journal = {Electronic Journal of Statistics},
keywords = {FDR,Multiple testing,ordered testing},
mendeley-tags = {FDR,Multiple testing,ordered testing},
number = {2},
pages = {4649--4673},
publisher = {The Institute of Mathematical Statistics and the Bernoulli Society},
title = {{The control of the false discovery rate in fixed sequence multiple testing}},
volume = {11},
year = {2017}
}
@article{Blanchard2019,
abstract = {This document is a book chapter which gives a partial survey on post hoc approaches to false positive control.},
archivePrefix = {arXiv},
arxivId = {1910.11575},
author = {Blanchard, Gilles and Neuvial, Pierre and Roquain, Etienne},
eprint = {1910.11575},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Blanchard, Neuvial, Roquain - 2019 - On agnostic post hoc approaches to false positive control.pdf:pdf},
journal = {arXiv},
pages = {1--20},
title = {{On agnostic post hoc approaches to false positive control}},
url = {http://arxiv.org/abs/1910.11575},
year = {2019}
}
@article{G11,
annote = {21328616},
author = {Garner, C},
journal = {Genetic Epidemiology},
month = {feb},
title = {{{\{}C{\}}onfounded by sequencing depth in association studies of rare alleles}},
year = {2011}
}
@article{GetR14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25422463{\}}{\{}25422463{\}}},
author = {Golan, D and Lander, E S and Rosset, S},
journal = {Proceedings of the National Academy of Sciences},
month = {dec},
number = {49},
pages = {E5272----5281},
title = {{{\{}M{\}}easuring missing heritability: inferring the contribution of common variants}},
volume = {111},
year = {2014}
}
@article{Savoca2000,
abstract = {This paper presents an overview of the theory of measurement error bias in ordinary regression estimators when several binary explanatory variables are mismeasured. This situation commonly occurs in health-related applications where the effects of illness are modeled in a multivariate framework and where health conditions are usually 0-1 survey responses indicating the absence or presence of diseases. An analysis of the effect of psychiatric diseases on male earnings provides an empirical example that indicates extensive measurement error bias even in sophisticated survey measures that are designed to simulate clinical diagnoses. A corrected covariance matrix is constructed from a validity study of the survey mental health indicators. When ordinary least squares estimators are adjusted by this correction matrix, the estimated earnings effects drop for certain diseases (drug abuse, general phobic disorders) and rise for others (anti-social personality).},
author = {Savoca, E.},
doi = {10.1023/A:1012541005920},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Health Services and Outcomes Research Methodology/Savoca - 2000 - Measurement errors in binary regressors An application to measuring the effects of specific psychiatric diseases on earn.pdf:pdf},
issn = {13873741},
journal = {Health Services and Outcomes Research Methodology},
keywords = {Binary variables,Measurement error,Multiple regression,Psychiatric diseases,error-in-variables},
mendeley-tags = {error-in-variables},
number = {2},
pages = {149--164},
title = {{Measurement errors in binary regressors: An application to measuring the effects of specific psychiatric diseases on earnings}},
volume = {1},
year = {2000}
}
@article{Durand2018a,
abstract = {In a high dimensional multiple testing framework, we present new confidence bounds on the false positives contained in subsets S of selected null hypotheses. The coverage probability holds simultaneously over all subsets S, which means that the obtained confidence bounds are post hoc. Therefore, S can be chosen arbitrarily, possibly by using the data set several times. We focus in this paper specifically on the case where the null hypotheses are spatially structured. Our method is based on recent advances in post hoc inference and particularly on the general methodology of Blanchard et al. (2017); we build confidence bounds for some pre-specified forest-structured subsets {\{}R k , k {\$}\backslashin{\$} K{\}}, called the reference family, and then we deduce a bound for any subset S by interpolation. The proposed bounds are shown to improve substantially previous ones when the signal is locally structured. Our findings are supported both by theoretical results and numerical experiments. Moreover, we show that our bound can be obtained by a low-complexity algorithm, which makes our approach completely operational for a practical use. The proposed bounds are implemented in the open-source R package sansSouci.},
archivePrefix = {arXiv},
arxivId = {1807.01470},
author = {Durand, Guillermo and Blanchard, Gilles and Neuvial, Pierre and Roquain, Etienne},
eprint = {1807.01470},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Durand et al. - 2018 - Post hoc false positive control for spatially structured hypotheses.pdf:pdf},
journal = {arXiv},
keywords = {and phrases,dkw inequality,forest structure,inequality,multiple testing,post hoc inference,selective inference,simes},
pages = {1--24},
title = {{Post hoc false positive control for spatially structured hypotheses}},
url = {http://arxiv.org/abs/1807.01470},
year = {2018}
}
@article{Lee2019,
abstract = {The use of inverse probability weighting (IPW) methods to estimate the causal effect of treatments from observational studies is widespread in econometrics, medicine and social sciences. Although these studies often involve sensitive information, thus far there has been no work on privacy-preserving IPW methods. We address this by providing a novel framework for privacy-preserving IPW (PP-IPW) methods. We include a theoretical analysis of the effects of our proposed privati-sation procedure on the estimated average treatment effect, and evaluate our PP-IPW framework on synthetic, semi-synthetic and real datasets. The empirical results are consistent with our theoretical findings.},
archivePrefix = {arXiv},
arxivId = {1905.12592v2},
author = {Lee, Si Kai and Gresele, Luigi and Park, Mijung and Muandet, Krikamol},
eprint = {1905.12592v2},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Lee et al. - 2019 - Privacy-Preserving Causal Inference via Inverse Probability Weighting.pdf:pdf},
journal = {arXiv},
keywords = {causality,error-in-variables,privacy},
mendeley-tags = {causality,error-in-variables,privacy},
title = {{Privacy-Preserving Causal Inference via Inverse Probability Weighting}},
year = {2019}
}
@article{SH14,
abstract = {{\textcopyright} 2014 Journal of Statistical Software. All right reserved. The R package structSSI provides an accessible implementation of two recently developed simultaneous and selective inference techniques: the group Benjamini-Hochberg and hierarchical false discovery rate procedures. Unlike many multiple testing schemes, these methods specifically incorporate existing information about the grouped or hierarchical dependence between hypotheses under consideration while controlling the false discovery rate. Doing so increases statistical power and interpretability. Furthermore, these procedures provide novel approaches to the central problem of encoding complex dependency between hypotheses. We briey describe the group Benjamini-Hochberg and hierarchical false discovery rate procedures and then illustrate them using two examples, one a measure of ecological microbial abundances and the other a global temperature time series. For both procedures, we detail the steps associated with the analysis of these particular data sets, including establishing the dependence structures, performing the test, and interpreting the results. These steps are encapsulated by R functions, and we explain their applicability to general data sets.},
author = {Sankaran, Kris and Holmes, Susan},
doi = {10.18637/jss.v059.i13},
issn = {1548-7660},
journal = {Journal of Statistical Software},
keywords = {Multiple testing,microbiome,software,structured multiple testing,trees},
mendeley-tags = {Multiple testing,microbiome,software,structured multiple testing,trees},
number = {13},
pages = {1--21},
title = {{structSSI : Simultaneous and Selective Inference for Grouped or Hierarchically Structured Data}},
url = {https://www.jstatsoft.org/v059/i13},
volume = {59},
year = {2015}
}
@book{Bickel1993,
address = {Baltimore},
author = {Bickel, P.J. and Klaassen, C.A. and Ritov, Y.A. and Wellner, J.A.},
keywords = {semiparametrics},
mendeley-tags = {semiparametrics},
publisher = {Johns Hopkins University Press},
title = {{Efficient and Adaptive Estimation for Semiparametric Models}},
year = {1993}
}
@article{Shi2019,
abstract = {Small {\$}p{\$}-values are often required to be accurately estimated in large scale genomic studies for the adjustment of multiple hypothesis tests and the ranking of genomic features based on their statistical significance. For those complicated test statistics whose cumulative distribution functions are analytical intractable, existing methods usually do not work well with small {\$}p{\$}-values due to lack of accuracy or computational restrictions. We propose a general approach for accurately and efficiently calculating small {\$}p{\$}-values for a broad range of complicated test statistics based on the principle of the cross-entropy method and Markov chain Monte Carlo sampling techniques.We evaluate the performance of the proposed algorithm through simulations and demonstrate its application to three real examples in genomic studies. The results show that our approach can accurately evaluate small to extremely small {\$}p{\$}-values (e.g. {\$}10{\^{}}{\{}-6{\}}{\$} to {\$}10{\^{}}{\{}-100{\}}{\$}). The proposed algorithm is helpful to the improvement of existing test procedures and the development of new test procedures in genomic studies.},
author = {Shi, Yang and Wang, Mengqiao and Shi, Weiping and Lee, Ji Hyun and Kang, Huining and Jiang, Hui},
doi = {10.1093/bioinformatics/bty1005},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Shi et al. - 2019 - Accurate and efficient estimation of small P-values with the cross-entropy method Applications in genomic data analy.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
keywords = {Monte Carlo,Multiple testing},
mendeley-tags = {Monte Carlo,Multiple testing},
number = {14},
pages = {2441--2448},
title = {{Accurate and efficient estimation of small P-values with the cross-entropy method: Applications in genomic data analysis}},
volume = {35},
year = {2019}
}
@article{RetD06,
abstract = {Scanning the genome for association between markers and complex diseases typically requires testing hundreds of thousands of genetic polymorphisms. Testing such a large number of hypotheses exacerbates the trade-off between power to detect meaningful associations and the chance of making false discoveries. Even before the full genome is scanned, investigators often favor certain regions on the basis of the results of prior investigations, such as previous linkage scans. The remaining regions of the genome are investigated simultaneously because genotyping is relatively inexpensive compared with the cost of recruiting participants for a genetic study and because prior evidence is rarely sufficient to rule out these regions as harboring genes with variation of conferring liability (liability genes). However, the multiple testing inherent in broad genomic searches diminishes power to detect association, even for genes falling in regions of the genome favored a priori. Multiple testing problems of this nature are well suited for application of the false-discovery rate (FDR) principle, which can improve power. To enhance power further, a new FDR approach is proposed that involves weighting the hypotheses on the basis of prior data. We present a method for using linkage data to weight the association P values. Our investigations reveal that if the linkage study is informative, the procedure improves power considerably. Remarkably, the loss in power is small, even when the linkage study is uninformative. For a class of genetic models, we calculate the sample size required to obtain useful prior information from a linkage study. This inquiry reveals that, among genetic models that are seemingly equal in genetic information, some are much more promising than others for this mode of analysis.},
annote = {16400608},
author = {Roeder, Kathryn and Bacanu, Silvi-Alin and Wasserman, Larry and Devlin, B},
journal = {American Journal of Human Genetics},
keywords = {GWAS,genetics},
mendeley-tags = {GWAS,genetics},
pages = {243--252},
title = {{{\{}Using{\}} Linkage Genome Scans to Improve Power of Association in Genome Scans}},
volume = {78},
year = {2006}
}
@article{Gilbert2013,
abstract = {The genetic interrogation and reprogramming of cells requires methods for robust and precise targeting of genes for expression or repression. The CRISPR-associated catalytically inactive dCas9 protein offers a general platform for RNA-guided DNA targeting. Here, we show that fusion of dCas9 to effector domains with distinct regulatory functions enables stable and efficient transcriptional repression or activation in human and yeast cells, with the site of delivery determined solely by a coexpressed short guide (sg)RNA. Coupling of dCas9 to a transcriptional repressor domain can robustly silence expression of multiple endogenous genes. RNA-seq analysis indicates that CRISPR interference (CRISPRi)-mediated transcriptional repression is highly specific. Our results establish that the CRISPR system can be used as a modular and flexible DNA-binding platform for the recruitment of proteins to a target DNA sequence, revealing the potential of CRISPRi as a general tool for the precise regulation of gene expression in eukaryotic cells. {\textcopyright} 2013 Elsevier Inc.},
author = {Gilbert, Luke A. and Larson, Matthew H. and Morsut, Leonardo and Liu, Zairan and Brar, Gloria A. and Torres, Sandra E. and Stern-Ginossar, Noam and Brandman, Onn and Whitehead, Evan H. and Doudna, Jennifer A. and Lim, Wendell A. and Weissman, Jonathan S. and Qi, Lei S.},
doi = {10.1016/j.cell.2013.06.044},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Gilbert et al. - 2013 - CRISPR-mediated modular RNA-guided regulation of transcription in eukaryotes.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
number = {2},
pages = {442},
publisher = {Elsevier Inc.},
title = {{CRISPR-mediated modular RNA-guided regulation of transcription in eukaryotes}},
url = {http://dx.doi.org/10.1016/j.cell.2013.06.044},
volume = {154},
year = {2013}
}
@article{ZZ14,
author = {Zhang, Cun-Hui and Zhang, Stephanie S},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society Series B (Statistical Methodology)/Zhang, Zhang - 2014 - Confidence intervals for low dimensional parameters in high dimensional linear models.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {1},
pages = {217--242},
publisher = {Wiley Online Library},
title = {{Confidence intervals for low dimensional parameters in high dimensional linear models}},
volume = {76},
year = {2014}
}
@article{OConnor2016,
abstract = {Identifying the genomic regions and regulatory factors that control the transcription of genes is an important, unsolved problem. The current method of choice predicts transcription factor (TF) binding sites using chromatin immunoprecipitation followed by sequencing (ChIP-seq), and then links the binding sites to putative target genes solely on the basis of the genomic distance between them. Evidence from chromatin conformation capture experiments shows that this approach is inadequate due to long-distance regulation via chromatin looping. We present CisMapper, which predicts the regulatory targets of a TF using the correlation between a histone mark at the TF's bound sites and the expression of each gene across a panel of tissues. Using both chromatin conformation capture and differential expression data, we show that CisMapper is more accurate at predicting the target genes of a TF than the distance-based approaches currently used, and is particularly advantageous for predicting the long-range regulatory interactions typical of tissue-specific gene expression. CisMapper also predicts which TF binding sites regulate a given gene more accurately than using genomic distance. Unlike distance-based methods, CisMapper can predict which transcription start site of a gene is regulated by a particular binding site of the TF.},
author = {O'Connor, Timothy and Bod{\'{e}}n, Mikael and Bailey, Timothy L.},
doi = {10.1093/nar/gkw956},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nucleic acids research/O'Connor, Bod{\'{e}}n, Bailey - 2017 - CisMapper predicting regulatory interactions from transcription factor ChIP-seq data.pdf:pdf},
issn = {13624962},
journal = {Nucleic acids research},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {4},
pages = {e19},
title = {{CisMapper: predicting regulatory interactions from transcription factor ChIP-seq data}},
url = {https://academic.oup.com/nar/article-abstract/45/4/e19/2290926},
volume = {45},
year = {2017}
}
@article{FetS13,
author = {Flutre, T and Wen, X and Pritchard, J and Stephens, M},
journal = {PLoS Genetics},
keywords = {multiple phenotypes},
mendeley-tags = {multiple phenotypes},
month = {may},
number = {5},
pages = {e1003486},
title = {{{\{}A{\}} statistical framework for joint e{\{}Q{\}}{\{}T{\}}{\{}L{\}} analysis in multiple tissues}},
volume = {9},
year = {2013}
}
@article{Lieberman-aiden2009,
abstract = {We describe Hi-C, a method that probes the three-dimensional architecture of whole genomes by coupling proximity-based ligation with massively parallel sequencing. We constructed spatial proximity maps of the human genome with Hi-C at a resolution of 1 megabase. These maps confirm the presence of chromosome territories and the spatial proximity of small, gene-rich chromosomes. We identified an additional level of genome organization that is characterized by the spatial segregation of open and closed chromatin to form two genome-wide compartments. At the megabase scale, the chromatin conformation is consistent with a fractal globule, a knot-free, polymer conformation that enables maximally dense packing while preserving the ability to easily fold and unfold any genomic locus. The fractal globule is distinct from the more commonly used globular equilibrium model. Our results demonstrate the power of Hi-C to map the dynamic conformations of whole genomes},
author = {Lieberman-Aiden, Erez and Berkum, Nynke L Van and Williams, Louise and Imakaev, Maxim and Ragoczy, Tobias and Telling, Agnes and Amit, Ido and Lajoie, Bryan R and Sabo, Peter J and Dorschner, Michael O and Sandstrom, Richard and Bernstein, Bradley and Bender, M A and Groudine, Mark and Gnirke, Andreas and Stamatoyannopoulos, John and Mirny, Leonid A},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Lieberman-Aiden et al. - 2009 - Comprehensive Mapping of Long-Range Interactions Reveals Folding Principles of the Human Genome.pdf:pdf},
journal = {Science},
keywords = {HI-C,Kathryn,gene-enhancer},
mendeley-tags = {HI-C,Kathryn,gene-enhancer},
pages = {289--293},
title = {{Comprehensive Mapping of Long-Range Interactions Reveals Folding Principles of the Human Genome}},
volume = {326},
year = {2009}
}
@article{Alvo2018,
abstract = {In 1937, Neyman introduced the notion of smooth tests of the null hypothesis that the sample data come from a uniform distribution on the interval (0,1) against alternatives in a smooth parametric family. This idea can be used to embed various nonparametric inference problems in a parametric family. Focusing on nonparametric rank tests, we show how to derive traditional rank tests by applying this approach. We also show how to use it to obtain simplifying insights and optimality results in complicated settings that involve censored and truncated data, for which it is more convenient to use hazard functions to define the embedded family. We describe an application of the embedding approach to the problem of testing for trend in environmental studies.},
author = {Alvo, Mayer and Lai, Tze Leung and Yu, Philip L.H.},
doi = {10.1080/15598608.2017.1399840},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Statistical Theory and Practice/Alvo, Lai, Yu - 2018 - Parametric embedding of nonparametric inference problems.pdf:pdf},
issn = {15598616},
journal = {Journal of Statistical Theory and Practice},
keywords = {Parametric embedding,asymptotics,censored and truncated data,hazard rank tests,nonparametric inference,smooth tests},
mendeley-tags = {asymptotics},
number = {1},
pages = {151--164},
title = {{Parametric embedding of nonparametric inference problems}},
volume = {12},
year = {2018}
}
@article{KetT15,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26699465{\}}{\{}26699465{\}}},
author = {{Krishna Kumar}, S and Feldman, M W and Rehkopf, D H and Tuljapurkar, S},
journal = {Proceedings of the National Academy of Sciences},
keywords = {GWAS,linear mixed models},
mendeley-tags = {GWAS,linear mixed models},
month = {jan},
number = {1},
pages = {61--70},
title = {{{\{}L{\}}imitations of {\{}G{\}}{\{}C{\}}{\{}T{\}}{\{}A{\}} as a solution to the missing heritability problem}},
volume = {113},
year = {2016}
}
@article{GetH16,
author = {Gaziano, John Michael and Concato, John and Brophy, Mary and Fiore, Louis and Pyarajan, Saiju and Breeling, James and Whitbourne, Stacey and Deen, Jennifer and Shannon, Colleen and Humphries, Donald and Others},
journal = {Journal of Clinical Epidemiology},
keywords = {GWAS,genetics},
mendeley-tags = {GWAS,genetics},
pages = {214--223},
publisher = {Elsevier},
title = {{Million Veteran Program: a mega-biobank to study genetic influences on health and disease}},
volume = {70},
year = {2016}
}
@article{MacArthur2017,
abstract = {The NHGRI-EBI GWAS Catalog has provided data from published genome-wide association studies since 2008. In 2015, the database was redesigned and relocated to EMBL-EBI. The new infrastructure includes a new graphical user interface (www.ebi. ac.uk/gwas/), ontology supported search functionality and an improved curation interface. These developments have improved the data release frequency by increasing automation of curation and providing scaling improvements. The range of available Catalog data has also been extended with structured ancestry and recruitment information added for all studies. The infrastructure improvements also support scaling for larger arrays, exome and sequencing studies, allowing the Catalog to adapt to the needs of evolving study design, genotyping technologies and user needs in the future.},
author = {MacArthur, Jacqueline and Bowler, Emily and Cerezo, Maria and Gil, Laurent and Hall, Peggy and Hastings, Emma and Junkins, Heather and McMahon, Aoife and Milano, Annalisa and Morales, Joannella and MayPendlington, Zoe and Welter, Danielle and Burdett, Tony and Hindorff, Lucia and Flicek, Paul and Cunningham, Fiona and Parkinson, Helen},
doi = {10.1093/nar/gkw1133},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nucleic Acids Research/MacArthur et al. - 2017 - The new NHGRI-EBI Catalog of published genome-wide association studies (GWAS Catalog).pdf:pdf},
issn = {13624962},
journal = {Nucleic Acids Research},
number = {D1},
pages = {D896--D901},
pmid = {27899670},
title = {{The new NHGRI-EBI Catalog of published genome-wide association studies (GWAS Catalog)}},
volume = {45},
year = {2017}
}
@article{Segal2018,
abstract = {Researchers in genetics and other life sciences commonly use permutation tests to evaluate differences between groups. Permutation tests have desirable properties, including exactness if data are exchangeable, and are applicable even when the distribution of the test statistic is analytically intractable. However, permutation tests can be computationally intensive. We propose both an asymptotic approximation and a resampling algorithm for quickly estimating small permutation p-values (e.g. {\$}{\textless}10{\^{}}{\{}-6{\}}{\$}) for the difference and ratio of means in two-sample tests. Our methods are based on the distribution of test statistics within and across partitions of the permutations, which we define. In this article, we present our methods and demonstrate their use through simulations and an application to cancer genomic data. Through simulations, we find that our resampling algorithm is more computationally efficient than another leading alternative, particularly for extremely small p-values (e.g. {\$}{\textless}10{\^{}}{\{}-30{\}}{\$}). Through application to cancer genomic data, we find that our methods can successfully identify up- and down-regulated genes. While we focus on the difference and ratio of means, we speculate that our approaches may work in other settings.},
author = {Segal, Brian D. and Braun, Thomas and Elliott, Michael R. and Jiang, Hui},
doi = {10.1111/biom.12731},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrics/Segal et al. - 2018 - Fast approximation of small p-values in permutation tests by partitioning the permutations.pdf:pdf},
issn = {15410420},
journal = {Biometrics},
keywords = {Computational efficiency,Genomics,Monte Carlo,Multiple hypothesis tests,Multiple testing,Resampling methods,Two-sample tests},
mendeley-tags = {Monte Carlo,Multiple testing},
number = {1},
pages = {196--206},
title = {{Fast approximation of small p-values in permutation tests by partitioning the permutations}},
volume = {74},
year = {2018}
}
@article{Buzkova2011,
abstract = {Permutation tests are widely used in genomic research as a straightforward way to obtain reliable statistical inference without making strong distributional assumptions. However, in this paper we show that in genetic association studies it is not typically possible to construct exact permutation tests of gene-gene or gene-environment interaction hypotheses. We describe an alternative to the permutation approach in testing for interaction, a parametric bootstrap approach. Using simulations, we compare the finite-sample properties of a few often-used permutation tests and the parametric bootstrap. We consider interactions of an exposure with single and multiple polymorphisms. Finally, we address when permutation tests of interaction will be approximately valid in large samples for specific test statistics. {\textcopyright} 2010 The Authors Annals of Human Genetics {\textcopyright} 2010 Blackwell Publishing Ltd/University College London.},
author = {Bů{\v{z}}kov{\'{a}}, Petra and Lumley, Thomas and Rice, Kenneth},
doi = {10.1111/j.1469-1809.2010.00572.x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Human Genetics/Bů{\v{z}}kov{\'{a}}, Lumley, Rice - 2011 - Permutation and parametric bootstrap tests for gene-gene and gene-environment interactions.pdf:pdf},
issn = {00034800},
journal = {Annals of Human Genetics},
keywords = {Interaction testing,Parametric bootstrap,Permutation methods,bootstrap,interactions},
mendeley-tags = {bootstrap,interactions},
number = {1},
pages = {36--45},
pmid = {20384625},
title = {{Permutation and parametric bootstrap tests for gene-gene and gene-environment interactions}},
volume = {75},
year = {2011}
}
@article{Ahlmann-Eltze2020a,
abstract = {Motivation: The Gamma-Poisson distribution is a theoretically and empirically motivated model for the sampling variability of single cell RNA-sequencing counts (Gr{\&}uumln et al., 2014; Townes et al., 2019; Svensson, 2020; Silverman et al., 2018; Hafemeister and Satija, 2019) and an essential building block for analysis approaches including differential expression analysis (Robinson et al., 2010; McCarthy et al., 2012; Anders and Huber, 2010; Love et al., 2014), principal component analysis (Townes et al., 2019) and factor analysis(Risso et al., 2018). Existing implementations for inferring its parameters from data often struggle with the size of single cell datasets, which typically comprise thousands or millions of cells; at the same time, they do not take full advantage of the fact that zero and other small numbers are frequent in the data. These limitations have hampered uptake of the model, leaving room for statistically inferior approaches such as logarithm(-like) transformation. Results: We present a new R package for fitting the Gamma-Poisson distribution to data with the characteristics of modern single cell datasets more quickly and more accurately than existing methods. The software can work with data on disk without having to load them into RAM simultaneously. {\#}{\#}{\#} Competing Interest Statement The authors have declared no competing interest.},
author = {Ahlmann-Eltze, Constantin and Huber, Wolfgang},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Ahlmann-Eltze, Huber - 2020 - glmGamPoi Fitting Gamma-Poisson Generalized Linear Models on Single Cell Count Data.pdf:pdf},
journal = {Bioinformatics},
keywords = {negative binomial,single cell},
mendeley-tags = {negative binomial,single cell},
title = {{glmGamPoi: Fitting Gamma-Poisson Generalized Linear Models on Single Cell Count Data}},
url = {https://www.biorxiv.org/content/10.1101/2020.08.13.249623v1},
year = {2020}
}
@article{Loh2016,
abstract = {Haplotype phasing is a fundamental problem in medical and population genetics. Phasing is generally performed via statistical phasing in a genotyped cohort, an approach that can yield high accuracy in very large cohorts but attains lower accuracy in smaller cohorts. Here we instead explore the paradigm of reference-based phasing. We introduce a new phasing algorithm, Eagle2, that attains high accuracy across a broad range of cohort sizes by efficiently leveraging information from large external reference panels (such as the Haplotype Reference Consortium; HRC) using a new data structure based on the positional Burrows-Wheeler transform. We demonstrate that Eagle2 attains a {\~{}}20× speedup and {\~{}}10{\%} increase in accuracy compared to reference-based phasing using SHAPEIT2. On European-ancestry samples, Eagle2 with the HRC panel achieves {\textgreater}2× the accuracy of 1000 Genomes-based phasing. Eagle2 is open source and freely available for HRC-based phasing via the Sanger Imputation Service and the Michigan Imputation Server. Haplotype phasing is a central problem in human genetics 1. Over the past decade, phasing has most commonly been performed via statistical methods applied in a genotyped cohort 2-14. Wet-lab technologies for direct phasing have also generated considerable recent interest, but these methods are currently much less scalable 15. In general, the accuracy of statistical phasing methods increases steadily with sample size owing to improved modeling of linkage disequilibrium and increasing prevalence of identity by descent. We and others have recently developed methods that achieve very high statistical phasing accuracy in cohorts comprising a large fraction of a population 8 or containing {\textgreater}100,000 samples 13,14. However, for smaller cohorts, accuracy of cohort-based statistical phasing is fundamentally limited by the quantity of data available. Here we explore an alternative paradigm, reference-based phasing, which can be used to achieve high accuracy even in smaller cohorts by leveraging information from an external reference panel. This paradigm targets a user group complementary to recent methods for phasing very large cohorts 13,14. In particular, methods for mapping molecular QTLs using allele-specific reads require accurate phasing information, but recent papers introducing these methods have reported that inaccurate phasing currently limits their potential 16,17. We present a new reference-based phasing algorithm, Eagle2, which we incorporated into the Sanger Imputation Service and the Michigan Imputation Server 18 to perform free reference phasing using the 32,470-sample HRC panel 19. This approach achieved {\textgreater}2× improved phasing accuracy over 1000 Genomes-based phasing on small European-ancestry cohorts, with smaller improvements for larger cohort sizes. The Eagle2 algorithm represents a substantial computational advance over existing reference-based phasing algorithms: Eagle2 achieved a 20× speedup over SHAPEIT2 (ref. 12), i.e., genome-wide phasing in 1.5 min per sample, with a 10{\%} improvement in accuracy across a range of ancestries. Eagle2 achieved this performance via two key ideas that distinguish it from previous phasing algorithms 3-14 : a new data structure based on the positional Burrows-Wheeler transform 20 and a rapid search algorithm that explores only the most relevant phase paths through a hidden Markov model (HMM). We released Eagle2 as open-source software (see URLs). RESULTS Overview of methods The Eagle2 phasing algorithm takes as input a diploid target sample and a library of reference haplotypes. The statistical model underlying Eagle2 is a haplotype copying model similar to the Li-Stephens model 21 used by previous HMM-based methods. However, Eagle2 has two key differences compared to previous HMM-based methods.},
author = {Loh, Po-Ru and Danecek, Petr and Palamara, Pier Francesco and Fuchsberger, Christian and Reshef, Yakir A and Finucane, Hilary K and Schoenherr, Sebastian and Forer, Lukas and Mccarthy, Shane and Abecasis, Goncalo R and Durbin, Richard and Price, Alkes L},
doi = {10.1038/ng.3679},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Loh et al. - 2016 - Reference-based phasing using the Haplotype Reference Consortium panel.pdf:pdf},
journal = {Nature Genetics},
keywords = {genetics,phasing,software},
mendeley-tags = {genetics,phasing,software},
number = {11},
pages = {1443--1448},
title = {{Reference-based phasing using the Haplotype Reference Consortium panel}},
volume = {48},
year = {2016}
}
@article{GB07,
author = {Goeman, Jelle and Buhlmann, Peter},
journal = {Bioinformatics},
number = {8},
pages = {980--987},
title = {{Analyzing gene expression data in terms of gene sets: methodological issues}},
volume = {23},
year = {2007}
}
@article{C14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/24817879{\}}{\{}24817879{\}}},
author = {Chen, G B},
journal = {Front Genet},
keywords = {heritability},
mendeley-tags = {heritability},
pages = {107},
title = {{{\{}E{\}}stimating heritability of complex traits from genome-wide association studies using {\{}I{\}}{\{}B{\}}{\{}S{\}}-based {\{}H{\}}aseman-{\{}E{\}}lston regression}},
volume = {5},
year = {2014}
}
@inproceedings{DB16,
author = {Dai, Ran and Barber, Rina Foygel},
booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
keywords = {FDR,Multiple testing,high-dimensional regression,knockoffs},
mendeley-tags = {FDR,Multiple testing,high-dimensional regression,knockoffs},
pages = {1851--1859},
publisher = {JMLR.org},
series = {ICML'16},
title = {{The Knockoff Filter for FDR Control in Group-sparse and Multitask Regression}},
url = {http://dl.acm.org/citation.cfm?id=3045390.3045586},
year = {2016}
}
@article{Gandy2014,
abstract = {Consider testing multiple hypotheses using tests that can only be evaluated by simulation, such as permutation tests or bootstrap tests. This article introduces MMCTest, a sequential algorithm which gives, with arbitrarily high probability, the same classification as a specific multiple testing procedure applied to ideal p-values. The method can be used with a class of multiple testing procedures which includes the Benjamini {\&} Hochberg False Discovery Rate (FDR) procedure and the Bonferroni correction controlling the Familywise Error Rate. One of the key features of the algorithm is that it stops sampling for all the hypotheses which can already be decided as being rejected or non-rejected. MMCTest can be interrupted at any stage and then returns three sets of hypotheses: the rejected, the non-rejected and the undecided hypotheses. A simulation study motivated by actual biological data shows that MMCTest is usable in practice and that, despite the additional guarantee, it can be computationally more efficient than other methods.},
author = {Gandy, Axel and Hahn, Georg},
doi = {10.1111/sjos.12085},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Scandinavian Journal of Statistics/Gandy, Hahn - 2014 - MMCTest-A safe algorithm for implementing multiple monte carlo tests.pdf:pdf},
issn = {14679469},
journal = {Scandinavian Journal of Statistics},
keywords = {Benjamini-Hochberg,Bonferroni correction,Bootstrap,False discovery rate,Monte Carlo,Multiple comparisons,Multiple testing,Resampling,Sequential algorithm},
mendeley-tags = {Monte Carlo,Multiple testing},
number = {4},
pages = {1083--1101},
title = {{MMCTest-A safe algorithm for implementing multiple monte carlo tests}},
volume = {41},
year = {2014}
}
@article{M55,
abstract = {Information on linkage in man is accumulated as a succession of samples, each of which is typically small relative to the amount of data required to detect even moderately close linkage. The best method of analysis for such sequential samples, in the sense of requiring the least number of observations consistent with a given risk of error, has been found to be a sequential probability ratio test (Wald, 1947). It will now be shown that this test, in addition to minimizing the number of observations, is in other respects a useful method for the detection of linkage in man.},
annote = {13258560},
author = {MORTON, N E},
issn = {0002-9297},
journal = {American Journal of Human Genetics},
number = {3},
pages = {277--318},
pmid = {13258560},
title = {{Sequential tests for the detection of linkage.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/13258560{\%}0Ahttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC1716611},
volume = {7},
year = {1955}
}
@article{Bahadur1967,
abstract = {The classical chi-square test for independence in a two-way contigency table often rejects the independence hypothesis at an extremely small significance level, particularly when the sample size is large. This paper proposes some alternative distributions to independence, to help interpret the X{\^{}}2 statistic in such situations. The uniform alternative, in which every possible contingency table of the given dimension and sample size receives equal probability, leads to the volume test, as originally suggested in a regression context by H. Hotelling. Exponential family theory is used to generate a class of intermediate alternatives between independence and uniformity, leading to a random effects model for contingency tables.},
author = {Bahadur, R. R.},
doi = {10.1214/aoms/1177698949},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Mathematical Statistics/Bahadur - 1967 - Rates of Convergence of Estimates and Test Statistics.pdf:pdf},
issn = {0003-4851},
journal = {The Annals of Mathematical Statistics},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {2},
pages = {303--324},
title = {{Rates of Convergence of Estimates and Test Statistics}},
volume = {38},
year = {1967}
}
@article{Wang2019d,
abstract = {Causal inference from observational data is a vital problem, but it comes with strong assumptions. Most methods assume that we observe all confounders, variables that affect both the causal variables and the outcome variables. This assumption is standard but it is also untestable. In this article, we develop the deconfounder, a way to do causal inference with weaker assumptions than the traditional methods require. The deconfounder is designed for problems of multiple causal inference: scientific studies that involve multiple causes whose effects are simultaneously of interest. Specifically, the deconfounder combines unsupervised machine learning and predictive model checking to use the dependencies among multiple causes as indirect evidence for some of the unobserved confounders. We develop the deconfounder algorithm, prove that it is unbiased, and show that it requires weaker assumptions than traditional causal inference. We analyze its performance in three types of studies: semi-simulated data around smoking and lung cancer, semi-simulated data around genome-wide association studies, and a real dataset about actors and movie revenue. The deconfounder is an effective approach to estimating causal effects in problems of multiple causal inference. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1805.06826},
author = {Wang, Yixin and Blei, David M.},
doi = {10.1080/01621459.2019.1686987},
eprint = {1805.06826},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Wang, Blei - 2019 - The Blessings of Multiple Causes.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Causal inference,Machine learning,Probabilistic models,Unconfoundedness,Unobserved confounding,causality},
mendeley-tags = {causality},
number = {528},
pages = {1574--1596},
publisher = {Taylor {\&} Francis},
title = {{The Blessings of Multiple Causes}},
url = {https://doi.org/10.1080/01621459.2019.1686987},
volume = {114},
year = {2019}
}
@article{MetT10,
abstract = {In a genetic association study, it is often desirable to perform an overall test of whether any or all single-nucleotide polymorphisms (SNPs) in a gene are associated with a phenotype. Several such tests exist, but most of them are powerful only under very specific assumptions about the genetic effects of the individual SNPs. In addition, some of the existing tests assume that the direction of the effect of each SNP is known, which is a highly unlikely scenario. Here, we propose a new kernel-based association test of joint association of several SNPs. Our test is non-parametric and robust, and does not make any assumption about the directions of individual SNP effects. It can be used to test multiple correlated SNPs within a gene and can also be used to test independent SNPs or genes in a biological pathway. Our test uses an analysis of variance paradigm to compare variation between cases and controls to the variation within the groups. The variation is measured using kernel functions for each marker, and then a composite statistic is constructed to combine the markers into a single test. We present simulation results comparing our statistic to the U-statistic-based method by Schaid et al. ([2005] Am. J. Hum. Genet. 76:780-793) and another statistic by Wessel and Schork ([2006] Am. J. Hum. Genet. 79:792-806). We consider a variety of different disease models and assumptions about how many SNPs within the gene are actually associated with disease. Our results indicate that our statistic has higher power than other statistics under most realistic conditions.},
annote = {19697357},
author = {Mukhopadhyay, I and Feingold, E and Weeks, D E and Thalamuthu, A},
doi = {10.1002/gepi.20451},
journal = {Genetic Epidemiology},
keywords = {GWAS},
mendeley-tags = {GWAS},
number = {3},
pages = {213--221},
title = {{Association tests using kernel-based measures of multi-locus genotype similarity between individuals}},
url = {http://www.hubmed.org/display.cgi?uids=19697357},
volume = {34},
year = {2010}
}
@article{KetR08,
abstract = {When many correlated traits are measured the potential exists to discover the coordinated control of these traits via genotyped polymorphisms. A common statistical approach to this problem involves assessing the relationship between each phenotype and each single nucleotide polymorphism (SNP) individually (PHN); and taking a Bonferroni correction for the effective number of independent tests conducted. Alternatively, one can apply a dimension reduction technique, such as estimation of principal components, and test for an association with the principal components of the phenotypes (PCP) rather than the individual phenotypes. Building on the work of Lange and colleagues we develop an alternative method based on the principal component of heritability (PCH). For each SNP the PCH approach reduces the phenotypes to a single trait that has a higher heritability than any other linear combination of the phenotypes. As a result, the association between a SNP and derived trait is often easier to detect than an association with any of the individual phenotypes or the PCP. When applied to unrelated subjects, PCH has a drawback. For each SNP it is necessary to estimate the vector of loadings that maximize the heritability over all phenotypes. We develop a method of iterated sample splitting that uses one portion of the data for training and the remainder for testing. This cross-validation approach maintains the type I error control and yet utilizes the data efficiently, resulting in a powerful test for association.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/17922480{\}}{\{}17922480{\}}},
author = {Klei, Lambertus and Luca, Diana and Devlin, B and Roeder, Kathryn},
journal = {Genetic Epidemiology},
pages = {9--19},
title = {{{\{}Pleiotropy{\}} and Principal Components of Heritability Combine to Increase Power for Association Analysis}},
volume = {32},
year = {2008}
}
@article{Kim2010,
abstract = {We used genome-wide sequencing methods to study stimulus-dependent enhancer function in mouse cortical neurons. We identified approximately 12,000 neuronal activity-regulated enhancers that are bound by the general transcriptional co-activator CBP in an activity-dependent manner. A function of CBP at enhancers may be to recruit RNA polymerase II (RNAPII), as we also observed activity-regulated RNAPII binding to thousands of enhancers. Notably, RNAPII at enhancers transcribes bi-directionally a novel class of enhancer RNAs (eRNAs) within enhancer domains defined by the presence of histone H3 monomethylated at lysine 4. The level of eRNA expression at neuronal enhancers positively correlates with the level of messenger RNA synthesis at nearby genes, suggesting that eRNA synthesis occurs specifically at enhancers that are actively engaged in promoting mRNA synthesis. These findings reveal that a widespread mechanism of enhancer activation involves RNAPII binding and eRNA synthesis.},
author = {Kim, Tae Kyung and Hemberg, Martin and Gray, Jesse M. and Costa, Allen M. and Bear, Daniel M. and Wu, Jing and Harmin, David A. and Laptewicz, Mike and Barbara-Haley, Kellie and Kuersten, Scott and Markenscoff-Papadimitriou, Eirene and Kuhl, Dietmar and Bito, Haruhiko and Worley, Paul F. and Kreiman, Gabriel and Greenberg, Michael E.},
doi = {10.1038/nature09033},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Kim et al. - 2010 - Widespread transcription at neuronal activity-regulated enhancers.pdf:pdf},
issn = {00280836},
journal = {Nature},
keywords = {Kathryn,eRNA},
mendeley-tags = {Kathryn,eRNA},
number = {7295},
pages = {182--187},
publisher = {Nature Publishing Group},
title = {{Widespread transcription at neuronal activity-regulated enhancers}},
url = {http://dx.doi.org/10.1038/nature09033},
volume = {465},
year = {2010}
}
@article{ZD11,
author = {Zeisel, Amit and Zuk, Or and Domany, Eytan},
doi = {10.1214/10-AOAS399},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Applied Statistics/Zeisel, Zuk, Domany - 2011 - FDR control with adaptive procedures and FDR monotonicity.pdf:pdf},
issn = {1932-6157},
journal = {The Annals of Applied Statistics},
keywords = {Multiple testing,null proportion adaptivity},
mendeley-tags = {Multiple testing,null proportion adaptivity},
number = {2A},
pages = {943--968},
title = {{FDR control with adaptive procedures and FDR monotonicity}},
url = {https://doi.org/10.1214/10-AOAS399},
volume = {5},
year = {2011}
}
@article{Hoeffding1952,
author = {Hoeffding, Wassily},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Mathematical Statistics/Hoeffding - 1952 - The Large-Sample Power of Tests Based on Permutations of Observations.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
number = {2},
pages = {169--192},
title = {{The Large-Sample Power of Tests Based on Permutations of Observations}},
volume = {23},
year = {1952}
}
@article{VanDeGeer2014,
abstract = {We propose a general method for constructing confidence intervals and statistical tests for single or low-dimensional components of a large parameter vector in a high-dimensional model. It can be easily adjusted for multiplicity taking dependence among tests into account. For linear models, our method is essentially the same as in Zhang and Zhang [J. R. Stat. Soc. Ser. B Stat. Methodol. 76 (2014) 217-242]: we analyze its asymptotic properties and establish its asymptotic optimality in terms of semiparametric efficiency. Our method naturally extends to generalized linear models with convex loss functions. We develop the corresponding theory which includes a careful analysis for Gaussian, sub-Gaussian and bounded correlated designs.},
author = {{Van De Geer}, Sara and B{\"{u}}hlmann, Peter and Ritov, Ya'acov and Dezeure, Ruben},
doi = {10.1214/14-AOS1221},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Van De Geer et al. - 2014 - On asymptotically optimal confidence regions and tests for high-dimensional models.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Central limit theorem,Generalized linear model,Lasso,Linear model,Multiple testing,Semiparametric efficiency,Sparsity},
number = {3},
pages = {1166--1202},
title = {{On asymptotically optimal confidence regions and tests for high-dimensional models}},
volume = {42},
year = {2014}
}
@article{S102,
abstract = {Measures of genomic similarity are often the basis of flexible statistical analyses, and when based on kernel methods, they provide a powerful platform to take advantage of a broad and deep statistical theory, and a wide range of existing software; see the companion paper for a review of this material [1]. The kernel method converts information - perhaps complex or high-dimensional information - for a pair of subjects to a quantitative value representing either similarity or dissimilarity, with the requirement that it must create a positive semidefinite matrix when applied to all pairs of subjects. This approach provides enormous opportunities to enhance genetic analyses by including a wide range of publically-available data as structured kernel 'prior' information. Kernel methods are appealing for their generality, yet this generality can make it challenging to formulate measures of similarity that directly address a specific scientific aim, or that are most powerful to detect a specific genetic mechanism. Although it is difficult to create a cook book of kernels for genetic studies, useful guidelines can be gleaned from a variety of novel published approaches. We review some novel developments of kernels for specific analyses and speculate on how to build kernels for complex genomic attributes based on publically available data. The creativity of analysts, with rigorous evaluations by applications to real and simulated data, will ultimately provide a much stronger array of kernel 'tools' for genetic analyses.},
annote = {20606458},
author = {Schaid, D J},
doi = {10.1159/000312643},
journal = {Hum Hered},
number = {2},
pages = {132--140},
title = {{Genomic Similarity and Kernel Methods II: Methods for Genomic Information}},
url = {http://www.hubmed.org/display.cgi?uids=20606458},
volume = {70},
year = {2010}
}
@article{Peets2019,
abstract = {Genetic screens based on CRISPR/Cas technology are a powerful tool for understanding cellular phenotypes. However, the coverage and replicate requirements result in large experiment sizes, which are limiting when samples are scarce, or the protocols are expensive and laborious. Here, we present an approach to reduce the scale of genome-wide perturbation screens up to fivefold without sacrificing performance. To do so, we deliver two randomly paired gRNAs into each cell, and rely on recent advances in gRNA design, as well as availability of gRNA effect measurements, to reduce the number of gRNAs per gene. We designed a human genome-wide library that has effective size of 30,000 constructs, yet targets each gene with three gRNAs. Our minimized double guide RNA library gives similar results to a standard single gRNA one, but using substantially fewer cells. We demonstrate that genome-wide screens can be optimized in a demanding model of induced pluripotent stem cells, reducing reagent cost 70{\%} per replicate compared to conventional approach, while retaining high performance. The screen design and the reduction in scale it provides will enable functional genomics experiments across many possible combinations of environments and genetic backgrounds, as well as in hard to obtain and culture primary cells.},
author = {Peets, Elin Madli and Crepaldi, Luca and Zhou, Yan and Allen, Felicity and Elmentaite, Rasa and Noell, Guillaume and Turner, Gemma and Parts, Leopold and Campus, Wellcome Genome},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Peets et al. - 2019 - Minimized double guide RNA libraries enable scale-limited CRISPR Cas9 screens.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,gene-enhancer},
mendeley-tags = {CRISPR,gene-enhancer},
title = {{Minimized double guide RNA libraries enable scale-limited CRISPR / Cas9 screens}},
year = {2019}
}
@article{SJ06,
abstract = {In systems like Escherichia Coli, the abundance of sequence information, gene expression array studies and small scale experiments allows one to reconstruct the regulatory network and to quantify the effects of transcription factors on gene expression. However, this goal can only be achieved if all information sources are used in concert.Our method integrates literature information, DNA sequences and expression arrays. A set of relevant transcription factors is defined on the basis of literature. Sequence data are used to identify potential target genes and the results are used to define a prior distribution on the topology of the regulatory network. A Bayesian hidden component model for the expression array data allows us to identify which of the potential binding sites are actually used by the regulatory proteins in the studied cell conditions, the strength of their control, and their activation profile in a series of experiments. We apply our methodology to 35 expression studies in E.Coli with convincing results.www.genetics.ucla.edu/labs/sabatti/software.htmlThe supplementary material are available at Bioinformatics online.},
annote = {16368767},
author = {Sabatti, C and James, G M},
doi = {10.1093/bioinformatics/btk017},
journal = {Bioinformatics},
number = {6},
pages = {739--746},
title = {{Bayesian sparse hidden components analysis for transcription regulation networks}},
url = {http://www.hubmed.org/display.cgi?uids=16368767},
volume = {22},
year = {2006}
}
@article{Zhu2019,
abstract = {The Gene Ontology (GO) is a central resource for functional-genomics research. Scientists rely on the functional annotations in the GO for hypothesis generation and couple it with high-throughput biological data to enhance interpretation of results. At the same time, the sheer number of concepts ({\textgreater}30,000) and relationships ({\textgreater}70,000) presents a challenge: it can be difficult to draw a comprehensive picture of how certain concepts of interest might relate with the rest of the ontology structure. Here we present new visualization strategies to facilitate the exploration and use of the information in the GO. We rely on novel graphical display and software architecture that allow significant interaction. To illustrate the potential of our strategies, we provide examples from high-throughput genomic analyses, including chromatin immunoprecipitation experiments and genome-wide association studies. The scientist can also use our visualizations to identify gene sets that likely experience coordinated changes in their expression and use them to simulate biologically-grounded single cell RNA sequencing data, or conduct power studies for differential gene expression studies using our built-in pipeline. Our software and documentation are available at http://aegis.stanford.edu.},
author = {Zhu, Junjie and Zhao, Qian and Katsevich, Eugene and Sabatti, Chiara},
doi = {10.1038/s41598-019-42178-x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Scientific Reports/Zhu et al. - 2019 - Exploratory Gene Ontology Analysis with Interactive Visualization.pdf:pdf},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {1--9},
pmid = {31127124},
publisher = {Springer US},
title = {{Exploratory Gene Ontology Analysis with Interactive Visualization}},
volume = {9},
year = {2019}
}
@article{Wang2017a,
abstract = {Learning directed acyclic graphs using both observational and interventional data is now a fundamentally important problem due to recent technological developments in genomics that generate such single-cell gene expression data at a very large scale. In order to utilize this data for learning gene regulatory networks, efficient and reliable causal inference algorithms are needed that can make use of both observational and interventional data. In this paper, we present two algorithms of this type and prove that both are consistent under the faithfulness assumption. These algorithms are interventional adaptations of the Greedy SP algorithm and are the first algorithms using both observational and interventional data with consistency guarantees. Moreover, these algorithms have the advantage that they are nonparametric, which makes them useful also for analyzing non-Gaussian data. In this paper, we present these two algorithms and their consistency guarantees, and we analyze their performance on simulated data, protein signaling data, and single-cell gene expression data.},
archivePrefix = {arXiv},
arxivId = {1705.10220},
author = {Wang, Yuhao and Solus, Liam and Yang, Karren Dai and Uhler, Caroline},
eprint = {1705.10220},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Advances in Neural Information Processing Systems/Wang et al. - 2017 - Permutation-based causal inference algorithms with interventions.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
keywords = {CRISPR,causality},
mendeley-tags = {CRISPR,causality},
number = {Nips 2017},
pages = {5823--5832},
title = {{Permutation-based causal inference algorithms with interventions}},
volume = {2017-Decem},
year = {2017}
}
@article{Lazzarotto2020,
author = {Lazzarotto, Cicera R and Malinin, Nikolay L and Li, Yichao and Zhang, Ruochi and Yang, Yang and Lee, Gahyun and Cowley, Eleanor and He, Yanghua and Lan, Xin and Jividen, Kasey and Katta, Varun and Kolmakova, Natalia G and Petersen, Christopher T and Qi, Qian and Strelcov, Evgheni and Maragh, Samantha and Krenciute, Giedre and Ma, Jian and Cheng, Yong and Tsai, Shengdar Q},
doi = {10.1038/s41587-020-0555-7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Lazzarotto et al. - 2020 - CHANGE-seq reveals genetic and epigenetic effects on CRISPR – Cas9 genome-wide activity.pdf:pdf},
issn = {1546-1696},
journal = {Nature Biotechnology},
keywords = {CRISPR,to-read},
mendeley-tags = {CRISPR,to-read},
publisher = {Springer US},
title = {{CHANGE-seq reveals genetic and epigenetic effects on CRISPR – Cas9 genome-wide activity}},
url = {http://dx.doi.org/10.1038/s41587-020-0555-7},
year = {2020}
}
@article{Taylor2015,
abstract = {We describe the problem of "selective inference." This addresses the following challenge: Having mined a set of data to find potential associations, how do we properly assess the strength of these associations? The fact that we have "cherry-picked"-searched for the strongest associations-means that we must set a higher bar for declaring significant the associations that we see. This challenge becomes more important in the era of big data and complex statistical modeling. The cherry tree (dataset) can be very large and the tools for cherry picking (statistical learning methods) are now very sophisticated. We describe some recent new developments in selective inference and illustrate their use in forward stepwise regression, the lasso, and principal components analysis. inference | P values | lasso S tatistical science has changed a great deal in the past 10-20 years, and is continuing to change, in response to technological advances in science and industry. The world is awash with big and complicated data, and researchers are trying to make sense out of it. Leading examples include data from "omic" assays in the biomedical sciences, financial forecasting from economic and business indicators, and the analysis of user click patterns to optimize ad placement on websites. This has led to an explosion of interest in the fields of statistics and machine learning and spawned a new field some call "data science." In the words of Yoav Benjamini, statistical methods have become "industrialized" in response to these changes. Whereas traditionally scientists fit a few statistical models by hand, now they use sophisticated computational tools to search through a large number of models, looking for meaningful patterns. Having done this search, the challenge is then to judge the strength of the apparent associations that have been found. For example, a correlation of 0.9 between two measurements A and B is probably noteworthy. However, suppose that I had arrived at A and B as follows: I actually started with 1,000 measurements and I searched among all pairs of measurements for the most correlated pair; these turn out to be A and B, with correlation 0.9. With this backstory, the finding is not nearly as impressive and could well have happened by chance, even if all 1,000 measurements were uncorrelated. Now, if I just reported to you that these two measures A and B have correlation 0.9, and did not tell which of these two routes I used to obtain them, you would not have enough information to judge the strength of the apparent relationship. This statistical problem has become known as "selective inference," the assessment of significance and effect sizes from a dataset after mining the same data to find these associations. As another example, suppose that we have a quantitative value y, a measurement of the survival time of a patient after receiving either a standard treatment or a new experimental treatment. I give the old drug (1) or new drug (2) at random to a set of patients and compute the mean difference in the outcome z = ðy 2 − y 1 Þ=s, where s is an estimate of SD of the raw difference. Then I could approximate the distribution of z by a standard normal distribution , and hence if I reported to you a value of, say, z = 2.5 you would be impressed because a value that large is unlikely to occur by chance if the new treatment had the same effectiveness as the old one (the P value is about 1{\%}). However, what if instead I tried out many new treatments and reported to you only ones for which jzj {\textgreater} 2? Then a value of 2.5 is not nearly as surprising. Indeed, if the two treatments were equivalent, the conditional probability that jzj exceeds 2.5, given that it is larger than 2, is about 27{\%}. Armed with knowledge of the process that led to the value z = 2.5, the correct selective inference would assign a P value of 0.27 to the finding, rather than 0.01. If not taken into account, the effects of selection can greatly exaggerate the apparent strengths of relationships. We feel that this is one of the causes of the current crisis in reproducibility in science (e.g., ref. 1). With increased competiveness and pressure to publish, it is natural for researchers to exaggerate their claims, intentionally or otherwise. Journals are much more likely to publish studies with low P values, and we (the readers) never hear about the great number of studies that showed no effect and were filed away (the "file-drawer effect"). This makes it difficult to assess the strength of a reported P value of, say, 0.04. The challenge of correcting for the effects of selection is a complex one, because the selective decisions can occur at many different stages in the analysis process. However, some exciting progress has recently been made in more limited problems, such as that of adaptive regression techniques for supervised learning. Here the selections are made in a well-defined way, so that we can exactly measure their effects on subsequent inferences. We describe these new techniques here, as applied to two widely used statistical methods: classic supervised learning, via forward stepwise regression, and modern sparse learning, via the "lasso." Later, we indicate the broader scope of their potential applications, including principal components analysis. Forward Stepwise Regression Supposed that we have a dataset with N observations ðx i , y i Þ, i = 1,2,. .. N, y i being the outcome measurement and each x i a vector of p predictors (or features). We wish to build a model for predicting y i from x i. This is known as the supervised learning problem, because the outcome y supervises (or guides) the prediction process. † The standard linear regression model has the form Significance Most statistical analyses involve some kind of "selection"-searching through the data for the strongest associations. Measuring the strength of the resulting associations is a challenging task, because one must account for the effects of the selection. There are some new tools in selective inference for this task, and we illustrate their use in forward stepwise regression, the lasso, and principal components analysis. By way of contrast, in the unsupervised learning problem we observe just the features x and no outcome variables y, and we try to uncover the correlations and other dependencies between these features. Principal components analysis is a leading example and is discussed later in this article.},
author = {Taylor, Jonathan and Tibshirani, Robert J.},
doi = {10.1073/pnas.1507583112},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences/Taylor, Tibshirani - 2015 - Statistical learning and selective inference.pdf:pdf},
journal = {Proceedings of the National Academy of Sciences},
keywords = {post-selection inference},
mendeley-tags = {post-selection inference},
number = {25},
pages = {7629--7634},
title = {{Statistical learning and selective inference}},
url = {www.pnas.org/cgi/doi/10.1073/pnas.1507583112},
volume = {112},
year = {2015}
}
@article{KRN10,
abstract = {Sequencing technologies are becoming cheap enough to apply to large numbers of study participants and promise to provide new insights into human phenotypes by bringing to light rare and previously unknown genetic variants. We develop a new framework for the analysis of sequence data that incorporates all of the major features of previously proposed approaches, including those focused on allele counts and allele burden, but is both more general and more powerful. We harness population genetic theory to provide prior information on effect sizes and to create a pooling strategy for information from rare variants. Our method, EMMPAT (Evolutionary Mixed Model for Pooled Association Testing), generates a single test per gene (substantially reducing multiple testing concerns), facilitates graphical summaries, and improves the interpretation of results by allowing calculation of attributable variance. Simulations show that, relative to previously used approaches, our method increases the power to detect genes that affect phenotype when natural selection has kept alleles with large effect sizes rare. We demonstrate our approach on a population-based re-sequencing study of association between serum triglycerides and variation in ANGPTL4.},
annote = {21085648},
author = {King, C Ryan and Rathouz, Paul J and Nicolae, Dan L},
journal = {PLoS Genetics},
pages = {e1001202--e1001202},
title = {{{\{}An{\}} Evolutionary Framework for Association Testing in Resequencing Studies}},
volume = {6},
year = {2010}
}
@article{E08,
author = {Efron, Bradley},
doi = {10.1214/07-AOAS141},
issn = {1932-6157},
journal = {The Annals of Applied Statistics},
number = {1},
pages = {197--223},
title = {{Simultaneous inference: when should hypothesis testing problems be combined?}},
url = {http://dx.doi.org/10.1214/07-AOAS141},
volume = {2},
year = {2008}
}
@article{WetS10,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21179394{\}}{\{}21179394{\}}},
author = {Wilson, M A and Iversen, E S and Clyde, M A and Schmidler, S C and Schildkraut, J M},
journal = {The Annals of Applied Statistics},
month = {sep},
number = {3},
pages = {1342--1364},
title = {{{\{}B{\}}ayesian model search and multilevel inference for {\{}S{\}}{\{}N{\}}{\{}P{\}} association studies}},
volume = {4},
year = {2010}
}
@article{Yekutieli2019a,
abstract = {Bayesian modeling is now ubiquitous in problems of large-scale inference even when frequentist criteria are in mind for evaluating the performance of a procedure. By far most popular in the statistical literature of the past decade and a half are empirical Bayes methods, that have shown in practice to improve significantly over strictly-frequentist competitors in many different problems. As an alternative to empirical Bayes methods, in this paper we propose hierarchical Bayes modeling for large-scale problems, and address two separate points that, in our opinion, deserve more attention. The first is nonparametric "deconvolution" methods that are applicable also outside the sequence model. The second point is the adequacy of Bayesian modeling for situations where the parameters are by assumption deterministic. We provide partial answers to both: first, we demonstrate how our methodology applies in the analysis of a logistic regression model. Second, we appeal to Robbins's compound decision theory and provide an extension, to give formal justification for the Bayesian approach in the sequence case.},
archivePrefix = {arXiv},
arxivId = {1908.08444},
author = {Yekutieli, Daniel and Weinstein, Asaf},
eprint = {1908.08444},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Yekutieli, Weinstein - 2019 - Hierarchical Bayes Modeling for Large-Scale Inference(2).pdf:pdf},
journal = {arXiv},
title = {{Hierarchical Bayes Modeling for Large-Scale Inference}},
url = {http://arxiv.org/abs/1908.08444},
year = {2019}
}
@article{Patra2016,
abstract = {Given a random vector (X, Z), we define a notion of nonparametric residual of X on Z that is always independent of Z. Given (X, Y, Z), we use this notion of residual to develop a test for the conditional independence between X and Y, given Z.},
author = {Patra, Rohit K. and Sen, Bodhisattva and Sz{\'{e}}kely, G{\'{a}}bor J.},
doi = {10.1016/j.spl.2015.10.011},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics and Probability Letters/Patra, Sen, Sz{\'{e}}kely - 2016 - On a nonparametric notion of residual and its applications.pdf:pdf},
issn = {01677152},
journal = {Statistics and Probability Letters},
keywords = {Conditional distribution function,Testing conditional independence,conditional independence testing},
mendeley-tags = {conditional independence testing},
pages = {208--213},
publisher = {Elsevier B.V.},
title = {{On a nonparametric notion of residual and its applications}},
url = {http://dx.doi.org/10.1016/j.spl.2015.10.011},
volume = {109},
year = {2016}
}
@article{Chatterjee2013,
abstract = {Zou [J. Amer. Statist. Assoc. 101 (2006) 1418-1429] proposed the Adaptive LASSO (ALASSO) method for simultaneous variable selection and estimation of the regression parameters, and established its oracle property. In this paper, we investigate the rate of convergence of the ALASSO estimator to the oracle distribution when the dimension of the regression parameters may grow to infinity with the sample size. It is shown that the rate critically depends on the choices of the penalty parameter and the initial estimator, among other factors, and that confidence intervals (CIs) based on the oracle limit law often have poor coverage accuracy. As an alternative, we consider the residual bootstrap method for the ALASSO estimators that has been recently shown to be consistent; cf. Chatterjee and Lahiri [J. Amer. Statist. Assoc. 106 (2011a) 608-625]. We show that the bootstrap applied to a suitable studentized version of the ALASSO estimator achieves second-order correctness, even when the dimension of the regression parameters is unbounded. Results from a moderately large simulation study show marked improvement in coverage accuracy for the bootstrap CIs over the oracle based CIs. {\textcopyright} 2013 Institute of Mathematical Statistics.},
author = {Chatterjee, A. and Lahiri, S. N.},
doi = {10.1214/13-AOS1106},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Chatterjee, Lahiri - 2013 - Rates of convergence of the adaptive lasso estimators to the oracle distribution and higher order refinement.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bootstrap,Edgeworth expansion,Penalized regression},
number = {3},
pages = {1232--1259},
title = {{Rates of convergence of the adaptive lasso estimators to the oracle distribution and higher order refinements by the bootstrap}},
volume = {41},
year = {2013}
}
@article{Dwork2018,
abstract = {Differential privacy provides a rigorous framework for privacy-preserving data analysis. This paper proposes the first differentially private procedure for controlling the false discovery rate (FDR) in multiple hypothesis testing. Inspired by the Benjamini-Hochberg procedure (BHq), our approach is to first repeatedly add noise to the logarithms of the p-values to ensure differential privacy and to select an approximately smallest p-value serving as a promising candidate at each iteration; the selected p-values are further supplied to the BHq and our private procedure releases only the rejected ones. Apart from the privacy considerations, we develop a new technique that is based on a backward submartingale for proving FDR control of a broad class of multiple testing procedures, including our private procedure, and both the BHq step-up and step-down procedures. As a novel aspect, the proof works for arbitrary dependence between the true null and false null test statistics, while FDR control is maintained up to a small multiplicative factor. This theoretical guarantee is the first in the FDR literature to explain the empirical validity of the BHq procedure in three simulation studies.},
archivePrefix = {arXiv},
arxivId = {1807.04209v1},
author = {Dwork, Cynthia and Su, Weijie J and Zhang, Li},
eprint = {1807.04209v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Dwork, Su, Zhang - 2018 - Differentially Private False Discovery Rate Control.pdf:pdf},
journal = {arXiv},
keywords = {Benjamini-Hochberg procedure,Differential privacy,FDR,Report Noisy Max,false discovery rate,positive regression dependence on subset,submartingale},
mendeley-tags = {FDR},
title = {{Differentially Private False Discovery Rate Control}},
year = {2018}
}
@article{Buhlmann2015,
abstract = {We consider high-dimensional inference when the assumed linear model is misspecified. We describe some correct interpretations and corresponding sufficient assumptions for valid asymptotic inference of the model parameters, which still have a useful meaning when the model is misspecified. We largely focus on the de-sparsified Lasso procedure but we also indicate some implications for (multiple) sample splitting techniques. In view of available methods and software, our results contribute to robust-ness considerations with respect to model misspecification. MSC 2010 subject classifications: Primary 62J07; secondary 62F25.},
author = {B{\"{u}}hlmann, Peter and {Van De Geer}, Sara},
doi = {10.1214/15-EJS1041},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Electronic Journal of Statistics/B{\"{u}}hlmann, Van De Geer - 2015 - High-dimensional inference in misspecified linear models.pdf:pdf},
issn = {1935-7524},
journal = {Electronic Journal of Statistics},
keywords = {62F25Confidence interval,62J07,Lasso,de-sparsified Lasso,high-dimensional regression,hypothesis test,multiple sample splitting,sparsity},
mendeley-tags = {Lasso,high-dimensional regression},
pages = {1449--1473},
title = {{High-dimensional inference in misspecified linear models}},
volume = {9},
year = {2015}
}
@article{BetK14,
author = {Belloni, Alexandre and Chernozhukov, Victor and Kato, Kengo},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Belloni, Chernozhukov, Kato - 2014 - Uniform post-selection inference for least absolute deviation regression and other Z-estimation pro.pdf:pdf},
journal = {Biometrika},
keywords = {post-selection inference},
mendeley-tags = {post-selection inference},
number = {1},
pages = {77--94},
publisher = {Oxford University Press},
title = {{Uniform post-selection inference for least absolute deviation regression and other Z-estimation problems}},
volume = {102},
year = {2014}
}
@inproceedings{JetP10,
author = {Jalali, Ali and Sanghavi, Sujay and Ruan, Chao and Ravikumar, Pradeep K},
booktitle = {Advances in Neural Information Processing Systems},
keywords = {high-dimensional regression,multiple phenotypes},
mendeley-tags = {high-dimensional regression,multiple phenotypes},
pages = {964--972},
title = {{A dirty model for multi-task learning}},
year = {2010}
}
@book{Rosenbaum_book_draft,
abstract = {An observational study is an empiric investigation of treatment effects when random assignment to treatment or control is not feasible. Because observa- tional studies are structured to resemble simple randomized experiments, an under- standing of the role randomization plays in experiments is important as background. As a prelude to the discussion of observational studies in later chapters, the current chapter contains a brief review of the logic of causal inference in a randomized ex- periment. Only one simple case is discussed in detail, namely a randomized paired experiment in which subjects are paired before randomization and one subject in each pair is picked at random to receive treatment, the other receiving control. Al- though a foundation for later chapters, much of the material in this chapter is quite old, dating from Sir Ronald Fisher's work in the 1920s and 1930s, and it is likely to be familiar from other contexts, such as a course in the design of experiments.},
author = {Rosenbaum, Paul},
doi = {10.4159/9780674982697-006},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Rosenbaum - Unknown - Replication and Evidence Factors in Observational Studies.pdf:pdf},
keywords = {causality,observational studies},
mendeley-tags = {causality,observational studies},
title = {{Replication and Evidence Factors in Observational Studies}}
}
@article{Lavergne2015,
abstract = {We consider testing the significance of a subset of covariates in a nonparametric regression. These covariates can be continuous and/or discrete. We propose a new kernel-based test that smoothes only over the covariates appearing under the null hypothesis, so that the curse of dimensionality is mitigated. The test statistic is asymptotically pivotal and the rate of which the test detects local alternatives depends only on the dimension of the covariates under the null hypothesis. We show the validity of wild bootstrap for the test. In small samples, our test is competitive compared to existing procedures.},
author = {Lavergne, Pascal and Maistre, Samuel and Patilea, Valentin},
doi = {10.1214/15-EJS1005},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Electronic Journal of Statistics/Lavergne, Maistre, Patilea - 2015 - A significance test for covariates in nonparametric regression.pdf:pdf},
issn = {19357524},
journal = {Electronic Journal of Statistics},
keywords = {Asymptotic pivotal test statistic,Bootstrap,Kernel smoothing,U-statistic,asymptotics},
mendeley-tags = {asymptotics},
number = {June 2014},
pages = {643--678},
title = {{A significance test for covariates in nonparametric regression}},
volume = {9},
year = {2015}
}
@article{BetE16,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26942286{\}}{\{}26942286{\}}},
author = {Broadaway, K A and Cutler, D J and Duncan, R and Moore, J L and Ware, E B and Jhun, M A and Bielak, L F and Zhao, W and Smith, J A and Peyser, P A and Kardia, S L and Ghosh, D and Epstein, M P},
journal = {American Journal of Human Genetics},
month = {mar},
number = {3},
pages = {525--540},
title = {{{\{}A{\}} {\{}S{\}}tatistical {\{}A{\}}pproach for {\{}T{\}}esting {\{}C{\}}ross-{\{}P{\}}henotype {\{}E{\}}ffects of {\{}R{\}}are {\{}V{\}}ariants}},
volume = {98},
year = {2016}
}
@article{BetC15,
author = {Bogdan, Ma{\l}gorzata and van den Berg, Ewout and Sabatti, Chiara and Su, Weijie and Cand{\`{e}}s, Emmanuel J},
journal = {The Annals of Applied Statistics},
keywords = {FDR,high-dimensional regression},
mendeley-tags = {FDR,high-dimensional regression},
number = {3},
pages = {1103},
publisher = {NIH Public Access},
title = {{{\{}SLOPE{\}}---adaptive variable selection via convex optimization}},
volume = {9},
year = {2015}
}
@article{Thurman2012,
abstract = {DNase I hypersensitive sites (DHSs) are markers of regulatory DNA and have underpinned the discovery of all classes of cis-regulatory elements including enhancers, promoters, insulators, silencers and locus control regions. Here we present the first extensive map of human DHSs identified through genome-wide profiling in 125 diverse cell and tissue types. We identify ∼2.9 million DHSs that encompass virtually all known experimentally validated cis-regulatory sequences and expose a vast trove of novel elements, most with highly cell-selective regulation. Annotating these elements using ENCODE data reveals novel relationships between chromatin accessibility, transcription, DNA methylation and regulatory factor occupancy patterns. We connect ∼580,000 distal DHSs with their target promoters, revealing systematic pairing of different classes of distal DHSs and specific promoter types. Patterning of chromatin accessibility at many regulatory regions is organized with dozens to hundreds of co-activated elements, and the transcellular DNase I sensitivity pattern at a given region can predict cell-type-specific functional behaviours. The DHS landscape shows signatures of recent functional evolutionary constraint. However, the DHS compartment in pluripotent and immortalized cells exhibits higher mutation rates than that in highly differentiated cells, exposing an unexpected link between chromatin accessibility, proliferative potential and patterns of human variation.},
author = {Thurman, Robert E. and Rynes, Eric and Humbert, Richard and Vierstra, Jeff and Maurano, Matthew T. and Haugen, Eric and Sheffield, Nathan C. and Stergachis, Andrew B. and Wang, Hao and Vernot, Benjamin and Garg, Kavita and John, Sam and Sandstrom, Richard and Bates, Daniel and Boatman, Lisa and Canfield, Theresa K. and Diegel, Morgan and Dunn, Douglas and Ebersol, Abigail K. and Frum, Tristan and Giste, Erika and Johnson, Audra K. and Johnson, Ericka M. and Kutyavin, Tanya and Lajoie, Bryan and Lee, Bum Kyu and Lee, Kristen and London, Darin and Lotakis, Dimitra and Neph, Shane and Neri, Fidencio and Nguyen, Eric D. and Qu, Hongzhu and Reynolds, Alex P. and Roach, Vaughn and Safi, Alexias and Sanchez, Minerva E. and Sanyal, Amartya and Shafer, Anthony and Simon, Jeremy M. and Song, Lingyun and Vong, Shinny and Weaver, Molly and Yan, Yongqi and Zhang, Zhancheng and Zhang, Zhuzhu and Lenhard, Boris and Tewari, Muneesh and Dorschner, Michael O. and Hansen, R. Scott and Navas, Patrick A. and Stamatoyannopoulos, George and Iyer, Vishwanath R. and Lieb, Jason D. and Sunyaev, Shamil R. and Akey, Joshua M. and Sabo, Peter J. and Kaul, Rajinder and Furey, Terrence S. and Dekker, Job and Crawford, Gregory E. and Stamatoyannopoulos, John A.},
doi = {10.1038/nature11232},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Thurman et al. - 2012 - The accessible chromatin landscape of the human genome.pdf:pdf},
issn = {00280836},
journal = {Nature},
keywords = {Kathryn,epigenetics,gene-enhancer},
mendeley-tags = {Kathryn,epigenetics,gene-enhancer},
number = {7414},
pages = {75--82},
publisher = {Nature Publishing Group},
title = {{The accessible chromatin landscape of the human genome}},
volume = {489},
year = {2012}
}
@article{wtccc,
abstract = {There is increasing evidence that genome-wide association (GWA) studies represent a powerful approach to the identification of genes involved in common human diseases. We describe a joint GWA study (using the Affymetrix GeneChip 500K Mapping Array Set) undertaken in the British population, which has examined approximately 2,000 individuals for each of 7 major diseases and a shared set of approximately 3,000 controls. Case-control comparisons identified 24 independent association signals at P {\textless} 5 x 10(-7): 1 in bipolar disorder, 1 in coronary artery disease, 9 in Crohn's disease, 3 in rheumatoid arthritis, 7 in type 1 diabetes and 3 in type 2 diabetes. On the basis of prior findings and replication studies thus-far completed, almost all of these signals reflect genuine susceptibility effects. We observed association at many previously identified loci, and found compelling evidence that some loci confer risk for more than one of the diseases studied. Across all diseases, we identified a large number of further signals (including 58 loci with single-point P values between 10(-5) and 5 x 10(-7)) likely to yield additional susceptibility loci. The importance of appropriately large samples was confirmed by the modest effect sizes observed at most loci identified. This study thus represents a thorough validation of the GWA approach. It has also demonstrated that careful use of a shared control group represents a safe and effective approach to GWA analyses of multiple disease phenotypes; has generated a genome-wide genotype database for future studies of common diseases in the British population; and shown that, provided individuals with non-European ancestry are excluded, the extent of population stratification in the British population is generally modest. Our findings offer new avenues for exploring the pathophysiology of these important disorders. We anticipate that our data, results and software, which will be widely available to other investigators, will provide a powerful resource for human genetics research.},
annote = {17554300},
author = {Consortium, Wellcome Trust Case Control},
journal = {Nature},
month = {jun},
pages = {661--678},
title = {{{\{}G{\}}enome-wide association study of 14,000 cases of seven common diseases and 3,000 shared controls}},
volume = {447},
year = {2007}
}
@article{LL08,
abstract = {Although whole-genome association studies using tagSNPs are a powerful approach for detecting common variants, they are underpowered for detecting associations with rare variants. Recent studies have demonstrated that common diseases can be due to functional variants with a wide spectrum of allele frequencies, ranging from rare to common. An effective way to identify rare variants is through direct sequencing. The development of cost-effective sequencing technologies enables association studies to use sequence data from candidate genes and, in the future, from the entire genome. Although methods used for analysis of common variants are applicable to sequence data, their performance might not be optimal. In this study, it is shown that the collapsing method, which involves collapsing genotypes across variants and applying a univariate test, is powerful for analyzing rare variants, whereas multivariate analysis is robust against inclusion of noncausal variants. Both methods are superior to analyzing each variant individually with univariate tests. In order to unify the advantages of both collapsing and multiple-marker tests, we developed the Combined Multivariate and Collapsing (CMC) method and demonstrated that the CMC method is both powerful and robust. The CMC method can be applied to either candidate-gene or whole-genome sequence data. {\textcopyright} 2008 The American Society of Human Genetics.},
annote = {18691683},
author = {Li, Bingshan and Leal, Suzanne M.},
doi = {10.1016/j.ajhg.2008.06.024},
issn = {00029297},
journal = {American Journal of Human Genetics},
number = {3},
pages = {311--321},
title = {{Methods for Detecting Associations with Rare Variants for Common Diseases: Application to Analysis of Sequence Data}},
url = {http://www.hubmed.org/display.cgi?uids=18691683},
volume = {83},
year = {2008}
}
@article{Yu2016,
abstract = {Motivation: Functional genomics (FG) screens, using RNAi or CRISPR technology, have become a standard tool for systematic, genome-wide loss-of-function studies for therapeutic target discovery. As in many large-scale assays, however, off-target effects, variable reagents' potency and experimental noise must be accounted for appropriately control for false positives. Indeed, rigorous statistical analysis of high-throughput FG screening data remains challenging, particularly when integrative analyses are used to combine multiple sh/sgRNAs targeting the same gene in the library. Method: We use large RNAi and CRISPR repositories that are publicly available to evaluate a novel meta-analysis approach for FG screens via Bayesian hierarchical modeling, Screening Bayesian Evaluation and Analysis Method (ScreenBEAM). Results: Results from our analysis show that the proposed strategy, which seamlessly combines all available data, robustly outperforms classical algorithms developed for microarray data sets as well as recent approaches designed for next generation sequencing technologies. Remarkably, the ScreenBEAM algorithm works well even when the quality of FG screens is relatively low, which accounts for about 80-95{\%} of the public datasets. Availability and implementation: R package and source code are available at: https://github.com/jyyu/ScreenBEAM. Contact:, jose.silva@mssm.edu, yujiyang@gmail.com Supplementary information: Supplementary data are available at Bioinformatics online.},
author = {Yu, Jiyang and Silva, Jose and Califano, Andrea},
doi = {10.1093/bioinformatics/btv556},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Yu, Silva, Califano - 2016 - ScreenBEAM A novel meta-analysis algorithm for functional genomics screens via Bayesian hierarchical modeli.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {2},
pages = {260--267},
title = {{ScreenBEAM: A novel meta-analysis algorithm for functional genomics screens via Bayesian hierarchical modeling}},
volume = {32},
year = {2016}
}
@article{Dixit2019,
abstract = {Genetic interactions, defined as the non-additive phenotypic impact of combinations of genes, are a hallmark of the mapping from genotype to phenotype. However, genetic interactions remain challenging to systematically test given the massive number of possible combinations. In particular, while large-scale screening efforts in yeast have quantified pairwise interactions that affect cell viability, or synthetic lethality, between all pairs of genes as well as for a limited number of three-way interactions, it has previously been intractable to perform the large screens needed to comprehensively assess interactions in a mammalian genome. Here, we develop Shuffle-Seq, a scalable method to assay genetic interactions. Shuffle-Seq leverages the co-inheritance of genetically encoded barcodes in dividing cells and can scale in proportion to sequencing throughput. We demonstrate the technical validity of Shuffle-Seq and apply it to screening for mechanisms underlying drug resistance in a melanoma model. Shuffle-Seq should allow screens of hundreds of millions of combinatorial perturbations and facilitate the understanding of genetic dependencies and drug sensitivities.},
author = {Dixit, Atray and Kuksenko, Olena and Feldman, David and Regev, Aviv},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Dixit et al. - 2019 - Shuffle-Seq En masse combinatorial encoding for n-way genetic interaction screens.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,gene-enhancer},
mendeley-tags = {CRISPR,gene-enhancer},
title = {{Shuffle-Seq: En masse combinatorial encoding for n-way genetic interaction screens}},
year = {2019}
}
@article{Hennessy2016,
author = {Hennessy, Jonathan and Dasgupta, Tirthankar and Miratrix, Luke and Pattanayak, Cassandra},
doi = {10.1515/jci-2015-0018},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Causal Inference/Hennessy et al. - 2016 - A Conditional Randomization Test to Account for Covariate Imbalance in Randomized Experiments.pdf:pdf},
journal = {Journal of Causal Inference},
keywords = {balance function,causality,conditional randomization test,potential outcomes,sharp null hypothesis},
mendeley-tags = {causality,conditional randomization test},
number = {1},
pages = {61--80},
title = {{A Conditional Randomization Test to Account for Covariate Imbalance in Randomized Experiments}},
volume = {4},
year = {2016}
}
@article{Lei2014,
abstract = {We study distribution-free, non-parametric prediction bands with a focus on their finite sample behaviour. First we investigate and develop different notions of finite sample coverage guarantees. Then we give a new prediction band by combining the idea of 'conformal prediction' with non-parametric conditional density estimation. The proposed estimator, called COPS (conformal optimized prediction set), always has a finite sample guarantee. Under regularity conditions the estimator converges to an oracle band at a minimax optimal rate. A fast approximation algorithm and a data-driven method for selecting the bandwidth are developed. The method is illustrated in simulated and real data examples.},
author = {Lei, Jing and Wasserman, Larry},
doi = {10.1111/rssb.12021},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society. Series B Statistical Methodology/Lei, Wasserman - 2014 - Distribution-free prediction bands for non-parametric regression.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society. Series B: Statistical Methodology},
keywords = {Conformal prediction,Finite sample property,Kernel density,Prediction bands,conformal prediction,to-skim},
mendeley-tags = {conformal prediction,to-skim},
number = {1},
pages = {71--96},
title = {{Distribution-free prediction bands for non-parametric regression}},
volume = {76},
year = {2014}
}
@article{Vipin2018,
abstract = {Transcription control plays a crucial role in establishing a unique gene expression signature for each of the hundreds of mammalian cell types. Though gene expression data have been widely used to infer cellular regulatory networks, existing methods mainly infer correlations rather than causality. We developed statistical models and likelihood-ratio tests to infer causal gene regulatory networks using enhancer RNA (eRNA) expression information as a causal anchor and applied the framework to eRNA and transcript expression data from the FANTOM Consortium. Predicted causal targets of transcription factors (TFs) in mouse embryonic stem cells, macrophages and erythroblastic leukaemia overlapped significantly with experimentally-validated targets from ChIP-seq and perturbation data. We further improved the model by taking into account that some TFs might act in a quantitative, dosage-dependent manner, whereas others might act predominantly in a binary on/off fashion. We predicted TF targets from concerted variation of eRNA and TF and target promoter expression levels within a single cell type, as well as across multiple cell types. Importantly, TFs with high-confidence predictions were largely different between these two analyses, demonstrating that variability within a cell type is highly relevant for target prediction of cell type-specific factors. Finally, we generated a compendium of high-confidence TF targets across diverse human cell and tissue types.},
author = {Vipin, Deepti and Wang, Lingfei and Devailly, Guillaume and Michoel, Tom and Joshi, Anagha},
doi = {10.3390/ijms19113609},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/International Journal of Molecular Sciences/Vipin et al. - 2018 - Causal transcription regulatory network inference using enhancer activity as a causal anchor.pdf:pdf},
issn = {14220067},
journal = {International Journal of Molecular Sciences},
keywords = {Causal inference,Enhancer activity,Gene expression,Kathryn,Transcription regulation,causality,enhancer,gene-enhancer},
mendeley-tags = {Kathryn,causality,enhancer,gene-enhancer},
number = {11},
pages = {1--15},
title = {{Causal transcription regulatory network inference using enhancer activity as a causal anchor}},
volume = {19},
year = {2018}
}
@misc{Xu2013,
abstract = {In this article we consider the Two-Way ANOVA model with unequal cell frequencies without the assumption of equal error variances. For the problem of testing no interaction effects and equal main effects, we propose a parametric bootstrap (PB) approach and compare it with existing the generalized F (GF) test. The Type I error rates and powers of the tests are evaluated using Monte Carlo simulation. Our studies show that the PB test performs better than the generalized F-test. The PB test performs very satisfactorily even for small samples while the GF test exhibits poor Type I error properties when the number of factorial combinations or treatments goes up. {\textcopyright} 2012 Elsevier Inc.},
author = {Xu, Li Wen and Yang, Fang Qin and Abula, Aji'erguli and Qin, Shuang},
booktitle = {Journal of Multivariate Analysis},
doi = {10.1016/j.jmva.2012.10.008},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Multivariate Analysis/Xu et al. - 2013 - A parametric bootstrap approach for two-way ANOVA in presence of possible interactions with unequal variances.pdf:pdf},
issn = {0047259X},
keywords = {Bootstrap re-sampling,Generalized p-values,Heteroscedasticity,Unbalanced data,bootstrap,interactions},
mendeley-tags = {bootstrap,interactions},
pages = {172--180},
title = {{A parametric bootstrap approach for two-way ANOVA in presence of possible interactions with unequal variances}},
volume = {115},
year = {2013}
}
@article{Emmenegger2021,
abstract = {We estimate the linear coefficient in a partially linear model with confounding variables. We rely on double machine learning (DML) and extend it with an additional regularization and selection scheme. We allow for more general dependence structures among the model variables than what has been investigated previously, and we prove that this DML estimator remains asymptotically Gaussian and converges at the parametric rate. The DML estimator has a two-stage least squares interpretation and may produce overly wide confidence intervals. To address this issue, we propose the regularization-selection regsDML method that leads to narrower confidence intervals. It is fully data driven and optimizes an estimated asymptotic mean squared error of the coefficient estimate. Empirical examples demonstrate our methodological and theoretical developments. Software code for our regsDML method will be made available in the R-package dmlalg.},
archivePrefix = {arXiv},
arxivId = {2101.12525v1},
author = {Emmenegger, Corinne and B{\"{u}}hlmann, Peter},
eprint = {2101.12525v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Emmenegger, B{\"{u}}hlmann - 2021 - Regularizing Double Machine Learning in Partially Linear Endogenous Models.pdf:pdf},
keywords = {Double machine learning,K-class estimation,endogenous variables,generalized method of mo-ments,instrumental variables,partially linear model,regularization,semiparametric estimation,two-stage least squares},
title = {{Regularizing Double Machine Learning in Partially Linear Endogenous Models}},
year = {2021}
}
@article{2015arXiv150308278D,
archivePrefix = {arXiv},
arxivId = {stat.AP/1503.08278},
author = {{De Iorio}, M and Elliott, L.{\~{}}T. and Favaro, S and Adhikari, K and Teh, Y.{\~{}}W.},
eprint = {1503.08278},
journal = {arXiv},
keywords = {Statistics - Applications,Statistics - Methodology,Statistics - Other Statistics,unpublished},
mendeley-tags = {unpublished},
month = {mar},
primaryClass = {stat.AP},
title = {{Modeling population structure under hierarchical Dirichlet processes}},
year = {2015}
}
@article{Yi2015,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25354699{\}}{\{}25354699{\}}},
author = {Yi, H and Breheny, P and Imam, N and Liu, Y and Hoeschele, I},
journal = {Genetics},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
number = {1},
pages = {205--222},
title = {{Penalized multimarker vs.$\backslash$ single-marker regression methods for genome-wide association studies of quantitative traits}},
volume = {199},
year = {2015}
}
@article{Ernst2013,
author = {Ernst, Jason and Kellis, Manolis},
doi = {10.1101/gr.144840.112.Freely},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Research/Ernst, Kellis - 2013 - Interplay between chromatin state , regulator binding , and regulatory motifs in six human cell types.pdf:pdf},
journal = {Genome Research},
keywords = {Kathryn,epigenetics,gene-enhancer},
mendeley-tags = {Kathryn,epigenetics,gene-enhancer},
pages = {1142--1154},
title = {{Interplay between chromatin state , regulator binding , and regulatory motifs in six human cell types}},
volume = {23},
year = {2013}
}
@article{Montazeri2019,
abstract = {Systematic perturbation screens provided comprehensive resources for the elucidation of cancer driver genes. However, few algorithms have been developed to robustly interrogate such datasets, particularly with limited number of samples. Here we developed a computational tool called APSiC (Analysis of Perturbation Screens for identifying novel Cancer genes) and applied it to the large-scale deep shRNA screen DRIVE1 to unveil novel genetic and non-genetic driver genes. APSiC identified both well-known and novel drivers across all cancer types and within individual cancer types. The analysis of individual cancer types revealed that cancer drivers segregate by cell of origin and that genes involved in mRNA splicing may be oncogenic or tumor suppressive depending on the cancer type. We discovered and functionally demonstrated that LRRC4B is a novel putative tumor suppressor gene in breast cancer. The analysis of DRIVE using APSiC is provided as a web portal and represents a valuable resource for the discovery of novel cancer genes.},
author = {Montazeri, Hesam and Coto-Llerena, Mairene and Bianco, Gaia and Zangeneh, Ehsan and Taha-Mehlitz, Stephanie and Paradiso, Viola and Srivatsa, Sumana and de Weck, Antoine and Roma, Guglielmo and Lanzafame, Manuela and Bolli, Martin and Beerenwinkel, Niko and von Fl{\"{u}}e, Markus and Terracciano, Luigi M. and Piscuoglio, Salvatore and Ng, Charlotte K. Y.},
journal = {biorXiv},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
title = {{APSiC: Analysis of Perturbation Screens for the Identification of Novel Cancer Genes}},
year = {2019}
}
@article{Chernozhukov2019,
abstract = {We propose a robust method for constructing conditionally valid prediction intervals based on regression models for conditional distributions such as quantile and distribution regression. Our approach exploits the probability integral transform and relies on permuting estimated ``ranks'' instead of regression residuals. Unlike residuals, these ranks are independent of the covariates, which allows us to establish the conditional validity of the resulting prediction intervals under consistent estimation of the conditional distributions. We also establish theoretical performance guarantees under arbitrary model misspecification. The usefulness of the proposed method is illustrated based on two applications. First, we study the problem of predicting daily returns using realized volatility. Second, we consider a synthetic control setting where the goal is to predict a country's counterfactual GDP growth rate based on the contemporaneous GDP growth rates of other countries.},
archivePrefix = {arXiv},
arxivId = {1909.07889},
author = {Chernozhukov, Victor and W{\"{u}}thrich, Kaspar and Zhu, Yinchu},
eprint = {1909.07889},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Chernozhukov, W{\"{u}}thrich, Zhu - 2019 - Distributional conformal prediction.pdf:pdf},
journal = {arXiv},
keywords = {conformal prediction,to-skim},
mendeley-tags = {conformal prediction,to-skim},
title = {{Distributional conformal prediction}},
url = {http://arxiv.org/abs/1909.07889},
year = {2019}
}
@article{HetE14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25104515{\}}{\{}25104515{\}}},
author = {Hormozdiari, F and Kostem, E and Kang, E Y and Pasaniuc, B and Eskin, E},
doi = {10.1534/genetics.114.167908},
journal = {Genetics},
number = {2},
pages = {497--508},
title = {{Identifying Causal Variants at Loci with Multiple Signals of Association}},
volume = {198},
year = {2014}
}
@article{Robins1992,
author = {Robins, James M. and Mark, Steven D. and Newey, Whitney K.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrics/Robins, Mark, Newey - 1992 - Estimating Exposure Effects by Modelling the Expectation of Exposure Conditional on Confounders.pdf:pdf},
journal = {Biometrics},
keywords = {causality},
mendeley-tags = {causality},
number = {2},
pages = {479--495},
title = {{Estimating Exposure Effects by Modelling the Expectation of Exposure Conditional on Confounders}},
volume = {48},
year = {1992}
}
@article{meinshausen2006estimating,
author = {Meinshausen, Nicolai and Rice, John},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Meinshausen, Rice - 2006 - Estimating the proportion of false null hypotheses among a large number of independently tested hypotheses.pdf:pdf},
journal = {The Annals of Statistics},
number = {1},
pages = {373--393},
publisher = {Institute of Mathematical Statistics},
title = {{Estimating the proportion of false null hypotheses among a large number of independently tested hypotheses}},
volume = {34},
year = {2006}
}
@article{BC15,
author = {Barber, Rina Foygel and Cand{\`{e}}s, Emmanuel J},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Barber, Cand{\`{e}}s - 2015 - Controlling the false discovery rate via knockoffs.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {FDR,Multiple testing,canonical,high-dimensional regression,knockoffs},
mendeley-tags = {FDR,Multiple testing,canonical,high-dimensional regression,knockoffs},
number = {5},
pages = {2055--2085},
publisher = {Institute of Mathematical Statistics},
title = {{Controlling the false discovery rate via knockoffs}},
volume = {43},
year = {2015}
}
@article{AetL06,
author = {A., Alexa and J., Rahnenfuhrer and T., Lengauer},
journal = {Bioinformatics},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
number = {13},
pages = {1600--1607},
publisher = {Oxford University Press},
title = {{Improved scoring of functional groups from gene expression data by decorrelating GO graph structure.}},
volume = {22},
year = {2006}
}
@article{Wilson2020,
author = {Wilson, Daniel J},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Wellcome Open Research/Wilson - 2020 - Generalized mean p -values for combining dependent tests comparison of generalized central limit theorem and robust ris.pdf:pdf},
journal = {Wellcome Open Research},
keywords = {closed testing,global testing},
mendeley-tags = {closed testing,global testing},
title = {{Generalized mean p -values for combining dependent tests : comparison of generalized central limit theorem and robust risk analysis}},
year = {2020}
}
@article{DS_99,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/9872974{\}}{\{}9872974{\}}},
author = {Dupuis, J and Siegmund, D O},
journal = {Genetics},
keywords = {genetics},
mendeley-tags = {genetics},
pages = {373--386},
title = {{Statistical methods for mapping quantitative trait loci from a dense set of markers}},
volume = {151},
year = {1999}
}
@article{BH07,
author = {Benjamini, Yoav and Heller, Ruth},
doi = {10.1198/016214507000000941},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Benjamini, Heller - 2007 - False discovery rates for spatial signals.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {FDR,spatial data},
mendeley-tags = {FDR,spatial data},
number = {480},
pages = {1272--1281},
title = {{False discovery rates for spatial signals}},
url = {http://dx.doi.org/10.1198/016214507000000941},
volume = {102},
year = {2007}
}
@article{Arias-Castro2017,
abstract = {We study a stylized multiple testing problem where the test statistics are independent and assumed to have the same distribution under their respective null hypotheses. We first show that, in the normal means model where the test statistics are normal Z-scores, the well-known method of Benjamini and Hochberg [4] is optimal in some asymptotic sense. We then show that this is also the case of a recent distribution-free method proposed by Barber and Cand{\`{e}}s [14]. The method is distribution-free in the sense that it is agnostic to the null distribution — it only requires that the null distribution be symmetric. We extend these optimality results to other location models with a base distribution having fast-decaying tails.},
archivePrefix = {arXiv},
arxivId = {1604.07520},
author = {Arias-Castro, Ery and Chen, Shiyun},
doi = {10.1214/17-EJS1277},
eprint = {1604.07520},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Electronic Journal of Statistics/Arias-Castro, Chen - 2017 - Distribution-free multiple testing.pdf:pdf},
issn = {19357524},
journal = {Electronic Journal of Statistics},
keywords = {Asymptotic optimality,Benjamini-Hochberg procedure,Distribution-free procedure,FDR,False discovery rate (FDR) control,Multiple testing},
mendeley-tags = {FDR,Multiple testing},
number = {1},
pages = {1983--2001},
title = {{Distribution-free multiple testing}},
volume = {11},
year = {2017}
}
@article{RetC09,
author = {Ridker, Paul M and Par{\'{e}}, Guillaume and Parker, Alex N and Zee, Robert Y L and Miletich, Joseph P and Chasman, Daniel I},
journal = {Circulation: Cardiovascular Genetics},
number = {1},
pages = {26--33},
publisher = {Am Heart Assoc},
title = {{Polymorphism in the {\{}CETP{\}} Gene Region, {\{}HDL{\}} Cholesterol, and Risk of Future Myocardial Infarction}},
volume = {2},
year = {2009}
}
@article{Aigner1973,
author = {Aigner, Dennis J.},
doi = {10.1016/0304-4076(73)90005-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Econometrics/Aigner - 1973 - Regression with a binary independent variable subject to errors of observation.pdf:pdf},
issn = {03044076},
journal = {Journal of Econometrics},
keywords = {error-in-variables},
mendeley-tags = {error-in-variables},
number = {1},
pages = {49--59},
title = {{Regression with a binary independent variable subject to errors of observation}},
volume = {1},
year = {1973}
}
@article{FL08,
author = {Fan, J and Lv, J},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {high-dimensional regression,screening},
mendeley-tags = {high-dimensional regression,screening},
pages = {849--911},
title = {{{\{}S{\}}ure independence screening for ultrahigh dimensional feature space}},
volume = {70},
year = {2008}
}
@article{Cao2011,
abstract = {This article considers the problem of multiple hypothesis testing using t -tests. The observed data are assumed to be independently generated conditional on an underlying and unknown two-state hidden model. We propose an asymptotically valid data-driven procedure to find critical values for rejection regions controlling the k-familywise error rate (k-FWER), false discovery rate (FDR) and the tail probability of false discovery proportion (FDTP) by using one-sample and two-sample t -statistics. We only require a finite fourth moment plus some very general conditions on the mean and variance of the population by virtue of the moderate deviations properties of t -statistics. A new consistent estimator for the proportion of alternative hypotheses is developed. Simulation studies support our theoretical results and demonstrate that the power of a multiple testing procedure can be substantially improved by using critical values directly, as opposed to the conventional p-value approach. Our method is applied in an analysis of the microarray data from a leukemia cancer study that involves testing a large number of hypotheses simultaneously. {\textcopyright} 2011 ISI/BS.},
author = {Cao, Hongyuan and Kosorok, Michael R.},
doi = {10.3150/10-BEJ272},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bernoulli/Cao, Kosorok - 2011 - Simultaneous critical values for t -tests in very high dimensions.pdf:pdf},
issn = {13507265},
journal = {Bernoulli},
keywords = {Empirical processes,FDR,High dimension,Microarrays,Multiple hypothesis testing,One-sample t-statistics,Self-normalized moderate deviation,Two-sample t-statistics,t-test},
mendeley-tags = {t-test},
number = {1},
pages = {347--394},
title = {{Simultaneous critical values for t -tests in very high dimensions}},
volume = {17},
year = {2011}
}
@article{Doran2014,
abstract = {Determining conditional independence (CI) relationships between random variables is a challenging but important task for problems such as Bayesian network learning and causal discovery. We propose a new kernel CI test that uses a single, learned permutation to convert the CI test problem into an easier two-sample test problem. The learned permutation leaves the joint distribution unchanged if and only if the null hypothesis of CI holds. Then, a kernel two-sample test, which has been studied extensively in prior work, can be applied to a permuted and an unpermuted sample to test for CI. We demonstrate that the test (1) easily allows the incorporation of prior knowledge during the permutation step, (2) has power competitive with state-of-the-art kernel CI tests, and (3) accurately estimates the null distribution of the test statistic, even as the dimensionality of the conditioning variable grows.},
author = {Doran, Gary and Muandet, Krikamol and Zhang, Kun and Sch{\"{o}}lkopf, Bernhard},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Uncertainty in Artificial Intelligence - Proceedings of the 30th Conference, UAI 2014/Doran et al. - 2014 - A permutation-based kernel conditional independence test.pdf:pdf},
isbn = {9780974903910},
journal = {Uncertainty in Artificial Intelligence - Proceedings of the 30th Conference, UAI 2014},
pages = {132--141},
title = {{A permutation-based kernel conditional independence test}},
year = {2014}
}
@article{Mancuso2019,
abstract = {T ranscriptome-wide association studies (TWASs) using predicted expression levels have been proposed as an approach to identify novel genomic risk regions and putative risk genes involved in complex traits and diseases 1-3. Since TWAS based on predicted expression relies on only the genetic component of expression , it can be viewed as a test for non-zero local genetic correlation between expression and trait 1,4,5. Significant genetic correlation in this setting is often interpreted as an estimate of the effect of SNPs on a trait mediated by the gene of interest. However, this interpretation requires very strong assumptions that are probably violated in empirical data due to linkage disequilibrium (LD) and/or pleiotro-pic SNP effects 1-3,6-11. Therefore, TWAS has been mostly utilized as a test of association, in contrast to methods that attempt to directly estimate the mediated effect (that is, Mendelian randomization 3,6-9). In this work, we show that the gene-trait association statistics from TWAS at a known risk region are correlated as a function of LD among SNPs and expression quantitative trait loci (eQTL) weights used in the prediction models. The effect is similar to LD tagging in genome-wide association studies (GWASs) where LD within a region induces associations at tag SNPs (yielding the traditional Manhattan-style plots). Even in the simplest case where a single SNP causally impacts the expression of a gene, which in turn causally impacts a trait, LD among SNPs used in the eQTL prediction models induces significant gene-trait associations at nearby non-causal genes in the region. The tagging effect is further exacerbated in the presence of multiple causal SNPs and genes. As an illustrative example , consider a risk region with six genes where a single SNP is causal for a single gene which impacts the trait (Fig. 1). Although genes 3 and 4 in Fig. 1 have non-overlapping prediction weights due to different eQTL genetic regulation, LD among SNPs with non-zero prediction weights induces correlations in the TWAS statistics at genes 3 and 4. Estimating the correlation structure of predicted expression among nearby genes enables statistical fine-mapping over gene-trait associations. However, several confounding factors can bias inference. First, there is a body of evidence supporting horizontal pleiotropic effects from SNPs 8,11,12 , which bias gene-trait association statistics. Second, it is critical that TWAS fine-mapping approaches maintain robustness when the causal mechanism is not steady-state levels of gene expression 10. Fine-mapping in these instances without controlling for confounding could prioritize non-causal genes. Here, we propose an approach to perform statistical fine-mapping over the gene-trait association signals from TWAS. Our approach, FOCUS (fine-mapping of causal gene sets), accounts for the correlation structure induced by LD and prediction weights used in the TWAS and controls for certain pleiotropic effects. FOCUS takes as input GWAS summary data, expression prediction weights (as estimated from eQTL reference panels), and LD among all SNPs in the risk region, and estimates the probability for any given set of genes to explain the TWAS signal. We extend proba-bilistic SNP fine-mapping approaches 13-15 to estimate sets of genes that contain the causal genes (defined here as a gene responsible for the association signal) at a predefined confidence level (that is, $\rho$-credible gene sets). We perform extensive simulations and show that FOCUS is approximately unbiased in estimating the posterior probabilities and credible sets at a specified certainty when the causal gene is present in the data. When the causal tissue is unavailable and alternative tissues with correlated expression levels are used as a proxy, FOCUS maintains its performance under standard assumptions. Finally, as a demonstration using real GWAS data, we apply FOCUS to four GWASs of lipid levels 16. We find that FOCUS prioritizes genes with established roles in low-density lipoprotein (LDL) risk (for example, SORT1) 17. Results Methods overview. To disentangle the causal and tagging gene-trait associations at a TWAS-significant region, we analytically derive the covariance structure among TWAS statistics as a function of LD and eQTL weights used in prediction. Next, we model the entire Transcriptome-wide association studies using predicted expression have identified thousands of genes whose locally regulated expression is associated with complex traits and diseases. In this work, we show that linkage disequilibrium induces significant gene-trait associations at non-causal genes as a function of the expression quantitative trait loci weights used in expression prediction. We introduce a probabilistic framework that models correlation among transcriptome-wide association study signals to assign a probability for every gene in the risk region to explain the observed association signal. Importantly, our approach remains accurate when expression data for causal genes are not available in the causal tissue by leveraging expression prediction from other tissues. Our approach yields credible sets of genes containing the causal gene at a nominal confidence level (for example, 90{\%}) that can be used to prioritize genes for functional assays. We illustrate our approach by using an integrative analysis of lipid traits, where our approach prioritizes genes with strong evidence for causality.},
author = {Mancuso, Nicholas and Freund, Malika K and Johnson, Ruth and Shi, Huwenbo and Kichaev, Gleb and Gusev, Alexander and Pasaniuc, Bogdan},
doi = {10.1038/s41588-019-0367-1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Mancuso et al. - 2019 - Probabilistic fine-mapping of transcriptome-wide association studies.pdf:pdf},
journal = {Nature Genetics},
keywords = {TWAS,gene expression,genetics,to-skim},
mendeley-tags = {TWAS,gene expression,genetics,to-skim},
pages = {675--682},
title = {{Probabilistic fine-mapping of transcriptome-wide association studies}},
url = {https://doi.org/10.1038/s41588-019-0367-1},
volume = {51},
year = {2019}
}
@article{Iterative,
author = {Sun, T and Zhang, C},
journal = {Biometrika},
keywords = {high-dimensional regression},
mendeley-tags = {high-dimensional regression},
number = {4},
pages = {879--898},
title = {{Scaled sparse linear regression}},
volume = {99},
year = {2012}
}
@article{Fulco2019a,
abstract = {Mammalian genomes harbor millions of noncoding elements called enhancers that quantitatively regulate gene expression, but it remains unclear which enhancers regulate which genes. Here we describe an experimental approach, based on CRISPR interference, RNA FISH, and flow cytometry (CRISPRi-FlowFISH), to perturb enhancers in the genome, and apply it to test {\textgreater}3,000 potential regulatory enhancer-gene connections across multiple genomic loci. A simple equation based on a mechanistic model for enhancer function performed remarkably well at predicting the complex patterns of regulatory connections we observe in our CRISPR dataset. This Activity-by-Contact (ABC) model involves multiplying measures of enhancer activity and enhancer-promoter 3D contacts, and can predict enhancer-gene connections in a given cell type based on chromatin state maps. Together, CRISPRi-FlowFISH and the ABC model provide a systematic approach to map and predict which enhancers regulate which genes, and will help to interpret the functions of the thousands of disease risk variants in the noncoding genome.},
author = {Fulco, Charles P and Nasser, Joseph and Jones, Thouis R and Munson, Glen and Bergman, Drew T and Subramanian, Vidya and Grossman, Sharon R and Anyoha, Rockwell and Patwardhan, Tejal A and Nguyen, Tung H and Kane, Michael and Doughty, Benjamin and Perez, Elizabeth M and Durand, Neva C and Stamenova, Elena K and Aiden, Erez Lieberman and Lander, Eric S and Engreitz, Jesse M},
doi = {10.1101/529990},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Fulco et al. - 2019 - Activity-by-Contact model of enhancer specificity from thousands of CRISPR perturbations (CRISPRi FlowFISH).pdf:pdf},
issn = {1546-1718},
journal = {Nature Genetics},
keywords = {CRISPR,gene-enhancer,genetics,to-read},
mendeley-tags = {CRISPR,gene-enhancer,genetics,to-read},
number = {December},
pages = {1664--1669},
publisher = {Springer US},
title = {{Activity-by-Contact model of enhancer specificity from thousands of CRISPR perturbations (CRISPRi FlowFISH)}},
url = {https://www.biorxiv.org/content/10.1101/529990v1},
volume = {51},
year = {2019}
}
@article{Ernst2012,
abstract = {Chromatin - state annotation using combinations of chromatin modification patterns has emerged as a powerful approach for discovering regulatory regions and their cell type– specific activity patterns and for interpreting disease-association studies 1, 2, 3, 4, 5. ... $\backslash$n},
author = {Ernst, Jason and Kellis, Manolis},
doi = {10.1038/nmeth.1906},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Ernst, Kellis - 2012 - ChromHMM Automating chromatin-state discovery and characterization.pdf:pdf},
issn = {15487091},
journal = {Nature Methods},
keywords = {enhancer,epigenetics,genetics},
mendeley-tags = {enhancer,epigenetics,genetics},
number = {3},
pages = {215--216},
publisher = {Nature Publishing Group},
title = {{ChromHMM: Automating chromatin-state discovery and characterization}},
volume = {9},
year = {2012}
}
@article{PetS10,
abstract = {Deep sequencing will soon generate comprehensive sequence information in large disease samples. Although the power to detect association with an individual rare variant is limited, pooling variants by gene or pathway into a composite test provides an alternative strategy for identifying susceptibility genes. We describe a statistical method for detecting association of multiple rare variants in protein-coding genes with a quantitative or dichotomous trait. The approach is based on the regression of phenotypic values on individuals' genotype scores subject to a variable allele-frequency threshold, incorporating computational predictions of the functional effects of missense variants. Statistical significance is assessed by permutation testing with variable thresholds. We used a rigorous population-genetics simulation framework to evaluate the power of the method, and we applied the method to empirical sequencing data from three disease studies. {\textcopyright} 2010 The American Society of Human Genetics.},
annote = {20471002},
author = {Price, Alkes L. and Kryukov, Gregory V. and de Bakker, Paul I.W. and Purcell, Shaun M. and Staples, Jeff and Wei, Lee Jen and Sunyaev, Shamil R.},
doi = {10.1016/j.ajhg.2010.04.005},
issn = {00029297},
journal = {American Journal of Human Genetics},
keywords = {genetics,rare variants},
mendeley-tags = {genetics,rare variants},
number = {6},
pages = {832--838},
title = {{Pooled Association Tests for Rare Variants in Exon-Resequencing Studies}},
url = {http://www.hubmed.org/display.cgi?uids=20471002},
volume = {86},
year = {2010}
}
@article{Vallejos2015,
abstract = {Single-cell mRNA sequencing can uncover novel cell-to-cell heterogeneity in gene expression levels in seemingly homogeneous populations of cells. However, these experiments are prone to high levels of unexplained technical noise, creating new challenges for identifying genes that show genuine heterogeneous expression within the population of cells under study. BASiCS (Bayesian Analysis of Single-Cell Sequencing data) is an integrated Bayesian hierarchical model where: (i) cell-specific normalisation constants are estimated as part of the model parameters, (ii) technical variability is quantified based on spike-in genes that are artificially introduced to each analysed cell's lysate and (iii) the total variability of the expression counts is decomposed into technical and biological components. BASiCS also provides an intuitive detection criterion for highly (or lowly) variable genes within the population of cells under study. This is formalised by means of tail posterior probabilities associated to high (or low) biological cell-to-cell variance contributions, quantities that can be easily interpreted by users. We demonstrate our method using gene expression measurements from mouse Embryonic Stem Cells. Cross-validation and meaningful enrichment of gene ontology categories within genes classified as highly (or lowly) variable supports the efficacy of our approach.},
author = {Vallejos, Catalina A. and Marioni, John C. and Richardson, Sylvia},
doi = {10.1371/journal.pcbi.1004333},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/PLoS Computational Biology/Vallejos, Marioni, Richardson - 2015 - BASiCS Bayesian Analysis of Single-Cell Sequencing Data.PDF:PDF},
issn = {15537358},
journal = {PLoS Computational Biology},
number = {6},
pages = {1--18},
pmid = {26107944},
title = {{BASiCS: Bayesian Analysis of Single-Cell Sequencing Data}},
volume = {11},
year = {2015}
}
@article{Ignatiadis2019a,
abstract = {We study methods for simultaneous analysis of many noisy experiments in the presence of rich covariate information. The goal of the analyst is to optimally estimate the true effect underlying each experiment. Both the noisy experimental results and the auxiliary covariates are useful for this purpose, but neither data source on its own captures all the information available to the analyst. In this paper, we propose a flexible plug-in empirical Bayes estimator that synthesizes both sources of information and may leverage any black-box predictive model. We show that our approach is within a constant factor of minimax for a simple data-generating model. Furthermore, we establish robust convergence guarantees for our method that hold under considerable generality, and exhibit promising empirical performance on both real and simulated data.},
archivePrefix = {arXiv},
arxivId = {1906.01611},
author = {Ignatiadis, Nikolaos and Wager, Stefan},
eprint = {1906.01611},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Ignatiadis, Wager - 2019 - Covariate-Powered Empirical Bayes Estimation.pdf:pdf},
journal = {arXiv},
title = {{Covariate-Powered Empirical Bayes Estimation}},
url = {http://arxiv.org/abs/1906.01611},
year = {2019}
}
@article{RetJ17,
author = {Ramdas, Aaditya and {Foygel Barber}, Rina and Wainwright, Martin J. and Jordan, Michael I.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Ramdas et al. - 2019 - A unified treatment of multiple testing with prior knowledge using the p-filter.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {FDR,Multiple testing,groups},
mendeley-tags = {FDR,Multiple testing,groups},
number = {5},
pages = {2790--2821},
title = {{A unified treatment of multiple testing with prior knowledge using the p-filter}},
volume = {47},
year = {2019}
}
@article{Liu,
abstract = {Investigators often use the data to generate interesting hypotheses and then perform inference for the generated hypotheses. P-values and confidence intervals must account for this explorative data analysis. A fruitful method for doing so is to condition any inferences on the components of the data used to generate the hypotheses, thus preventing information in those components from being used again. Some currently popular methods "over-condition," leading to wide intervals. We show how to perform the minimal conditioning in a computationally tractable way. In high dimensions, even this minimal conditioning can lead to intervals that are too wide to be useful, suggesting that up to now the cost of hypothesis generation has been underestimated. We show how to generate hypotheses in a strategic manner that sharply reduces the cost of data exploration and results in useful confidence intervals. Our discussion focuses on the problem of post-selection inference after fitting a lasso regression model, but we also outline its extension to a much more general setting.},
archivePrefix = {arXiv},
arxivId = {1801.09037v2},
author = {Liu, Keli and Markovic, Jelena and Tibshirani, Robert},
eprint = {1801.09037v2},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Liu, Markovic, Tibshirani - 2019 - More powerful post-selection inference, with application to the Lasso.pdf:pdf},
journal = {arXiv},
keywords = {high-dimensional regression,post-selection inference,to-skim,unpublished},
mendeley-tags = {high-dimensional regression,post-selection inference,to-skim,unpublished},
title = {{More powerful post-selection inference, with application to the Lasso}},
year = {2019}
}
@article{Hernandez2019,
abstract = {The recent explosive growth of human populations has produced an abundance of genetic variants with minor allele frequencies (MAFs) less than 1{\%} (ref. 1). While many rare variants underlying Mendelian diseases have been found 2 , their role in complex disease is unknown 3-8. Evolutionary models predict that the contribution of rare variants to complex disease is highly dependent on selection strength 9,10 and that population growth can magnify their impact 10-12. Recent methodological breakthroughs 13,14 have enabled researchers to jointly estimate the independent contributions of low-and high-frequency alleles to complex traits, often demonstrating a large rare variant contribution probably driven by natural selection 5,15-18. However, these studies excluded the rarest variants 15 or included only well-imputed variants 5. This is a problematic limitation given that some plausible evolutionary models predict that the largest contributions to phenotypic variance could be from the rarest variants 9-11,19. Directly querying the role of all variants with large-scale sequencing and sensitive statistical tests has the potential to reveal important sources of missing heritability, inform strategies to increase the success rate of association studies and clarify how natural selection has shaped human phenotypes. In this study, we develop, validate and apply an approach for inferring the relative phenotypic contributions of all variants, from singletons to high-frequency variants. We focus on the narrow-sense heritability (h 2) of gene expression because a growing body of literature suggests that genetic variants primarily affect disease by modifying gene regulatory programs 20-23 , and recent examinations have identified significant rare variant effects on transcription 8. To characterize the genetic architecture of gene expression, we analyzed 360 unrelated individuals of European ancestry with paired whole-genome DNA 24 and RNA 25 sequencing (RNA-seq) of lymphoblastoid cell lines (LCLs). We evaluate the robustness of our approach to genotyping errors, read mapping errors, population structure, rare variant stratification and a wide range of possible genetic architectures. Results Building and testing our model. We developed a method to estimate the effect of rare alleles on trait variance and validated our approach with an extensive set of simulations. Before analyzing real expression data, we performed a rigorous series of simulations to identify an approach for estimating heritability that is robust to possible confounding factors. In our simulations, we used real genotype data (all variants within 1 megabase (Mb) of the transcription start or end sites of genes) and generated gene expression phenotypes across individuals while varying the number of causal variants contributing to the phenotype (from 1 to 1,000), the distribution of effect sizes (including uniform, frequency-dependent and an evolutionary-based model) and the distribution of causal allele frequencies (ranging from predominantly rare to predominantly common; see Supplementary Note). In total, we simulated 440 different genotype-phenotype models that span the range of genetic architectures that are likely to underlie complex phenotypes such as gene expression, and analyzed each simulated dataset using multiple distinct methods. These include fitting a linear mixed model via restricted maximum likelihood 26,27 and Haseman-Elston regression, an alternative approach based on regressing phenotypic covariance on genotypic covariance 26 , which is more robust in small samples (see Supplementary Note). Similar to previous work 28 , we found that for many simulation settings, jointly analyzing all variants together can result in a substantial over-or underestimate of heritability (Fig. 1a; it shows results when true h 2 = 0.2). One common solution is to partition sites by frequency 5,15,29. We found that simply isolating rare (MAF ≤ 1{\%}) from common variants using two partitions and performing joint The vast majority of human mutations have minor allele frequencies under 1{\%}, with the plurality observed only once (that is, 'singletons'). While Mendelian diseases are predominantly caused by rare alleles, their cumulative contribution to complex phenotypes is largely unknown. We develop and rigorously validate an approach to jointly estimate the contribution of all alleles, including singletons, to phenotypic variation. We apply our approach to transcriptional regulation, an intermediate between genetic variation and complex disease. Using whole-genome DNA and lymphoblastoid cell line RNA sequencing data from 360 European individuals, we conservatively estimate that singletons contribute approximately 25{\%} of cis heritability across genes (dwarfing the contributions of other frequencies). The majority (approximately 76{\%}) of singleton heritability derives from ultrarare variants absent from thousands of additional samples. We develop an inference procedure to demonstrate that our results are consistent with pervasive purifying selection shaping the regulatory architecture of most human genes.},
author = {Hernandez, Ryan D and Uricchio, Lawrence H and Hartman, Kevin and Ye, Chun and Dahl, Andrew and Zaitlen, Noah},
doi = {10.1038/s41588-019-0487-7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Hernandez et al. - 2019 - Ultrarare variants drive substantial cis heritability of human gene expression.pdf:pdf},
isbn = {4158801904877},
journal = {Nature Genetics},
keywords = {gene expression,genetics},
mendeley-tags = {gene expression,genetics},
pages = {1349--1355},
title = {{Ultrarare variants drive substantial cis heritability of human gene expression}},
url = {https://doi.org/10.1038/s41588-019-0487-7},
volume = {51},
year = {2019}
}
@article{Grundberg2012,
author = {Grundberg, E and Small, K S and Hedman, $\backslash$r A K and Nica, A C and Buil, A and Others},
journal = {Nature Genetics},
keywords = {gene regulation},
mendeley-tags = {gene regulation},
number = {10},
pages = {1084--1089},
title = {{Mapping cis- and trans- regulatory effects across multiple tissues in twins}},
volume = {44},
year = {2012}
}
@article{Raic2019,
abstract = {We provide a Lyapunov type bound in the multivariate central limit theorem for sums of independent, but not necessarily identically distributed random vectors. The error in the normal approximation is estimated for certain classes of sets, which include the class of measurable convex sets. The error bound is stated with explicit constants. The result is proved by means of Stein's method. In addition, we improve the constant in the bound of the Gaussian perimeter of convex sets.},
author = {Rai{\v{c}}, Martin},
doi = {10.3150/18-BEJ1072},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bernoulli/Rai{\v{c}} - 2019 - A multivariate Berry-Esseen theorem with explicit constants.pdf:pdf},
issn = {13507265},
journal = {Bernoulli},
keywords = {Berry-Esseen theorem,Explicit constants,Lyapunov bound,Multivariate central limit theorem,Stein's method},
number = {4 A},
pages = {2824--2853},
title = {{A multivariate Berry-Esseen theorem with explicit constants}},
volume = {25},
year = {2019}
}
@article{Turley2018,
abstract = {T he standard approach in genetic association studies is to analyze a single trait. Such studies do not exploit information contained in summary statistics from GWAS of related traits. In this report, we develop a method, multi-trait analysis of GWAS (MTAG), that enables joint analysis of multiple traits, thus boosting statistical power to detect genetic associations for each trait analyzed. In comparison to the many existing multi-trait methods 1-5 , MTAG has a unique combination of four features that make it potentially useful in many settings. First, it can be applied to GWAS summary statistics (without access to individual-level data) from an arbitrary number of traits. Second, the summary statistics need not come from independent discovery samples: MTAG uses bivariate linkage disequilibrium (LD) score regression 6 to account for (possi-bly unknown) sample overlap between the GWAS results for different traits. Third, MTAG generates trait-specific effect estimates for each SNP. Finally, even when applied to many traits, MTAG is com-putationally quick because every step has a closed-form solution. The MTAG estimator is a generalization of inverse-variance-weighted meta-analysis that takes summary statistics from single-trait GWAS and outputs trait-specific association statistics. The resulting P values can be used like P values from a single-trait GWAS, for example, to prioritize SNPs for subsequent analyses such as biological annotation or to construct polygenic scores. The key assumption of MTAG is that all SNPs share the same variance-covariance matrix of effect sizes across traits. This assumption is strong and is violated in many circumstances, most intuitively in scenarios where some SNPs influence only a subset of the traits. Even if this assumption is not satisfied, however, we show analytically that MTAG is a consistent estimator and that its effect estimates always have a lower genome-wide mean-squared error (MSE) than the corresponding single-trait GWAS estimates. Hence, polygenic scores constructed from MTAG results are expected to outperform GWAS-based predictors very generally. The main potential problem arises for SNPs that are truly null for one trait but non-null for another trait. For such SNPs, MTAG's effect size estimates for the first trait are biased away from zero, leading to an increased rate of false positives (and an inflated type I error rate). We derive an analytic formula for the resulting false discovery rate (FDR), given any specified mixture-normal distribution of effect sizes (including multivariate spike-and-slab distributions), and we illustrate how the formula can be used to probe the credibility of MTAG-identified loci. We introduce multi-trait analysis of GWAS (MTAG), a method for joint analysis of summary statistics from genome-wide association studies (GWAS) of different traits, possibly from overlapping samples. We apply MTAG to summary statistics for depressive symptoms (N eff = 354,862), neuroticism (N = 168,105), and subjective well-being (N = 388,538). As compared to the 32, 9, and 13 genome-wide significant loci identified in the single-trait GWAS (most of which are themselves novel), MTAG increases the number of associated loci to 64, 37, and 49, respectively. Moreover, association statistics from MTAG yield more informative bioinformatics analyses and increase the variance explained by polygenic scores by approximately 25{\%}, matching theoretical expectations.},
author = {Turley, Patrick and Cesarini, David and Neale, Benjamin M and Benjamin, Daniel J and Walters, Raymond K and Maghzian, Omeed and Okbay, Aysu and Lee, James J and Fontana, Mark Alan and Nguyen, Tuan Anh},
doi = {10.1038/s41588-017-0009-4},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Turley et al. - 2018 - Multi-trait analysis of genome-wide association summary statistics using MTAG.pdf:pdf},
journal = {Nature Genetics},
keywords = {GWAS,genetics,multiple phenotypes},
mendeley-tags = {GWAS,genetics,multiple phenotypes},
pages = {229--237},
title = {{Multi-trait analysis of genome-wide association summary statistics using MTAG}},
url = {www.nature.com/naturegenetics},
volume = {50},
year = {2018}
}
@inproceedings{Zhang2017,
abstract = {Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family , or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.},
author = {Zhang, Chiyuan and Bengio, Samy and Brain, Google and Hardt, Moritz and Recht, Benjamin and Vinyals, Oriol and Deepmind, Google},
booktitle = {ICLR},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/ICLR/Zhang et al. - 2017 - UNDERSTANDING DEEP LEARNING REQUIRES RE-THINKING GENERALIZATION.pdf:pdf},
keywords = {deep learning,to-skim},
mendeley-tags = {deep learning,to-skim},
title = {{UNDERSTANDING DEEP LEARNING REQUIRES RE-THINKING GENERALIZATION}},
year = {2017}
}
@article{Shalem2014,
abstract = {The simplicity of programming the CRISPR (clustered regularly interspaced short palindromic repeats)–associated nuclease Cas9 to modify specific genomic loci suggests a new way to interrogate gene function on a genome-wide scale. We show that lentiviral delivery of a genome-scale CRISPR-Cas9 knockout (GeCKO) library targeting 18,080 genes with 64,751 unique guide sequences enables both negative and positive selection screening in human cells. First, we used the GeCKO library to identify genes essential for cell viability in cancer and pluripotent stem cells. Next, in a melanoma model, we screened for genes whose loss is involved in resistance to vemurafenib, a therapeutic RAF inhibitor. Our highest-ranking candidates include previously validated genes NF1 and MED12, as well as novel hits NF2, CUL3, TADA2B, and TADA1. We observe a high level of consistency between independent guide RNAs targeting the same gene and a high rate of hit confirmation, demonstrating the promise of genome-scale screening with Cas9.},
author = {Shalem, Ophir and Sanjana, Neville E. and Hartenian, Ella and Shi, Xi and Scott, David A. and Mikkelsen, Tarjei S. and Heckl, Dirk and Ebert, Benjamin L. and Root, David E. and Doench, John G. and Zhang, Feng},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Shalem et al. - 2014 - Genome-Scale CRISPR-Cas9 Knockout Screening in Human Cells.pdf:pdf},
journal = {Science},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {33},
pages = {84--87},
title = {{Genome-Scale CRISPR-Cas9 Knockout Screening in Human Cells}},
volume = {343},
year = {2014}
}
@article{ZetR11,
author = {Zeeberg, Barry R. and Reinhold, William and Pommier, Yves G. and Liu, Hongfang and Larionov, Vladimir L. and Kahn, Ari B. and Ehler, Martin and Bonner, Robert F. and Rajapakse, Vinodh N. and Brown, Jacob D. and Brooks, Brian P. and Weinstein, John N.},
doi = {10.1186/1471-2105-12-52},
issn = {1471-2105},
journal = {BMC Bioinformatics},
keywords = {Gene Ontology,bioinformatics,biological process,biology,gene expression profiling,gene mapping,genetics,microarray,nominal number,ontology,proteomics,similarity measure},
mendeley-tags = {Gene Ontology},
number = {1},
pages = {52},
publisher = {BioMed Central},
title = {{RedundancyMiner: De-replication of redundant GO categories in microarray and proteomics analysis}},
volume = {12},
year = {2011}
}
@article{Dukler2017,
abstract = {Most studies of responses to transcriptional stimuli measure changes in cellular mRNA concentrations. By sequencing na-scent RNA instead, it is possible to detect changes in transcription in minutes rather than hours and thereby distinguish primary from secondary responses to regulatory signals. Here, we describe the use of PRO-seq to characterize the immediate transcriptional response in human cells to celastrol, a compound derived from traditional Chinese medicine that has potent anti-inflammatory, tumor-inhibitory, and obesity-controlling effects. Celastrol is known to elicit a cellular stress response resembling the response to heat shock, but the transcriptional basis of this response remains unclear. Our analysis of PRO-seq data for K562 cells reveals dramatic transcriptional effects soon after celastrol treatment at a broad collection of both coding and noncoding transcription units. This transcriptional response occurred in two major waves, one within 10 min, and a second 40-60 min after treatment. Transcriptional activity was generally repressed by celastrol, but one distinct group of genes, enriched for roles in the heat shock response, displayed strong activation. Using a regression approach, we identified key transcription factors that appear to drive these transcriptional responses, including members of the E2F and RFX families. We also found sequence-based evidence that particular transcription factors drive the activation of enhancers. We observed increased polymerase pausing at both genes and enhancers, suggesting that pause release may be widely inhibited during the celastrol response. Our study demonstrates that a careful analysis of PRO-seq time-course data can disentangle key aspects of a complex transcriptional response, and it provides new insights into the activity of a powerful pharmacological agent.},
author = {Dukler, Noah and Booth, Gregory T and Huang, Yi-Fei and Tippens, Nathaniel and Waters, Colin T and Danko, Charles G and Lis, John T and Siepel, Adam},
doi = {10.1101/gr.222935.117},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Research/Dukler et al. - 2017 - Nascent RNA sequencing reveals a dynamic global transcriptional response at genes and enhancers to the natural me.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Genome Research/Dukler et al. - 2017 - Nascent RNA sequencing reveals a dynamic global transcriptional response at genes and enhancers to the natural(2).pdf:pdf},
journal = {Genome Research},
keywords = {Kathryn,PRO-seq,gene-enhancer},
mendeley-tags = {Kathryn,PRO-seq,gene-enhancer},
pages = {1816--1829},
title = {{Nascent RNA sequencing reveals a dynamic global transcriptional response at genes and enhancers to the natural medicinal compound celastrol}},
url = {http://www.genome.org/cgi/doi/10.1101/gr.222935.117.},
volume = {27},
year = {2017}
}
@article{I05,
abstract = {There is increasing concern that most current published research findings are false. The probability that a research claim is true may depend on study power and bias, the number of other studies on the same question, and, importantly, the ratio of true to no relationships among the relationships probed in each scientific field. In this framework, a research finding is less likely to be true when the studies conducted in a field are smaller; when effect sizes are smaller; when there is a greater number and lesser preselection of tested relationships; where there is greater flexibility in designs, definitions, outcomes, and analytical modes; when there is greater financial and other interest and prejudice; and when more teams are involved in a scientific field in chase of statistical significance. Simulations show that for most study designs and settings, it is more likely for a research claim to be false than true. Moreover, for many current scientific fields, claimed research findings may often be simply accurate measures of the prevailing bias. In this essay, I discuss the implications of these problems for the conduct and interpretation of research.},
annote = {16060722},
author = {Ioannidis, John P A},
journal = {PLoS Med},
pages = {e124--e124},
title = {{{\{}Why{\}} most Published Research Findings are False}},
volume = {2},
year = {2005}
}
@article{MG15_Holm,
author = {Meijer, Rosa J. and Goeman, Jelle J.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrical Journal/Meijer, Goeman - 2015 - A multiple testing method for hypotheses structured in a directed acyclic graph.pdf:pdf},
journal = {Biometrical Journal},
keywords = {FWER,Multiple testing,hierarchical multiple testing},
mendeley-tags = {FWER,Multiple testing,hierarchical multiple testing},
number = {1},
pages = {123--143},
publisher = {Wiley Online Library},
title = {{A multiple testing method for hypotheses structured in a directed acyclic graph}},
volume = {57},
year = {2015}
}
@article{Arensbergen2019,
abstract = {Most of the millions of SNPs in the human genome are non-coding, and many overlap with putative regulatory elements. Genome-wide association studies (GWAS) have linked many of these SNPs to human traits or to gene expression levels, but rarely with sufficient resolution to identify the causal SNPs. Functional screens based on reporter assays have previously been of insufficient throughput to test the vast space of SNPs for possible effects on regulatory element activity. Here we leveraged the throughput and resolution of the survey of regulatory elements (SuRE) reporter technology to survey the effect of 5.9 million SNPs, including 57{\%} of the known common SNPs, on enhancer and promoter activity. We identified more than 30,000 SNPs that alter the activity of putative regulatory elements, partially in a cell-type-specific manner. Integration of this dataset with GWAS results may help to pinpoint SNPs that underlie human traits.},
author = {Arensbergen, Joris and Pagie, Ludo and FitzPatrick, Vincent D and Haas, Marcel and Baltissen, Marijke P and Comoglio, Federico and Weide, Robin H and Teunissen, Hans and V{\~{o}}sa, Urmo and Franke, Lude and Wit, Elzo and Vermeulen, Michiel and Bussemaker, Harmen J and Steensel, Bas},
doi = {10.1038/s41588-019-0455-2},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Arensbergen et al. - 2019 - High-throughput identification of human SNPs affecting regulatory element activity.pdf:pdf},
isbn = {2,390,729,347},
journal = {Nature Genetics},
keywords = {Kathryn,genetics,massively parallel reporter assays},
mendeley-tags = {Kathryn,genetics,massively parallel reporter assays},
pages = {1160--1169},
title = {{High-throughput identification of human SNPs affecting regulatory element activity}},
url = {https://doi.org/10.1038/s41588-019-0455-2},
volume = {51},
year = {2019}
}
@phdthesis{Zhao2016,
author = {Zhao, Qingyuan},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Zhao - 2016 - Topics in Causal and High Dimensional Inference.pdf:pdf},
keywords = {causality},
mendeley-tags = {causality},
title = {{Topics in Causal and High Dimensional Inference}},
year = {2016}
}
@article{BetB10,
abstract = {Genome wide association (GWA) studies, which test for association between common genetic markers and a disease phenotype, have shown varying degrees of success. While many factors could potentially confound GWA studies, we focus on the possibility that multiple, rare variants (RVs) may act in concert to influence disease etiology. Here, we describe an algorithm for RV analysis, RareCover. The algorithm combines a disparate collection of RVs with low effect and modest penetrance. Further, it does not require the rare variants be adjacent in location. Extensive simulations over a range of assumed penetrance and population attributable risk (PAR) values illustrate the power of our approach over other published methods, including the collapsing and weighted-collapsing strategies. To showcase the method, we apply RareCover to re-sequencing data from a cohort of 289 individuals at the extremes of Body Mass Index distribution (NCT00263042). Individual samples were re-sequenced at two genes, FAAH and MGLL, known to be involved in endocannabinoid metabolism (187Kbp for 148 obese and 150 controls). The RareCover analysis identifies exactly one significantly associated region in each gene, each about 5 Kbp in the upstream regulatory regions. The data suggests that the RVs help disrupt the expression of the two genes, leading to lowered metabolism of the corresponding cannabinoids. Overall, our results point to the power of including RVs in measuring genetic associations.},
annote = {20976246},
author = {Bhatia, G and Bansal, V and Harismendy, O and Schork, N J and Topol, E J and Frazer, K and Bafna, V},
doi = {10.1371/journal.pcbi.1000954},
journal = {PLoS Comput Biol},
keywords = {GWAS,rare variants},
mendeley-tags = {GWAS,rare variants},
number = {10},
title = {{A covering method for detecting genetic associations between rare variants and common phenotypes}},
url = {http://www.hubmed.org/display.cgi?uids=20976246},
volume = {6},
year = {2010}
}
@article{JM14,
author = {Javanmard, Adel and Montanari, Andrea},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Machine Learning Research/Javanmard, Montanari - 2014 - Confidence intervals and hypothesis testing for high-dimensional regression.pdf:pdf},
journal = {Journal of Machine Learning Research},
number = {1},
pages = {2869--2909},
title = {{Confidence intervals and hypothesis testing for high-dimensional regression.}},
volume = {15},
year = {2014}
}
@article{Lee2012,
abstract = {Mapping human genetic variation is fundamentally interesting in fields such as anthropology and forensic inference. At the same time patterns of genetic diversity confound efforts to determine the genetic basis of complex disease. Due to technological advances it is now possible to measure hundreds of thousands of genetic variants per individual across the genome. Principal component analysis (PCA) is routinely used to summarize the genetic similarity between subjects. The eigenvectors are interpreted as dimensions of ancestry. We build on this idea using a spectral graph approach. In the process we draw on connections between multidimensional scaling and spectral kernel methods. Our approach, based on a spectral embedding derived from the normalized Laplacian of a graph, can produce more meaningful delineation of ancestry than by using PCA. The method is stable to outliers and can more easily incorporate different similarity measures of genetic data than PCA. We illustrate a new algorithm for genetic clustering and association analysis on a large, genetically heterogeneous sample.},
author = {Lee, Ann B. and Luca, Diana and Roeder, Kathryn},
doi = {10.1214/09-AOAS281},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Applied Statistics/Lee, Luca, Roeder - 2012 - A spectral graph approach to discovering genetic ancestry.pdf:pdf},
isbn = {0014081067},
issn = {19326157},
journal = {The Annals of Applied Statistics},
keywords = {Dimension reduction,Human genetics,Kathryn,Multidimensional scaling,Population structure,Spectral embedding},
mendeley-tags = {Kathryn},
number = {1},
pages = {179--202},
title = {{A spectral graph approach to discovering genetic ancestry}},
volume = {6},
year = {2012}
}
@article{MetZ15,
abstract = {Genetic risk prediction has several potential applications in medical research and clinical practice and could be used, for example, to stratify a heterogeneous population of patients by their predicted genetic risk. However, for polygenic traits, such as psychiatric disorders, the accuracy of risk prediction is low. Here we use a multivariate linear mixed model and apply multi-trait genomic best linear unbiased prediction for genetic risk prediction. This method exploits correlations between disorders and simultaneously evaluates individual risk for each disorder. We show that the multivariate approach significantly increases the prediction accuracy for schizophrenia, bipolar disorder, and major depressive disorder in the discovery as well as in independent validation datasets. By grouping SNPs based on genome annotation and fitting multiple random effects, we show that the prediction accuracy could be further improved. The gain in prediction accuracy of the multivariate approach is equivalent to an increase in sample size of 34{\%} for schizophrenia, 68{\%} for bipolar disorder, and 76{\%} for major depressive disorders using single trait models. Because our approach can be readily applied to any number of GWAS datasets of correlated traits, it is a flexible and powerful tool to maximize prediction accuracy. With current sample size, risk predictors are not useful in a clinical setting but already are a valuable research tool, for example in experimental designs comparing cases with high and low polygenic risk.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25640677{\}}{\{}25640677{\}}},
author = {R., Maier and G., Moser and G.-B., Chen and S., Ripke and W., Coryell and J.B., Potash and W.A., Scheftner and J., Shi and M.M., Weissman and C.M., Hultman and M., Land{\'{e}}n and D.F., Levinson and K.S., Kendler and J.W., Smoller and N.R., Wray and S.H., Lee and D., Absher and I., Agartz and H., Akil and F., Amin and O.A., Andreassen and A., Anjorin and R., Anney and D.E., Arking and P., Asherson and M.H., Azevedo and L., Backlund and J.A., Badner and A.J., Bailey and T., Banaschewski and J.D., Barchas and M.R., Barnes and T.B., Barrett and N., Bass and A., Battaglia and M., Bauer and M., Bay{\'{e}}s and F., Bellivier and S.E., Bergen and W., Berrettini and C., Betancur and T., Bettecken and J., Biederman and E.B., Binder and D.W., Black and D.H.R., Blackwood and C.S., Bloss and M., Boehnke and D.I., Boomsma and G., Breen and R., Breuer and R., Bruggeman and N.G., Buccola and J.K., Buitelaar and W.E., Bunney and J.D., Buxbaum and W.F., Byerley and S., Caesar and W., Cahn and R.M., Cantor and M., Casas and A., Chakravarti and K., Chambert and K., Choudhury and S., Cichon and C., Robert Cloninger and D.A., Collier and E.H., Cook and H., Coon and B., Cormand and P., Cormican and A., Corvin and W.H., Coryell and N., Craddock and D.W., Craig and I.W., Craig and J., Crosbie and M.L., Cuccaro and D., Curtis and D., Czamara and M.J., Daly and S., Datta and G., Dawson and R., Day and E.J., De Geus and F., Degenhardt and B., Devlin and S., Djurovic and G.J., Donohoe and A.E., Doyle and J., Duan and F., Dudbridge and E., Duketis and R.P., Ebstein and H.J., Edenberg and J., Elia and S., Ennis and B., Etain and A., Fanous and S.V., Faraone and A.E., Farmer and I., Nicol Ferrier and M., Flickinger and E., Fombonne and T., Foroud and J., Frank and B., Franke and C., Fraser and R., Freedman and N.B., Freimer and C.M., Freitag and M., Friedl and L., Fris{\'{e}}n and L., Gallagher and P.V., Gejman and L., Georgieva and E.S., Gershon and D.H., Geschwind and I., Giegling and M., Gill and S.D., Gordon and K., Gordon-Smith and E.K., Green and T.A., Greenwood and D.E., Grice and M., Gross and D., Grozeva and W., Guan and H., Gurling and L., De Haan and J.L., Haines and H., Hakonarson and J., Hallmayer and S.P., Hamilton and M.L., Hamshere and T.F., Hansen and A.M., Hartmann and M., Hautzinger and A.C., Heath and A.K., Henders and S., Herms and I.B., Hickie and M., Hipolito and S., Hoefels and P.A., Holmans and F., Holsboer and W.J., Hoogendijk and J.-J., Hottenga and C.M., Hultman and V., Hus and A., Ingason and M., Ising and S., Jamain and I., Jones and L., Jones and A.K., K{\"{a}}hler and R.S., Kahn and R., Kandaswamy and M.C., Keller and J.R., Kelsoe and K.S., Kendler and J.L., Kennedy and E., Kenny and L., Kent and Y., Kim and G.K., Kirov and S.M., Klauck and L., Klei and J.A., Knowles and M.A., Kohli and D.L., Koller and B., Konte and A., Korszun and L., Krabbendam and R., Krasucki and J., Kuntsi and P., Kwan and M., Land{\'{e}}n and N., L{\aa}ngstr{\"{o}}m and M., Lathrop and J., Lawrence and W.B., Lawson and M., Leboyer and D.H., Ledbetter and P.H., Lee and T., Lencz and K.-P., Lesch and D.F., Levinson and C.M., Lewis and J., Li and P., Lichtenstein and J.A., Lieberman and D.-Y., Lin and D.H., Linszen and C., Liu and F.W., Lohoff and S.K., Loo and C., Lord and J.K., Lowe and S., Lucae and D.J., MacIntyre and P.A.F., Madden and E., Maestrini and P.K.E., Magnusson and P.B., Mahon and W., Maier and A.K., Malhotra and S.M., Mane and C.L., Martin and N.G., Martin and M., Mattheisen and K., Matthews and M., Mattingsdal and S.A., McCarroll and K.A., McGhee and J.J., McGough and P.J., McGrath and P., McGuffin and M.G., McInnis and A., McIntosh and R., McKinney and A.W., McLean and F.J., McMahon and W.M., McMahon and A., McQuillin and H., Medeiros and S.E., Medland and S., Meier and I., Melle and F., Meng and J., Meyer and C.M., Middeldorp and L., Middleton and V., Milanova and A., Miranda and A.P., Monaco and G.W., Montgomery and J.L., Moran and D., Moreno-De-Luca and G., Morken and D.W., Morris and E.M., Morrow and V., Moskvina and B.J., Mowry and P., Muglia and T.W., M{\"{u}}hleisen and B., M{\"{u}}ller-Myhsok and M., Murtha and R.M., Myers and I., Myin-Germeys and B.M., Neale and S.F., Nelson and C.M., Nievergelt and I., Nikolov and V., Nimgaonkar and W.A., Nolen and M.M., N{\"{o}}then and J.I., Nurnberger and E.A., Nwulia and D.R., Nyholt and M.C., O'Donovan and C., O'Dushlaine and R.D., Oades and A., Olincy and G., Oliveira and L., Olsen and R.A., Ophoff and U., Osby and M.J., Owen and A., Palotie and J.R., Parr and A.D., Paterson and C.N., Pato and M.T., Pato and B.W., Penninx and M.L., Pergadia and M.A., Pericak-Vance and R.H., Perlis and B.S., Pickard and J., Pimm and J., Piven and D., Posthuma and J.B., Potash and F., Poustka and P., Propping and S.M., Purcell and V., Puri and D.J., Quested and E.M., Quinn and J.A., Ramos-Quiroga and H.B., Rasmussen and S., Raychaudhuri and K., Rehnstr{\"{o}}m and A., Reif and M., Ribas{\'{e}}s and J.P., Rice and M., Rietschel and S., Ripke and K., Roeder and H., Roeyers and L., Rossin and A., Rothenberger and G., Rouleau and D., Ruderfer and D., Rujescu and A.R., Sanders and S.J., Sanders and S.L., Santangelo and R., Schachar and M., Schalling and A.F., Schatzberg and W.A., Scheftner and G.D., Schellenberg and S.W., Scherer and N.J., Schork and T.G., Schulze and J., Schumacher and M., Schwarz and E., Scolnick and L.J., Scott and J.A., Sergeant and J., Shi and P.D., Shilling and S.I., Shyn and J.M., Silverman and P., Sklar and S.L., Slager and S.L., Smalley and J.H., Smit and E.N., Smith and J.W., Smoller and E.J.S., Sonuga-Barke and D., St Clair and M., State and M., Steffens and H.-C., Steinhausen and J.S., Strauss and J., Strohmaier and T., Scott Stroup and P.F., Sullivan and J., Sutcliffe and P., Szatmari and S., Szelinger and A., Thapar and S., Thirumalai and R.C., Thompson and A.A., Todorov and F., Tozzi and J., Treutlein and J.-Y., Tzeng and M., Uhr and E.J.C.G., van den Oord and G., Van Grootheest and J., Van Os and A.M., Vicente and V.J., Vieland and J.B., Vincent and P.M., Visscher and C.A., Walsh and T.H., Wassink and S.J., Watson and L.A., Weiss and M.M., Weissman and T., Werge and T.F., Wienker and D., Wiersma and E.M., Wijsman and G., Willemsen and N., Williams and A., Jeremy Willsey and S.H., Witt and N.R., Wray and W., Xu and A.H., Young and T.W., Yu and S., Zammit and P.P., Zandi and P., Zhang and F.G., Zitman and S., Z{\"{o}}llner},
doi = {10.1016/j.ajhg.2014.12.006 LK - http://sfx.library.uu.nl/utrecht?sid=EMBASE&issn=15376605&id=doi:10.1016%2Fj.ajhg.2014.12.006&atitle=Joint+analysis+of+psychiatric+disorders+increases+accuracy+of+risk+prediction+for+schizophrenia%2C+bipolar+disorder%2C+and+major+depressive+disorder&stitle=Am.+J.+Hum.+Genet.&title=American+Journal+of+Human+Genetics&volume=96&issue=2&spage=283&epage=294&aulast=Maier&aufirst=Robert&auinit=R.&aufull=Maier+R.&coden=AJHGA&isbn=&pages=283-294&date=2015&auinit1=R&auinit},
issn = {1537-6605},
journal = {American Journal of Human Genetics},
keywords = {adult,article,bipolar disorder,clinical practice,experimental design,female,genetic association,genetic correlation,genetic risk,genetic variability,genetics,heritability,human,intellectual impairment,major clinical study,major depression,male,mental disease,multiple phenotypes,phenotype,practice guideline,prediction,priority journal,risk assessment,sample size,schizophrenia,single nucleotide polymorphism},
mendeley-tags = {genetics,multiple phenotypes},
month = {feb},
number = {2},
pages = {283--294},
title = {{Joint analysis of psychiatric disorders increases accuracy of risk prediction for schizophrenia, bipolar disorder, and major depressive disorder}},
url = {http://www.embase.com/search/results?subaction=viewrecord{\&}from=export{\&}id=L601976671{\%}0Ahttp://dx.doi.org/10.1016/j.ajhg.2014.12.006},
volume = {96},
year = {2015}
}
@article{Tsiatis2008,
abstract = {This paper presents the synchronization between a pair of identical susceptible- infected-recovered (SIR) epidemic chaotic systems and fractional-order time derivative using active control method. The fractional derivative is described in Caputo sense. Numerical simulation results show that the method is effective and reliable for synchronizing the fractional-order chaotic systems while it allows the system to remain in chaotic state. The striking features of this paper are: the successful presentation of the stability of the equilibrium state and the revelation that time for synchronization varies with the variation in fractional-order derivatives close to the standard one for different specified values of the parameters of the system.},
author = {Tsiatis, Anastasios A. and Davidian, Marie and Zhang, Min and Lu, Xiaomin},
doi = {10.1002/sim},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics in Medicine/Tsiatis et al. - 2008 - Covariate adjustment for two-sample treatment comparisons in randomized clinical trials A principled yet flexibl.pdf:pdf},
journal = {Statistics in Medicine},
keywords = {causality,publication bias,selection bias,selection model,sensitivity analysis,unpublished studies},
mendeley-tags = {causality},
pages = {4267--4278},
title = {{Covariate adjustment for two-sample treatment comparisons in randomized clinical trials: A principled yet flexible approach}},
volume = {27},
year = {2008}
}
@article{VanIterson2010,
abstract = {Background: In high-dimensional data analysis such as differential gene expression analysis, people often use filtering methods like fold-change or variance filters in an attempt to reduce the multiple testing penalty and improve power. However, filtering may introduce a bias on the multiple testing correction. The precise amount of bias depends on many quantities, such as fraction of probes filtered out, filter statistic and test statistic used.},
author = {{Van Iterson}, Maarten and Boer, Judith M and Menezes, Ren{\'{e}}e X},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Bioinformatics/Van Iterson, Boer, Menezes - 2010 - Filtering, FDR and power.pdf:pdf},
journal = {BMC Bioinformatics},
keywords = {FDR,Multiple testing,genetics,to-read},
mendeley-tags = {FDR,Multiple testing,genetics,to-read},
title = {{Filtering, FDR and power}},
url = {http://www.biomedcentral.com/1471-2105/11/450},
volume = {11},
year = {2010}
}
@article{LetK12,
author = {Logsdon, B A and Carty, C L and Reiner, A P and Dai, J Y and Kooperberg, C},
journal = {Bioinformatics},
keywords = {GWAS},
mendeley-tags = {GWAS},
month = {may},
title = {{{\{}A{\}} novel variational {\{}B{\}}ayes multiple locus {\{}Z{\}}-statistic for genome-wide association studies with {\{}B{\}}ayesian model averaging}},
year = {2012}
}
@article{Liley2019,
abstract = {High-dimensional hypothesis testing is ubiquitous in the biomedical sciences, and informative covariates may be employed to improve power. The conditional false discovery rate (cFDR) is widely-used approach suited to the setting where the covariate is a set of p-values for the equivalent hypotheses for a second trait. Although related to the Benjamini-Hochberg procedure, it does not permit any easy control of type-1 error rate, and existing methods are over-conservative. We propose a new method for type-1 error rate control based on identifying mappings from the unit square to the unit interval defined by the estimated cFDR, and splitting observations so that each map is independent of the observations it is used to test. We also propose an adjustment to the existing cFDR estimator which further improves power. We show by simulation that the new method more than doubles potential improvement in power over unconditional analyses compared to existing methods. We demonstrate our method on transcriptome-wide association studies, and show that the method can be used in an iterative way, enabling the use of multiple covariates successively. Our methods substantially improve the power and applicability of cFDR analysis.},
author = {Liley, James and Wallace, Chris},
doi = {10.1101/414318},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Liley, Wallace - 2019 - Accurate error control in high dimensional association testing using conditional false discovery rates.pdf:pdf},
journal = {bioRxiv},
keywords = {Multiple testing,genetics,weighted multiple testing},
mendeley-tags = {Multiple testing,genetics,weighted multiple testing},
title = {{Accurate error control in high dimensional association testing using conditional false discovery rates}},
url = {http://dx.doi.org/10.1101/414318},
year = {2019}
}
@article{Barber2018,
abstract = {We consider the variable selection problem, which seeks to identify important variables influencing a response {\$}Y{\$} out of many candidate features {\$}X{\_}1, \backslashldots, X{\_}p{\$}. We wish to do so while offering finite-sample guarantees about the fraction of false positives - selected variables {\$}X{\_}j{\$} that in fact have no effect on {\$}Y{\$} after the other features are known. When the number of features {\$}p{\$} is large (perhaps even larger than the sample size {\$}n{\$}), and we have no prior knowledge regarding the type of dependence between {\$}Y{\$} and {\$}X{\$}, the model-X knockoffs framework nonetheless allows us to select a model with a guaranteed bound on the false discovery rate, as long as the distribution of the feature vector {\$}X=(X{\_}1,\backslashdots,X{\_}p){\$} is exactly known. This model selection procedure operates by constructing "knockoff copies'" of each of the {\$}p{\$} features, which are then used as a control group to ensure that the model selection algorithm is not choosing too many irrelevant features. In this work, we study the practical setting where the distribution of {\$}X{\$} could only be estimated, rather than known exactly, and the knockoff copies of the {\$}X{\_}j{\$}'s are therefore constructed somewhat incorrectly. Our results, which are free of any modeling assumption whatsoever, show that the resulting model selection procedure incurs an inflation of the false discovery rate that is proportional to our errors in estimating the distribution of each feature {\$}X{\_}j{\$} conditional on the remaining features {\$}\backslash{\{}X{\_}k:k\backslashneq j\backslash{\}}{\$}. The model-X knockoff framework is therefore robust to errors in the underlying assumptions on the distribution of {\$}X{\$}, making it an effective method for many practical applications, such as genome-wide association studies, where the underlying distribution on the features {\$}X{\_}1,\backslashdots,X{\_}p{\$} is estimated accurately but not known exactly.},
archivePrefix = {arXiv},
arxivId = {1801.03896},
author = {Barber, Rina Foygel and Cand{\`{e}}s, Emmanuel J. and Samworth, Richard J.},
eprint = {1801.03896},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics, to appear/Barber, Cand{\`{e}}s, Samworth - 2020 - Robust inference with knockoffs.pdf:pdf},
issn = {0090-5364},
journal = {Annals of Statistics, to appear},
title = {{Robust inference with knockoffs}},
url = {http://arxiv.org/abs/1801.03896},
year = {2020}
}
@article{Wei2020,
author = {Wei, Xiaolin and Xiang, Yu and Shan, Ruocheng and Peters, Derek T. and Sun, Tongyu and Lin, Xin and Li, Wei and Diao, Yarui},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Wei et al. - 2020 - Multi-omics analysis of chromatin accessibility and interactions with transcriptome by HiCAR.pdf:pdf},
journal = {bioRxiv},
keywords = {multi-omics},
mendeley-tags = {multi-omics},
title = {{Multi-omics analysis of chromatin accessibility and interactions with transcriptome by HiCAR}},
year = {2020}
}
@article{Mumbach2017,
abstract = {The challenge of linking intergenic mutations to target genes has limited molecular understanding of human diseases. Here we show that H3K27ac HiChIP generates high-resolution contact maps of active enhancers and target genes in rare primary human T cell subtypes and coronary artery smooth muscle cells. Differentiation of naive T cells into T helper 17 cells or regulatory T cells creates subtype-specific enhancer-promoter interactions, specifically at regions of shared DNA accessibility. These data provide a principled means of assigning molecular functions to autoimmune and cardiovascular disease risk variants, linking hundreds of noncoding variants to putative gene targets. Target genes identified with HiChIP are further supported by CRISPR interference and activation at linked enhancers, by the presence of expression quantitative trait loci, and by allele-specific enhancer loops in patient-derived primary cells. The majority of disease-associated enhancers contact genes beyond the nearest gene in the linear genome, leading to a fourfold increase in the number of potential target genes for autoimmune and cardiovascular diseases.},
author = {Mumbach, Maxwell R. and Satpathy, Ansuman T. and Boyle, Evan A. and Dai, Chao and Gowen, Benjamin G. and Cho, Seung Woo and Nguyen, Michelle L. and Rubin, Adam J. and Granja, Jeffrey M. and Kazane, Katelynn R. and Wei, Yuning and Nguyen, Trieu and Greenside, Peyton G. and Corces, M. Ryan and Tycko, Josh and Simeonov, Dimitre R. and Suliman, Nabeela and Li, Rui and Xu, Jin and Flynn, Ryan A. and Kundaje, Anshul and Khavari, Paul A. and Marson, Alexander and Corn, Jacob E. and Quertermous, Thomas and Greenleaf, William J. and Chang, Howard Y.},
doi = {10.1038/ng.3963},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Mumbach et al. - 2017 - Enhancer connectome in primary human cells identifies target genes of disease-associated DNA elements(2).pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {11},
pages = {1602--1612},
title = {{Enhancer connectome in primary human cells identifies target genes of disease-associated DNA elements}},
volume = {49},
year = {2017}
}
@article{dvoretzky1956asymptotic,
author = {Dvoretzky, Aryeh and Kiefer, Jack and Wolfowitz, Jacob},
journal = {The Annals of Mathematical Statistics},
keywords = {canonical,empirical process},
mendeley-tags = {canonical,empirical process},
pages = {642--669},
publisher = {JSTOR},
title = {{Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator}},
year = {1956}
}
@article{AB98,
abstract = {Multipoint linkage analysis of quantitative-trait loci (QTLs) has previously been restricted to sibships and small pedigrees. In this article, we show how variance-component linkage methods can be used in pedigrees of arbitrary size and complexity, and we develop a general framework for multipoint identity-by-descent (IBD) probability calculations. We extend the sib-pair multipoint mapping approach of Fulker et al. to general relative pairs. This multipoint IBD method uses the proportion of alleles shared identical by descent at genotyped loci to estimate IBD sharing at arbitrary points along a chromosome for each relative pair. We have derived correlations in IBD sharing as a function of chromosomal distance for relative pairs in general pedigrees and provide a simple framework whereby these correlations can be easily obtained for any relative pair related by a single line of descent or by multiple independent lines of descent. Once calculated, the multipoint relative-pair IBDs can be utilized in variance-component linkage analysis, which considers the likelihood of the entire pedigree jointly. Examples are given that use simulated data, demonstrating both the accuracy of QTL localization and the increase in power provided by multipoint analysis with 5-, 10-, and 20-cM marker maps. The general pedigree variance component and IBD estimation methods have been implemented in the SOLAR (Sequential Oligogenic Linkage Analysis Routines) computer package.},
annote = {9545414},
author = {Almasy, Laura and Blangero, John},
doi = {10.1086/301844},
issn = {00029297},
journal = {American Journal of Human Genetics},
keywords = {genetics},
mendeley-tags = {genetics},
month = {may},
number = {5},
pages = {1198--1211},
title = {{Multipoint Quantitative-Trait Linkage Analysis in General Pedigrees}},
volume = {62},
year = {2002}
}
@article{MetV09,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/19812666{\}}{\{}19812666{\}}},
author = {Manolio, T A and Collins, F S and Cox, N J and Goldstein, D B and Hindorff, L A and Hunter, D J and McCarthy, M I and Ramos, E M and Cardon, L R and Chakravarti, A and Cho, J H and Guttmacher, A E and Kong, A and Kruglyak, L and Mardis, E and Rotimi, C N and Slatkin, M and Valle, D and Whittemore, A S and Boehnke, M and Clark, A G and Eichler, E E and Gibson, G and Haines, J L and Mackay, T F and McCarroll, S A and Visscher, P M},
journal = {Nature},
keywords = {GWAS,canonical},
mendeley-tags = {GWAS,canonical},
month = {oct},
pages = {747--753},
title = {{{\{}F{\}}inding the missing heritability of complex diseases}},
volume = {461},
year = {2009}
}
@article{Arnold2013,
author = {Gaulton, Kyle J and Nammo, Takao and Pasquali, Lorenzo and Simon, Jeremy M and Giresi, Paul G and Fogarty, Marie P and Panhuis, Tami M and Mieczkowski, Piotr and Secchi, Antonio and Bosco, Domenico and Berney, Thierry and Montanya, Eduard and Mohlke, Karen L and Lieb, Jason D and Ferrer, Jorge},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Gaulton et al. - 2013 - Genome-Wide Quantitative Enhancer Activity Maps Identified by STARR-seq.pdf:pdf},
issn = {1546-1718},
journal = {Science},
keywords = {Binding Sites,Binding Sites: drug effects,Biological,Cells,Chromatin,Chromatin Assembly and Disassembly,Chromatin Assembly and Disassembly: genetics,Chromatin: genetics,Chromatin: isolation {\&} purification,Chromatin: metabolism,Chromosome Mapping,Cultured,DNA,Diabetes Mellitus,Formaldehyde,Formaldehyde: pharmacology,Genetic Predisposition to Disease,HeLa Cells,Humans,Islets of Langerhans,Islets of Langerhans: metabolism,K562 Cells,Kathryn,Models,Nucleic Acid,Nucleic Acid: drug effects,Nucleic Acid: genetics,Oligonucleotide Array Sequence Analysis,Regulatory Sequences,Sequence Analysis,TCF Transcription Factors,TCF Transcription Factors: genetics,Transcription Factor 7-Like 2 Protein,Type 2,Type 2: genetics},
mendeley-tags = {Kathryn},
pages = {1074--1077},
title = {{Genome-Wide Quantitative Enhancer Activity Maps Identified by STARR-seq}},
volume = {339},
year = {2013}
}
@article{Wu2020,
abstract = {The Fisher randomization test (FRT) is appropriate for any test statistic, under a sharp null hypothesis that can recover all missing potential outcomes. However, it is often sought after to test a weak null hypothesis that the treatment does not affect the units on average. To use the FRT for a weak null hypothesis, we must address two issues. First, we need to impute the missing potential outcomes although the weak null hypothesis cannot determine all of them. Second, we need to choose a proper test statistic. For a general weak null hypothesis, we propose an approach to imputing missing potential outcomes under a compatible sharp null hypothesis. Building on this imputation scheme, we advocate a studentized statistic. The resulting FRT has multiple desirable features. First, it is model-free. Second, it is finite-sample exact under the sharp null hypothesis that we use to impute the potential outcomes. Third, it conservatively controls large-sample type I errors under the weak null hypothesis of interest. Therefore, our FRT is agnostic to the treatment effect heterogeneity. We establish a unified theory for general factorial experiments. We also extend it to stratified and clustered experiments.},
archivePrefix = {arXiv},
arxivId = {1809.07419},
author = {Wu, Jason and Ding, Peng},
doi = {10.1080/01621459.2020.1750415},
eprint = {1809.07419},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Wu, Ding - 2020 - Randomization Tests for Weak Null Hypotheses in Randomized Experiments.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
month = {apr},
pages = {1--35},
publisher = {Informa UK Limited},
title = {{Randomization Tests for Weak Null Hypotheses in Randomized Experiments}},
year = {2020}
}
@incollection{Seidenfeld1992,
author = {Seidenfeld, T.},
booktitle = {The Founders of Evolutionary Genetics},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Founders of Evolutionary Genetics/Seidenfeld - 1992 - Fisher on Design.pdf:pdf},
pages = {23--36},
publisher = {Springer},
title = {{Fisher on Design}},
year = {1992}
}
@article{GF12,
author = {Goeman, Jelle J and Finos, Livio},
doi = {10.1515/1544-6115.1554},
issn = {2194-6302},
journal = {Stat. Appl. Genet. Mol. Biol.},
keywords = {Multiple testing,hierarchical multiple testing},
mendeley-tags = {Multiple testing,hierarchical multiple testing},
number = {1},
pages = {Art. 11, 20},
title = {{The inheritance procedure: multiple testing of tree-structured hypotheses}},
url = {https://doi.org/10.1515/1544-6115.1554},
volume = {11},
year = {2012}
}
@article{WetL09,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/19176549{\}}{\{}19176549{\}}},
author = {Wu, T T and Chen, Y F and Hastie, T and Sobel, E and Lange, K},
journal = {Bioinformatics},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
month = {mar},
number = {6},
pages = {714--721},
title = {{{\{}G{\}}enome-wide association analysis by lasso penalized logistic regression}},
volume = {25},
year = {2009}
}
@article{MatrixEQTL,
author = {Shabalin, A A},
journal = {Bioinformatics},
keywords = {gene expression},
mendeley-tags = {gene expression},
number = {10},
pages = {1353--1358},
title = {{Matrix {\{}eQTL{\}}: ultra fast {\{}eQTL{\}} analysis via large matrix operations}},
volume = {28},
year = {2012}
}
@article{Kuchibhotla2018,
abstract = {Construction of valid statistical inference for estimators based on data-driven selection has received a lot of attention in the recent times. Berk et al. (2013) is possibly the first work to provide valid inference for Gaussian homoscedastic linear regression with fixed covariates under arbitrary covariate/variable selection. The setting is unrealistic and is extended by Bachoc et al. (2016) by relaxing the distributional assumptions. A major drawback of the aforementioned works is that the construction of valid confidence regions is computationally intensive. In this paper, we first prove that post-selection inference is equivalent to simultaneous inference and then construct valid post-selection confidence regions which are computationally simple. Our construction is based on deterministic inequalities and apply to independent as well as dependent random variables without the requirement of correct distributional assumptions. Finally, we compare the volume of our confidence regions with the existing ones and show that under non-stochastic covariates, our regions are much smaller.},
archivePrefix = {arXiv},
arxivId = {1806.04119},
author = {Kuchibhotla, Arun Kumar and Brown, Lawrence D. and Buja, Andreas and George, Edward I. and Zhao, Linda},
eprint = {1806.04119},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Kuchibhotla et al. - 2018 - Valid Post-selection Inference in Assumption-lean Linear Regression.pdf:pdf},
journal = {The Annals of Statistics},
pages = {(to appear)},
title = {{Valid Post-selection Inference in Assumption-lean Linear Regression}},
url = {http://arxiv.org/abs/1806.04119},
year = {2018}
}
@article{Dai2020,
author = {Dai, Zhiming},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Dai - 2020 - Transcription factor-target relationships complicated by knockout analysis.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,transcription factors},
mendeley-tags = {CRISPR,transcription factors},
title = {{Transcription factor-target relationships complicated by knockout analysis}},
year = {2020}
}
@article{troendle2000stepwise,
author = {Troendle, J F},
journal = {Journal of Statistical Planning and Inference},
keywords = {FDR,Multiple testing},
mendeley-tags = {FDR,Multiple testing},
number = {1-2},
pages = {139--158},
publisher = {Elsevier},
title = {{Stepwise normal theory multiple test procedures controlling the false discovery rate}},
volume = {84},
year = {2000}
}
@article{Hafez2017,
abstract = {{\textcopyright} 2017 The Author(s). Transcriptional enhancers regulate spatio-temporal gene expression. While genomic assays can identify putative enhancers en masse, assigning target genes is a complex challenge. We devised a machine learning approach, McEnhancer, which links target genes to putative enhancers via a semi-supervised learning algorithm that predicts gene expression patterns based on enriched sequence features. Predicted expression patterns were 73-98{\%} accurate, predicted assignments showed strong Hi-C interaction enrichment, enhancer-associated histone modifications were evident, and known functional motifs were recovered. Our model provides a general framework to link globally identified enhancers to targets and contributes to deciphering the regulatory genome.},
author = {Hafez, Dina and Karabacak, Aslihan and Krueger, Sabrina and Hwang, Yih Chii and Wang, Li San and Zinzen, Robert P. and Ohler, Uwe},
doi = {10.1186/s13059-017-1316-x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Hafez et al. - 2017 - McEnhancer Predicting gene expression via semi-supervised assignment of enhancers to target genes.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Drosophila melanogaster,Enhancer to target gene assignment,Gene expression,Gene regulation,Interpolated Markov model,Kathryn,Machine learning,Semi-supervised model,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {1},
pages = {1--21},
publisher = {Genome Biology},
title = {{McEnhancer: Predicting gene expression via semi-supervised assignment of enhancers to target genes}},
volume = {18},
year = {2017}
}
@article{PetS16,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26626037{\}}{\{}26626037{\}}},
author = {Peterson, C B and Bogomolov, M and Benjamini, Y and Sabatti, C},
journal = {Genetic Epidemiology},
keywords = {FDR,GWAS,Multiple testing,high-dimensional regression},
mendeley-tags = {FDR,GWAS,Multiple testing,high-dimensional regression},
month = {jan},
pages = {45--56},
title = {{{\{}M{\}}any {\{}P{\}}henotypes {\{}W{\}}ithout {\{}M{\}}any {\{}F{\}}alse {\{}D{\}}iscoveries: {\{}E{\}}rror {\{}C{\}}ontrolling {\{}S{\}}trategies for {\{}M{\}}ultitrait {\{}A{\}}ssociation {\{}S{\}}tudies}},
volume = {40},
year = {2016}
}
@article{Zheng2019,
abstract = {The genomes of multicellular organisms are extensively folded into 3D chromosome territories within the nucleus 1 . Advanced 3D genome-mapping methods that combine proximity ligation and high-throughput sequencing (such as chromosome conformation capture, Hi-C) 2 , and chromatin immunoprecipitation techniques (such as chromatin interaction analysis by paired-end tag sequencing, ChIA-PET) 3 , have revealed topologically associating domains 4 with frequent chromatin contacts, and have identified chromatin loops mediated by specific protein factors for insulation and regulation of transcription 5–7 . However, these methods rely on pairwise proximity ligation and reflect population-level views, and thus cannot reveal the detailed nature of chromatin interactions. Although single-cell Hi-C 8 potentially overcomes this issue, this method may be limited by the sparsity of data that is inherent to current single-cell assays. Recent advances in microfluidics have opened opportunities for droplet-based genomic analysis 9 but this approach has not yet been adapted for chromatin interaction analysis. Here we describe a strategy for multiplex chromatin-interaction analysis via droplet-based and barcode-linked sequencing, which we name ChIA-Drop. We demonstrate the robustness of ChIA-Drop in capturing complex chromatin interactions with single-molecule precision, which has not been possible using methods based on population-level pairwise contacts. By applying ChIA-Drop to Drosophila cells, we show that chromatin topological structures predominantly consist of multiplex chromatin interactions with high heterogeneity; ChIA-Drop also reveals promoter-centred multivalent interactions, which provide topological insights into transcription.},
author = {Zheng, Meizhen and Tian, Simon Zhongyuan and Capurso, Daniel and Kim, Minji and Maurya, Rahul and Lee, Byoungkoo and Piecuch, Emaly and Gong, Liang and Zhu, Jacqueline Jufen and Li, Zhihui and Wong, Chee Hong and Ngan, Chew Yee and Wang, Ping and Ruan, Xiaoan and Wei, Chia Lin and Ruan, Yijun},
doi = {10.1038/s41586-019-0949-1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Zheng et al. - 2019 - Multiplex chromatin interactions with single-molecule precision.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {HI-C,single cell},
mendeley-tags = {HI-C,single cell},
number = {7745},
pages = {558--562},
publisher = {Springer US},
title = {{Multiplex chromatin interactions with single-molecule precision}},
url = {http://dx.doi.org/10.1038/s41586-019-0949-1},
volume = {566},
year = {2019}
}
@book{Efron2018,
author = {Efron, Bradley},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Efron - 2018 - Exponential Families in Theory and Practice.pdf:pdf},
keywords = {exponential families,generalized linear models},
mendeley-tags = {exponential families,generalized linear models},
title = {{Exponential Families in Theory and Practice}},
url = {http://statweb.stanford.edu/{~}ckirby/brad/STATS305B{\_}Part-1.pdf},
year = {2018}
}
@article{Hou2019,
abstract = {S NP-heritability, the proportion of phenotypic variance attributable to the additive effects of a given set of SNPs, is a fundamental quantity in genetics 1 ; it provides an upper bound on risk prediction from a linear model 2 and, when defined as a function of all SNPs on an array, yields insights into the 'missing heritability' of complex traits 3-5. Traditionally, SNP-heritability is estimated by fitting variance components models with restricted maximum likelihood (REML) 3,6-9. With some exceptions 8 , REML-based methods are not scalable to biobanks that assay hundreds of thousands of individuals (for example, UK Biobank 10). SNP-heritability can also be estimated by assessing the deviation in marginal association statistics as a function of LD scores 11-14 ; such methods can scale to millions of individuals. More recently, a randomized extension of Haseman-Elston regression 15 was shown to estimate a single genetic variance component from individual-level data as accurately as REML methods but in a fraction of the runtime 16. To facilitate inference, all existing methods for genome-wide SNP-heritability inference make assumptions on genetic architecture , which is typically parametrized by polygenicity (the number of variants with effects larger than some small constant $\delta$) and minor allele frequency (MAF)/LD-dependence (the coupling of effects with MAF, local LD or other functional annotations) 17. Since the true genetic architecture of any given trait is unknown, existing methods are susceptible to bias and often yield vastly different estimates even when applied to the same data 9,14,18. Although multi-component methods that stratify SNPs by MAF/LD ameliorate some of these robustness issues 7,18,19 , fitting multiple variance components to biobank-scale data with REML is highly resource-intensive 8 and it is unclear whether multi-component methods based on summary statistics produce accurate estimates of total SNP-heritability. Alternate methods that explicitly model MAF/LD-dependency 6,9,14 are also sensitive to model misspecification 6,9,14,18,19. In addition, genetic architecture varies across traits and populations due to, for example, variable degrees of negative selection acting on different traits in different populations 17,20-25. Methods that jointly infer SNP-heritability and parameters such as the strength of negative selection or polygenicity 14,23,26 are computationally intensive and/or sensitive to LD-dependency. Thus, it remains unclear which estimates of SNP-heritability computed from biobank-scale data are reliable. In this study, we investigate whether genome-wide SNP-heritability can be accurately estimated under a generalized random effects (GRE) model that makes minimal assumptions on genetic architecture. Under this model, every causal effect has an arbitrary SNP-specific variance and SNP-heritability is defined as the sum of the SNP-specific variances (Methods). To the best of our knowledge , all existing methods make additional assumptions on top of the GRE model (Table 1). For example, GREML 3 (and several other methods 8,16,27) imposes an inverse relationship between MAF and allelic effect size whereas Linkage Disequilibrium Adjusted Kinships (LDAK) assumes that each SNP-specific variance is inversely proportional to both MAF and LD tagging 6,9. We derive a closed-form estimator for SNP-heritability as a function of marginal association statistics and in-sample LD and show that this estimator is consistent (approaches the true SNP-heritability as sample size increases) and unbiased (its expectation is equal to the true SNP-heritability) when the number of individuals exceeds the number of SNP-heritability is a fundamental quantity in the study of complex traits. Recent studies have shown that existing methods to estimate genome-wide SNP-heritability can yield biases when their assumptions are violated. While various approaches have been proposed to account for frequency-and linkage disequilibrium (LD)-dependent genetic architectures, it remains unclear which estimates reported in the literature are reliable. Here we show that genome-wide SNP-heritability can be accurately estimated from biobank-scale data irrespective of genetic architecture, without specifying a heritability model or partitioning SNPs by allele frequency and/or LD. We show analytically and through extensive simulations starting from real genotypes (UK Biobank, N = 337 K) that, unlike existing methods, our closed-form estimator is robust across a wide range of architectures. We provide estimates of SNP-heritability for 22 complex traits in the UK Biobank and show that, consistent with our results in simulations, existing biobank-scale methods yield estimates up to 30{\%} different from our theoretically-justified approach.},
author = {Hou, Kangcheng and Burch, Kathryn S and Majumdar, Arunabha and Shi, Huwenbo and Mancuso, Nicholas and Wu, Yue and Sankararaman, Sriram and Pasaniuc, Bogdan},
doi = {10.1038/s41588-019-0465-0},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Hou et al. - 2019 - Accurate estimation of SNP-heritability from biobank-scale data irrespective of genetic architecture.pdf:pdf},
journal = {Nature Genetics},
keywords = {GWAS,genetics,heritability,to-skim},
mendeley-tags = {GWAS,genetics,heritability,to-skim},
title = {{Accurate estimation of SNP-heritability from biobank-scale data irrespective of genetic architecture}},
url = {https://doi.org/10.1038/s41588-019-0465-0},
year = {2019}
}
@article{SSF03,
abstract = {We explore the implications of the false discovery rate (FDR) controlling procedure in disease gene mapping. With the aid of simulations, we show how, under models commonly used, the simple step-down procedure introduced by Benjamini and Hochberg controls the FDR for the dependent tests on which linkage and association genome screens are based. This adaptive multiple comparison procedure may offer an important tool for mapping susceptibility genes for complex diseases.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/12807801{\}}{\{}12807801{\}}},
author = {Sabatti, C and Service, S and Freimer, N},
journal = {Genetics},
keywords = {FDR,genetics},
mendeley-tags = {FDR,genetics},
number = {2},
pages = {829--833},
title = {{False discovery rate in linkage and association genome screens for complex disorders}},
url = {http://www.hubmed.org/display.cgi?uids=12807801},
volume = {164},
year = {2003}
}
@article{Stringer2011,
annote = {$\backslash$href{\{}http://Www.ncbi.nlm.nih.gov/pubmed/22140493{\}}{\{}22140493{\}}},
author = {Stringer, S and Wray, N R and Kahn, R S and Derks, E M},
journal = {PLOS One},
keywords = {GWAS},
mendeley-tags = {GWAS},
number = {11},
pages = {e27964},
title = {{Underestimated effect sizes in {\{}GWAS{\}}: fundamental limitations of single {\{}SNP{\}} analysis for dichotomous phenotypes}},
volume = {6},
year = {2011}
}
@article{RY13,
author = {Rempala, Grzegorz A. and Yang, Yuhong},
journal = {Statistics and its interface},
keywords = {Multiple testing,gene expression,resampling},
mendeley-tags = {Multiple testing,gene expression,resampling},
number = {1},
publisher = {NIH Public Access},
title = {{On permutation procedures for strong control in multiple testing with gene expression data}},
volume = {6},
year = {2013}
}
@article{Gandy2017,
abstract = {Software packages usually report the results of statistical tests using p-values. Users often interpret these by comparing them to standard thresholds, e.g. 0.1{\%}, 1{\%} and 5{\%}, which is sometimes re-inforced by a star rating (***, **, *). In this article, we consider an arbitrary statistical test whose p-value p is not available explicitly, but can be approximated by Monte Carlo samples, e.g. bootstrap or permutation tests. The standard implementation of such tests usually draws a fixed number of samples to approximate p. However, the probability that the exact and the approximated p-value lie on different sides of a threshold (thus changing the interpretation) can be high, particularly for p-values close to a threshold. We present a method to overcome this. We consider a finite set of user-specified intervals which cover [0,1] and which can be overlapping. We call these p-value buckets. We present algorithms that, with high probability, return a p-value bucket containing p. Suitably chosen overlapping buckets allow decisions in finite time and lead to an extension of the star rating. The proposed methods are suitable for use in standard software and can be computationally more efficient than standard implementations. We illustrate our methods using a contingency table example.},
archivePrefix = {arXiv},
arxivId = {1703.09305},
author = {Gandy, Axel and Hahn, Georg and Ding, Dong},
eprint = {1703.09305},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Gandy, Hahn, Ding - 2017 - Implementing Monte Carlo Tests with P-value Buckets.pdf:pdf},
journal = {arXiv},
keywords = {Monte Carlo,Multiple testing,algorithms,bootstrap,hypothesis testing,resampling,sampling},
mendeley-tags = {Monte Carlo,Multiple testing,bootstrap},
title = {{Implementing Monte Carlo Tests with P-value Buckets}},
url = {http://arxiv.org/abs/1703.09305},
year = {2017}
}
@article{PetR15,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26201697{\}}{\{}26201697{\}}},
author = {Pendergrass, S A and Verma, A and Okula, A and Hall, M A and Crawford, D C and Ritchie, M D},
journal = {Hum. Hered.},
keywords = {genetics},
mendeley-tags = {genetics},
number = {3-4},
pages = {111--123},
title = {{{\{}P{\}}henome-{\{}W{\}}ide {\{}A{\}}ssociation {\{}S{\}}tudies: {\{}E{\}}mbracing {\{}C{\}}omplexity for {\{}D{\}}iscovery}},
volume = {79},
year = {2015}
}
@article{Weiss1975,
abstract = {In an earlier article [8] conditions were given under which maximum likelihood estimators are asymptotically normal and asymptotically efficient in certain nonstandard cases. Under these same conditions, the asymptotic distribution of the likelihood ratio is found. An easily computed asymptotic equivalent of the likelihood ratio is developed, and is applied to a problem of testing fit. {\textcopyright} 1975, Taylor {\&} Francis Group, LLC.},
author = {Weiss, Lionel},
doi = {10.1080/01621459.1975.10480289},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Weiss - 1975 - The asymptotic distribution of the likelihood ratio in some nonstandard cases.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {349},
pages = {204--208},
title = {{The asymptotic distribution of the likelihood ratio in some nonstandard cases}},
volume = {70},
year = {1975}
}
@article{HP10,
abstract = {Since associations between complex diseases and common variants are typically weak, and approaches to genotyping rare variants (e.g. by next-generation resequencing) multiply, there is an urgent demand to develop powerful association tests that are able to detect disease associations with both common and rare variants. In this article we present such a test. It is based on data-adaptive modifications to a so-called Sum test originally proposed for common variants, which aims to strike a balance between utilizing information on multiple markers in linkage disequilibrium and reducing the cost of large degrees of freedom or of multiple testing adjustment. When applied to multiple common or rare variants in a candidate region, the proposed test is easy to use with 1 degree of freedom and without the need for multiple testing adjustment. We show that the proposed test has high power across a wide range of scenarios with either common or rare variants, or both. In particular, in some situations the proposed test performs better than several commonly used methods.},
annote = {20413981},
author = {Han, Fang and Pan, Wei},
journal = {Hum Hered},
keywords = {GWAS,rare variants},
mendeley-tags = {GWAS,rare variants},
pages = {42--54},
title = {{{\{}A{\}} Data-adaptive sum test for Disease Association with Multiple Common or rare Variants}},
volume = {70},
year = {2010}
}
@article{Liu2014,
abstract = {Applying the Benjamini and Hochberg (B-H) method to multiple Student's t tests is a popular technique for gene selection in microarray data analysis. Given the nonnormality of the population, the true p-values of the hypothesis tests are typically unknown. Hence it is common to use the standard normal distribution N(0, 1), Student's t distribution tn-1 or the bootstrap method to estimate the p-values. In this paper, we prove that when the population has the finite 4th moment and the dimension m and the sample size n satisfy logm = o(n1/3), the B-H method controls the false discovery rate (FDR) and the false discovery proportion (FDP) at a given level $\alpha$ asymptotically with p-values estimated from N(0, 1) or tn-1 distribution. However, a phase transition phenomenon occurs when log m ≥ c0 n1/3. In this case, the FDR and the FDP of the B-H method may be larger than $\alpha$ or even converge to one. In contrast, the bootstrap calibration is accurate for logm = o(n1/2) as long as the underlying distribution has the sub-Gaussian tails. However, such a light-tailed condition cannot generally be weakened. The simulation study shows that the bootstrap calibration is very conservative for the heavy tailed distributions. To solve this problem, a regularized bootstrap correction is proposed and is shown to be robust to the tails of the distributions. The simulation study shows that the regularized bootstrap method performs better than its usual counterpart.},
author = {Liu, Weidong and Shao, Qi Man},
doi = {10.1214/14-AOS1249},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Liu, Shao - 2014 - Phase transition and regularized bootstrap in large-scale t-tests with false discovery rate control.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bootstrap correction,False discovery rate,Multiple t-tests,Phase transition,t-test},
mendeley-tags = {t-test},
number = {5},
pages = {2003--2025},
title = {{Phase transition and regularized bootstrap in large-scale t-tests with false discovery rate control}},
volume = {42},
year = {2014}
}
@article{Statistics2009,
author = {Chernoff, Herman},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Mathematical Statistics/Chernoff - 1952 - A Measure of Asymptotic Efficiency for Tests of a Hypothesis Based on the sum of Observations.pdf:pdf},
journal = {The Annals of Mathematical Statistics},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {4},
pages = {493--507},
title = {{A Measure of Asymptotic Efficiency for Tests of a Hypothesis Based on the sum of Observations}},
volume = {23},
year = {1952}
}
@article{Berk2019,
abstract = {It is well known that with observational data, models used in conventional regression analyses are commonly misspecified. Yet in practice, one tends to proceed with interpretations and inferences that rely on correct specification. Even those who invoke Box's maxim that all models are wrong proceed as if results were generally useful. Misspecification, however, has implications that affect practice. Regression models are approximations to a true response surface and should be treated as such. Accordingly, regression parameters should be interpreted as statistical functionals. Importantly, the regressor distribution affects targets of estimation and regressor randomness affects the sampling variability of estimates. As a consequence, inference should be based on sandwich estimators or the pairs (x-y) bootstrap. Traditional prediction intervals lose their pointwise coverage guarantees, but empirically calibrated intervals can be justified for future populations. We illustrate the key concepts with an empirical application. ARTICLE HISTORY},
author = {Berk, Richard and Buja, Andreas and Brown, Lawrence and George, Edward and {Kumar Kuchibhotla}, Arun and Su, Weijie and Zhao, Linda},
doi = {10.1080/00031305.2019.1592781},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The American Statistician/Berk et al. - 2019 - Assumption Lean Regression.pdf:pdf},
issn = {1537-2731},
journal = {The American Statistician},
keywords = {Foundational issues,Generalized linear models,Linear regression,Misspecified regression models,Regression functionals,high-dimensional regression,to-skim},
mendeley-tags = {high-dimensional regression,to-skim},
title = {{Assumption Lean Regression}},
url = {https://www.tandfonline.com/action/journalInformation?journalCode=utas20},
year = {2019}
}
@article{Wilson2019,
abstract = {Analysis of “big data” frequently involves statistical comparison of millions of competing hypotheses to discover hidden processes underlying observed patterns of data, for example, in the search for genetic determinants of disease in genome-wide association studies (GWAS). Controlling the familywise error rate (FWER) is considered the strongest protection against false positives but makes it difficult to reach the multiple testing-corrected significance threshold. Here, I introduce the harmonic mean p-value (HMP), which controls the FWER while greatly improving statistical power by combining dependent tests using generalized central limit theorem. I show that the HMP effortlessly combines information to detect statistically significant signals among groups of individually nonsignificant hypotheses in examples of a human GWAS for neuroticism and a joint human–pathogen GWAS for hepatitis C viral load. The HMP simultaneously tests all ways to group hypotheses, allowing the smallest groups of hypotheses that retain significance to be sought. The power of the HMP to detect significant hypothesis groups is greater than the power of the Benjamini–Hochberg procedure to detect significant hypotheses, although the latter only controls the weaker false discovery rate (FDR). The HMP has broad implications for the analysis of large datasets, because it enhances the potential for scientific discovery.},
author = {Wilson, Daniel J.},
doi = {10.1073/pnas.1814092116},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/Wilson - 2019 - The harmonic mean p-value for combining dependent tests.pdf:pdf},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Big data,False positives,Model averaging,Multiple testing,P-values,global testing},
mendeley-tags = {global testing},
number = {4},
pages = {1195--1200},
pmid = {30610179},
title = {{The harmonic mean p-value for combining dependent tests}},
volume = {116},
year = {2019}
}
@article{Yu2019a,
abstract = {The traditional framework for feature selection treats all features as costing the same amount. However, in reality, a scientist often has considerable discretion regarding what variables to measure, and the decision involves a tradeoff between model accuracy and cost (where cost can refer to money, time, difficulty, or intrusiveness). In particular, unnecessarily including an expensive feature in a model is worse than unnecessarily including a cheap feature. We propose a procedure, based on multiple knockoffs, for performing feature selection in a cost-conscious manner. The key idea behind our method is to force higher cost features to compete with more knockoffs than cheaper features. We derive an upper bound on the weighted false discovery proportion associated with this procedure, which corresponds to the fraction of the feature cost that is wasted on unimportant features. We prove that this bound holds simultaneously with high probability over a path of selected variable sets of increasing size. A user may thus select a set of features based, for example, on the overall budget, while knowing that no more than a particular fraction of feature cost is wasted. In a simulation study, we investigate the practical importance of incorporating cost considerations into the feature selection process.},
archivePrefix = {arXiv},
arxivId = {1910.03627},
author = {Yu, Guo and Witten, Daniela and Bien, Jacob},
eprint = {1910.03627},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Yu, Witten, Bien - 2019 - Controlling Costs Feature Selection on a Budget.pdf:pdf},
keywords = {cost,feature selection,weighted false discovery proportion},
pages = {1--16},
title = {{Controlling Costs: Feature Selection on a Budget}},
url = {http://arxiv.org/abs/1910.03627},
year = {2019}
}
@article{Howard2019,
abstract = {This paper develops a class of exponential bounds for the probability that a martingale sequence crosses a time-dependent linear threshold. Our key insight is that it is both natural and fruitful to formulate exponential concentration inequalities in this way. We illustrate this point by presenting a single assumption and a single theorem that together strengthen many tail bounds for martingales, including classical inequalities (1960-80) by Bernstein, Bennett, Hoeffding, and Freedman; contemporary inequalities (1980-2000) by Shorack and Wellner, Pinelis, Blackwell, van de Geer, and de la Pe{\~{n}}a; and several modern inequalities (post-2000) by Khan, Tropp, Bercu and Touati, Delyon, and others. In each of these cases, we give the strongest and most general statements to date, quantifying the time-uniform concentration of scalar, matrix, and Banach-space-valued martingales, under a variety of nonparametric assumptions in discrete and continuous time. In doing so, we bridge the gap between existing line-crossing inequalities, the sequential probability ratio test, the Cram{\'{e}}r-Chernoff method, self-normalized processes, and other parts of the literature.},
archivePrefix = {arXiv},
arxivId = {1808.03204v4},
author = {Howard, Steven R and Ramdas, Aaditya and Mcauliffe, Jon and Sekhon, Jasjeet},
eprint = {1808.03204v4},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Howard et al. - 2019 - Exponential line-crossing inequalities.pdf:pdf},
journal = {arXiv},
keywords = {inequalities,sequential analysis,to-skim},
mendeley-tags = {inequalities,sequential analysis,to-skim},
title = {{Exponential line-crossing inequalities}},
year = {2019}
}
@article{OConnor2019,
abstract = {Complex traits and common diseases are extremely polygenic, their heritability spread across thousands of loci. One possible explana-tion is that thousands of genes and loci have similarly important biological effects when mutated. However, we hypothesize that formost complex traits, relatively few genes and loci are critical, and negative selection—purging large-effect mutations in theseregions—leaves behind common-variant associations in thousands of less critical regions instead. We refer to this phenomenon asflattening. To quantify its effects, we introduce a mathematical definition of polygenicity, the effective number of independently asso-ciated SNPs (Me), which describes how evenly the heritability of a trait is spread across the genome. We developed a method, stratified LDfourth moments regression (S-LD4M), to estimateMe, validating that it produces robust estimates in simulations. Analyzing 33 complextraits (average N¼361k), we determined that heritability is spread43more evenly among common SNPs than among low-frequencySNPs. This difference, together with evolutionary modeling of new mutations, suggests that complex traits would be orders of magnitudeless polygenic if not for the influence of negative selection. We also determined that heritability is spread more evenly within function-ally important regions in proportion to their heritability enrichment; functionally important regions do not harbor common SNPs withgreatly increased causal effect sizes, due to selective constraint. Our results suggest that for most complex traits, the genes and loci withthe most critical biological effects often differ from those with the strongest common-variant associations.},
author = {O'Connor, Luke J. and Schoech, Armin P. and Hormozdiari, Farhad and Gazal, Steven and Patterson, Nick and Price, Alkes L.},
doi = {10.1016/j.ajhg.2019.07.003},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The American Journal of Human Genetics/O'Connor et al. - 2019 - Extreme Polygenicity of Complex Traits Is Explained by Negative Selection.pdf:pdf},
issn = {00029297},
journal = {The American Journal of Human Genetics},
keywords = {GWAS,genetics},
mendeley-tags = {GWAS,genetics},
pages = {1--21},
publisher = {ElsevierCompany.},
title = {{Extreme Polygenicity of Complex Traits Is Explained by Negative Selection}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0002929719302666},
volume = {105},
year = {2019}
}
@article{pmid23408905,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23408905{\}}{\{}23408905{\}}},
author = {Zhou, X and Carbonetto, P and Stephens, M},
journal = {PLoS Genetics},
keywords = {genetics,linear mixed models},
mendeley-tags = {genetics,linear mixed models},
number = {2},
pages = {e1003264},
title = {{{\{}P{\}}olygenic modeling with bayesian sparse linear mixed models}},
volume = {9},
year = {2013}
}
@article{CL13,
author = {Chatterjee, A and Lahiri, S N},
journal = {The Annals of Statistics},
keywords = {high-dimensional regression,lasso},
mendeley-tags = {high-dimensional regression,lasso},
number = {3},
pages = {1232--1259},
publisher = {Institute of Mathematical Statistics},
title = {{Rates of convergence of the adaptive LASSO estimators to the oracle distribution and higher order refinements by the bootstrap}},
volume = {41},
year = {2013}
}
@article{An2018,
abstract = {Whole-genome sequencing (WGS) has facilitated the first genome-wide evaluations of the contribution of de novo noncoding mutations to complex disorders. Using WGS, we identified 255,106 de novo mutations among sample genomes from members of 1902 quartet families in which one child, but not a sibling or their parents, was affected by autism spectrum disorder (ASD). In contrast to coding mutations, no noncoding functional annotation category, analyzed in isolation, was significantly associated with ASD. Casting noncoding variation in the context of a de novo risk score across multiple annotation categories, however, did demonstrate association with mutations localized to promoter regions. We found that the strongest driver of this promoter signal emanates from evolutionarily conserved transcription factor binding sites distal to the transcription start site. These data suggest that de novo mutations in promoter regions, characterized by evolutionary and functional signatures, contribute to ASD.},
author = {An, Joon Yong and Lin, Kevin and Zhu, Lingxue and Werling, Donna M. and Dong, Shan and Brand, Harrison and Wang, Harold Z. and Zhao, Xuefang and Schwartz, Grace B. and Collins, Ryan L. and Currall, Benjamin B. and Dastmalchi, Claudia and Dea, Jeanselle and Duhn, Clif and Gilson, Michael C. and Klei, Lambertus and Liang, Lindsay and Markenscoff-Papadimitriou, Eirene and Pochareddy, Sirisha and Ahituv, Nadav and Buxbaum, Joseph D. and Coon, Hilary and Daly, Mark J. and Kim, Young Shin and Marth, Gabor T. and Neale, Benjamin M. and Quinlan, Aaron R. and Rubenstein, John L. and Sestan, Nenad and State, Matthew W. and Willsey, A. Jeremy and Talkowski, Michael E. and Devlin, Bernie and Roeder, Kathryn and Sanders, Stephan J.},
doi = {10.1126/science.aat6576},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/An et al. - 2018 - Genome-wide de novo risk score implicates promoter variation in autism spectrum disorder.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Science/An et al. - 2018 - Genome-wide de novo risk score implicates promoter variation in autism spectrum disorder(2).pdf:pdf},
issn = {10959203},
journal = {Science},
keywords = {Kathryn,autism,de novo mutations,psychiatric genomics,whole genome sequencing},
mendeley-tags = {Kathryn,autism,de novo mutations,psychiatric genomics,whole genome sequencing},
number = {6420},
title = {{Genome-wide de novo risk score implicates promoter variation in autism spectrum disorder}},
url = {http://science.sciencemag.org/},
volume = {362},
year = {2018}
}
@article{Diao2017,
abstract = {Millions of cis-regulatory elements are predicted to be present in the human genome, but direct evidence for their biological function is scarce. Here we report a high-throughput method, cis-regulatory element scan by tiling-deletion and sequencing (CREST-seq), for the unbiased discovery and functional assessment of cis-regulatory sequences in the genome. We used it to interrogate the 2-Mb POU5F1 locus in human embryonic stem cells, and identified 45 cis-regulatory elements. A majority of these elements have active chromatin marks, DNase hypersensitivity, and occupancy by multiple transcription factors, which confirms the utility of chromatin signatures in cis-element mapping. Notably, 17 of them are previously annotated promoters of functionally unrelated genes, and like typical enhancers, they form extensive spatial contacts with the POU5F1 promoter. These results point to the commonality of enhancer-like promoters in the human genome.},
author = {Diao, Yarui and Fang, Rongxin and Li, Bin and Meng, Zhipeng and Yu, Juntao and Qiu, Yunjiang and Lin, Kimberly C. and Huang, Hui and Liu, Tristin and Marina, Ryan J. and Jung, Inkyung and Shen, Yin and Guan, Kun Liang and Ren, Bing},
doi = {10.1038/nmeth.4264},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Methods/Diao et al. - 2017 - A tiling-deletion-based genetic screen for cis-regulatory element identification in mammalian cells.pdf:pdf},
issn = {15487105},
journal = {Nature Methods},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
month = {may},
number = {6},
pages = {629--635},
publisher = {Nature Publishing Group},
title = {{A tiling-deletion-based genetic screen for cis-regulatory element identification in mammalian cells}},
volume = {14},
year = {2017}
}
@article{DetS11,
abstract = {The need to collect accurate and complete pedigree information has been a drawback of family-based linkage and association studies. Even in case-control studies, investigators should be aware of, and condition on, familial relationships. In single nucleotide polymorphism (SNP) genome scans, relatedness can be directly inferred from the genetic data rather than determined through interviews. Various methods of estimating relatedness have previously been implemented, most notably in PLINK. We present new fast and accurate algorithms for estimating global and local kinship coefficients from dense SNP genotypes. These algorithms require only a single pass through the SNP genotype data. We also show that these estimates can be used to cluster individuals into pedigrees. With these estimates in hand, quantitative trait locus linkage analysis proceeds via traditional variance components methods without any prior relationship information. We demonstrate the success of our algorithms on simulated and real data sets. Our procedures make linkage analysis as easy as a typical genomewide association study. Genet. Epidemiol. 2011. {\^{A}}{\textcopyright} 2011 Wiley-Liss, Inc.},
annote = {21465549},
author = {Day-Williams, Aaron G and Blangero, John and Dyer, Thomas D and Lange, Kenneth and Sobel, Eric M},
journal = {Genetic Epidemiology},
pages = {epub},
title = {{{\{}Linkage{\}} Analysis Without Defined Pedigrees}},
year = {2011}
}
@article{Gao2016,
abstract = {MOTIVATION Multiple high-throughput approaches have recently been developed and allowed the discovery of enhancers on a genome scale in a single experiment. However, the datasets generated from these approaches are not fully utilized by the research community due to technical challenges such as lack of consensus enhancer annotation and integrative analytic tools. RESULTS We developed an interactive database, EnhancerAtlas, which contains an atlas of 2,534,123 enhancers for 105 cell/tissue types. A consensus enhancer annotation was obtained for each cell by summation of independent experimental datasets with the relative weights derived from a cross-validation approach. Moreover, EnhancerAtlas provides a set of useful analytic tools that allow users to query and compare enhancers in a particular genomic region or associated with a gene of interest, and assign enhancers and their target genes from a custom dataset. AVAILABILITY AND IMPLEMENTATION The database with analytic tools is available at http://www.enhanceratlas.org/ CONTACT: jiang.qian@jhmi.edu or tank1@email.chop.eduSupplementary information: Supplementary data are available at Bioinformatics online.},
author = {Gao, Tianshun and He, Bing and Liu, Sheng and Zhu, Heng and Tan, Kai and Qian, Jiang},
doi = {10.1093/bioinformatics/btw495},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Gao et al. - 2016 - EnhancerAtlas A resource for enhancer annotation and analysis in 105 human celltissue types.pdf:pdf},
issn = {14602059},
journal = {Bioinformatics},
keywords = {Kathryn,enhancer,gene regulation,genetics},
mendeley-tags = {Kathryn,enhancer,gene regulation,genetics},
number = {23},
pages = {3543--3551},
title = {{EnhancerAtlas: A resource for enhancer annotation and analysis in 105 human cell/tissue types}},
volume = {32},
year = {2016}
}
@misc{SWISS,
annote = {$\backslash$url{\{}https://github.com/welchr/swiss{\}} [Accessed: 2018]},
author = {Welch, R},
keywords = {genetics,software},
mendeley-tags = {genetics,software},
title = {{{\{}$\backslash$tt SWISS{\}}: Software to help identify overlap between association scan results and GWAS hit catalogs}},
year = {2014}
}
@article{Feller1943,
author = {Feller, W.},
doi = {10.2307/1990252},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Transactions of the American Mathematical Society/Feller - 1943 - Generalization of a Probability Limit Theorem of Cramer.pdf:pdf},
issn = {00029947},
journal = {Transactions of the American Mathematical Society},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {3},
pages = {361},
title = {{Generalization of a Probability Limit Theorem of Cramer}},
volume = {54},
year = {1943}
}
@article{Gimenez2018,
abstract = {The Model-X knockoff procedure has recently emerged as a powerful approach for feature selection with statistical guarantees. The advantage of knockoff is that if we have a good model of the features X, then we can identify salient features without knowing anything about how the outcome Y depends on X. An important drawback of knockoffs is its instability: running the procedure twice can result in very different selected features, potentially leading to different conclusions. Addressing this instability is critical for obtaining reproducible and robust results. Here we present a generalization of the knockoff procedure that we call simultaneous multi-knockoffs. We show that multi-knockoff guarantees false discovery rate (FDR) control, and is substantially more stable and powerful compared to the standard (single) knockoff. Moreover we propose a new algorithm based on entropy maximization for generating Gaussian multi-knockoffs. We validate the improved stability and power of multi-knockoffs in systematic experiments. We also illustrate how multi-knockoffs can improve the accuracy of detecting genetic mutations that are causally linked to phenotypes.},
author = {Gimenez, Jaime Roquero and Zou, James},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of Machine Learning Research/Gimenez, Zou - 2019 - Improving the Stability of the Knockoff Procedure Multiple Simultaneous Knockoffs and Entropy Maximization.pdf:pdf},
journal = {Proceedings of Machine Learning Research},
pages = {2184--2192},
title = {{Improving the Stability of the Knockoff Procedure: Multiple Simultaneous Knockoffs and Entropy Maximization}},
url = {http://arxiv.org/abs/1810.11378},
volume = {89},
year = {2019}
}
@book{Lahnemann2020,
abstract = {The recent boom in microfluidics and combinatorial indexing strategies, combined with low sequencing costs, has empowered single-cell sequencing technology. Thousands - or even millions - of cells analyzed in a single experiment amount to a data revolution in single-cell biology and pose unique data science problems. Here, we outline eleven challenges that will be central to bringing this emerging field of single-cell data science forward. For each challenge, we highlight motivating research questions, review prior work, and formulate open problems. This compendium is for established researchers, newcomers, and students alike, highlighting interesting and rewarding problems for the coming years.},
author = {L{\"{a}}hnemann, David and K{\"{o}}ster, Johannes and Szczurek, Ewa and McCarthy, Davis J. and Hicks, Stephanie C. and Robinson, Mark D. and Vallejos, Catalina A. and Campbell, Kieran R. and Beerenwinkel, Niko and Mahfouz, Ahmed and Pinello, Luca and Skums, Pavel and Stamatakis, Alexandros and Attolini, Camille Stephan Otto and Aparicio, Samuel and Baaijens, Jasmijn and Balvert, Marleen and de Barbanson, Buys and Cappuccio, Antonio and Corleone, Giacomo and Dutilh, Bas E. and Florescu, Maria and Guryev, Victor and Holmer, Rens and Jahn, Katharina and Lobo, Thamar Jessurun and Keizer, Emma M. and Khatri, Indu and Kielbasa, Szymon M. and Korbel, Jan O. and Kozlov, Alexey M. and Kuo, Tzu Hao and Lelieveldt, Boudewijn P.F. and Mandoiu, Ion I. and Marioni, John C. and Marschall, Tobias and M{\"{o}}lder, Felix and Niknejad, Amir and Raczkowski, Lukasz and Reinders, Marcel and de Ridder, Jeroen and Saliba, Antoine Emmanuel and Somarakis, Antonios and Stegle, Oliver and Theis, Fabian J. and Yang, Huan and Zelikovsky, Alex and McHardy, Alice C. and Raphael, Benjamin J. and Shah, Sohrab P. and Sch{\"{o}}nhuth, Alexander},
booktitle = {Genome Biology},
doi = {10.1186/s13059-020-1926-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/L{\"{a}}hnemann et al. - 2020 - Eleven grand challenges in single-cell data science.pdf:pdf},
isbn = {1305902019266},
issn = {1474760X},
keywords = {single cell},
mendeley-tags = {single cell},
number = {1},
pages = {1--35},
pmid = {32033589},
publisher = {Genome Biology},
title = {{Eleven grand challenges in single-cell data science}},
volume = {21},
year = {2020}
}
@article{Reshef2011,
abstract = {Identifying interesting relationships between pairs of variables in large data sets is increasingly important. Here, we present a measure of dependence for two-variable relationships: the maximal information coefficient (MIC). MIC captures a wide range of associations both functional and not, and for functional relationships provides a score that roughly equals the coefficient of determination (R 2) of the data relative to the regression function. MIC belongs to a larger class of maximal information-based nonparametric exploration (MINE) statistics for identifying and classifying relationships. We apply MIC and MINE to data sets in global health, gene expression, major-league baseball, and the human gut microbiota and identify known and novel relationships.},
author = {Reshef, David N and Reshef, Yakir A and Finucane, Hilary K and Grossman, Sharon R and Mcvean, Gilean and Turnbaugh, Peter J and Lander, Eric S and Mitzenmacher, Michael and Pardis, ‡ and Sabeti, C},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Reshef et al. - 2011 - Detecting Novel Associations in Large Data Sets.pdf:pdf},
journal = {Science},
keywords = {to-skim},
mendeley-tags = {to-skim},
pages = {1518--1524},
title = {{Detecting Novel Associations in Large Data Sets}},
url = {http://science.sciencemag.org/},
volume = {334},
year = {2011}
}
@article{WetR10,
abstract = {Epistasis could be an important source of risk for disease. How interacting loci might be discovered is an open question for genome-wide association studies (GWAS). Most researchers limit their statistical analyses to testing individual pairwise interactions (i.e., marginal tests for association). A more effective means of identifying important predictors is to fit models that include many predictors simultaneously (i.e., higher-dimensional models). We explore a procedure called screen and clean (SC) for identifying liability loci, including interactions, by using the lasso procedure, which is a model selection tool for high-dimensional regression. We approach the problem by using a varying dictionary consisting of terms to include in the model. In the first step the lasso dictionary includes only main effects. The most promising single-nucleotide polymorphisms (SNPs) are identified using a screening procedure. Next the lasso dictionary is adjusted to include these main effects and the corresponding interaction terms. Again, promising terms are identified using lasso screening. Then significant terms are identified through the cleaning process. Implementation of SC for GWAS requires algorithms to explore the complex model space induced by the many SNPs genotyped and their interactions. We propose and explore a set of algorithms and find that SC successfully controls Type I error while yielding good power to identify risk loci and their interactions. When the method is applied to data obtained from the Wellcome Trust Case Control Consortium study of Type 1 Diabetes it uncovers evidence supporting interaction within the HLA class II region as well as within Chromosome 12q24.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/20088021{\}}{\{}20088021{\}}},
author = {Wu, Jing and Devlin, Bernie and Ringquist, Steven and Trucco, Massimo and Roeder, Kathryn},
journal = {Genetic Epidemiology},
keywords = {GWAS,genetics,high-dimensional regression},
mendeley-tags = {GWAS,genetics,high-dimensional regression},
pages = {275--285},
title = {{Screen and Clean: a tool for Identifying Interactions in Genome-wide Association Studies}},
volume = {34},
year = {2010}
}
@article{Wang2018a,
abstract = {Despite progress in defining genetic risk for psychiatric disorders, their molecular mechanisms remain elusive. Addressing this, the PsychENCODE Consortium has generated a comprehensive online resource for the adult brain across 1866 individuals. The PsychENCODE resource contains {\~{}}79,000 brain-active enhancers, sets of Hi-C linkages, and topologically associating domains; single-cell expression profiles for many cell types; expression quantitative-trait loci (QTLs); and further QTLs associated with chromatin, splicing, and cell-type proportions. Integration shows that varying cell-type proportions largely account for the cross-population variation in expression (with {\textgreater}88{\%} reconstruction accuracy). It also allows building of a gene regulatory network, linking genome-wide association study variants to genes (e.g., 321 for schizophrenia). We embed this network into an interpretable deep-learning model, which improves disease prediction by {\~{}}6-fold versus polygenic risk scores and identifies key genes and pathways in psychiatric disorders.},
author = {Wang, Daifeng and Liu, Shuang and Warrell, Jonathan and Won, Hyejung and Shi, Xu and Navarro, Fabio C.P. and Clarke, Declan and Gu, Mengting and Emani, Prashant and Yang, Yucheng T. and Min, X. and Gandal, Michael J. and Lou, Shaoke and Zhang, Jing and Park, Jonathan J. and Yan, Chengfei and KyongRhie, Suhn and Manakongtreecheep, Kasidet and Zhou, Holly and {Aparna Natha}, A. and Peters, Mette and Mattei, Eugenio and Fitzgerald, Dominic and Brunetti, Tonya and Moore, Jill and Jiang, Yan and Girdhar, Kiran and Hoffman, Gabriel E. and Kalayci, Selim and G{\"{u}}m{\"{u}}ş, Zeynep H. and Crawford, Gregory E. and Roussos, Panos and Akbarian, Schahram and Jaffe, Andrew E. and White, Kevin P. and Weng, Zhiping and Sestan, Nenad and Geschwind, Daniel H. and Knowles, James A. and Gerstein, Mark B.},
doi = {10.1126/science.aat8464},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Wang et al. - 2018 - Comprehensive functional genomic resource and integrative model for the human brain.pdf:pdf},
issn = {10959203},
journal = {Science},
keywords = {HI-C,Kathryn,gene-enhancer,genetics},
mendeley-tags = {HI-C,Kathryn,gene-enhancer,genetics},
number = {6420},
title = {{Comprehensive functional genomic resource and integrative model for the human brain}},
volume = {362},
year = {2018}
}
@article{HL11,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21036813{\}}{\{}21036813{\}}},
author = {He, Q and Lin, D Y},
journal = {Bioinformatics},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
month = {jan},
number = {1},
pages = {1--8},
title = {{{\{}A{\}} variable selection method for genome-wide association studies}},
volume = {27},
year = {2011}
}
@article{B36,
author = {Bonferroni, C},
journal = {Pubblicazioni del R Istituto Superiore di Scienze Economiche e Commericiali di Firenze},
keywords = {Multiple testing,canonical},
mendeley-tags = {Multiple testing,canonical},
pages = {3--62},
title = {{Teoria statistica delle classi e calcolo delle probabilita}},
volume = {8},
year = {1936}
}
@article{lehmann2005generalizations,
author = {Lehmann, E L and Romano, J},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Lehmann, Romano - 2005 - Generalizations of the familywise error rate.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {FDX,FWER,Multiple testing,canonical},
mendeley-tags = {FDX,FWER,Multiple testing,canonical},
number = {3},
pages = {1138--1154},
title = {{Generalizations of the familywise error rate}},
volume = {33},
year = {2005}
}
@article{Bodapati2020,
abstract = {Genome-wide pooled CRISPR-Cas-mediated knockout, activation, and repression screens are powerful tools for functional genomic investigations. Despite their increasing importance, there is currently little guidance on how to design and analyze CRISPR-pooled screens. Here, we provide a review of the commonly used algorithms in the computational analysis of pooled CRISPR screens. We develop a comprehensive simulation framework to benchmark and compare the performance of these algorithms using both synthetic and real datasets. Our findings inform parameter choices of CRISPR screens and provide guidance to researchers on the design and analysis of pooled CRISPR screens.},
author = {Bodapati, Sunil and Daley, Timothy P. and Lin, Xueqiu and Zou, James and Qi, Lei S.},
doi = {10.1186/s13059-020-01972-x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Bodapati et al. - 2020 - A benchmark of algorithms for the analysis of pooled CRISPR screens.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Benchmarking,CRISPR,CRISPR activation,CRISPR interference,CRISPR knockoout,CRISPR screen,Screen algorithms,Simulation},
mendeley-tags = {CRISPR},
number = {1},
pages = {1--13},
pmid = {32151271},
publisher = {Genome Biology},
title = {{A benchmark of algorithms for the analysis of pooled CRISPR screens}},
volume = {21},
year = {2020}
}
@article{Rosenbaum2006,
abstract = {The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two-dimensional plot.},
author = {Rosenbaum, Paul R. and Rubin, Donald B.},
doi = {10.1017/CBO9780511810725.016},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Rosenbaum, Rubin - 1983 - The central role of the propensity score in observational studies for causal effects.pdf:pdf},
isbn = {9780511810725},
journal = {Biometrika},
keywords = {causality},
mendeley-tags = {causality},
number = {1},
pages = {41--55},
title = {{The central role of the propensity score in observational studies for causal effects}},
volume = {70},
year = {1983}
}
@article{Fernando2020,
abstract = {The genetic architecture of each individual comprises common and rare variants that, acting alone and in combination, confer risk of disease. The cell-type-specific and/or context-dependent functional consequences of the risk variants linked to brain disease must be resolved. Coupling human induced pluripotent stem cell (hiPSC)-based technology with CRISPR-based genome engineering facilitates precise isogenic comparisons of variants across genetic backgrounds. Although functional-validation studies are typically performed on one variant in isolation and in one cell type at a time, complex genetic diseases require multiplexed gene perturbations to interrogate combinations of genes and resolve physiologically relevant disease biology. Our aim is to discuss advances at the intersection of genomics, hiPSCs and CRISPR. A better understanding of the molecular mechanisms underlying disease risk will improve genetic diagnosis, drive phenotypic drug discovery and pave the way toward precision medicine.},
author = {Fernando, Michael B. and Ahfeldt, Tim and Brennand, Kristen J.},
doi = {10.1038/s41588-020-0596-3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Fernando, Ahfeldt, Brennand - 2020 - Modeling the complex genetic architectures of brain disease.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {CRISPR,GWAS,to-read},
mendeley-tags = {CRISPR,GWAS,to-read},
number = {4},
pages = {363--369},
pmid = {32203467},
publisher = {Springer US},
title = {{Modeling the complex genetic architectures of brain disease}},
url = {http://dx.doi.org/10.1038/s41588-020-0596-3},
volume = {52},
year = {2020}
}
@article{Xing2019,
abstract = {Simultaneously finding multiple influential variables and controlling the false discovery rate (FDR) for linear regression models is a fundamental problem with a long history. We here propose the Gaussian Mirror (GM) method, which creates for each predictor variable a pair of mirror variables by adding and subtracting a randomly generated Gaussian random variable, and proceeds with a certain regression method, such as the ordinary least-square or the Lasso. The mirror variables naturally lead to a test statistic highly effective for controlling the FDR. Under a weak dependence assumption, we show that the FDR can be controlled at a user-specified level asymptotically. It is shown that the GM method is more powerful than many existing methods in selecting important variables, subject to the control of FDR especially under the case when high correlations among the covariates exist.},
archivePrefix = {arXiv},
arxivId = {1911.09761},
author = {Xing, Xin and Zhao, Zhigen and Liu, Jun S.},
eprint = {1911.09761},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Xing, Zhao, Liu - 2019 - Controlling False Discovery Rate Using Gaussian Mirrors.pdf:pdf},
pages = {1--36},
title = {{Controlling False Discovery Rate Using Gaussian Mirrors}},
url = {http://arxiv.org/abs/1911.09761},
year = {2019}
}
@article{SetB07F,
abstract = {Identifying the genetic variants that increase the risk of type 2 diabetes (T2D) in humans has been a formidable challenge. Adopting a genome-wide association strategy, we genotyped 1161 Finnish T2D cases and 1174 Finnish normal glucose-tolerant (NGT) controls with $\backslash$mbox{\{}{\$}{\textless}{\$}{\}}315,000 single-nucleotide polymorphisms (SNPs) and imputed genotypes for an additional $\backslash$mbox{\{}{\$}{\textless}{\$}{\}}2 million autosomal SNPs. We carried out association analysis with these SNPs to identify genetic variants that predispose to T2D, compared our T2D association results with the results of two similar studies, and genotyped 80 SNPs in an additional 1215 Finnish T2D cases and 1258 Finnish NGT controls. We identify T2D-associated variants in an intergenic region of chromosome 11p12, contribute to the identification of T2D-associated variants near the genes IGF2BP2 and CDKAL1 and the region of CDKN2A and CDKN2B, and confirm that variants near TCF7L2, SLC30A8, HHEX, FTO, PPARG, and KCNJ11 are associated with T2D risk. This brings the number of T2D loci now confidently identified to at least 10.},
annote = {17463248},
author = {Scott, Laura J and Mohlke, Karen L and Bonnycastle, Lori L and Willer, Cristen J and Li, Yun and Duren, William L and Erdos, Michael R and Stringham, Heather M and Chines, Peter S and Jackson, Anne U and Prokunina-Olsson, Ludmila and Ding, Chia-Jen and Swift, Amy J and Narisu, Narisu and Hu, Tianle and Pruim, Randall and Xiao, Rui and Li, Xiao-Yi and Conneely, Karen N and Riebow, Nancy L and Sprau, Andrew G and Tong, Maurine and White, Peggy P and Hetrick, Kurt N and Barnhart, Michael W and Bark, Craig W and Goldstein, Janet L and Watkins, Lee and Xiang, Fang and Saramies, Jouko and Buchanan, Thomas A and Watanabe, Richard M and Valle, Timo T and Kinnunen, Leena and Abecasis, Gon{\c{c}}alo R and Pugh, Elizabeth W and Doheny, Kimberly F and Bergman, Richard N and Tuomilehto, Jaakko and Collins, Francis S and Boehnke, Michael},
journal = {Science},
pages = {1341--1345},
title = {{{\{}A{\}} Genome-wide Association Study of type 2 Diabetes in {\{}Finns{\}} Detects Multiple Susceptibility Variants}},
volume = {316},
year = {2007}
}
@article{PetW04,
author = {{Perone Pacifico}, Marco and Genovese, Christopher and Verdinelli, Isabella and Wasserman, Larry},
doi = {10.1198/0162145000001655},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Perone Pacifico et al. - 2004 - False discovery control for random fields.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {FDR,Multiple testing,simultaneous inference,spatial data},
mendeley-tags = {FDR,Multiple testing,simultaneous inference,spatial data},
number = {468},
pages = {1002--1014},
title = {{False discovery control for random fields}},
url = {http://dx.doi.org/10.1198/0162145000001655},
volume = {99},
year = {2004}
}
@article{Bachoc2016,
author = {Bachoc, F. and Preinerstorfer, D. and Steinberger, L.},
journal = {arXiv},
title = {{Uniformly valid confidence intervals post-model-selection}},
year = {2016}
}
@article{Zhang2020,
author = {Zhang, Lu and Janson, Lucas},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Zhang, Janson - 2020 - Floodgate inference for model-free variable importance.pdf:pdf},
journal = {arXiv},
keywords = {confidence intervals,effect size,heritability,heterogeneous treatment effects,high-dimensional regression,model-X,model-x,variable importance},
mendeley-tags = {confidence intervals,high-dimensional regression,model-X},
pages = {1--67},
title = {{Floodgate : inference for model-free variable importance}},
year = {2020}
}
@article{Rebafka2019,
abstract = {In this paper, a noisy version of the stochastic block model (NSBM) is introduced and we investigate the three following statistical inferences in this model: estimation of the model parameters, clustering of the nodes and identification of the underlying graph. While the two first inferences are done by using a variational expectation-maximization (VEM) algorithm, the graph inference is done by controlling the false discovery rate (FDR), that is, the average proportion of errors among the edges declared significant, and by maximizing the true discovery rate (TDR), that is, the average proportion of edges declared significant among the true edges. Provided that the VEM algorithm provides reliable parameter estimates and clustering, we theoretically show that our procedure does control the FDR while satisfying an optimal TDR property, up to remainder terms that become small when the size of the graph grows. Numerical experiments show that our method outperforms the classical FDR controlling methods that ignore the underlying SBM topology. In addition, these simulations demonstrate that the FDR/TDR properties of our method are robust to model mis-specification, that is, are essentially maintained outside our model.},
archivePrefix = {arXiv},
arxivId = {1907.10176},
author = {Rebafka, Tabea and Roquain, Etienne and Villers, Fanny},
eprint = {1907.10176},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Rebafka, Roquain, Villers - 2019 - Graph inference with clustering and false discovery rate control.pdf:pdf},
journal = {arXiv},
keywords = {and phrases,false discovery rate,graph inference,multiple testing,q -value,stochastic block model},
title = {{Graph inference with clustering and false discovery rate control}},
url = {http://arxiv.org/abs/1907.10176},
year = {2019}
}
@article{Kasy2019,
abstract = {When are asymptotic approximations using the delta-method uniformly valid? We provide sufficient conditions as well as closely related necessary conditions for uniform negligibility of the remainder of such approximations. These conditions are easily verified by empirical practitioners and permit to identify settings and parameter regions where pointwise asymptotic approximations perform poorly. Our framework allows for a unified and transparent discussion of uniformity issues in various sub-fields of statistics and econometrics. Our conditions involve uniform bounds on the remainder of a first-order approximation for the function of interest.},
archivePrefix = {arXiv},
arxivId = {1507.05731},
author = {Kasy, Maximilian},
doi = {10.1515/jem-2018-0001},
eprint = {1507.05731},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Econometric Methods/Kasy - 2019 - Uniformity and the Delta Method.pdf:pdf},
issn = {21566674},
journal = {Journal of Econometric Methods},
keywords = {asymptotic theory,delta method,uniformity},
title = {{Uniformity and the Delta Method}},
year = {2019}
}
@article{Wang2013,
abstract = {Cell type-specific gene expression in humans involves complex interactions between regulatory factors and DNA at enhancers and promoters. Mapping studies for expression quantitative trait loci (eQTLs), transcription factors (TFs) and chromatin markers have become widely used tools for identifying gene regulatory elements, but prediction of target genes remains a major challenge. Here, we integrate genome-wide data on TF-binding sites, chromatin markers and functional annotations to predict genes associated with human eQTLs. Using the random forest classifier, we found that genomic proximity plus five TF and chromatin features are able to predict {\textgreater}90{\%} of target genes within 1 megabase of eQTLs. Despite being regularly used to map target genes, proximity is not a good indicator of eQTL targets for genes 150 kilobases away, but insulators, TF co-occurrence, open chromatin and functional similarities between TFs and genes are better indicators. Using all six features in the classifier achieved an area under the specificity and sensitivity curve of 0.91, much better compared with at most 0.75 for using any single feature. We hope this study will not only provide validation of eQTL-mapping studies, but also provide insight into the molecular mechanisms explaining how genetic variation can influence gene expression. {\textcopyright} 2012 The Author(s) 2012. Published by Oxford University Press.},
author = {Wang, Dennis and Rendon, Augusto and Wernisch, Lorenz},
doi = {10.1093/nar/gks1339},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nucleic Acids Research/Wang, Rendon, Wernisch - 2013 - Transcription factor and chromatin features predict genes associated with eQTLs.pdf:pdf},
issn = {03051048},
journal = {Nucleic Acids Research},
keywords = {Kathryn,eQTL,epigenetics,gene-enhancer},
mendeley-tags = {Kathryn,eQTL,epigenetics,gene-enhancer},
number = {3},
pages = {1450--1463},
title = {{Transcription factor and chromatin features predict genes associated with eQTLs}},
volume = {41},
year = {2013}
}
@article{CHX11,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21615941{\}}{\{}21615941{\}}},
author = {Cai, X and Huang, A and Xu, S},
journal = {BMC Bioinformatics},
keywords = {Lasso,genetics,high-dimensional regression},
mendeley-tags = {Lasso,genetics,high-dimensional regression},
pages = {211},
title = {{{\{}F{\}}ast empirical {\{}B{\}}ayesian {\{}L{\}}{\{}A{\}}{\{}S{\}}{\{}S{\}}{\{}O{\}} for multiple quantitative trait locus mapping}},
volume = {12},
year = {2011}
}
@article{Wang2017,
abstract = {We consider large-scale studies in which thousands of significance tests are performed simultaneously. In some of these studies, the multiple testing procedure can be severely biased by latent confounding factors such as batch effects and unmeasured covariates that correlate with both primary vari-able(s) of interest (e.g., treatment variable, phenotype) and the outcome. Over the past decade, many statistical methods have been proposed to adjust for the confounders in hypothesis testing. We unify these methods in the same framework, generalize them to include multiple primary variables and multiple nuisance variables, and analyze their statistical properties. In particular, we provide theoretical guarantees for RUV-4 [Gagnon-Bartsch, Jacob and Speed (2013)] and LEAPP [Ann. Appl. Stat. 6 (2012) 1664-1688], which correspond to two different identification conditions in the framework: the first requires a set of "negative controls" that are known a priori to follow the null distribution; the second requires the true nonnulls to be sparse. Two different estimators which are based on RUV-4 and LEAPP are then applied to these two scenarios. We show that if the confounding factors are strong, the resulting estimators can be asymptotically as powerful as the oracle es-timator which observes the latent confounding factors. For hypothesis testing , we show the asymptotic z-tests based on the estimators can control the type I error. Numerical experiments show that the false discovery rate is also controlled by the Benjamini-Hochberg procedure when the sample size is reasonably large.},
author = {Wang, Jingshu and Zhao, Qingyuan and Hastie, Trevor and Owen, Art B},
doi = {10.1214/16-AOS1511},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Wang et al. - 2017 - CONFOUNDER ADJUSTMENT IN MULTIPLE HYPOTHESIS TESTING.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {62H25,62J15,Empirical null,batch effect,confounder adjustment,robust regression,surrogate variable analysis,to-skim,unwanted variation},
mendeley-tags = {confounder adjustment,to-skim},
number = {5},
pages = {1863--1894},
title = {{CONFOUNDER ADJUSTMENT IN MULTIPLE HYPOTHESIS TESTING}},
volume = {45},
year = {2017}
}
@inproceedings{RYWJ17,
author = {Ramdas, A and Yang, F and Wainwright, M J and Jordan, M I},
booktitle = {Advances In Neural Information Processing Systems},
keywords = {FDR,Multiple testing,online multiple testing},
mendeley-tags = {FDR,Multiple testing,online multiple testing},
title = {{Online control of the false discovery rate with decaying memory}},
year = {2017}
}
@article{Editorial2013,
annote = {doi:10.1038/496398a},
author = {Editorial},
journal = {Nature},
keywords = {reproducibility},
mendeley-tags = {reproducibility},
month = {apr},
pages = {398},
title = {{{\{}R{\}}educing our irreproducibility}},
volume = {496},
year = {2013}
}
@article{Yu2019b,
author = {Yu, Ruoqi and Rosenbaum, Paul R},
doi = {10.1111/biom.13098},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrics/Yu, Rosenbaum - 2019 - Directional penalties for optimal matching in observational studies.pdf:pdf},
journal = {Biometrics},
keywords = {causality,fine balance,lagrangian relaxation,matching,observational studies,observational study,propensity score},
mendeley-tags = {causality,matching,observational studies},
pages = {1380--1390},
title = {{Directional penalties for optimal matching in observational studies}},
volume = {75},
year = {2019}
}
@article{Chia2020,
author = {Chia, Charmaine and Sesia, Matteo and Ho, Chi-sing and Jeffrey, Stefanie S and Dionne, Jennifer and Cand{\`{e}}s, Emmanuel and Howe, Roger T},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Chia et al. - 2020 - Interpretable Signal Analysis with Knockoffs Enhances Classification of Bacterial Raman Spectra.pdf:pdf},
journal = {arXiv},
keywords = {applied,knockoffs},
mendeley-tags = {applied,knockoffs},
title = {{Interpretable Signal Analysis with Knockoffs Enhances Classification of Bacterial Raman Spectra}},
year = {2020}
}
@article{genovese2006false,
author = {Genovese, C and Roeder, K and Wasserman, L},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Genovese, Roeder, Wasserman - 2006 - False discovery control with p-value weighting.pdf:pdf},
journal = {Biometrika},
keywords = {FDR,Multiple testing,weighted multiple testing},
mendeley-tags = {FDR,Multiple testing,weighted multiple testing},
number = {3},
pages = {509--524},
publisher = {Biometrika Trust},
title = {{False discovery control with p-value weighting}},
volume = {93},
year = {2006}
}
@article{Weinstein2019,
abstract = {The false coverage rate (FCR) is the expected ratio of number of constructed confidence intervals (CIs) that fail to cover their respective parameters to the total number of constructed CIs. Procedures for FCR control exist in the offline setting, but none so far have been designed with the online setting in mind. In the online setting, there is an infinite sequence of fixed unknown parameters $\theta$t ordered by time. At each step, we see independent data that is informative about $\theta$t, and must immediately make a decision whether to report a CI for $\theta$t or not. If $\theta$t is selected for coverage, the task is to determine how to construct a CI for $\theta$t such that FCR ≤ $\alpha$ for any T ∈ N. A straightforward solution is to construct at each step a (1 − $\alpha$) level conditional CI. In this paper, we present a novel solution to the problem inspired by online false discovery rate (FDR) algorithms , which only requires the statistician to be able to construct a marginal CI at any given level. Apart from the fact that marginal CIs are usually simpler to construct than conditional ones, the marginal procedure has an important qualitative advantage over the conditional solution, namely, it allows selection to be determined by the candidate CI itself. We take advantage of this to offer solutions to some online problems which have not been addressed before. For example, we show that our general CI procedure can be used to devise online sign-classification procedures that control the false sign rate (FSR). In terms of power and length of the constructed CIs, we demonstrate that the two approaches have complementary strengths and weaknesses using simulations. Last, all of our methodology applies equally well to online FCR control for prediction intervals, having particular implications for assumption-free selective conformal inference.},
archivePrefix = {arXiv},
arxivId = {1905.01059v1},
author = {Weinstein, Asaf and Ramdas, Aaditya},
eprint = {1905.01059v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Weinstein, Ramdas - 2019 - Online Control of the False Coverage Rate and False Sign Rate.pdf:pdf},
isbn = {1905.01059v1},
journal = {arXiv},
keywords = {Multiple testing,confidence intervals,false coverage rate,online multiple testing,to-read},
mendeley-tags = {Multiple testing,confidence intervals,false coverage rate,online multiple testing,to-read},
title = {{Online Control of the False Coverage Rate and False Sign Rate}},
year = {2019}
}
@article{BCI10,
abstract = {Second-generation sequencing (sec-gen) technology can sequence millions of short fragments of DNA in parallel, making it capable of assembling complex genomes for a small fraction of the price and time of previous technologies. In fact, a recently formed international consortium, the 1000 Genomes Project, plans to fully sequence the genomes of approximately 1200 people. The prospect of comparative analysis at the sequence level of a large number of samples across multiple populations may be achieved within the next five years. These data present unprecedented challenges in statistical analysis. For instance, analysis operates on millions of short nucleotide sequences, or reads-strings of A,C,G, or T's, between 30 and 100 characters long-which are the result of complex processing of noisy continuous fluorescence intensity measurements known as base-calling. The complexity of the base-calling discretization process results in reads of widely varying quality within and across sequence samples. This variation in processing quality results in infrequent but systematic errors that we have found to mislead downstream analysis of the discretized sequence read data. For instance, a central goal of the 1000 Genomes Project is to quantify across-sample variation at the single nucleotide level. At this resolution, small error rates in sequencing prove significant, especially for rare variants. Sec-gen sequencing is a relatively new technology for which potential biases and sources of obscuring variation are not yet fully understood. Therefore, modeling and quantifying the uncertainty inherent in the generation of sequence reads is of utmost importance. In this article, we present a simple model to capture uncertainty arising in the base-calling procedure of the Illumina/Solexa GA platform. Model parameters have a straightforward interpretation in terms of the chemistry of base-calling allowing for informative and easily interpretable metrics that capture the variability in sequencing quality. Our model provides these informative estimates readily usable in quality assessment tools while significantly improving base-calling performance.},
annote = {19912177},
author = {Bravo, H{\'{e}}ctor Corrada and Irizarry, Rafael A},
journal = {Biometrics},
pages = {665--674},
title = {{{\{}Model-based{\}} Quality Assessment and Base-calling for Second-generation Sequencing data}},
volume = {66},
year = {2010}
}
@article{Walton2019,
abstract = {The recent focus on the role of epigenetic mechanisms in mental health has led to several studies examining the association of epigenetic processes with psychiatric conditions and neurodevelopmental traits. Some studies suggest that epigenetic changes might be causal in the development of the psychiatric condition under investigation. However, other scenarios are possible, e.g., statistical confounding or reverse causation, making it particularly challenging to derive conclusions on causality. In the present review, we examine the evidence from human population studies for a possible role of epigenetic mechanisms in neurodevelopment and mental health and discuss methodological approaches on how to strengthen causal inference, including the need for replication, (quasi-)experimental approaches and Mendelian randomization. We signpost openly accessible resources (e.g., “MR-Base” “EWAS catalog” as well as tissue-specific methylation and gene expression databases) to aid the application of these approaches.},
author = {Walton, Esther and Relton, Caroline L. and Caramaschi, Doretta},
doi = {10.3390/genes10030193},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genes/Walton, Relton, Caramaschi - 2019 - Using openly accessible resources to strengthen causal inference in epigenetic epidemiology of neuro.pdf:pdf},
issn = {20734425},
journal = {Genes},
keywords = {Causal inference,DNA methylation,Epigenetics,Mendelian randomization,Mental health,Neurodevelopment},
number = {3},
title = {{Using openly accessible resources to strengthen causal inference in epigenetic epidemiology of neurodevelopment and mental health}},
volume = {10},
year = {2019}
}
@article{PetS13,
author = {Pirinen, Matti and Donnelly, Peter and Spencer, Chris C A},
doi = {10.1214/12-AOAS586},
issn = {1932-6157},
journal = {The Annals of Applied Statistics},
keywords = {genetics,linear mixed models},
mendeley-tags = {genetics,linear mixed models},
number = {1},
pages = {369--390},
title = {{Efficient computation with a linear mixed model on large-scale data sets with applications to genetic studies}},
url = {http://dx.doi.org/10.1214/12-AOAS586},
volume = {7},
year = {2013}
}
@article{GHS19,
author = {Goeman, Jelle and Hemerik, Jesse and Solari, Aldo},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Goeman, Hemerik, Solari - 2019 - Only Closed Testing Procedures are Admissible for Controlling False Discovery Proportions.pdf:pdf},
journal = {arXiv},
keywords = {Multiple testing,closed testing,simultaneous inference,unpublished},
mendeley-tags = {Multiple testing,closed testing,simultaneous inference,unpublished},
title = {{Only Closed Testing Procedures are Admissible for Controlling False Discovery Proportions}},
year = {2019}
}
@article{Thormann2018,
abstract = {Genomic binding of transcription factors, like the glucocorticoid receptor (GR), is linked to the regulation of genes. However, as we show here, GR binding is a poor predictor of GR-dependent gene regulation even when taking the 3D organization of the genome into account. To connect GR binding sites to the regulation of genes in the endogenous genomic context, we turned to genome editing. By deleting GR binding sites, individually or in combination, we uncovered how cooperative interactions between binding sites contribute to the regulation of genes. Specifically, for the GR target gene GILZ, we show that the simultaneous presence of a cluster of GR binding sites is required for the activity of an individual enhancer and that the GR-dependent regulation of GILZ depends on multiple GR-bound enhancers. Further, by deleting GR binding sites that are shared between different cell types, we show how cell type-specific genome organization and enhancer-blocking can result in cell type-specific wiring of promoter-enhancer contacts. This rewiring allows an individual GR binding site shared between different cell types to direct the expression of distinct transcripts and thereby contributes to the cell type-specific consequences of glucocorticoid signaling.},
author = {Thormann, Verena and Rothkegel, Maika C. and Sch{\"{o}}pflin, Robert and Glaser, Laura V. and Djuric, Petar and Li, Na and Chung, Ho Ryun and Schwahn, Kevin and Vingron, Martin and Meijsing, Sebastiaan H.},
doi = {10.1093/nar/gky051},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nucleic Acids Research/Thormann et al. - 2018 - Genomic dissection of enhancers uncovers principles of combinatorial regulation and cell type-specific wiring o.pdf:pdf},
issn = {13624962},
journal = {Nucleic Acids Research},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {6},
pages = {2868--2882},
title = {{Genomic dissection of enhancers uncovers principles of combinatorial regulation and cell type-specific wiring of enhancer-promoter contacts}},
url = {https://academic.oup.com/nar/article-abstract/46/6/2868/4827090},
volume = {46},
year = {2018}
}
@article{FRTB,
author = {Frommlet, F and Ruhaltinger, F and Twar{\'{o}}g, P and Bogdan, M},
journal = {Computational Statistics and Data Analysis},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
number = {56},
pages = {1038--1051},
title = {{A model selection approach to genome wide association studies}},
year = {2012}
}
@book{Weak_Convergence_Book,
abstract = {This book explores weak convergence theory and empirical processes and their applications to many applications in statistics. Part one reviews stochastic convergence in its various forms. Part two offers the theory of empirical processes in a form accessible to statisticians and probabilists. Part three covers a range of topics demonstrating the applicability of the theory to key questions such as measures of goodness of fit and the bootstrap.},
address = {New York},
author = {{Van der Vaart}, Aad W. and Wellner, Jon A.},
doi = {10.2307/2965734},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Van der Vaart, Wellner - 1996 - Weak Convergence and Empirical Processes.pdf:pdf},
isbn = {9781475725476},
issn = {01621459},
publisher = {Springer-Verlag},
title = {{Weak Convergence and Empirical Processes}},
year = {1996}
}
@article{Duan2019,
abstract = {Global null testing is a classical problem going back about a century to Fisher's and Stouffer's combination tests. In this work, we present simple martingale analogs of these classical tests, which are applicable in two distinct settings: (a) the online setting in which there is a possibly infinite sequence of {\$}p{\$}-values, and (b) the batch setting, where one uses prior knowledge to preorder the hypotheses. Through theory and simulations, we demonstrate that our martingale variants have higher power than their classical counterparts even when the preordering is only weakly informative. Finally, using a recent idea of "masking" {\$}p{\$}-values, we develop a novel interactive test for the global null that can take advantage of covariates and repeated user guidance to create a data-adaptive ordering that achieves higher detection power against structured alternatives.},
archivePrefix = {arXiv},
arxivId = {1909.07339},
author = {Duan, Boyan and Ramdas, Aaditya and Balakrishnan, Sivaraman and Wasserman, Larry},
eprint = {1909.07339},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Duan et al. - 2019 - Interactive Martingale Tests for the Global Null.pdf:pdf},
journal = {arXiv},
keywords = {Multiple testing,structured multiple testing},
mendeley-tags = {Multiple testing,structured multiple testing},
title = {{Interactive Martingale Tests for the Global Null}},
url = {http://arxiv.org/abs/1909.07339},
year = {2019}
}
@article{SS16,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26680660{\}}{\{}26680660{\}}},
author = {Stell, L and Sabatti, C},
journal = {Genetics},
keywords = {genetics,multiple phenotypes},
mendeley-tags = {genetics,multiple phenotypes},
month = {feb},
number = {2},
pages = {439--455},
title = {{{\{}G{\}}enetic {\{}V{\}}ariant {\{}S{\}}election: {\{}L{\}}earning {\{}A{\}}cross {\{}T{\}}raits and {\{}S{\}}ites}},
volume = {202},
year = {2016}
}
@article{genovese2004stochastic,
author = {Genovese, C and Wasserman, L},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Genovese, Wasserman - 2004 - A stochastic process approach to false discovery control.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {FDR,Multiple testing,simultaneous inference},
mendeley-tags = {FDR,Multiple testing,simultaneous inference},
pages = {1035--1061},
publisher = {JSTOR},
title = {{A stochastic process approach to false discovery control}},
year = {2004}
}
@article{Wei2014,
abstract = {Understanding the functional relevance of DNA variants is essential for all exome and genome sequencing projects. However, current mutagenesis cloning protocols require Sanger sequencing, and thus are prohibitively costly and labor-intensive. We describe a massively-parallel site-directed mutagenesis approach, "Clone-seq", leveraging next-generation sequencing to rapidly and cost-effectively generate a large number of mutant alleles. Using Clone-seq, we further develop a comparative interactome-scanning pipeline integrating high-throughput GFP, yeast two-hybrid (Y2H), and mass spectrometry assays to systematically evaluate the functional impact of mutations on protein stability and interactions. We use this pipeline to show that disease mutations on protein-protein interaction interfaces are significantly more likely than those away from interfaces to disrupt corresponding interactions. We also find that mutation pairs with similar molecular phenotypes in terms of both protein stability and interactions are significantly more likely to cause the same disease than those with different molecular phenotypes, validating the in vivo biological relevance of our high-throughput GFP and Y2H assays, and indicating that both assays can be used to determine candidate disease mutations in the future. The general scheme of our experimental pipeline can be readily expanded to other types of interactome-mapping methods to comprehensively evaluate the functional relevance of all DNA variants, including those in non-coding regions.},
author = {Wei, Xiaomu and Das, Jishnu and Fragoza, Robert and Liang, Jin and {Bastos de Oliveira}, Francisco M. and Lee, Hao Ran and Wang, Xiujuan and Mort, Matthew and Stenson, Peter D. and Cooper, David N. and Lipkin, Steven M. and Smolka, Marcus B. and Yu, Haiyuan},
doi = {10.1371/journal.pgen.1004819},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/PLoS Genetics/Wei et al. - 2014 - A Massively Parallel Pipeline to Clone DNA Variants and Examine Molecular Phenotypes of Human Disease Mutations.pdf:pdf},
issn = {15537404},
journal = {PLoS Genetics},
keywords = {Kathryn},
mendeley-tags = {Kathryn},
number = {12},
title = {{A Massively Parallel Pipeline to Clone DNA Variants and Examine Molecular Phenotypes of Human Disease Mutations}},
volume = {10},
year = {2014}
}
@article{Wellner1978,
author = {Wellner, Jon},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Zeitschrift f{\"{u}}r Wahrscheinlichkeitstheorie und verwandte Gebiete/Wellner - 1978 - Limit theorems for the ratio of the empirical distribution function to the true distribution function.pdf:pdf},
journal = {Zeitschrift f{\"{u}}r Wahrscheinlichkeitstheorie und verwandte Gebiete},
keywords = {empirical process},
mendeley-tags = {empirical process},
number = {1},
pages = {73--88},
title = {{Limit theorems for the ratio of the empirical distribution function to the true distribution function}},
volume = {45},
year = {1978}
}
@article{BenZouari2019,
abstract = {Capture Hi-C (CHi-C) is a new technique for assessing genome organization based on chromosome conformation capture coupled to oligonucleotide capture of regions of interest, such as gene promoters. Chromatin loop detection is challenging because existing Hi-C/4C-like tools, which make different assumptions about the technical biases presented, are often unsuitable. We describe a new approach, ChiCMaxima, which uses local maxima combined with limited filtering to detect DNA looping interactions, integrating information from biological replicates. ChiCMaxima shows more stringency and robustness compared to previously developed tools. The tool includes a GUI browser for flexible visualization of CHi-C profiles alongside epigenomic tracks.},
author = {{Ben Zouari}, Yousra and Molitor, Anne M. and Sikorska, Natalia and Pancaldi, Vera and Sexton, Tom},
doi = {10.1186/s13059-019-1706-3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Ben Zouari et al. - 2019 - ChiCMaxima A robust and simple pipeline for detection and visualization of chromatin looping in Capture Hi-C.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Biological replicates,Capture Hi-C,Chromatin assortativity,Chromatin loops,Gene regulation,HI-C,Kathryn,Promoter-enhancer interactions,gene-enhancer,genetics},
mendeley-tags = {HI-C,Kathryn,gene-enhancer,genetics},
number = {1},
pages = {1--19},
publisher = {Genome Biology},
title = {{ChiCMaxima: A robust and simple pipeline for detection and visualization of chromatin looping in Capture Hi-C}},
volume = {20},
year = {2019}
}
@article{BH97,
author = {Benjamini, Yoav and Hochberg, Yosef},
doi = {10.1111/1467-9469.00072},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Scandinavian Journal of Statistics/Benjamini, Hochberg - 1997 - Multiple hypotheses testing with weights.pdf:pdf},
issn = {0303-6898},
journal = {Scandinavian Journal of Statistics},
keywords = {FDR,Multiple testing,weighted multiple testing},
mendeley-tags = {FDR,Multiple testing,weighted multiple testing},
number = {3},
pages = {407--418},
title = {{Multiple hypotheses testing with weights}},
url = {http://dx.doi.org/10.1111/1467-9469.00072},
volume = {24},
year = {1997}
}
@article{Li2011,
abstract = {We describe a novel approach to nonparametric point and interval estimation of a treatment effect in the presence of many continuous confounders. We show that the problem can be reduced to that of point and interval estimation of the expected conditional covariance between treatment and response given the confounders. Our estimators are higher order U-statistics. The approach applies equally to the regular case where the expected conditional covariance is root-n estimable and to the irregular case where slower nonparametric rates prevail.},
author = {Li, Lingling and {Tchetgen Tchetgen}, Eric and van der Vaart, Aad and Robins, James M.},
doi = {10.1016/j.spl.2011.02.030},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics and Probability Letters/Li et al. - 2011 - Higher order inference on a treatment effect under low regularity conditions.pdf:pdf},
issn = {01677152},
journal = {Statistics and Probability Letters},
keywords = {Influence functions,Minimax,Nonparametric,Semiparametric,U-statistics,causality},
mendeley-tags = {causality},
number = {7},
pages = {821--828},
title = {{Higher order inference on a treatment effect under low regularity conditions}},
volume = {81},
year = {2011}
}
@article{Hochberg1994,
author = {Hochberg, Y and Liberman, U},
journal = {Statistics {\&} Probability Letters},
keywords = {canonical,multiple testing},
mendeley-tags = {canonical,multiple testing},
number = {2},
pages = {101--105},
title = {{An extended Simes' test}},
volume = {21},
year = {1994}
}
@techreport{ICDA2020,
title = {{International Common Disease Alliance Recommendations and White Paper}},
year = {2020}
}
@article{Liscovitch-Brauer2020,
author = {Liscovitch-Brauer, Noa and Montalbano, Antonino and Deng, Jiale and Mendez-Mancilla, Alejandro and Wessels, Hans-Hermann and Moss, Nicholas G. and Kung, Chia-Yu and Sookdeo, Akash and Guo, Xinyi and Geller, Evan and Jaini, Suma and Smibert, Peter and Sanjana, Neville E.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Liscovitch-Brauer et al. - 2020 - Scalable pooled CRISPR screens with single-cell chromatin accessibility profiling.pdf:pdf},
journal = {bioRxiv},
keywords = {10,11,1101,20,2020,390971,CRISPR,all rights reserved,atac-seq,biorxiv preprint doi,by peer review,chromatin,crispr-sciatac,doi,functional genomics,funder,https,is the author,multi-omics,no reuse allowed without,org,permission,pooled crispr screens,sequencing,single cell,single-cell,the copyright holder for,this preprint,this version posted november,which was not certified},
mendeley-tags = {CRISPR,multi-omics,single cell},
title = {{Scalable pooled CRISPR screens with single-cell chromatin accessibility profiling}},
year = {2020}
}
@article{Bates2019,
abstract = {Model-X knockoffs is a wrapper that transforms essentially any feature importance measure into a variable selection algorithm, which discovers true effects while rigorously controlling the expected fraction of false positives. A frequently discussed challenge to apply this method is to construct knockoff variables, which are synthetic variables obeying a crucial exchangeabil-ity property with the explanatory variables under study. This paper introduces techniques for knockoff generation in great generality: we provide a sequential characterization of all possible knockoff distributions, which leads to a Metropolis-Hastings formulation of an exact knockoff sampler. We further show how to use conditional independence structure to speed up computations. Combining these two threads, we introduce an explicit set of sequential algorithms and empirically demonstrate their effectiveness. Our theoretical analysis proves that our algorithms achieve near-optimal computational complexity in certain cases. The techniques we develop are sufficiently rich to enable knockoff sampling in challenging models including cases where the covariates are continuous and heavy-tailed, and follow a graphical model such as the Ising model.},
archivePrefix = {arXiv},
arxivId = {1903.00434v1},
author = {Bates, Stephen and Cand{\`{e}}s, Emmanuel and Janson, Lucas and Wang, Wenshuo},
eprint = {1903.00434v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Bates et al. - 2020 - Metropolized Knockoff Sampling.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {FDR,False discovery rate (FDR),Ising model,Markov chain,Metropolis-Hastings,Multiple testing,graphical models,junction tree,knockoffs,model-X,to-skim,treewidth},
mendeley-tags = {FDR,Multiple testing,knockoffs,model-X,to-skim},
title = {{Metropolized Knockoff Sampling}},
year = {2020}
}
@article{LZ09,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/19051285{\}}{\{}19051285{\}}},
author = {Lin, D Y and Zeng, D},
journal = {Genetic Epidemiology},
month = {apr},
number = {3},
pages = {256--265},
title = {{{\{}P{\}}roper analysis of secondary phenotype data in case-control association studies}},
volume = {33},
year = {2009}
}
@article{BetN15,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26414676{\}}{\{}26414676{\}}},
author = {Bulik-Sullivan, B and Finucane, H K and Anttila, V and Gusev, A and Day, F R and Loh, P R and Duncan, L and Perry, J R and Patterson, N and Robinson, E B and Daly, M J and Price, A L and Neale, B M},
journal = {Nature Genetics},
keywords = {GWAS,multiple phenotypes},
mendeley-tags = {GWAS,multiple phenotypes},
month = {nov},
number = {11},
pages = {1236--1241},
title = {{{\{}A{\}}n atlas of genetic correlations across human diseases and traits}},
volume = {47},
year = {2015}
}
@article{Wang2019b,
abstract = {Modern statistical learning techniques have often emphasized prediction performance over interpretability, giving rise to "black box" models that may be difficult to understand, and to generalize to other settings. We conceptually divide a prediction model into interpretable and non-interpretable portions, as a means to produce models that are highly interpretable with little loss in performance. Implementation of the model is achieved by considering separability of the interpretable and non-interpretable portions, along with a doubly penalized procedure for model fitting. We specify conditions under which convergence of model estimation can be achieved via cyclic coordinate ascent, and the consistency of model estimation holds. We apply the methods to datasets for microbiome host trait prediction and a diabetes trait, and discuss practical tradeoff diagnostics to select models with high interpretability.},
archivePrefix = {arXiv},
arxivId = {1909.06263},
author = {Wang, Wenjia and Zhou, Yi-Hui},
eprint = {1909.06263},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Wang, Zhou - 2019 - A Double Penalty Model for Interpretability.pdf:pdf},
journal = {arXiv},
keywords = {double penalty model,high-dimensional regression,intepretable prediction,interpretability,partially linear model,separability,to-skim},
mendeley-tags = {high-dimensional regression,intepretable prediction,to-skim},
title = {{A Double Penalty Model for Interpretability}},
url = {http://arxiv.org/abs/1909.06263},
year = {2019}
}
@article{XSEDE,
address = {Los Alamitos, CA, USA},
author = {Towns, J and Cockerill, T and Dahan, M and Foster, I and Gaither, K and Grimshaw, A and Hazlewood, V and Lathrop, S and Lifka, D and Peterson, G D and Roskies, R and Scott, J and Wilkins-Diehr, N},
doi = {10.1109/MCSE.2014.80},
issn = {1558-366X},
journal = {Computing in Science {\&} Engineering},
keywords = {digital systems,knowledge discovery,materials engineering,scientific computing,supercomputers},
month = {sep},
number = {05},
pages = {62--74},
publisher = {IEEE Computer Society},
title = {{XSEDE: Accelerating Scientific Discovery}},
volume = {16},
year = {2014}
}
@article{Kennedy2017,
author = {Kennedy, Edward H and Ma, Zongming and Mchugh, Matthew D and Small, Dylan S},
doi = {10.1111/rssb.12212},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society, Series B (Methodological)/Kennedy et al. - 2017 - Non-parametric methods for doubly robust estimation of continuous treatment effects.pdf:pdf},
journal = {Journal of the Royal Statistical Society, Series B (Methodological)},
keywords = {causal inference,dose,efficient influence function,kernel smoothing,response,semiparametric estimation},
pages = {1229--1245},
title = {{Non-parametric methods for doubly robust estimation of continuous treatment effects}},
volume = {4},
year = {2017}
}
@article{Machulla2003,
abstract = {The expression of human leukocyte antigen (HLA) alleles plays an important role in the development and recurrence of benign and malignant diseases. Association of single HLA alleles or haplotypes with neoplastic processes has been investigated previously, and correlation between HLA and solid tumors, such as head and neck cancers or uterine cervical squamous epithelial lesions, were reported. However, there is no published data on the influence of the HLA system on the development of symptomatic cerebral meningioma, a mostly benign intracranial tumor of mesenchymal origin in adults. The present investigation is comparing the frequency of single HLA alleles and haplotypes in 81 adult Caucasian patients with symptomatic central nervous system meningiomas to that of 157 area- and race-matched healthy controls. Both standard serological and molecular genetic (PCR) techniques were used for HLA typing. Our results suggest an association between single HLA alleles and occurrence of clinically symptomatic meningioma. Patients with HLA.A*02 had a 2.5-fold increased risk of meningioma (P = 0.02), and those with HLA-DQB1*05 had a 1.8-fold increased risk of meningioma (P = 0.05). Conversely, HLA-A*01, -B*08, and -DRB*03 were associated with a 0.4-, 0.5-, and 0.5-fold, respectively, decreased risk of meningioma (P = 0.008, P = 0.05, and P = 0.04). Moreover, the occurrence rate of combinations and estimated haplotypes containing these HLA alleles was strikingly different in meningioma patients compared with controls: significantly increased for the haplotypes HLA-A*02:DRB1*04 (P = 0.02, relative risk = 2.5) and HLA-A*02:DRB1*04:DQB1*0302,DQB1*05 (P = 0.03, RR = 7.5), and significantly decreased for the haplotype HLA-A*01:B* 08:DRB1*03 (P = 0.01, relative risk = 0.2). In conclusion, these data suggest that some single HLA alleles and haplotypes may protect from or predispose to developing symptomatic central nervous system meningioma during adult life. These associations may be indicative of the involvement of the immune system in the host antitumor surveillance, recognition, and destruction of de novo arising human tumor cells.},
author = {Machulla, Helmut K.G. and Steinborn, Frank and Tschigrjai, Michail and Langner, J{\"{u}}rgen and Rainov, Nikolai G.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cancer Epidemiology Biomarkers and Prevention/Machulla et al. - 2003 - Meningioma Is There an Association with Human Leukocyte Antigens.pdf:pdf},
issn = {10559965},
journal = {Cancer Epidemiology Biomarkers and Prevention},
number = {12},
pages = {1438--1442},
title = {{Meningioma: Is There an Association with Human Leukocyte Antigens?}},
volume = {12},
year = {2003}
}
@article{SR09,
author = {Sz{\'{e}}kely, G{\'{a}}bor J and Rizzo, Maria},
doi = {doi:10.1214/09-AOAS312},
journal = {The Annals of Applied Statistics},
number = {4},
pages = {1236--1265},
title = {{Brownian distance covariance}},
volume = {3},
year = {2009}
}
@article{Y11,
archivePrefix = {arXiv},
arxivId = {stat.CO/0801.0499},
author = {Yekutieli, D},
eprint = {0801.0499},
journal = {arXiv},
keywords = {Statistics - Computation,Statistics - Methodology,unpublished},
mendeley-tags = {unpublished},
primaryClass = {stat.CO},
title = {{Adjusted Bayesian inference for selected parameters}},
year = {2008}
}
@book{Hastie2016,
author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Hastie, Tibshirani, Wainwright - 2016 - Statistical Learning with Sparsity.pdf:pdf},
publisher = {CRC Press},
title = {{Statistical Learning with Sparsity}},
year = {2016}
}
@article{ROBINS1997,
abstract = {We argue, that due to the curse of dimensionality, there are major difficulties with any pure or smoothed likelihood-based method of inference in designed studies with randomly missing data when missingness depends on a high-dimensional vector of variables. We study in detail a semi-parametric superpopulation version of continuously stratified random sampling. We show that all estimators of the population mean that are uniformly consistent or that achieve an algebraic rate of convergence, no matter how slow, require the use of the selection (randomization) probabilities. We argue that, in contrast to likelihood methods which ignore these probabilities, inverse selection probability weighted estimators continue to perform well achieving uniform n 1/2-rates of convergence. We propose a curse of dimensionality appropriate (CODA) asymptotic theory for inference in non- and semi-parametric models in an attempt to formalize our arguments. We discuss whether our results constitute a fatal blow to the likelihood principle and study the attitude toward these that a committed subjective Bayesian would adopt. Finally, we apply our CODA theory to analyse the effect of the 'curse of dimensionality' in several interesting semi-parametric models, including a model for a two-armed randomized trial with randomization probabilities depending on a vector of continuous pretreatment covariates X. We provide substantive settings under which a subjective Bayesian would ignore the randomization probabilities in analysing the trial data. We then show that any statistician who ignores the randomization probabilities is unable to construct nominal 95 per cent confidence intervals for the true treatment effect that have both: (i) an expected length which goes to zero with increasing sample size; and (ii) a guaranteed expected actual coverage rate of at least 95 per cent over the ensemble of trials analysed by the statistician during his or her lifetime. However, we derive a new interval estimator, depending on the Randomization probabilities, that satisfies (i) and (ii).},
author = {ROBINS, JAMES M. and RITOV, YA'ACOV},
doi = {10.1002/(sici)1097-0258(19970215)16:3<285::aid-sim535>3.0.co;2-#},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics in Medicine/ROBINS, RITOV - 1997 - Toward a Curse of Dimensionality Appropriate (Coda) Asymptotic Theory for Semi-Parametric Models.pdf:pdf},
issn = {0277-6715},
journal = {Statistics in Medicine},
number = {3},
pages = {285--319},
title = {{Toward a Curse of Dimensionality Appropriate (Coda) Asymptotic Theory for Semi-Parametric Models}},
volume = {16},
year = {1997}
}
@article{Schrode2019,
abstract = {The mechanisms by which common risk variants of small effect interact to contribute to complex genetic disorders are unclear. Here, we apply a genetic approach, using isogenic human induced pluripotent stem cells, to evaluate the effects of schizophrenia (SZ)-associated common variants predicted to function as SZ expression quantitative trait loci (eQTLs). By integrating CRISPR-mediated gene editing, activation and repression technologies to study one putative SZ eQTL (FURIN rs4702) and four top-ranked SZ eQTL genes (FURIN, SNAP91, TSNARE1andCLCN3), our platform resolves pre- and postsynaptic neuronal deficits, recapitulates genotype-dependent gene expression differences and identifies convergence downstream of SZ eQTL gene perturbations. Our observations highlight the cell-type-specific effects of common variants and demonstrate a synergistic effect between SZ eQTL genes that converges on synaptic function. We propose that the links between rare and common variants implicated in psychiatric disease risk constitute a potentially generalizable phenomenon occurring more widely in complex genetic disorders.},
author = {Schrode, Nadine and Ho, Seok Man and Yamamuro, Kazuhiko and Dobbyn, Amanda and Huckins, Laura and Matos, Marliette R. and Cheng, Esther and Deans, P. J.Michael and Flaherty, Erin and Barretto, Natalie and Topol, Aaron and Alganem, Khaled and Abadali, Sonya and Gregory, James and Hoelzli, Emily and Phatnani, Hemali and Singh, Vineeta and Girish, Deeptha and Aronow, Bruce and Mccullumsmith, Robert and Hoffman, Gabriel E. and Stahl, Eli A. and Morishita, Hirofumi and Sklar, Pamela and Brennand, Kristen J.},
doi = {10.1038/s41588-019-0497-5},
file = {:Users/ekatsevi/Downloads/s41588-019-0497-5.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {CRISPR,GWAS,to-read},
mendeley-tags = {CRISPR,GWAS,to-read},
number = {10},
pages = {1475--1485},
pmid = {31548722},
publisher = {Springer US},
title = {{Synergistic effects of common schizophrenia risk variants}},
url = {http://dx.doi.org/10.1038/s41588-019-0497-5},
volume = {51},
year = {2019}
}
@article{SetT05,
abstract = {The genetic basis of many common human diseases is expected to be highly heterogeneous, with multiple causative loci and multiple alleles at some of the causative loci. Analyzing the association of disease with one genetic marker at a time can have weak power, because of relatively small genetic effects and the need to correct for multiple testing. Testing the simultaneous effects of multiple markers by multivariate statistics might improve power, but they too will not be very powerful when there are many markers, because of the many degrees of freedom. To overcome some of the limitations of current statistical methods for case-control studies of candidate genes, we develop a new class of nonparametric statistics that can simultaneously test the association of multiple markers with disease, with only a single degree of freedom. Our approach, which is based on U-statistics, first measures a score over all markers for pairs of subjects and then compares the averages of these scores between cases and controls. Genetic scoring for a pair of subjects is measured by a ``kernel'' function, which we allow to be fairly general. However, we provide guidelines on how to choose a kernel for different types of genetic effects. Our global statistic has the advantage of having only one degree of freedom and achieves its greatest power advantage when the contrasts of average genotype scores between cases and controls are in the same direction across multiple markers. Simulations illustrate that our proposed methods have the anticipated type I-error rate and that they can be more powerful than standard methods. Application of our methods to a study of candidate genes for prostate cancer illustrates their potential merits, and offers guidelines for interpretation.},
annote = {15786018},
author = {Schaid, Daniel J and McDonnell, Shannon K and Hebbring, Scott J and Cunningham, Julie M and Thibodeau, Stephen N},
journal = {American Journal of Human Genetics},
keywords = {genetics},
mendeley-tags = {genetics},
pages = {780--793},
title = {{{\{}Nonparametric{\}} Tests of Association of Multiple Genes with Human Disease}},
volume = {76},
year = {2005}
}
@article{CetB05,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/16251966{\}}{\{}16251966{\}}},
author = {Cheung, V G and Spielman, R S and Ewens, K G and Weber, T M and Morley, M and Burdick, J T},
journal = {Nature},
keywords = {GWAS,gene expression,genetics},
mendeley-tags = {GWAS,gene expression,genetics},
month = {oct},
number = {7063},
pages = {1365--1369},
title = {{{\{}M{\}}apping determinants of human gene expression by regional and genome-wide association}},
volume = {437},
year = {2005}
}
@article{Ahlmann-Eltze2020,
abstract = {Motivation: The Gamma-Poisson distribution is a theoretically and empirically motivated model for the sampling variability of single cell RNA-sequencing counts (Gr{\&}uumln et al., 2014; Townes et al., 2019; Svensson, 2020; Silverman et al., 2018; Hafemeister and Satija, 2019) and an essential building block for analysis approaches including differential expression analysis (Robinson et al., 2010; McCarthy et al., 2012; Anders and Huber, 2010; Love et al., 2014), principal component analysis (Townes et al., 2019) and factor analysis(Risso et al., 2018). Existing implementations for inferring its parameters from data often struggle with the size of single cell datasets, which typically comprise thousands or millions of cells; at the same time, they do not take full advantage of the fact that zero and other small numbers are frequent in the data. These limitations have hampered uptake of the model, leaving room for statistically inferior approaches such as logarithm(-like) transformation. Results: We present a new R package for fitting the Gamma-Poisson distribution to data with the characteristics of modern single cell datasets more quickly and more accurately than existing methods. The software can work with data on disk without having to load them into RAM simultaneously. {\#}{\#}{\#} Competing Interest Statement The authors have declared no competing interest.},
author = {Ahlmann-Eltze, Constantin and Huber, Wolfgang},
doi = {10.1101/2020.08.13.249623},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Ahlmann-Eltze, Huber - 2020 - glmGamPoi Fitting Gamma-Poisson Generalized Linear Models on Single Cell Count Data.pdf:pdf},
journal = {bioRxiv},
keywords = {computing,single cell},
mendeley-tags = {computing,single cell},
pages = {2020.08.13.249623},
title = {{glmGamPoi: Fitting Gamma-Poisson Generalized Linear Models on Single Cell Count Data}},
url = {https://www.biorxiv.org/content/10.1101/2020.08.13.249623v1},
year = {2020}
}
@article{Huang2019,
abstract = {The recent paper Cand$\backslash$`es et al. (2018) introduced model-X knockoffs, a method for variable selection that provably and non-asymptotically controls the false discovery rate with no restrictions or assumptions on the dimensionality of the data or the conditional distribution of the response given the covariates. The one requirement for the procedure is that the covariate samples are drawn independently and identically from a precisely-known (but arbitrary) distribution. The present paper shows that the exact same guarantees can be made without knowing the covariate distribution fully, but instead knowing it only up to a parametric model with as many as {\$}\backslashOmega(n{\^{}}{\{}*{\}}p){\$} parameters, where {\$}p{\$} is the dimension and {\$}n{\^{}}{\{}*{\}}{\$} is the number of covariate samples (which may exceed the usual sample size {\$}n{\$} of labeled samples when unlabeled samples are also available). The key is to treat the covariates as if they are drawn conditionally on their observed value for a sufficient statistic of the model. Although this idea is simple, even in Gaussian models conditioning on a sufficient statistic leads to a distribution supported on a set of zero Lebesgue measure, requiring techniques from topological measure theory to establish valid algorithms. We demonstrate how to do this for three models of interest, with simulations showing the new approach remains powerful under the weaker assumptions.},
archivePrefix = {arXiv},
arxivId = {1903.02806},
author = {Huang, Dongming and Janson, Lucas},
eprint = {1903.02806},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics, to appear/Huang, Janson - 2020 - Relaxing the Assumptions of Knockoffs by Conditioning.pdf:pdf},
journal = {Annals of Statistics, to appear},
keywords = {ery rate,false discov-,fdr,graphical model,high-dimensional inference,knockoffs,model-x,sufficient statistic,topological measure},
mendeley-tags = {knockoffs},
title = {{Relaxing the Assumptions of Knockoffs by Conditioning}},
url = {http://arxiv.org/abs/1903.02806},
year = {2020}
}
@article{Wang2018e,
abstract = {Differential gene expression analysis is one of the significant efforts in single cell RNA sequencing (scRNAseq) analysis to discover the specific changes in expression levels of individual cell types. Since scRNAseq exhibits multimodality, large amounts of zero counts, and sparsity, it is different from the traditional bulk RNA sequencing (RNAseq) data. The new challenges of scRNAseq data promote the development of new methods for identifying differentially expressed (DE) genes. In this study, we proposed a new method, SigEMD, that combines a data imputation approach, a logistic regression model and a nonparametric method based on the Earth Mover's Distance, to precisely and efficiently identify DE genes in scRNAseq data. The regression model and data imputation are used to reduce the impact of large amounts of zero counts, and the nonparametric method is used to improve the sensitivity of detecting DE genes from multimodal scRNAseq data. By additionally employing gene interaction network information to adjust the final states of DE genes, we further reduce the false positives of calling DE genes. We used simulated datasets and real datasets to evaluate the detection accuracy of the proposed method and to compare its performance with those of other differential expression analysis methods. Results indicate that the proposed method has an overall powerful performance in terms of precision in detection, sensitivity, and specificity.},
author = {Wang, Tianyu and Nabavi, Sheida},
doi = {10.1016/j.ymeth.2018.04.017},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Methods/Wang, Nabavi - 2018 - SigEMD A powerful method for differential gene expression analysis in single-cell RNA sequencing data.pdf:pdf},
issn = {10959130},
journal = {Methods},
keywords = {Data imputation,Differential gene expression analysis,Multimodal data,Nonparametric models,Single-cell RNAseq,differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {February},
pages = {25--32},
publisher = {Elsevier},
title = {{SigEMD: A powerful method for differential gene expression analysis in single-cell RNA sequencing data}},
url = {https://doi.org/10.1016/j.ymeth.2018.04.017},
volume = {145},
year = {2018}
}
@article{Romano2007,
abstract = {Consider the problem of testing s hypotheses simultaneously. The usual approach restricts attention to procedures that control the probability of even one false rejection, the familywise error rate (FWER). If s is large, one might be willing to tolerate more than one false rejection, thereby increasing the ability of the procedure to correctly reject false null hypotheses. One possibility is to replace control of the FWER by control of the probability of k or more false rejections, which is called the k-FWER. We derive both single-step and step-down procedures that control the k-FWER in finite samples or asymptotically, depending on the situation. We also consider the false discovery proportion (FDP) defined as the number of false rejections divided by the total number of rejections (and defined to be 0 if there are no rejections). The false discovery rate proposed by Benjamini and Hochberg [J. Roy. Sta-tist. Soc. Ser. B 57 (1995) 289-300] controls E(FDP). Here, the goal is to construct methods which satisfy, for a given $\gamma$ and $\alpha$, P {\{}FDP {\textgreater} $\gamma$ {\}} ≤ $\alpha$, at least asymptotically. In contrast to the proposals of Lehmann and Romano [Ann. Statist. 33 (2005) 1138-1154], we construct methods that implicitly take into account the dependence structure of the individual test statistics in order to further increase the ability to detect false null hypotheses. This feature is also shared by related work of van der Laan, Dudoit and Pollard [Stat. Appl. Genet. Mol. Biol. 3 (2004) article 15], but our methodology is quite different. Like the work of Pollard and van der Laan [Proc. 2003 International Multi-Conference in Computer Science and Engineering, METMBS'03 Conference (2003) 3-9] and Dudoit, van der Laan and Pollard [Stat. Appl. Genet. Mol. Biol. 3 (2004) article 13], we employ resampling methods to achieve our goals. Some simulations compare finite sample performance to currently available methods.},
author = {Romano, Joseph P and Wolf, Michael},
doi = {10.1214/009053606000001622},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Romano, Wolf - 2007 - CONTROL OF GENERALIZED ERROR RATES IN MULTIPLE TESTING.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {FDX,Multiple testing},
mendeley-tags = {FDX,Multiple testing},
number = {4},
pages = {1378--1408},
title = {{CONTROL OF GENERALIZED ERROR RATES IN MULTIPLE TESTING}},
volume = {35},
year = {2007}
}
@article{R08,
author = {Rosenbaum, Paul R},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Rosenbaum - 2008 - Testing hypotheses in order.pdf:pdf},
journal = {Biometrika},
keywords = {FWER,Multiple testing,ordered testing},
mendeley-tags = {FWER,Multiple testing,ordered testing},
number = {1},
pages = {248--252},
publisher = {Oxford University Press},
title = {{Testing hypotheses in order}},
volume = {95},
year = {2008}
}
@article{ZS16,
abstract = {Bayesian methods for large-scale multiple regression provide attractive approaches to the analysis of genome-wide association studies (GWAS). For example, they can estimate heritability of complex traits, allowing for both polygenic and sparse models; and by incorporating external genomic data into the priors they can increase power and yield new biological insights. However, these methods require access to individual genotypes and phenotypes, which are often not easily available. Here we provide a framework for performing these analyses without individual-level data. Specifically, we introduce a "Regression with Summary Statistics" (RSS) likelihood, which relates the multiple regression coefficients to univariate regression results that are often easily available. The RSS likelihood requires estimates of correlations among covariates (SNPs), which also can be obtained from public databases. We perform Bayesian multiple regression analysis by combining the RSS likelihood with previously-proposed prior distributions, sampling posteriors by Markov chain Monte Carlo. In a wide range of simulations RSS performs similarly to analyses using the individual data, both for estimating heritability and detecting associations. We apply RSS to a GWAS of human height that contains 253,288 individuals typed at 1.06 million SNPs, for which analyses of individual-level data are practically impossible. Estimates of heritability (52{\%}) are consistent with, but more precise, than previous results using subsets of these data. We also identify many previously-unreported loci that show evidence for association with height in our analyses. Software implementing RSS is available at https://github.com/stephenslab/rss.},
author = {Zhu, Xiang and Stephens, Matthew},
doi = {10.1101/042457},
journal = {bioRxiv},
keywords = {GWAS,unpublished},
mendeley-tags = {GWAS,unpublished},
publisher = {Cold Spring Harbor Labs Journals},
title = {{Bayesian large-scale multiple regression with summary statistics from genome-wide association studies}},
url = {http://biorxiv.org/content/early/2016/03/04/042457},
year = {2016}
}
@article{Gavrilov2009,
abstract = {In this work we study an adaptive step-down procedure for testing m hypotheses. It stems from the repeated use of the false discovery rate controlling the linear step-up procedure (sometimes called BH), and makes use of the critical constants iq/[(m+1-i(1-q)], i = 1, . . . , m. Motivated by its success as a model selection procedure, as well as by its asymptotic optimality, we are interested in its false discovery rate (FDR) controlling properties for a finite number of hypotheses. We prove this step-down procedure controls the FDR at level q for independent test statistics. We then numerically compare it with two other procedures with proven FDR control under independence, both in terms of power under independence and FDR control under positive dependence. {\textcopyright} Institute of Mathematical Statistics, 2009.},
archivePrefix = {arXiv},
arxivId = {arXiv:0903.5373v1},
author = {Gavrilov, Yulia and Benjamini, Yoav and Sarkar, Sanat K.},
doi = {10.1214/07-AOS586},
eprint = {arXiv:0903.5373v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Gavrilov, Benjamini, Sarkar - 2009 - An adaptive step-down procedure with proven FDR control under independence.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {FDR,False discovery rate,Multiple testing},
mendeley-tags = {FDR,Multiple testing},
number = {2},
pages = {619--629},
title = {{An adaptive step-down procedure with proven FDR control under independence}},
volume = {37},
year = {2009}
}
@article{Islam2011,
abstract = {Our understanding of the development and maintenance of tissues has been greatly aided by large-scale gene expression analysis. However, tissues are invariably complex, and expression analysis of a tissue confounds the true expression patterns of its constituent cell types. Here we describe a novel strategy to access such complex samples. Single-cell RNA-seq expression profiles were generated, and clustered to form a two-dimensional cell map onto which expression data were projected. The resulting cell map integrates three levels of organization: the whole population of cells, the functionally distinct subpopulations it contains, and the single cells themselves - all without need for known markers to classify cell types. The feasibility of the strategy was demonstrated by analyzing the transcriptomes of 85 single cells of two distinct types. We believe this strategy will enable the unbiased discovery and analysis of naturally occurring cell types during development, adult physiology, and disease. {\textcopyright} 2011 by Cold Spring Harbor Laboratory Press.},
author = {Islam, Saiful and Kj{\"{a}}llquist, Una and Moliner, Annalena and Zajac, Pawel and Fan, Jian Bing and L{\"{o}}nnerberg, Peter and Linnarsson, Sten},
doi = {10.1101/gr.110882.110},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Research/Islam et al. - 2011 - Characterization of the single-cell transcriptional landscape by highly multiplex RNA-seq.pdf:pdf},
issn = {10889051},
journal = {Genome Research},
number = {7},
pages = {1160--1167},
pmid = {21543516},
title = {{Characterization of the single-cell transcriptional landscape by highly multiplex RNA-seq}},
volume = {21},
year = {2011}
}
@article{Basu2018,
abstract = {The use of weights provides an effective strategy to incorporate prior domain knowledge in large-scale inference. This article studies weighted multiple testing in a decision-theoretical framework. We develop oracle and data-driven procedures that aim to maximize the expected number of true positives subject to a constraint on the weighted false discovery rate. The asymptotic validity and optimality of the proposed methods are established. The results demonstrate that incorporating informative domain knowledge enhances the interpretability of results and precision of inference. Simulation studies show that the proposed method controls the error rate at the nominal level, and the gain in power over existing methods is substantial in many settings. An application to a genome-wide association study is discussed. Supplementary materials for this article are available online.},
archivePrefix = {arXiv},
arxivId = {1508.01605},
author = {Basu, Pallavi and Cai, T. Tony and Das, Kiranmoy and Sun, Wenguang},
doi = {10.1080/01621459.2017.1336443},
eprint = {1508.01605},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Basu et al. - 2018 - Weighted False Discovery Rate Control in Large-Scale Multiple Testing.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Class weights,Decision weights,Multiple testing with groups,Prioritized subsets,Value-to-cost ratio,Weighted p-value},
number = {523},
pages = {1172--1183},
publisher = {Taylor {\&} Francis},
title = {{Weighted False Discovery Rate Control in Large-Scale Multiple Testing}},
url = {https://doi.org/10.1080/01621459.2017.1336443},
volume = {113},
year = {2018}
}
@article{Hill2012,
abstract = {MOTIVATION: Protein signaling networks play a key role in cellular function, and their dysregulation is central to many diseases, including cancer. To shed light on signaling network topology in specific contexts, such as cancer, requires interrogation of multiple proteins through time and statistical approaches to make inferences regarding network structure. RESULTS: In this study, we use dynamic Bayesian networks to make inferences regarding network structure and thereby generate testable hypotheses. We incorporate existing biology using informative network priors, weighted objectively by an empirical Bayes approach, and exploit a connection between variable selection and network inference to enable exact calculation of posterior probabilities of interest. The approach is computationally efficient and essentially free of user-set tuning parameters. Results on data where the true, underlying network is known place the approach favorably relative to existing approaches. We apply these methods to reverse-phase protein array time-course data from a breast cancer cell line (MDA-MB-468) to predict signaling links that we independently validate using targeted inhibition. The methods proposed offer a general approach by which to elucidate molecular networks specific to biological context, including, but not limited to, human cancers. AVAILABILITY: http://mukherjeelab.nki.nl/DBN (code and data).},
author = {Hill, Steven M. and Lu, Yiling and Molina, Jennifer and Heiser, Laura M. and Spellman, Paul T. and Speed, Terence P. and Gray, Joe W. and Mills, Gordon B. and Mukherjee, Sach},
doi = {10.1093/bioinformatics/bts514},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Hill et al. - 2012 - Bayesian Inference of Signaling Network Topology in a Cancer Cell Line.pdf:pdf},
issn = {13674803},
journal = {Bioinformatics},
keywords = {Kathryn,networks},
mendeley-tags = {Kathryn,networks},
number = {21},
pages = {2804--2810},
title = {{Bayesian Inference of Signaling Network Topology in a Cancer Cell Line}},
url = {http://mukherjeelab.nki.nl/DBN},
volume = {28},
year = {2012}
}
@article{CetM17,
author = {Cortes, Adrian and Dendrou, Calliope A. and Motyer, Allan and Jostins, Luke and Vukcevic, Damjan and Dilthey, Alexander and Donnelly, Peter and Leslie, Stephen and Fugger, Lars and McVean, Gil},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Cortes et al. - 2017 - Bayesian analysis of genetic association across tree-structured routine healthcare data in the UK Biobank.pdf:pdf},
journal = {Nature Genetics},
keywords = {GWAS,applied,genetics,hierarchical multiple testing},
mendeley-tags = {GWAS,applied,genetics,hierarchical multiple testing},
number = {9},
pages = {1311--1318},
title = {{Bayesian analysis of genetic association across tree-structured routine healthcare data in the UK Biobank}},
volume = {49},
year = {2017}
}
@article{Hirabayashi2019,
abstract = {Promoters and enhancers are key cis-regulatory elements, but how they operate to generate cell type-specific transcriptomes is not fully understood. We developed a simple and robust method, native elongating transcript–cap analysis of gene expression (NET-CAGE), to sensitively detect 5′ ends of nascent RNAs in diverse cells and tissues, including unstable transcripts such as enhancer-derived RNAs. We studied RNA synthesis and degradation at the transcription start site level, characterizing the impact of differential promoter usage on transcript stability. We quantified transcription from cis-regulatory elements without the influence of RNA turnover, and show that enhancer–promoter pairs are generally activated simultaneously on stimulation. By integrating NET-CAGE data with chromatin interaction maps, we show that cis-regulatory elements are topologically connected according to their cell type specificity. We identified new enhancers with high sensitivity, and delineated primary locations of transcription within super-enhancers. Our NET-CAGE dataset derived from human and mouse cells expands the FANTOM5 atlas of transcribed enhancers, with broad applicability to biomedical research.},
author = {Hirabayashi, Shigeki and Bhagat, Shruti and Matsuki, Yu and Takegami, Yujiro and Uehata, Takuya and Kanemaru, Ai and Itoh, Masayoshi and Shirakawa, Kotaro and Takaori-Kondo, Akifumi and Takeuchi, Osamu and Carninci, Piero and Katayama, Shintaro and Hayashizaki, Yoshihide and Kere, Juha and Kawaji, Hideya and Murakawa, Yasuhiro},
doi = {10.1038/s41588-019-0485-9},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Hirabayashi et al. - 2019 - NET-CAGE characterizes the dynamics and topology of human transcribed cis-regulatory elements.pdf:pdf},
journal = {Nature Genetics},
keywords = {Kathryn,PRO-seq,genetics},
mendeley-tags = {Kathryn,PRO-seq,genetics},
pages = {1369--1379},
title = {{NET-CAGE characterizes the dynamics and topology of human transcribed cis-regulatory elements}},
url = {https://doi.org/10.1038/s41588-019-0485-9},
volume = {51},
year = {2019}
}
@article{NY,
author = {Lehrer, J},
journal = {The New Yorker},
keywords = {reproducibility},
mendeley-tags = {reproducibility},
month = {dec},
title = {{{\{}T{\}}he truth wears off}},
year = {2010}
}
@article{RetB07,
abstract = {Gene expression and phenotypic functionality can best be associated when they are measured quantitatively within the same experiment. The analysis of such a complex experiment is presented, searching for associations between measures of exploratory behavior in mice and gene expression in brain regions. The analysis of such experiments raises several methodological problems. First and foremost, the size of the pool of potential discoveries being screened is enormous yet only few biologically relevant findings are expected, making the problem of multiple testing especially severe. We present solutions based on screening by testing related hypotheses, then testing the hypotheses of interest. In one variant the subset is selected directly, in the other one a tree of hypotheses is tested hierarchical; both variants control the False Discovery Rate (FDR). Other problems in such experiments are in the fact that the level of data aggregation may be different for the quantitative traits (one per animal) and gene expression measurements (pooled across animals); in that the association may not be linear; and in the resolution of interest only few replications exist. We offer solutions to these problems as well. The hierarchical FDR testing strategies presented here can serve beyond the structure of our motivating example study to any complex microarray study. Supplementary information: Supplementary data are available at Bioinformatics online.},
annote = {17827208},
author = {Reiner-Benaim, A and Yekutieli, D and Letwin, N E and Elmer, G I and Lee, N H and Kafkafi, N and Benjamini, Y},
doi = {10.1093/bioinformatics/btm300},
journal = {Bioinformatics},
number = {17},
pages = {2239--2246},
title = {{Associating quantitative behavioral traits with gene expression in the brain: searching for diamonds in the hay}},
url = {http://www.hubmed.org/display.cgi?uids=17827208},
volume = {23},
year = {2007}
}
@article{Celentano2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2007.13716v1},
author = {Celentano, Michael and Montanari, Andrea and Wei, Yuting},
eprint = {arXiv:2007.13716v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Celentano, Montanari, Wei - 2020 - The Lasso with general Gaussian designs with applications to hypothesis testing.pdf:pdf},
journal = {arXiv},
keywords = {AMP,Lasso,conditional randomization test,high-dimensional regression},
mendeley-tags = {AMP,Lasso,conditional randomization test,high-dimensional regression},
title = {{The Lasso with general Gaussian designs with applications to hypothesis testing}},
year = {2020}
}
@article{Chernoff1956,
author = {Chernoff, Herman},
doi = {10.1214/aoms/1177728347},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Mathematical Statistics/Chernoff - 1956 - Large-Sample Theory Parametric Case.pdf:pdf},
issn = {0003-4851},
journal = {The Annals of Mathematical Statistics},
keywords = {asymptotics},
mendeley-tags = {asymptotics},
number = {1},
pages = {1--22},
title = {{Large-Sample Theory: Parametric Case}},
volume = {27},
year = {1956}
}
@article{scad,
author = {Fan, J and Li, R},
journal = {Journal of the American Statistical Association},
keywords = {high-dimensional regression},
mendeley-tags = {high-dimensional regression},
number = {456},
pages = {1348--1360},
publisher = {Taylor {\&} Francis},
title = {{Variable selection via nonconcave penalized likelihood and its oracle properties}},
volume = {96},
year = {2001}
}
@article{FoygelBarber2019,
abstract = {This paper introduces the jackknife+, which is a novel method for constructing predictive confidence intervals. Whereas the jackknife outputs an interval centered at the predicted response of a test point, with the width of the interval determined by the quantiles of leave-one-out residuals, the jack-knife+ also uses the leave-one-out predictions at the test point to account for the variability in the fitted regression function. Assuming exchangeable training samples, we prove that this crucial modification permits rigorous coverage guarantees regardless of the distribution of the data points, for any algorithm that treats the training points symmetrically. Such guarantees are not possible for the original jackknife and we demonstrate examples where the coverage rate may actually vanish. Our theoretical and empirical analysis reveals that the jackknife and the jackknife+ intervals achieve nearly exact coverage and have similar lengths whenever the fitting algorithm obeys some form of stability. Further, we extend the jackknife+ to K-fold cross validation and similarly establish rigorous coverage properties. Our methods are related to cross-conformal prediction proposed by Vovk [2015] and we discuss connections.},
author = {{Foygel Barber}, Rina and Cand{\`{e}}s, Emmanuel J and Ramdas, Aaditya and Tibshirani, Ryan J},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics, to appear/Foygel Barber et al. - 2020 - Predictive inference with the jackknife.pdf:pdf},
journal = {Annals of Statistics, to appear},
keywords = {conformal prediction,to-skim,unpublished},
mendeley-tags = {conformal prediction,to-skim,unpublished},
title = {{Predictive inference with the jackknife+}},
year = {2020}
}
@article{LetA11,
abstract = {New sequencing technologies allow genomic variation to be surveyed in much greater detail than previously possible. While detailed analysis of a single individual typically requires deep sequencing, when many individuals are sequenced it is possible to combine shallow sequence data across individuals to generate accurate calls in shared stretches of chromosome. Here, we show that, as progressively larger numbers of individuals are sequenced, increasingly accurate genotype calls can be generated for a given sequence depth. We evaluate the implications of low-coverage sequencing for complex trait association studies. We systematically compare study designs based on genotyping of tagSNPs, sequencing of many individuals at depths ranging between 2{\~{A}}— and 30{\~{A}}—, and imputation of variants discovered by sequencing a subset of individuals into the remainder of the sample. We show that sequencing many individuals at low depth is an attractive strategy for studies of complex trait genetics. For example, for disease-associated variants with frequency $\backslash$mbox{\{}{\$}{\textless}{\$}{\}}0.2{\%}, sequencing 3000 individuals at 4{\~{A}}— depth provides similar power to deep sequencing of $\backslash$mbox{\{}{\$}{\textless}{\$}{\}}2000 individuals at 30{\~{A}}— depth but requires only {\^{a}}ˆ¼20{\%} of the sequencing effort. We also show low-coverage sequencing can be used to build a reference panel that can drive imputation into additional samples to increase power further. We provide guidance for investigators wishing to combine results from sequenced, genotyped, and imputed samples.},
annote = {21460063},
author = {Li, Yun and Sidore, Carlo and Kang, Hyun Min and Boehnke, Michael and Abecasis, Gon{\c{c}}alo R},
journal = {Genome Res},
keywords = {GWAS},
mendeley-tags = {GWAS},
title = {{{\{}Low-coverage{\}} Sequencing: {\{}Implications{\}} for Design of Complex Trait Association Studies}},
year = {2011}
}
@article{HMW10,
abstract = {Recent findings suggest that rare variants play an important role in both monogenic and common diseases. Due to their rarity, however, it remains unclear how to appropriately analyze the association between such variants and disease. A common approach entails combining rare variants together based on a priori information and analyzing them as a single group. Here one must make some assumptions about what to aggregate. Instead, we propose two approaches to empirically determine the most efficient grouping of rare variants. The first considers multiple possible groupings using existing information. The second is an agnostic ``step-up'' approach that determines an optimal grouping of rare variants analytically and does not rely on prior information. To evaluate these approaches, we undertook a simulation study using sequence data from genes in the one-carbon folate metabolic pathway. Our results show that using prior information to group rare variants is advantageous only when information is quite accurate, but the step-up approach works well across a broad range of plausible scenarios. This agnostic approach allows one to efficiently analyze the association between rare variants and disease while avoiding assumptions required by other approaches for grouping such variants.},
annote = {21072163},
author = {Hoffmann, Thomas J and Marini, Nicholas J and Witte, John S},
journal = {PLoS One},
keywords = {genetics},
mendeley-tags = {genetics},
pages = {e13584--e13584},
title = {{{\{}Comprehensive{\}} Approach to Analyzing rare Genetic Variants}},
volume = {5},
year = {2010}
}
@article{Ren2020,
archivePrefix = {arXiv},
arxivId = {arXiv:2001.07835v1},
author = {Ren, Zhimei and Cand{\`{e}}s, Emmanuel},
eprint = {arXiv:2001.07835v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Ren, Cand{\`{e}}s - 2020 - Knockoffs with Side Information.pdf:pdf},
journal = {arXiv},
keywords = {bayesian two-,false discovery rate,fdr,genome-wide association study,group model,gwas,knockoff filters,knockoffs,multiple testing,variable selection},
mendeley-tags = {knockoffs},
pages = {1--29},
title = {{Knockoffs with Side Information}},
year = {2020}
}
@article{Shadrin2019,
abstract = {Determining the contribution of functional genetic categories is fundamental to understanding the genetic etiology of complex human traits and diseases. Here we present Annotation Informed MiXeR: a likelihood-based method to estimate the number of variants influencing a phenotype and their effect sizes across different functional annotation categories of the genome using summary statistics from genome-wide association studies. Applying the model to 11 complex phenotypes suggests diverse patterns of functional category-specific genetic architectures across human diseases and traits.},
author = {Shadrin, Alexey A. and Frei, Oleksandr and Smeland, Olav B. and Bettella, Francesco and O`Connell, Kevin S. and Gani, Osman and Bahrami, Shahram and Uggen, Tea K.E. and Djurovic, Srdjan and Holland, Dominic and Andreassen, Ole A. and Dale, Anders M.},
doi = {10.1101/772202},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Shadrin et al. - 2019 - Annotation-Informed Causal Mixture Modeling (AI-MiXeR) reveals phenotype-specific differences in polygenicity an.pdf:pdf},
journal = {bioRxiv},
keywords = {GWAS,genetics,to-skim},
mendeley-tags = {GWAS,genetics,to-skim},
title = {{Annotation-Informed Causal Mixture Modeling (AI-MiXeR) reveals phenotype-specific differences in polygenicity and effect size distribution across functional annotation categories}},
url = {https://www.biorxiv.org/content/10.1101/772202v1?rss=1},
year = {2019}
}
@article{Li2020a,
abstract = {Single-cell RNA sequencing (scRNA-seq) can characterize cell types and states through unsupervised clustering, but the ever increasing number of cells and batch effect impose computational challenges. We present DESC, an unsupervised deep embedding algorithm that clusters scRNA-seq data by iteratively optimizing a clustering objective function. Through iterative self-learning, DESC gradually removes batch effects, as long as technical differences across batches are smaller than true biological variations. As a soft clustering algorithm, cluster assignment probabilities from DESC are biologically interpretable and can reveal both discrete and pseudotemporal structure of cells. Comprehensive evaluations show that DESC offers a proper balance of clustering accuracy and stability, has a small footprint on memory, does not explicitly require batch information for batch effect removal, and can utilize GPU when available. As the scale of single-cell studies continues to grow, we believe DESC will offer a valuable tool for biomedical researchers to disentangle complex cellular heterogeneity.},
author = {Li, Xiangjie and Wang, Kui and Lyu, Yafei and Pan, Huize and Zhang, Jingxiao and Stambolian, Dwight and Susztak, Katalin and Reilly, Muredach P. and Hu, Gang and Li, Mingyao},
doi = {10.1038/s41467-020-15851-3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Li et al. - 2020 - Deep learning enables accurate clustering with batch effect removal in single-cell RNA-seq analysis.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
keywords = {batch effects,single cell},
mendeley-tags = {batch effects,single cell},
number = {1},
pages = {1--14},
pmid = {32393754},
publisher = {Springer US},
title = {{Deep learning enables accurate clustering with batch effect removal in single-cell RNA-seq analysis}},
url = {http://dx.doi.org/10.1038/s41467-020-15851-3},
volume = {11},
year = {2020}
}
@article{Mahdipour2020,
author = {Mahdipour-Shirayeh, Ali and Erdmann, Natalie and Leung-hagesteijn, Chungyee and Rodger, E},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Mahdipour-Shirayeh et al. - 2020 - sciCNV High-throughput paired profiling of transcriptomes and DNA copy number variations at single c.pdf:pdf},
journal = {bioRxiv},
keywords = {cnv,copy number variation,multi-omics,multiple myeloma,normalization,rtam,scicnv,scrna-seq,single cell rna sequencing},
mendeley-tags = {multi-omics},
pages = {1--31},
title = {{sciCNV : High-throughput paired profiling of transcriptomes and DNA copy number variations at single cell resolution}},
year = {2020}
}
@inproceedings{lei2016power,
author = {Lei, Lihua and Fithian, Will},
booktitle = {International Conference on Machine Learning},
keywords = {FDR,Multiple testing,ordered testing},
mendeley-tags = {FDR,Multiple testing,ordered testing},
pages = {2924--2932},
title = {{Power of ordered hypothesis testing}},
year = {2016}
}
@article{NS03,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/12824425{\}}{\{}12824425{\}}},
author = {Ng, P C and Henikoff, S},
journal = {Nucleic Acids Research},
keywords = {genetics},
mendeley-tags = {genetics},
month = {jul},
pages = {3812--3814},
title = {{{\{}S{\}}{\{}I{\}}{\{}F{\}}{\{}T{\}}: {\{}P{\}}redicting amino acid changes that affect protein function}},
volume = {31},
year = {2003}
}
@article{BH13,
author = {Bogomolov, Marina and Heller, Ruth},
journal = {Journal of the American Statistical Association},
number = {504},
pages = {1480--1492},
publisher = {Taylor {\&} Francis},
title = {{Discovering findings that replicate from a primary study of high dimension to a follow-up study}},
volume = {108},
year = {2013}
}
@article{Ngaruiya2013,
abstract = {Reactive arthritis is an inflammatory condition with multiorgan system disease potential. Because the standard constellation of symptoms in Reiter syndrome (arthritis, conjunctivitis, and urethritis) is not typically present in all patients, the disease can be easily overlooked if clinical suspicion is not high upon presentation. To highlight the importance of recognizing the potential of this disease in patients with a history of either gastrointestinal or genitourinary illnesses, we present the case of a young healthy male presented on multiple occasions later diagnosed with Reiter syndrome in the setting of a recent diagnosis of prostatitis. He was noted to have classical symptoms including conjunctivitis and arthritis. He was treated with nonsteroidal anti-inflammatory drugs during a brief hospital stay and did well. Although reactive arthritis is an easily managed disease, it is easily missed particularly in young otherwise healthy patients who may not present with classic symptoms. Vigilance with regard to patients with vague seemingly unrelated complaints particularly with a history of gastrointestinal- or genitourinary-related illnesses deserves consideration for this disease process. {\textcopyright} 2013 Elsevier Inc. All rights reserved.},
author = {Ngaruiya, Christine M. and Martin, Ian B.K.},
doi = {10.1016/j.ajem.2012.04.019},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Emergency Medicine/Ngaruiya, Martin - 2013 - A case of reactive arthritis A great masquerader.pdf:pdf},
issn = {15328171},
journal = {American Journal of Emergency Medicine},
number = {1},
pages = {266.e5--266.e7},
title = {{A case of reactive arthritis: A great masquerader}},
volume = {31},
year = {2013}
}
@article{DelaTorre-Ubieta2018,
abstract = {Non-coding regions comprise most of the human genome and harbor a significant fraction of risk alleles for neuropsychiatric diseases, yet their functions remain poorly defined. We created a high-resolution map of non-coding elements involved in human cortical neurogenesis by contrasting chromatin accessibility and gene expression in the germinal zone and cortical plate of the developing cerebral cortex. We link distal regulatory elements (DREs) to their cognate gene(s) together with chromatin interaction data and show that target genes of human-gained enhancers (HGEs) regulate cortical neurogenesis and are enriched in outer radial glia, a cell type linked to human cortical evolution. We experimentally validate the regulatory effects of predicted enhancers for FGFR2 and EOMES. We observe that common genetic variants associated with educational attainment, risk for neuropsychiatric disease, and intracranial volume are enriched within regulatory elements involved in cortical neurogenesis, demonstrating the importance of this early developmental process for adult human cognitive function. A high-resolution map of non-coding regulatory elements driving human cortical neurogenesis reveals uniquely human enhancers linked to common genetic variants associated with cognitive function.},
author = {de la Torre-Ubieta, Luis and Stein, Jason L. and Won, Hyejung and Opland, Carli K. and Liang, Dan and Lu, Daning and Geschwind, Daniel H.},
doi = {10.1016/j.cell.2017.12.014},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/de la Torre-Ubieta et al. - 2018 - The Dynamic Landscape of Open Chromatin during Human Cortical Neurogenesis.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {ATAC-seq,HI-C,Kathryn,chromatin,enhancers,evolution,gene-enhancer,genetics,human neocortical development,transcription factors},
mendeley-tags = {HI-C,Kathryn,gene-enhancer,genetics},
number = {1-2},
pages = {289--304.e18},
title = {{The Dynamic Landscape of Open Chromatin during Human Cortical Neurogenesis}},
volume = {172},
year = {2018}
}
@book{Hayashi2000,
abstract = {This book is designed to serve as the textbook for a first-year graduate course in econometrics. It has two distinguishing features. First, it covers a full range of techniques with the estimation method called the Generalized Method of Moments (GMM) as the organizing principle. I believe this unified approach is the most efficient way to cover the first-year materials in an accessible yet rigorous manner. Second, most chapters include a section examining in detail original applied arti- cles from such diverse fields in economics as industrial organization, labor, finance, international, and macroeconomics. So the reader will know how to use the tech- niques covered in the chapter and under what conditions they are applicable. Over the last several years, the lecture notes on which this book is based have been used at the University of Pennsylvania, Columbia University, Prince- ton University, the University of Tokyo, Boston College, Harvard University, and Ohio State University. Students seem to like the book a lot. My own experience from teaching out of the book is that students think the book is better than the instructor.},
author = {Hayashi, Fumio},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Hayashi - 2000 - Econometrics.pdf:pdf},
isbn = {9780691010182},
publisher = {Princeton University Press},
title = {{Econometrics}},
year = {2000}
}
@article{SetH15,
annote = {$\backslash$href{\{}http://biorxiv.org/content/early/2015/11/24/031492{\}}{\{}http://dx.doi.org/10.1101/031492{\}}},
author = {Schweiger, R and Kaufman, S and Laaksonen, R and Kleber, M and Marz, W and Eskin, E and Rosset, S and Halperin, E},
journal = {BioRchive},
keywords = {GWAS,confidence intervals,heritability},
mendeley-tags = {GWAS,confidence intervals,heritability},
title = {{{\{}F{\}}ast and accurate construction of cofidence intervals for heritability}},
year = {2015}
}
@book{Lai1985a,
author = {Lai, T. L. and Siegmund, David},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Lai, Siegmund - 1985 - Herbert Robbins Selected Papers.pdf:pdf},
title = {{Herbert Robbins Selected Papers}},
year = {1985}
}
@article{KetP14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25357204{\}}{\{}25357204{\}}},
author = {Kichaev, G and Yang, W and Lindstrom, S and Hormozdiari, F and Eskin, E and Price, A L and Kraft, P and Pasaniuc, B},
doi = {10.1371/journal.pgen.1004722},
journal = {PLoS Genetics},
number = {10},
pages = {e1004722},
title = {{Integrating Functional Data to Prioritize Causal Variants in Statistical Fine-Mapping Studies}},
volume = {10},
year = {2014}
}
@article{GM08,
author = {Goeman, Jelle J and Mansmann, Ulrich},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Bioinformatics/Goeman, Mansmann - 2008 - Multiple testing on the directed acyclic graph of gene ontology.pdf:pdf},
journal = {Bioinformatics},
keywords = {Gene Ontology,Multiple testing},
mendeley-tags = {Gene Ontology,Multiple testing},
number = {4},
pages = {537--544},
publisher = {Oxford University Press},
title = {{Multiple testing on the directed acyclic graph of gene ontology}},
volume = {24},
year = {2008}
}
@article{B11,
abstract = {The data deluge is changing the operating environment of many sensing systems from data-poor to data-rich--so data-rich that we are in jeopardy of being overwhelmed. Managing and exploiting the data deluge require a reinvention of sensor system design and signal processing theory. The potential pay-offs are huge, as the resulting sensor systems will enable radically new information technologies and powerful new tools for scientific discovery.},
annote = {21311012},
author = {Baraniuk, Richard G},
journal = {Science},
pages = {717--719},
title = {{{\{}More{\}} is Less: Signal Processing and the data Deluge}},
volume = {331},
year = {2011}
}
@article{Boix2021,
abstract = {Annotating the molecular basis of human disease remains an unsolved challenge, as 93{\%} of disease loci are non-coding and gene-regulatory annotations are highly incomplete1–3. Here we present EpiMap, a compendium comprising 10,000 epigenomic maps across 800 samples, which we used to define chromatin states, high-resolution enhancers, enhancer modules, upstream regulators and downstream target genes. We used this resource to annotate 30,000 genetic loci that were associated with 540 traits4, predicting trait-relevant tissues, putative causal nucleotide variants in enriched tissue enhancers and candidate tissue-specific target genes for each. We partitioned multifactorial traits into tissue-specific contributing factors with distinct functional enrichments and disease comorbidity patterns, and revealed both single-factor monotropic and multifactor pleiotropic loci. Top-scoring loci frequently had multiple predicted driver variants, converging through multiple enhancers with a common target gene, multiple genes in common tissues, or multiple genes and multiple tissues, indicating extensive pleiotropy. Our results demonstrate the importance of dense, rich, high-resolution epigenomic annotations for the investigation of complex traits.},
author = {Boix, Carles A. and James, Benjamin T. and Park, Yongjin P. and Meuleman, Wouter and Kellis, Manolis},
doi = {10.1038/s41586-020-03145-z},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Boix et al. - 2021 - Regulatory genomic circuitry of human disease loci by integrative epigenomics.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {GWAS,epigenetics},
mendeley-tags = {epigenetics,GWAS},
number = {October 2019},
publisher = {Springer US},
title = {{Regulatory genomic circuitry of human disease loci by integrative epigenomics}},
url = {http://dx.doi.org/10.1038/s41586-020-03145-z},
volume = {590},
year = {2021}
}
@article{Lei2018,
abstract = {We develop a general framework for distribution-free predictive inference in regression, using conformal inference. The proposed methodology allows for the construction of a prediction band for the response variable using any estimator of the regression function. The resulting prediction band preserves the consistency properties of the original estimator under standard assumptions, while guaranteeing finite-sample marginal coverage even when these assumptions do not hold. We analyze and compare, both empirically and theoretically, the two major variants of our conformal framework: full conformal inference and split conformal inference, along with a related jackknife method. These methods offer different tradeoffs between statistical accuracy (length of resulting prediction intervals) and computational efficiency. As extensions, we develop a method for constructing valid in-sample prediction intervals called {\{}$\backslash$it rank-one-out{\}} conformal inference, which has essentially the same computational efficiency as split conformal inference. We also describe an extension of our procedures for producing prediction bands with locally varying length, in order to adapt to heteroskedascity in the data. Finally, we propose a model-free notion of variable importance, called {\{}$\backslash$it leave-one-covariate-out{\}} or LOCO inference. Accompanying this paper is an R package {\{}$\backslash$tt conformalInference{\}} that implements all of the proposals we have introduced. In the spirit of reproducibility, all of our empirical results can also be easily (re)generated using this package.},
author = {Lei, Jing and G'Sell, Max and Rinaldo, Alessandro and Tibshirani, Ryan J. and Wasserman, Larry},
doi = {10.1080/01621459.2017.1307116},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Lei et al. - 2018 - Distribution-Free Predictive Inference for Regression.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Distribution-free,Model misspecification,Prediction band,Regression,Variable importance,conformal prediction,to-skim},
mendeley-tags = {conformal prediction,to-skim},
number = {523},
pages = {1094--1111},
publisher = {Taylor {\&} Francis},
title = {{Distribution-Free Predictive Inference for Regression}},
url = {https://doi.org/10.1080/01621459.2017.1307116},
volume = {113},
year = {2018}
}
@article{Delmans2016,
abstract = {Background: The advent of high throughput RNA-seq at the single-cell level has opened up new opportunities to elucidate the heterogeneity of gene expression. One of the most widespread applications of RNA-seq is to identify genes which are differentially expressed between two experimental conditions. Results: We present a discrete, distributional method for differential gene expression (D3E), a novel algorithm specifically designed for single-cell RNA-seq data. We use synthetic data to evaluate D3E, demonstrating that it can detect changes in expression, even when the mean level remains unchanged. Since D3E is based on an analytically tractable stochastic model, it provides additional biological insights by quantifying biologically meaningful properties, such as the average burst size and frequency. We use D3E to investigate experimental data, and with the help of the underlying model, we directly test hypotheses about the driving mechanism behind changes in gene expression. Conclusion: Evaluation using synthetic data shows that D3E performs better than other methods for identifying differentially expressed genes since it is designed to take full advantage of the information available from single-cell RNA-seq experiments. Moreover, the analytical model underlying D3E makes it possible to gain additional biological insights.},
author = {Delmans, Mihails and Hemberg, Martin},
doi = {10.1186/s12859-016-0944-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Bioinformatics/Delmans, Hemberg - 2016 - Discrete distributional differential expression (D3E) - a tool for gene expression analysis of single-cell RNA.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {Differential gene expression,Single-cell RNA-seq,Software,Stochastic gene expression,Transcriptional bursting model,differential expression,single cell},
mendeley-tags = {differential expression,single cell},
number = {1},
pages = {1--13},
publisher = {BMC Bioinformatics},
title = {{Discrete distributional differential expression (D3E) - a tool for gene expression analysis of single-cell RNA-seq data}},
url = {http://dx.doi.org/10.1186/s12859-016-0944-6},
volume = {17},
year = {2016}
}
@article{Jiang2012a,
abstract = {Resampling-based methods for multiple hypothesis testing often lead to long run times when the number of tests is large. This paper presents a simple rule that substantially reduces computation by allowing resampling to terminate early on a subset of tests. We prove that the method has a low probability of obtaining a set of rejected hypotheses different from those rejected without early stopping, and obtain error bounds for multiple hypothesis testing. Simulation shows that our approach saves more computation than other available procedures.},
author = {Jiang, Hui and Salzman, Julia},
doi = {10.1093/biomet/ass051},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Jiang, Salzman - 2012 - Miscellanea Statistical properties of an early stopping rule for resampling-based multiple testing.pdf:pdf},
journal = {Biometrika},
keywords = {Early stopping,False discovery rate control,Multiple hypothesis testing,Resampling,Some key words: Bootstrap,resampling},
mendeley-tags = {resampling},
number = {4},
pages = {973--980},
title = {{Miscellanea Statistical properties of an early stopping rule for resampling-based multiple testing}},
volume = {99},
year = {2012}
}
@article{SetZ13,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23637621{\}}{\{}23637621{\}}},
author = {Schork, A J and [...] and and Zammit, S},
journal = {PLoS Genetics},
keywords = {GWAS},
mendeley-tags = {GWAS},
month = {apr},
number = {4},
pages = {e1003449},
title = {{{\{}A{\}}ll {\{}S{\}}{\{}N{\}}{\{}P{\}}s are not created equal: genome-wide association studies reveal a consistent pattern of enrichment among functionally annotated {\{}S{\}}{\{}N{\}}{\{}P{\}}s}},
volume = {9},
year = {2013}
}
@article{GR13,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21685087{\}}{\{}21685087{\}}},
author = {Golan, D and Rosset, S},
journal = {Bioinformatics},
keywords = {GWAS,linear mixed models},
mendeley-tags = {GWAS,linear mixed models},
month = {jul},
number = {13},
pages = {i317----323},
title = {{{\{}A{\}}ccurate estimation of heritability in genome wide studies using random effects models}},
volume = {27},
year = {2011}
}
@article{Y08,
author = {Yekutieli, Daniel},
doi = {10.1198/016214507000001373},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Yekutieli - 2008 - Hierarchical false discovery rate-controlling methodology.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {FDR,Multiple testing,hierarchical multiple testing},
mendeley-tags = {FDR,Multiple testing,hierarchical multiple testing},
number = {481},
pages = {309--316},
title = {{Hierarchical false discovery rate-controlling methodology}},
url = {http://dx.doi.org/10.1198/016214507000001373},
volume = {103},
year = {2008}
}
@article{Jin2019,
abstract = {The thousands of disease risk genes and loci identified through human genetic studies far outstrip our current capacity to systematically study their functions. New experimental approaches are needed for functional investigations of large panels of genes in a biologically relevant context. Here, we developed a scalable genetic screen approach, in vivo Perturb-Seq, and applied this method to the functional evaluation of 35 autism spectrum disorder (ASD) de novo loss-of-function risk genes. Using CRISPR-Cas9, we introduced frameshift mutations in these risk genes in pools, within the developing brain in utero, and then performed single-cell RNA-Seq in the postnatal brain. We identified cell type-specific gene signatures from both neuronal and glial cell classes that are affected by genetic perturbations and pointed at elements of both convergent and divergent cellular effects across this cohort of ASD risk genes. In vivo Perturb-Seq pioneers a systems genetics approach to investigate at scale how diverse mutations affect cell types and states in the biologically relevant context of the developing organism.},
author = {Jin, Xin and Simmons, Sean K and Guo, Amy X and Shetty, Ashwin S and Ko, Michelle and Nguyen, Lan and Robinson, Elise B and Oyler, Paul and Curry, Nathan and Deangeli, Giulio and Lodato, Simona and Levin, Joshua Z and Regev, Aviv and Zhang, Feng and Arlotta, Paola},
doi = {10.1101/791525},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Jin et al. - 2019 - In vivo Perturb-Seq reveals neuronal and glial abnormalities associated with Autism risk genes(2).pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Jin et al. - 2019 - In vivo Perturb-Seq reveals neuronal and glial abnormalities associated with Autism risk genes(3).pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,autism,single cell},
mendeley-tags = {CRISPR,autism,single cell},
pages = {791525},
title = {{In vivo Perturb-Seq reveals neuronal and glial abnormalities associated with Autism risk genes}},
url = {https://www.biorxiv.org/content/10.1101/791525v1},
year = {2019}
}
@article{Reilly2020,
abstract = {CRISPR screens for cis-regulatory elements (CREs) have shown unprecedented power to endogenously characterize the non-coding genome. To characterize CREs we developed HCR-FlowFISH (Hybridization Chain Reaction Fluorescent In-Situ Hybridization coupled with Flow Cytometry), which directly quantifies native transcripts within their endogenous loci following CRISPR perturbations of regulatory elements, eliminating the need for restrictive phenotypic assays such as growth or transcript-tagging. HCR-FlowFISH accurately quantifies gene expression across a wide range of transcript levels and cell types. We also developed CASA (CRISPR Activity Screen Analysis), a hierarchical Bayesian model to identify and quantify CRE activity. Using {\textgreater}270,000 perturbations, we identified CREs for GATA1, HDAC6, ERP29, LMO2, MEF2C, CD164, NMU, FEN1 and the FADS gene cluster. Our methods detect subtle gene expression changes and identify CREs regulating multiple genes, sometimes at different magnitudes and directions. We demonstrate the power of HCR-FlowFISH to parse genome-wide association signals by nominating causal variants and target genes. {\#}{\#}{\#} Competing Interest Statement PCS is a co-founder of and consultant to Sherlock Biosciences and Board Member of Danaher Corporation.},
author = {Reilly, SK and Gosai, SJ and Gutierrez, A and Ulirsch, JC and Kanai, M and Berenzy, D and Kales, S and Butler, GB and Gladden-Young, A and Finucane, HK and Sabeti, PC and Tewhey, R},
doi = {10.1101/2020.05.11.078675},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Reilly et al. - 2020 - HCR-FlowFISH A flexible CRISPR screening method to identify cis-regulatory elements and their target genes.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Reilly et al. - 2020 - HCR-FlowFISH A flexible CRISPR screening method to identify cis-regulatory elements and their target genes(2).pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Reilly et al. - 2020 - HCR-FlowFISH A flexible CRISPR screening method to identify cis-regulatory elements and their target genes(3).pdf:pdf},
keywords = {CRISPR,gene-enhancer,to-read},
mendeley-tags = {CRISPR,gene-enhancer,to-read},
pages = {1--12},
title = {{HCR-FlowFISH: A flexible CRISPR screening method to identify cis-regulatory elements and their target genes}},
year = {2020}
}
@article{Berk2019a,
abstract = {It is well known that with observational data, models used in conventional regression analyses are commonly misspecified. Yet in practice, one tends to proceed with interpretations and inferences that rely on correct specification. Even those who invoke Box's maxim that all models are wrong proceed as if results were generally useful. Misspecification, however, has implications that affect practice. Regression models are approximations to a true response surface and should be treated as such. Accordingly, regression parameters should be interpreted as statistical functionals. Importantly, the regressor distribution affects targets of estimation and regressor randomness affects the sampling variability of estimates. As a consequence, inference should be based on sandwich estimators or the pairs (x–y) bootstrap. Traditional prediction intervals lose their pointwise coverage guarantees, but empirically calibrated intervals can be justified for future populations. We illustrate the key concepts with an empirical application.},
archivePrefix = {arXiv},
arxivId = {1806.09014},
author = {Berk, Richard and Buja, Andreas and Brown, Lawrence and George, Edward and Kuchibhotla, Arun Kumar and Su, Weijie and Zhao, Linda},
doi = {10.1080/00031305.2019.1592781},
eprint = {1806.09014},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Statistician/Berk et al. - 2019 - Assumption Lean Regression.pdf:pdf},
issn = {15372731},
journal = {American Statistician},
keywords = {Foundational issues,Generalized linear models,Linear regression,Misspecified regression models,Regression functionals},
title = {{Assumption Lean Regression}},
year = {2019}
}
@article{Chong2019,
abstract = {A survey study is a research method commonly used to quantify population characteristics in biostatistics and public health research, two fields that often involve sensitive questions. However, if answering sensitive questions could cause social undesirability, respondents may not provide honest responses to questions that are asked directly. To mitigate the response distortion arising from dishonest answers to sensitive questions, the randomized response technique (RRT) is a useful and effective statistical method. However, research has seldom addressed how to apply the RRT in public health research using an online survey with multiple sensitive questions. Thus, we help fill this research gap by employing an innovative unrelated question design method. To illustrate how the RRT can be implemented in a multivariate analysis setting, we conducted a survey study to examine the factors affecting the intention of illegal waste disposal. This study demonstrates an application of the RRT to investigate the factors affecting people's intention of illegal waste disposal. The potential factors of the intention were adopted from the theory of planned behavior and the general deterrence theory, and a self-administered online questionnaire was employed to collect data. Using the RRT, a covariance matrix was extracted for examining the hypothesized model via structural equation modeling. The survey results show that people's attitude toward the behavior and their perceived behavioral control significantly positively affect their intention. This paper is useful for showing researchers and policymakers how to conduct surveys in environmental or public health related research that involves multiple sensitive questions.},
author = {Chong, Andy C.Y. and Chu, Amanda M.Y. and So, Mike K.P. and Chung, Ray S.W.},
doi = {10.3390/ijerph16060970},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/International Journal of Environmental Research and Public Health/Chong et al. - 2019 - Asking sensitive questions using the randomized response approach in public health research An empirical study on.pdf:pdf},
issn = {16604601},
journal = {International Journal of Environmental Research and Public Health},
keywords = {General deterrence theory,Online survey,Randomized response technique,Sensitive question,Solid waste charging scheme,Theory of planned behavior,Unrelated question design,causality,error-in-variables},
mendeley-tags = {causality,error-in-variables},
number = {6},
title = {{Asking sensitive questions using the randomized response approach in public health research: An empirical study on the factors of illegal waste disposal}},
volume = {16},
year = {2019}
}
@article{SMS16,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26715671{\}}{\{}26715671{\}}},
author = {Skelly, D A and Magwene, P M and Stone, E A},
journal = {Genetics},
keywords = {applied,genetics},
mendeley-tags = {applied,genetics},
month = {feb},
number = {2},
pages = {427--437},
title = {{{\{}S{\}}poradic, {\{}G{\}}lobal {\{}L{\}}inkage {\{}D{\}}isequilibrium {\{}B{\}}etween {\{}U{\}}nlinked {\{}S{\}}egregating {\{}S{\}}ites}},
volume = {202},
year = {2016}
}
@article{LL10,
abstract = {There is solid evidence that rare variants contribute to complex disease etiology. Next-generation sequencing technologies make it possible to uncover rare variants within candidate genes, exomes, and genomes. Working in a novel framework, the kernel-based adaptive cluster (KBAC) was developed to perform powerful gene/locus based rare variant association testing. The KBAC combines variant classification and association testing in a coherent framework. Covariates can also be incorporated in the analysis to control for potential confounders including age, sex, and population substructure. To evaluate the power of KBAC: 1) variant data was simulated using rigorous population genetic models for both Europeans and Africans, with parameters estimated from sequence data, and 2) phenotypes were generated using models motivated by complex diseases including breast cancer and Hirschsprung's disease. It is demonstrated that the KBAC has superior power compared to other rare variant analysis methods, such as the combined multivariate and collapsing and weight sum statistic. In the presence of variant misclassification and gene interaction, association testing using KBAC is particularly advantageous. The KBAC method was also applied to test for associations, using sequence data from the Dallas Heart Study, between energy metabolism traits and rare variants in ANGPTL 3,4,5 and 6 genes. A number of novel associations were identified, including the associations of high density lipoprotein and very low density lipoprotein with ANGPTL4. The KBAC method is implemented in a user-friendly R package.},
annote = {20976247},
author = {Liu, Dajiang J and Leal, Suzanne M},
journal = {PLoS Genetics},
pages = {e1001156--e1001156},
title = {{{\{}A{\}} Novel Adaptive Method for the Analysis of Next-generation Sequencing data to Detect Complex Trait Associations with rare Variants due to gene main Effects and Interactions}},
volume = {6},
year = {2010}
}
@article{Rajarajan2018,
abstract = {To explore the developmental reorganization of the three-dimensional genome of the brain in the context of neuropsychiatric disease, we monitored chromosomal conformations in differentiating neural progenitor cells. Neuronal and glial differentiation was associated with widespread developmental remodeling of the chromosomal contact map and included interactions anchored in common variant sequences that confer heritable risk for schizophrenia. We describe cell type–specific chromosomal connectomes composed of schizophrenia risk variants and their distal targets, which altogether show enrichment for genes that regulate neuronal connectivity and chromatin remodeling, and evidence for coordinated transcriptional regulation and proteomic interaction of the participating genes. Developmentally regulated chromosomal conformation changes at schizophrenia-relevant sequences disproportionally occurred in neurons, highlighting the existence of cell type–specific disease risk vulnerabilities in spatial genome organization.},
author = {Rajarajan, Prashanth and Borrman, Tyler and Liao, Will and Schrode, Nadine and Flaherty, Erin and Casi{\~{n}}o, Charlize and Powell, Samuel and Yashaswini, Chittampalli and LaMarca, Elizabeth A. and Kassim, Bibi and Javidfar, Behnam and Espeso-Gil, Sergio and Li, Aiqun and Won, Hyejung and Geschwind, Daniel H. and Ho, Seok Man and MacDonald, Matthew and Hoffman, Gabriel E. and Roussos, Panos and Zhang, Bin and Hahn, Chang Gyu and Weng, Zhiping and Brennand, Kristen J. and Akbarian, Schahram},
doi = {10.1126/science.aat4311},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Rajarajan et al. - 2018 - Neuron-specific signatures in the chromosomal connectome associated with schizophrenia risk.pdf:pdf},
issn = {10959203},
journal = {Science},
keywords = {HI-C,Kathryn,gene-enhancer,genetics},
mendeley-tags = {HI-C,Kathryn,gene-enhancer,genetics},
number = {6420},
title = {{Neuron-specific signatures in the chromosomal connectome associated with schizophrenia risk}},
volume = {362},
year = {2018}
}
@article{Nagano2013,
abstract = {Large-scale chromosome structure and spatial nuclear arrangement have been linked to control of gene expression and DNA replication and repair. Genomic techniques based on chromosome conformation capture (3C) assess contacts for millions of loci simultaneously, but do so by averaging chromosome conformations from millions of nuclei. Here we introduce single-cell Hi-C, combined with genome-wide statistical analysis and structural modelling of single-copy X chromosomes, to show that individual chromosomes maintain domain organization at the megabase scale, but show variable cell-to-cell chromosome structures at larger scales. Despite this structural stochasticity, localization of active gene domains to boundaries of chromosome territories is a hallmark of chromosomal conformation. Single-cell Hi-C data bridge current gaps between genomics and microscopy studies of chromosomes, demonstrating how modular organization underlies dynamic chromosome structure, and how this structure is probabilistically linked with genome activity patterns. {\textcopyright} 2013 Macmillan Publishers Limited. All rights reserved.},
author = {Nagano, Takashi and Lubling, Yaniv and Stevens, Tim J. and Schoenfelder, Stefan and Yaffe, Eitan and Dean, Wendy and Laue, Ernest D. and Tanay, Amos and Fraser, Peter},
doi = {10.1038/nature12593},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Nagano et al. - 2013 - Single-cell Hi-C reveals cell-to-cell variability in chromosome structure.pdf:pdf},
issn = {00280836},
journal = {Nature},
number = {7469},
pages = {59--64},
pmid = {24067610},
publisher = {Nature Publishing Group},
title = {{Single-cell Hi-C reveals cell-to-cell variability in chromosome structure}},
volume = {502},
year = {2013}
}
@article{Ignatiadis2018,
abstract = {A fundamental task in the analysis of datasets with many variables is screening for associations. This can be cast as a multiple testing task, where the major challenge is achieving high detection power while controlling type I error. We consider m hypothesis tests represented by pairs ((P i , X i)) 1≤i≤m of p-values P i and covariates X i , such that P i ⊥ X i under the null hypothesis. Here, we show how to use information potentially available in the covariates about heterogeneities among hypotheses to increase power compared to conventional procedures that only use the P i. To this end, we upgrade existing weighted multiple testing procedures through the Independent Hypothesis Weighting (IHW) framework to use data-driven weights which are a function of the covariate X i. Finite sample guarantees, e.g. false discovery rate (FDR) control, are derived from cross-weighting, a novel data-splitting approach that enables learning the weight-covariate function without overfitting as long as the hypotheses can be partitioned into independent folds, with arbitrary within-fold dependence. We show how the increased power of IHW can be understood in terms of the conditional two-groups model. A key implication of IHW is that hypothesis rejection in many common multiple testing setups should not proceed according to the ranking of the p-values, but by an alternative ranking implied by the covariate-weighted p-values. See Version 2 on arXiv (https://arxiv.org/abs/1701.05179v2) for a more disquisitional exposition .},
archivePrefix = {arXiv},
arxivId = {1701.05179v3},
author = {Ignatiadis, Nikolaos and Huber, Wolfgang and Heidelberg, Embl},
eprint = {1701.05179v3},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Ignatiadis, Huber, Heidelberg - 2018 - Covariate powered cross-weighted multiple testing.pdf:pdf},
journal = {arXiv},
keywords = {Benjamini-Hochberg,Empirical Bayes,False Discovery Rate,Independent Hypothesis Weighting,Multiple Testing,Multiple testing,p-value weighting,to-skim,unpublished,weighted multiple testing},
mendeley-tags = {Multiple testing,to-skim,unpublished,weighted multiple testing},
title = {{Covariate powered cross-weighted multiple testing}},
url = {https://arxiv.org/abs/1701.05179v2},
year = {2018}
}
@article{CetS15,
author = {Chernozhukov, Victor and Hansen, Christian and Spindler, Martin},
journal = {Annu. Rev. Econ.},
keywords = {post-selection inference},
mendeley-tags = {post-selection inference},
number = {1},
pages = {649--688},
publisher = {Annual Reviews},
title = {{Valid post-selection and post-regularization inference: An elementary, general approach}},
volume = {7},
year = {2015}
}
@misc{ptycho,
annote = {$\backslash$url{\{}https://cran.r-project.org/web/packages/ptycho/index.html{\}} [Accessed: 2016]},
author = {Stell, L},
keywords = {genetics,high-dimensional regression,software},
mendeley-tags = {genetics,high-dimensional regression,software},
title = {{{\{}$\backslash$tt ptycho{\}}: Bayesian Variable Selection with Hierarchical Priors}},
year = {2015}
}
@article{PetS16e,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/27153635{\}}{\{}27153635{\}}},
author = {Peterson, C B and Bogomolov, M and Benjamini, Y and Sabatti, C},
journal = {Bioinformatics},
number = {16},
pages = {2556--2558},
title = {{{\{}T{\}}ree{\{}Q{\}}{\{}T{\}}{\{}L{\}}: hierarchical error control for e{\{}Q{\}}{\{}T{\}}{\{}L{\}} findings}},
volume = {32},
year = {2016}
}
@article{Janssen2000,
abstract = {It is shown that the global power function of any nonparametric test is flat on balls of alternatives except for alternatives coming from a finite dimensional subspace. The present benchmark is here the upper one-sided (or two-sided) envelope power function. Every choice of a test fixes a priori a finite dimensional region with high power. It turns out that also the level points are far away from the corresponding Neyman-Pearson test level points except for a finite number of orthogonal directions of alternatives. For certain submodels the result is independent of the underlying sample size In the last section the statistical consequences and special goodness of fit tests are discussed.},
author = {Janssen, Arnold},
doi = {10.1214/aos/1016120371},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Janssen - 2000 - Global power functions of goodness of fit tests.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Bahadur efficiency,Curvature of power functions,Data driven Neyman's smooth test,Envelope power function,Goodness of fit test,Intermediate efficiency,Kolmogorov-Smirnov test,Leve points,Pitman efficiency,Power function},
number = {1},
pages = {239--253},
title = {{Global power functions of goodness of fit tests}},
volume = {28},
year = {2000}
}
@article{Fullwood2009,
abstract = {Genomes are organized into high-level three-dimensional structures, and DNA elements separated by long genomic distances can in principle interact functionally. Many transcription factors bind to regulatory DNA elements distant from gene promoters. Although distal binding sites have been shown to regulate transcription by long-range chromatin interactions at a few loci, chromatin interactions and their impact on transcription regulation have not been investigated in a genome-wide manner. Here we describe the development of a new strategy, chromatin interaction analysis by paired-end tag sequencing (ChIA-PET) for the de novo detection of global chromatin interactions, with which we have comprehensively mapped the chromatin interaction network bound by oestrogen receptor alpha (ER-alpha) in the human genome. We found that most high-confidence remote ER-alpha-binding sites are anchored at gene promoters through long-range chromatin interactions, suggesting that ER-alpha functions by extensive chromatin looping to bring genes together for coordinated transcriptional regulation. We propose that chromatin interactions constitute a primary mechanism for regulating transcription in mammalian genomes.},
author = {Fullwood, Melissa J. and Liu, Mei Hui and Pan, You Fu and Liu, Jun and Xu, Han and Mohamed, Yusoff Bin and Orlov, Yuriy L. and Velkov, Stoyan and Ho, Andrea and Mei, Poh Huay and Chew, Elaine G.Y. and Huang, Phillips Yao Hui and Welboren, Willem Jan and Han, Yuyuan and Ooi, Hong Sain and Ariyaratne, Pramila N. and Vega, Vinsensius B. and Luo, Yanquan and Tan, Peck Yean and Choy, Pei Ye and Wansa, K. D.Senali Abayratna and Zhao, Bing and Lim, Kar Sian and Leow, Shi Chi and Yow, Jit Sin and Joseph, Roy and Li, Haixia and Desai, Kartiki V. and Thomsen, Jane S. and Lee, Yew Kok and Karuturi, R. Krishna Murthy and Herve, Thoreau and Bourque, Guillaume and Stunnenberg, Hendrik G. and Ruan, Xiaoan and Cacheux-Rataboul, Valere and Sung, Wing Kin and Liu, Edison T. and Wei, Chia Lin and Cheung, Edwin and Ruan, Yijun},
doi = {10.1038/nature08497},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Fullwood et al. - 2009 - An oestrogen-receptor-$\alpha$-bound human chromatin interactome.pdf:pdf},
issn = {00280836},
journal = {Nature},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {7269},
pages = {58--64},
title = {{An oestrogen-receptor-$\alpha$-bound human chromatin interactome}},
url = {http://cms1.gis.a-star.edu.sg},
volume = {462},
year = {2009}
}
@article{Sanjana2017,
abstract = {Genome editing technologies such as clustered regularly interspaced short palindromic repeats (CRISPR) systems have ushered in a new era of targeted DNA manipulation. The easy programmability of CRISPR using short oligonucleotides enables rapid synthesis of large-scale libraries for functional genetic screens. Here we present fundamental concepts and methods for pooled CRISPR screens and review biological results from recent genome-scale loss-of-function and gain-of-function screens. We also discuss new frontiers in pooled screens, including novel effector domains for functional screens and applications in the noncoding genome.},
author = {Sanjana, Neville E.},
doi = {10.1016/j.ab.2016.05.014},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Analytical Biochemistry/Sanjana - 2017 - Genome-scale CRISPR pooled screens.pdf:pdf},
issn = {10960309},
journal = {Analytical Biochemistry},
keywords = {CRISPR,Cancer,Cas9,Genetic screens,Genome engineering,Kathryn,Noncoding},
mendeley-tags = {CRISPR,Kathryn},
pages = {95--99},
publisher = {Elsevier Inc},
title = {{Genome-scale CRISPR pooled screens}},
url = {http://dx.doi.org/10.1016/j.ab.2016.05.014},
volume = {532},
year = {2017}
}
@article{Jiang2012,
author = {Jiang, H U I and Salzman, Julia},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Jiang, Salzman - 2012 - Statistical properties of an early stopping rule for resampling-based multiple testing.pdf:pdf},
journal = {Biometrika},
keywords = {Monte Carlo,Multiple testing},
mendeley-tags = {Monte Carlo,Multiple testing},
number = {4},
pages = {973--980},
title = {{Statistical properties of an early stopping rule for resampling-based multiple testing}},
volume = {99},
year = {2012}
}
@article{Wang2018b,
abstract = {Genome-wide epigenomic maps have revealed millions of putative enhancers and promoters, but experimental validation of their function and high-resolution dissection of their driver nucleotides remain limited. Here, we present HiDRA (High-resolution Dissection of Regulatory Activity), a combined experimental and computational method for high-resolution genome-wide testing and dissection of putative regulatory regions. We test {\~{}}7 million accessible DNA fragments in a single experiment, by coupling accessible chromatin extraction with self-transcribing episomal reporters (ATAC-STARR-seq). By design, fragments are highly overlapping in densely-sampled accessible regions, enabling us to pinpoint driver regulatory nucleotides by exploiting differences in activity between partially-overlapping fragments using a machine learning model (SHARPR-RE). In GM12878 lymphoblastoid cells, we find {\~{}}65,000 regions showing enhancer function, and pinpoint {\~{}}13,000 high-resolution driver elements. These are enriched for regulatory motifs, evolutionarily-conserved nucleotides, and disease-associated genetic variants from genome-wide association studies. Overall, HiDRA provides a high-throughput, high-resolution approach for dissecting regulatory regions and driver nucleotides.},
author = {Wang, Xinchen and He, Liang and Goggin, Sarah M. and Saadat, Alham and Wang, Li and Sinnott-Armstrong, Nasa and Claussnitzer, Melina and Kellis, Manolis},
doi = {10.1038/s41467-018-07746-1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Wang et al. - 2018 - High-resolution genome-wide functional dissection of transcriptional regulatory regions and nucleotides in human.pdf:pdf},
issn = {20411723},
journal = {Nature Communications},
keywords = {Kathryn,gene-enhancer,genetics},
mendeley-tags = {Kathryn,gene-enhancer,genetics},
number = {1},
publisher = {Springer US},
title = {{High-resolution genome-wide functional dissection of transcriptional regulatory regions and nucleotides in human}},
url = {http://dx.doi.org/10.1038/s41467-018-07746-1},
volume = {9},
year = {2018}
}
@book{FisherBook,
author = {Fisher, R A},
keywords = {canonical},
mendeley-tags = {canonical},
publisher = {Oliver and Boyd, Edinburgh},
title = {{Statistical methods for research workers}},
year = {1925}
}
@article{Finak2015,
abstract = {Single-cell transcriptomics reveals gene expression heterogeneity but suffers from stochastic dropout and characteristic bimodal expression distributions in which expression is either strongly non-zero or non-detectable. We propose a two-part, generalized linear model for such bimodal data that parameterizes both of these features. We argue that the cellular detection rate, the fraction of genes expressed in a cell, should be adjusted for as a source of nuisance variation. Our model provides gene set enrichment analysis tailored to single-cell data. It provides insights into how networks of co-expressed genes evolve across an experimental treatment. MAST is available at https://github.com/RGLab/MAST.},
author = {Finak, Greg and McDavid, Andrew and Yajima, Masanao and Deng, Jingyuan and Gersuk, Vivian and Shalek, Alex K. and Slichter, Chloe K. and Miller, Hannah W. and McElrath, M. Juliana and Prlic, Martin and Linsley, Peter S. and Gottardo, Raphael},
doi = {10.1186/s13059-015-0844-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Finak et al. - 2015 - MAST A flexible statistical framework for assessing transcriptional changes and characterizing heterogeneity in si.pdf:pdf},
issn = {1474760X},
journal = {Genome Biology},
keywords = {Bimodality,Cellular detection rate,Co-expression,Empirical Bayes,Gene set enrichment analysis,Generalized linear model,single cell},
mendeley-tags = {single cell},
number = {1},
pages = {1--13},
pmid = {26653891},
publisher = {Genome Biology},
title = {{MAST: A flexible statistical framework for assessing transcriptional changes and characterizing heterogeneity in single-cell RNA sequencing data}},
url = {http://dx.doi.org/10.1186/s13059-015-0844-5},
volume = {16},
year = {2015}
}
@article{Chernozhukov2018,
abstract = {We revisit the classic semi-parametric problem of inference on a low-dimensional parameter $\theta$0 in the presence of high-dimensional nuisance parameters $\eta$0. We depart from the classical setting by allowing for $\eta$0 to be so high-dimensional that the traditional assumptions (e.g. Donsker properties) that limit complexity of the parameter space for this object break down. To estimate $\eta$0, we consider the use of statistical or machine learning (ML) methods, which are particularly well suited to estimation in modern, very high-dimensional cases. ML methods perform well by employing regularization to reduce variance and trading off regularization bias with overfitting in practice. However, both regularization bias and overfitting in estimating $\eta$0 cause a heavy bias in estimators of $\theta$0 that are obtained by naively plugging ML estimators of $\eta$0 into estimating equations for $\theta$0. This bias results in the naive estimator failing to be N-1/2 consistent, where N is the sample size. We show that the impact of regularization bias and overfitting on estimation of the parameter of interest $\theta$0 can be removed by using two simple, yet critical, ingredients: (1) using Neyman-orthogonal moments/scores that have reduced sensitivity with respect to nuisance parameters to estimate $\theta$0; (2) making use of cross-fitting, which provides an efficient form of data-splitting. We call the resulting set of methods double or debiased ML (DML). We verify that DML delivers point estimators that concentrate in an N-1 -neighbourhood of the true parameter values and are approximately unbiased and normally distributed, which allows construction of valid confidence statements. The generic statistical theory of DML is elementary and simultaneously relies on only weak theoretical requirements, which will admit the use of a broad array of modern ML methods for estimating the nuisance parameters, such as random forests, lasso, ridge, deep neural nets, boosted trees, and various hybrids and ensembles of these methods. We illustrate the general theory by applying it to provide theoretical properties of the following: DML applied to learn the main regression parameter in a partially linear regression model; DML applied to learn the coefficient on an endogenous variable in a partially linear instrumental variables model; DML applied to learn the average treatment effect and the average treatment effect on the treated under unconfoundedness; DML applied to learn the local average treatment effect in an instrumental variables setting. In addition to these theoretical applications, we also illustrate the use of DML in three empirical examples.},
author = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
doi = {10.1111/ectj.12097},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Econometrics Journal/Chernozhukov et al. - 2018 - Doubledebiased machine learning for treatment and structural parameters.pdf:pdf},
issn = {1368423X},
journal = {Econometrics Journal},
number = {1},
pages = {C1--C68},
title = {{Double/debiased machine learning for treatment and structural parameters}},
volume = {21},
year = {2018}
}
@article{Mikhaylichenko2018a,
abstract = {Gene expression is regulated by promoters, which initiate transcription, and enhancers, which control their temporal and spatial activity. However, the discovery that mammalian enhancers also initiate transcription questions the inherent differences between enhancers and promoters. Here, we investigate the transcriptional properties of enhancers during Drosophila embryogenesis using characterized developmental enhancers. We show that while the timing of enhancer transcription is generally correlated with enhancer activity, the levels and directionality of transcription are highly varied among active enhancers. To assess how this impacts function, we developed a dual transgenic assay to simultaneously measure enhancer and promoter activities from a single element in the same embryo. Extensive transgenic analysis revealed a relationship between the direction of endogenous transcription and the ability to function as an enhancer or promoter in vivo, although enhancer RNA (eRNA) production and activity are not always strictly coupled. Some enhancers (mainly bidirectional) can act as weak promoters, producing overlapping spatio-temporal expression. Conversely, bidirectional promoters often act as strong enhancers, while unidirectional promoters generally cannot. The balance between enhancer and promoter activity is generally reflected in the levels and directionality of eRNA transcription and is likely an inherent sequence property of the elements themselves.},
author = {Mikhaylichenko, Olga and Bondarenko, Vladyslav and Harnett, Dermot and Schor, Ignacio E. and Males, Matilda and Viales, Rebecca R. and Furlong, Eileen E.M.},
doi = {10.1101/gad.308619.117},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genes and Development/Mikhaylichenko et al. - 2018 - The degree of enhancer or promoter activity is reflected by the levels and directionality of eRNA tran(2).pdf:pdf},
issn = {15495477},
journal = {Genes and Development},
keywords = {Developmental enhancers,ERNA,Embryonic development],Kathryn,NcRNA,Promoters,Spatio,Temporal expression,eRNA,enhancer},
mendeley-tags = {Kathryn,eRNA,enhancer},
month = {jan},
number = {1},
pages = {42--57},
publisher = {Cold Spring Harbor Laboratory Press},
title = {{The degree of enhancer or promoter activity is reflected by the levels and directionality of eRNA transcription}},
volume = {32},
year = {2018}
}
@article{CetS15bayes,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25948564{\}}{\{}25948564{\}}},
author = {Chen, W and Larrabee, B R and Ovsyannikova, I G and Kennedy, R B and Haralambieva, I H and Poland, G A and Schaid, D J},
journal = {Genetics},
keywords = {fine mapping,genetics},
mendeley-tags = {fine mapping,genetics},
month = {jul},
number = {3},
pages = {719--736},
title = {{{\{}F{\}}ine {\{}M{\}}apping {\{}C{\}}ausal {\{}V{\}}ariants with an {\{}A{\}}pproximate {\{}B{\}}ayesian {\{}M{\}}ethod {\{}U{\}}sing {\{}M{\}}arginal {\{}T{\}}est {\{}S{\}}tatistics}},
volume = {200},
year = {2015}
}
@article{BY05j,
author = {Benjamini, Yoav and Yekutieli, Daniel},
doi = {10.1198/016214504000001907},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Multiple testing,canonical,confidence intervals},
mendeley-tags = {Multiple testing,canonical,confidence intervals},
number = {469},
pages = {71--93},
title = {{False discovery rate-adjusted multiple confidence intervals for selected parameters}},
url = {http://dx.doi.org/10.1198/016214504000001907},
volume = {100},
year = {2005}
}
@phdthesis{C14_thesis,
author = {Chouldechova, Alexandra},
keywords = {FDR,spatial data},
mendeley-tags = {FDR,spatial data},
school = {PhD thesis, Stanford University},
title = {{False discovery rate control for spatial data}},
year = {2014}
}
@article{NMR14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/24816252{\}}{\{}24816252{\}}},
author = {Shin, S Y and Fauman, E B and Petersen, A K and Krumsiek, J and Santos, R and Huang, J and Arnold, M and Erte, I and Forgetta, V and Yang, T P and Walter, K and Menni, C and Chen, L and Vasquez, L and Valdes, A M and Hyde, C L and Wang, V and Ziemek, D and Roberts, P and Xi, L and Grundberg, E and Waldenberger, M and Richards, J B and Mohney, R P and Milburn, M V and John, S L and Trimmer, J and Theis, F J and Overington, J P and Suhre, K and Brosnan, M J and Gieger, C and Kastenmuller, G and Spector, T D and Soranzo, N},
journal = {Nature Genetics},
month = {jun},
number = {6},
pages = {543--550},
title = {{{\{}A{\}}n atlas of genetic influences on human blood metabolites}},
volume = {46},
year = {2014}
}
@article{FC16,
archivePrefix = {arXiv},
arxivId = {stat.ME/1602.03574},
author = {{Foygel Barber}, R and Cand{\`{e}}s, E.{\~{}}J.},
eprint = {1602.03574},
journal = {arXiv},
keywords = {Mathematics - Statistics Theory,Multiple testing,Statistics - Methodology,knockoffs,unpublished},
mendeley-tags = {Multiple testing,knockoffs,unpublished},
month = {feb},
primaryClass = {stat.ME},
title = {{A knockoff filter for high-dimensional selective inference}},
year = {2016}
}
@article{LeCam1960,
author = {{Le Cam}, Lucien},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Univ. California Publ. Stat/Le Cam - 1960 - Locally asymptotically normal families of distributions.pdf:pdf},
journal = {Univ. California Publ. Stat.},
keywords = {asymptotics,monography experiment,statistics},
mendeley-tags = {asymptotics},
pages = {37--98},
title = {{Locally asymptotically normal families of distributions}},
volume = {3},
year = {1960}
}
@article{Cong2013,
abstract = {Functional elucidation of causal genetic variants and elements requires precise genome editing technologies. The type II prokaryotic CRISPR (clustered regularly interspaced short palindromic repeats)/Cas adaptive immune system has been shown to facilitate RNA-guided site-specific DNA cleavage. We engineered two different type II CRISPR/Cas systems and demonstrate that Cas9 nucleases can be directed by short RNAs to induce precise cleavage at endogenous genomic loci in human and mouse cells. Cas9 can also be converted into a nicking enzyme to facilitate homology-directed repair with minimal mutagenic activity. Lastly, multiple guide sequences can be encoded into a single CRISPR array to enable simultaneous editing of several sites within the mammalian genome, demonstrating easy programmability and wide applicability of the RNA-guided nuclease technology.},
author = {Cong, Le and Ran, F. Ann and Cox, David and Lin, Shuailiang and Barretto, Robert and Habib, Naomi and Hsu, Patrick D. and Wu, Xuebing and Jiang, Wenyan and Marraffini, Luciano A. and Zhang, Feng},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Cong et al. - 2013 - Multiplex Genome Engineering Using CRISPRCas Systems.pdf:pdf},
journal = {Science},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
pages = {819--823},
title = {{Multiplex Genome Engineering Using CRISPR/Cas Systems}},
volume = {339},
year = {2013}
}
@article{Hemerik2019a,
abstract = {Generalized linear models are often misspecified due to overdispersion, heteroscedasticity and ignored nuisance variables. Existing quasi-likelihood methods for testing in misspecified models often do not provide satisfactory type-I error rate control. We provide a novel semi-parametric test, based on sign-flipping individual score contributions. The tested parameter is allowed to be multi-dimensional and even high-dimensional. Our test is often robust against the mentioned forms of misspecification and provides better type-I error control than its competitors. When nuisance parameters are estimated, our basic test becomes conservative. We show how to take nuisance estimation into account to obtain an asymptotically exact test. Our proposed test is asymptotically equivalent to its parametric counterpart.},
archivePrefix = {arXiv},
arxivId = {1909.03796},
author = {Hemerik, Jesse and Goeman, Jelle J and Finos, Livio},
eprint = {1909.03796},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Hemerik, Goeman, Finos - 2019 - Robust testing in generalized linear models by sign-flipping score contributions.pdf:pdf},
journal = {arXiv},
keywords = {Multiple testing,glm,high-dimensional,permutation,robust,score,semi-parametric,sign-flipping,test,to-skim},
mendeley-tags = {Multiple testing,to-skim},
title = {{Robust testing in generalized linear models by sign-flipping score contributions}},
url = {http://arxiv.org/abs/1909.03796},
year = {2019}
}
@article{SetT10,
annote = {20197096},
author = {Stein, J L and Hua, X and Morra, J H and Lee, S and Hibar, D P and Ho, A J and Leow, A D and Toga, A W and Sul, J H and Kang, H M and Eskin, E and Saykin, A J and Shen, L and Foroud, T and Pankratz, N and Huentelman, M J and Craig, D W and Gerber, J D and Allen, A N and Corneveaux, J J and Stephan, D A and Webster, J and DeChairo, B M and Potkin, S G and Jack, C R and Weiner, M W and Thompson, P M},
journal = {Neuroimage},
month = {jun},
pages = {542--554},
title = {{{\{}G{\}}enome-wide analysis reveals novel genes influencing temporal lobe structure with relevance to neurodegeneration in {\{}A{\}}lzheimer's disease}},
volume = {51},
year = {2010}
}
@article{BetK02,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/11923494{\}}{\{}11923494{\}}},
author = {Brem, R B and Yvert, G and Clinton, R and Kruglyak, L},
journal = {Science},
keywords = {genetics},
mendeley-tags = {genetics},
month = {apr},
number = {5568},
pages = {752--755},
title = {{Genetic dissection of transcriptional regulation in budding yeast}},
volume = {296},
year = {2002}
}
@article{Gaffney2019,
abstract = {A new study presents a powerful experimental approach, CRISPRi-FlowFISH, for mapping regulatory interactions, and uses it to characterize thousands of putative enhancer–gene pairs. The results suggest that most current approaches for predicting enhancer–gene interactions perform poorly, but a simple mathematical model combining distance with enhancer activity shows promise.},
author = {Gaffney, Daniel J},
doi = {10.1038/s41588-019-0540-6},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Gaffney - 2019 - Mapping and predicting gene – enhancer.pdf:pdf},
issn = {1546-1718},
journal = {Nature Genetics},
keywords = {CRISPR,gene regulation,gene-enhancer,genetics},
mendeley-tags = {CRISPR,gene regulation,gene-enhancer,genetics},
pages = {1662--1663},
publisher = {Springer US},
title = {{Mapping and predicting gene – enhancer}},
url = {http://dx.doi.org/10.1038/s41588-019-0540-6},
volume = {51},
year = {2019}
}
@article{Rosenbaum1984,
abstract = {In observational studies, the distribution of treatment assignments is unknown, and therefore randomization tests are not generally applicable. However, permutation tests that condition on sample information about the treatment assignment mechanism can be applicable in observational studies, provided treatment assignment is strongly ignorable. These tests use the conditional distribution of the treatment assignments given a sufficient statistic for the unknown parameter of the propensity score. Several tests that are commonly used in observational studies are particular instances of this general procedure. Moreover, conditional permutation tests and covariance adjustment are closely related, in the sense that the conditional permutation distribution of the covariance adjusted difference leads to the same inferences as the conditional permutation distribution of the unadjusted difference of sample means. A backtrack algorithm is developed to permit efficient calculation of the exact conditional significance level, and two approximations are discussed. A clinical study of treatments for lung cancer is used to illustrate the technique. Conditional permutation tests extend previous large sample results on the propensity score by providing a basis for exact tests and confidence intervals in small observational studies when treatment assignment is strongly ignorable. {\textcopyright} 1984 Taylor {\&} Francis Group, LLC.},
author = {Rosenbaum, Paul R.},
doi = {10.1080/01621459.1984.10478082},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Rosenbaum - 1984 - Conditional permutation tests and the propensity score in observational studies.pdf:pdf},
issn = {1537274X},
journal = {Journal of the American Statistical Association},
keywords = {Conditional inference,Ignorable treatment assignment,Logistic models,Observational studies,Randomization tests},
number = {387},
pages = {565--574},
title = {{Conditional permutation tests and the propensity score in observational studies}},
volume = {79},
year = {1984}
}
@article{HZZ10,
annote = {21931466},
author = {Hu, J and Zhao, H and H., Zhou},
journal = {Journal of the American Statistical Association},
keywords = {FDR,groups},
mendeley-tags = {FDR,groups},
pages = {1215--1227},
title = {{False Discovery Rate Control With Groups}},
volume = {105},
year = {2010}
}
@article{Gandy2016,
abstract = {We are concerned with a situation in which we would like to test multiple hypotheses with tests whose p-values cannot be computed explicitly but can be approximated using Monte Carlo simulation. This scenario occurs widely in practice. We are interested in obtaining the same rejections and non-rejections as the ones obtained if the p-values for all hypotheses had been available. The present article introduces a framework for this scenario by providing a generic algorithm for a general multiple testing procedure. We establish conditions which guarantee that the rejections and non-rejections obtained through Monte Carlo simulations are identical to the ones obtained with the p-values. Our framework is applicable to a general class of step-up and step-down procedures which includes many established multiple testing corrections such as the ones of Bonferroni, Holm, Sidak, Hochberg or Benjamini-Hochberg. Moreover, we show how to use our framework to improve algorithms available in the literature in such a way as to yield theoretical guarantees on their results. These modifications can easily be implemented in practice and lead to a particular way of reporting multiple testing results as three sets together with an error bound on their correctness, demonstrated exemplarily using a real biological dataset.},
author = {Gandy, Axel and Hahn, Georg},
doi = {10.1111/sjos.12228},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Scandinavian Journal of Statistics/Gandy, Hahn - 2016 - A Framework for Monte Carlo based Multiple Testing.pdf:pdf},
issn = {14679469},
journal = {Scandinavian Journal of Statistics},
keywords = {Monte Carlo,algorithm,framework,hypothesis testing,multiple testing,multiple testing procedure,p-value},
mendeley-tags = {Monte Carlo,multiple testing},
number = {4},
pages = {1046--1063},
title = {{A Framework for Monte Carlo based Multiple Testing}},
volume = {43},
year = {2016}
}
@article{CetL16,
author = {Cand{\`{e}}s, Emmanuel and Fan, Yingying and Janson, Lucas and Lv, Jinchi},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society Series B (Statistical Methodology)/Cand{\`{e}}s et al. - 2018 - Panning for gold `model-X' knockoffs for high dimensional controlled variable selection.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,Multiple testing,high-dimensional regression,knockoffs,model-X,variable selection},
mendeley-tags = {FDR,Multiple testing,high-dimensional regression,knockoffs,model-X,variable selection},
number = {3},
pages = {551--577},
publisher = {Wiley Online Library},
title = {{Panning for gold: `model-X' knockoffs for high dimensional controlled variable selection}},
volume = {80},
year = {2018}
}
@article{AL11,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/22009793{\}}{\{}22009793{\}}},
author = {Alexander, D H and Lange, K},
journal = {Genetic Epidemiology},
keywords = {GWAS,high-dimensional regression,stability selection},
mendeley-tags = {GWAS,high-dimensional regression,stability selection},
month = {nov},
number = {7},
pages = {722--728},
title = {{{\{}S{\}}tability selection for genome-wide association}},
volume = {35},
year = {2011}
}
@article{meijer2017shortcut,
author = {Meijer, R and Krebs, R and Solari, A and Goeman, J},
journal = {arXiv},
keywords = {Multiple testing,simultaneous inference,unpublished},
mendeley-tags = {Multiple testing,simultaneous inference,unpublished},
title = {{A shortcut for {\{}H{\}}ommel's procedure in linearithmic time}},
year = {2017}
}
@article{Kim2020,
abstract = {When data analysts train a classifier and check if its accuracy is significantly different from a half, they are implicitly performing a two-sample test. We investigate the statistical optimality of this indirect but flexible method in the high-dimensional setting of {\$}d/n \backslashto c \backslashin (0,\backslashinfty){\$}. We provide a concrete answer for the case of distinguishing Gaussians with mean-difference {\$}\backslashdelta{\$} and common (known or unknown) covariance {\$}\backslashSigma{\$}, by contrasting the indirect approach using variants of linear discriminant analysis (LDA) such as naive Bayes, with the direct approach using corresponding variants of Hotelling's test. Somewhat surprisingly, the indirect approach achieves the same power as the direct approach in terms of {\$}n,d,\backslashdelta,\backslashSigma{\$}, and is only worse by a constant factor, achieving an asymptotic relative efficiency of {\$}1/\backslashpi{\$} for the balanced sample case. Other results of independent interest are provided, such as minimax lower bounds, and optimality of Hotelling's test when {\$}d=o(n){\$}. Simulation results validate our theory, and we present practical takeaway messages along with several open problems.},
archivePrefix = {arXiv},
arxivId = {1602.02210},
author = {Kim, Ilmun and Ramdas, Aaditya and Singh, Aarti and Wasserman, Larry},
eprint = {1602.02210},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics, to appear/Kim et al. - 2020 - Classification accuracy as a proxy for two sample testing.pdf:pdf},
journal = {Annals of Statistics, to appear},
title = {{Classification accuracy as a proxy for two sample testing}},
url = {http://arxiv.org/abs/1602.02210},
year = {2020}
}
@article{Besag1991,
abstract = {The assessment of statistical significance by Monte Carlo simulation may be costly in computer time. This paper looks at a number of ways of calculating exact Monte Carlo p-values by sequential sampling. Such p-values are shown to have properties similar to those obtained by sampling with a fixed sample size. Both standard and generalized Monte Carlo procedures are discussed and, in particular, a sequential method is proposed for dealing with situations in which values can only be conveniently generated using a Markov chain, conditioned to pass through the observed data.},
author = {Besag, Julian and Clifford, Peter},
doi = {10.1093/biomet/78.2.301},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Besag, Clifford - 1991 - Sequential Monte Carlo p-values.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {Markov chain,Monte Carlo,Monte Carlo testing,Multiple testing,P-value,Sequential estimation,Sequential test,Significance test},
mendeley-tags = {Monte Carlo,Multiple testing},
number = {2},
pages = {301--304},
title = {{Sequential Monte Carlo p-values}},
volume = {78},
year = {1991}
}
@article{Robinson1988,
author = {Robinson, P. M.},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Econometrica/Robinson - 1988 - Root-N-Consistent Semiparametric Regression.pdf:pdf},
journal = {Econometrica},
keywords = {causality},
mendeley-tags = {causality},
number = {4},
pages = {931--954},
title = {{Root-N-Consistent Semiparametric Regression}},
volume = {56},
year = {1988}
}
@article{Zetterqvist2019,
abstract = {Epidemiologic research often aims to estimate the association between a binary exposure and a binary outcome, while adjusting for a set of covariates (eg, confounders). When data are clustered, as in, for instance, matched case-control studies and co-twin-control studies, it is common to use conditional logistic regression. In this model, all cluster-constant covariates are absorbed into a cluster-specific intercept, whereas cluster-varying covariates are adjusted for by explicitly adding these as explanatory variables to the model. In this paper, we propose a doubly robust estimator of the exposure-outcome odds ratio in conditional logistic regression models. This estimator protects against bias in the odds ratio estimator due to misspecification of the part of the model that contains the cluster-varying covariates. The doubly robust estimator uses two conditional logistic regression models for the odds ratio, one prospective and one retrospective, and is consistent for the exposure-outcome odds ratio if at least one of these models is correctly specified, not necessarily both. We demonstrate the properties of the proposed method by simulations and by re-analyzing a publicly available dataset from a matched case-control study on induced abortion and infertility.},
author = {Zetterqvist, Johan and Vermeulen, Karel and Vansteelandt, Stijn and Sj{\"{o}}lander, Arvid},
doi = {10.1002/sim.8332},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics in Medicine/Zetterqvist et al. - 2019 - Doubly robust conditional logistic regression.pdf:pdf},
issn = {0277-6715},
journal = {Statistics in Medicine},
keywords = {conditional logistic regression,conditional maximum likelihood,double robustness,doubly robust estimation},
mendeley-tags = {double robustness},
month = {oct},
number = {23},
pages = {4749--4760},
publisher = {John Wiley and Sons Ltd},
title = {{Doubly robust conditional logistic regression}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.8332},
volume = {38},
year = {2019}
}
@article{Zhou2014,
abstract = {Targeted genome editing technologies are powerful tools for studying biology and disease, and have a broad range of research applications. In contrast to the rapid development of toolkits to manipulate individual genes, large-scale screening methods based on the complete loss of gene expression are only now beginning to be developed. Here we report the development of a focused CRISPR/Cas-based (clustered regularly interspaced short palindromic repeats/CRISPR-associated) lentiviral library in human cells and a method of gene identification based on functional screening and high-throughput sequencing analysis. Using knockout library screens, we successfully identified the host genes essential for the intoxication of cells by anthrax and diphtheria toxins, which were confirmed by functional validation. The broad application of this powerful genetic screening strategy will not only facilitate the rapid identification of genes important for bacterial toxicity but will also enable the discovery of genes that participate in other biological processes. {\textcopyright} 2014 Macmillan Publishers Limited. All rights reserved.},
author = {Zhou, Yuexin and Zhu, Shiyou and Cai, Changzu and Yuan, Pengfei and Li, Chunmei and Huang, Yanyi and Wei, Wensheng},
doi = {10.1038/nature13166},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Zhou et al. - 2014 - High-throughput screening of a CRISPRCas9 library for functional genomics in human cells.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {7501},
pages = {487--491},
pmid = {24717434},
title = {{High-throughput screening of a CRISPR/Cas9 library for functional genomics in human cells}},
volume = {509},
year = {2014}
}
@article{Hart2016,
abstract = {Background: The adaptation of the CRISPR-Cas9 system to pooled library gene knockout screens in mammalian cells represents a major technological leap over RNA interference, the prior state of the art. New methods for analyzing the data and evaluating results are needed. Results: We offer BAGEL (Bayesian Analysis of Gene EssentiaLity), a supervised learning method for analyzing gene knockout screens. Coupled with gold-standard reference sets of essential and nonessential genes, BAGEL offers significantly greater sensitivity than current methods, while computational optimizations reduce runtime by an order of magnitude. Conclusions: Using BAGEL, we identify {\~{}}2000 fitness genes in pooled library knockout screens in human cell lines at 5 {\%} FDR, a major advance over competing platforms. BAGEL shows high sensitivity and specificity even across screens performed by different labs using different libraries and reagents.},
author = {Hart, Traver and Moffat, Jason},
doi = {10.1186/s12859-016-1015-8},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/BMC Bioinformatics/Hart, Moffat - 2016 - BAGEL A computational framework for identifying essential genes from pooled library screens.pdf:pdf},
issn = {14712105},
journal = {BMC Bioinformatics},
keywords = {CRISPR,Cancer,Essential genes,Functional genomics,Genetic screens,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {1},
pages = {1--7},
pmid = {27083490},
publisher = {BMC Bioinformatics},
title = {{BAGEL: A computational framework for identifying essential genes from pooled library screens}},
volume = {17},
year = {2016}
}
@article{ZetLa10,
abstract = {This article extends our recent research on penalized estimation methods in genome-wide association studies to the realm of rare variants.The new strategy is tested on both simulated and real data. Our findings on breast cancer data replicate previous results and shed light on variant effects within genes.Rare variant discovery by group penalized regression is now implemented in the free program Mendel at http://www.genetics.ucla.edu/software/.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/20693321{\}}{\{}20693321{\}}},
author = {Zhou, H and Sehl, M E and Sinsheimer, J S and Lange, K},
doi = {10.1093/bioinformatics/btq448},
journal = {Bioinformatics},
keywords = {GWAS,high-dimensional regression},
mendeley-tags = {GWAS,high-dimensional regression},
number = {19},
pages = {2375--2382},
title = {{Association screening of common and rare genetic variants by penalized regression}},
url = {http://www.hubmed.org/display.cgi?uids=20693321},
volume = {26},
year = {2010}
}
@article{Liu2020,
author = {Liu, Molei and Katsevich, Eugene and Ramdas, Aaditya and Janson, Lucas},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Liu et al. - 2020 - Fast and Powerful Conditional Randomization Testing via Distillation.pdf:pdf},
journal = {arXiv},
keywords = {conditional independence testing,conditional randomization test,crt,high-dimensional inference,high-dimensional regression,machine learning,model-X,model-x},
mendeley-tags = {conditional randomization test,high-dimensional regression,model-X},
title = {{Fast and Powerful Conditional Randomization Testing via Distillation}},
url = {https://arxiv.org/abs/2006.03980},
year = {2020}
}
@article{BH95,
author = {Benjamini, Yoav and Hochberg, Yosef},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,Multiple testing,canonical},
mendeley-tags = {FDR,Multiple testing,canonical},
number = {1},
pages = {289--300},
title = {{Controlling the false discovery rate: a practical and powerful approach to multiple testing}},
volume = {57},
year = {1995}
}
@article{Mifsud2015,
abstract = {Genome organization influences transcriptional regulation by facili-tating interactions between gene promoters and distal regulatory elements. Many contacts have been identified using chromosome conformation capture methodologies 1–3 . For example, the ChIA-PET (chromatin interaction analysis by paired-end tag sequencing) method has been used to map long-range interactions extending over hundreds of kilobases; however, these studies have only interrogated the subset of interactions involving highly transcriptionally active genes, whereas long-range interactions for weakly expressed and transcrip-tionally inactive genes remain unknown. Although the 5C (chromatin conformation capture carbon copy) method is not restricted by the nature of interactions, thus far, it has only been applied to a few small genomic regions. The Hi-C method simultaneously captures all genomic interactions, which provides a population-average snapshot of the genome conformation within a single experiment 4 ; yet, owing to the enormous complexity of Hi-C libraries, it is costly to sequence to sufficient depth to provide enough spatial resolution to interro-gate specific contacts between gene promoters and distal regulatory elements 5,6 . To circumvent these issues, we have used solution hybrid-ization selection, originally developed for exon sequencing 7 —and recently used to capture the interactions of a few hundred promoters from 3C libraries 8 —to enrich Hi-C libraries for genome-wide, long-range contacts of both active and inactive promoters. RESULTS A -wide, long-range We prepared three HindIII - digested Hi-C librariesfromGM12878cells,ahumanEpstein-Barrvirus(EBV)-transformedlymphoblastoidcelllinethathasbeencomprehensivelyassayedintheEncyclopediaofDNAElements(ENCODE)Project,andtwolibrariesfromexvivoCD34+hematopoieticprogenitorcells.OneHi-Clibraryfromeachcelltypewassequencedtoexaminethedi-tag(paired-endread)interactiondistributionanddepthofreadcoverage(SupplementaryTable1).Asanticipated,weobservedahigherdensityofdi-taginteractionreadsbetweenrestrictionfragmentsincisascomparedwithfragmentsintrans,withthehighestdensityoccurringbetweenfragmentssepa-ratedbylessthan20kb(SupplementaryFig.1a,b).Wealsoobserveddemarcationofthegenomeintodistinctcontiguous,highlyintracon-nectedtopologicallyassociateddomains(TADs)5(SupplementaryFig.1candSupplementaryTable2).Thedistributionofreadcover-agewastypicalforaHi-Cexperiment.Inourinitialcomparison,wedownsampledalldatasetsto45millionuniquesequencingreads.Eachrestrictionfragmentwasrepresentedbyanaverageof143and139readsintheGM12878andCD34+libraries,respectively(SupplementaryFig.1d).Weprocessedthereadsusingbinomialsta-tisticstoidentifyligationfragmentsthatweresignificantlyenriched(q{\textless}0.05).ThisapproachrecognizesligationproductsbetweenMappinglong-rangepromotercontactsinhumancellswithhigh-resolutioncaptureHi-C},
author = {Mifsud, Borbala and Tavares-Cadete, Filipe and Young, Alice N. and Sugar, Robert and Schoenfelder, Stefan and Ferreira, Lauren and Wingett, Steven W. and Andrews, Simon and Grey, William and Ewels, Philip A. and Herman, Bram and Happe, Scott and Higgs, Andy and Leproust, Emily and Follows, George A. and Fraser, Peter and Luscombe, Nicholas M. and Osborne, Cameron S.},
doi = {10.1038/ng.3286},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Mifsud et al. - 2015 - Mapping long-range promoter contacts in human cells with high-resolution capture Hi-C.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {HI-C,Kathryn,gene-enhancer},
mendeley-tags = {HI-C,Kathryn,gene-enhancer},
number = {6},
pages = {598--606},
publisher = {Nature Publishing Group},
title = {{Mapping long-range promoter contacts in human cells with high-resolution capture Hi-C}},
volume = {47},
year = {2015}
}
@article{SetC17,
abstract = {In this paper we deepen and enlarge the reflection on the possible advantages of a knockoff approach to genome wide association studies (Sesia et al., 2018), starting from the discussions in Bottolo {\&} Richardson (2019); Jewell {\&} Witten (2019); Rosenblatt et al. (2019) and Marchini (2019). The discussants bring up a number of important points, either related to the knockoffs methodology in general, or to its specific application to genetic studies. In the following we offer some clarifications, mention relevant recent developments and highlight some of the still open problems.},
annote = {Forthcoming, preprint arXiv:1706.04677},
author = {Sesia, M. and Sabatti, C. and Cand{\`{e}}s, E. J.},
doi = {10.1093/biomet/asy033},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Sesia, Sabatti, Cand{\`{e}}s - 2019 - Gene hunting with hidden Markov model knockoffs.pdf:pdf},
issn = {14643510},
journal = {Biometrika},
keywords = {FDR,False discovery rate,Genome-wide association study,Knockoff,Multiple testing,Variable selection,genetics,high-dimensional regression,knockoffs,model-X},
mendeley-tags = {FDR,Multiple testing,genetics,high-dimensional regression,knockoffs,model-X},
number = {1},
pages = {1--18},
title = {{Gene hunting with hidden Markov model knockoffs}},
volume = {106},
year = {2019}
}
@article{Bogomolov2018,
abstract = {Replicability analysis aims to identify the overlapping signals across independent studies that examine the same features. For this purpose we develop hypothesis testing procedures that first select the promising features from each of two studies separately. Only those features selected in both studies are then tested. The proposed procedures have theoretical guarantees regarding their control of the familywise error rate or false discovery rate on the replicability claims. They can also be used for signal discovery in each study separately, with the desired error control. Their power for detecting truly replicable findings is compared to alternatives. We illustrate the procedures on behavioural genetics data.},
archivePrefix = {arXiv},
arxivId = {1504.00534},
author = {Bogomolov, Marina and Heller, Ruth},
doi = {10.1093/biomet/asy029},
eprint = {1504.00534},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Bogomolov, Heller - 2018 - Assessing replicability of findings across two studies of multiple features.pdf:pdf},
issn = {14643510},
journal = {Biometrika},
keywords = {Adaptive procedure,False discovery rate,Familywise error rate,Meta-analysis,Multiple testing,Replicability analysis,partial conjunction,reproducibility},
mendeley-tags = {partial conjunction,reproducibility},
number = {3},
pages = {505--516},
title = {{Assessing replicability of findings across two studies of multiple features}},
volume = {105},
year = {2018}
}
@article{Anders2013,
abstract = {A vast number of small-molecule ligands, including therapeutic drugs under development and in clinical use, elicit their effects by binding specific proteins associated with the genome. An ability to map the direct interactions of a chemical entity with chromatin genome-wide could provide important insights into chemical perturbation of cellular function. Here we describe a method that couples ligand-affinity capture and massively parallel DNA sequencing (Chem-seq) to identify the sites bound by small chemical molecules throughout the human genome. We show how Chem-seq can be combined with ChIP-seq to gain unique insights into the interaction of drugs with their target proteins throughout the genome of tumor cells. These methods will be broadly useful to enhance understanding of therapeutic action and to characterize the specificity of chemical entities that interact with DNA or genome-associated proteins. The ability to map the locations of proteins throughout the genome has had a profound impact on our understanding of a wide range of normal and disease biology. For example, discovery of the genome-wide location of proteins by means of chromatin immunoprecipita-tion (ChIP)-seq has allowed global mapping of the key transcription factors and chromatin regulators that control gene expression programs in various cells, the sites that act as origins of DNA replication, and regions of the genome that form euchromatin and hetero-chromatin 1-6. Models of the transcriptional regulatory circuitry that controls normal and disease states in cells have emerged from genome-wide data 7-10. Mapping the global interactions of a chemical entity with chromatin genome-wide could provide insights into the mechanisms by which a small molecule influences cellular functions. Many DNA-associated processes are targeted for disease therapy, including transcription, modification, replication and repair 11-16. Ligand-affinity methodolo-gies have greatly contributed to our understanding of drug and ligand function, and have led to the identification of numerous gene regulatory drug targets 17-20. There have been initial efforts to map the sites of interaction of metabolic compounds in the yeast genome 21 , but it would be ideal to have a method that allows investigators to determine how small-molecule therapeutics interact with the human genome. We describe here a method based on chemical affinity capture and massively parallel DNA sequencing (Chem-seq) that allows investigators to identify genomic sites where small chemical molecules interact with their target proteins or DNA (Fig. 1a). The Chem-seq method is similar to that employed for ChIP-seq, except that Chem-seq uses retrievable synthetic derivatives of a compound of interest to identify sites of genome occupancy whereas ChIP-seq uses antibodies against specific proteins for this purpose. We used Chem-seq to investigate the genome-wide binding of the bromodomain inhibitor JQ1 to the BET bromodomain family members BRD2, BRD3 and BRD4 in MM1.S multiple myeloma cells. JQ1 has previously been shown to bind all three co-activator proteins and to inhibit the growth of MM1.S and other tumor cells 13,22-27. We first investigated how BRD2, BRD3 and BRD4 occupy the genome of MM1.S cells using ChIP-seq (Supplementary Fig. 1). All three proteins were found to be associated with actively transcribed genes (Supplementary Fig. 1a). Inspection of individual gene tracks (Supplementary Fig. 1b) and analysis of global genome occupancy (Supplementary Fig. 1c) showed that most core promoter elements of active genes were co-occupied by BRD2, BRD3 and BRD4 together with RNA polymerase II (RNA Pol II), the Mediator complex subunit 1 (MED1) and histone H3K27Ac. In contrast, enhancers, which are occupied by histone H3K27Ac and Mediator, were preferentially occupied by BRD4, with lower relative levels of BRD2 and BRD3. To investigate the interaction of JQ1 with chromatin genome-wide, we used the Chem-seq technique (Fig. 1a) with a biotinylated derivative of JQ1 (bio-JQ1, Fig. 1b). Enantioretentive substitution at C-6 of the JQ1 diazepine allowed coupling of a polyethylene glycol spacer with appended biotin feature. The potency of bio-JQ1 binding to the first bromodomain of BRD4 was nearly equivalent to that of the unbiotinylated compound, as determined by both differential scanning fluorimetry and isothermal titration calorimetry (Supplementary Fig. 2). Consistent with this, bio-JQ1 had only slightly reduced bio-activity in MM1.S cells relative to JQ1 (Fig. 1c). We initially treated living cells with bio-JQ1 and cross-linked proteins to DNA with for-maldehyde (Fig. 1a). Cells were then lysed and sonicated to shear the DNA, and streptavidin beads were used to isolate biotinylated ligand and associated chromatin fragments. Massively parallel sequencing was used to identify enriched DNA fragments, and these sequences were mapped to the genome to reveal sites bound by the small-molecule probe. In addition, we developed an in vitro version of this method, which allows analysis of biotinylated molecules with potentially},
author = {Anders, Lars and Guenther, Matthew G and Qi, Jun and Fan, Zi Peng and Marineau, Jason J and Rahl, Peter B and Lov{\'{e}}n, Jakob and Sigova, Alla A and Smith, William B and Lee, Tong Ihn and Bradner, James E and Young, Richard A},
doi = {10.1038/nbt.2776},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Anders et al. - 2013 - Genome-wide localization of small molecules.pdf:pdf},
journal = {Nature Biotechnology},
keywords = {genetics,to-read},
mendeley-tags = {genetics,to-read},
number = {1},
pages = {92--96},
title = {{Genome-wide localization of small molecules}},
volume = {32},
year = {2013}
}
@article{Buenrostro2015,
abstract = {Cell-to-cell variation is a universal feature of life that affects a wide range of biological phenomena, from developmental plasticity to tumour heterogeneity. Although recent advances have improved our ability to document cellular phenotypic variation, the fundamental mechanisms that generate variability from identical DNA sequences remain elusive. Here we reveal the landscape and principles of mammalian DNA regulatory variation by developing a robust method for mapping the accessible genome of individual cells by assay for transposase-accessible chromatin using sequencing (ATAC-seq) integrated into a programmable microfluidics platform. Single-cell ATAC-seq (scATAC-seq) maps from hundreds of single cells in aggregate closely resemble accessibility profiles from tens of millions of cells and provide insights into cell-to-cell variation. Accessibility variance is systematically associated with specific trans-factors and cis-elements, and we discover combinations of trans-factors associated with either induction or suppression of cell-to-cell variability. We further identify sets of trans-factors associated with cell-type-specific accessibility variance across eight cell types. Targeted perturbations of cell cycle or transcription factor signalling evoke stimulus-specific changes in this observed variability. The pattern of accessibility variation in cis across the genome recapitulates chromosome compartments de novo, linking single-cell accessibility variation to three-dimensional genome organization. Single-cell analysis of DNA accessibility provides new insight into cellular variation of the 'regulome'.},
author = {Buenrostro, Jason D. and Wu, Beijing and Litzenburger, Ulrike M. and Ruff, Dave and Gonzales, Michael L. and Snyder, Michael P. and Chang, Howard Y. and Greenleaf, William J.},
doi = {10.1038/nature14590},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Buenrostro et al. - 2015 - Single-cell chromatin accessibility reveals principles of regulatory variation.pdf:pdf},
issn = {14764687},
journal = {Nature},
number = {7561},
pages = {486--490},
pmid = {26083756},
title = {{Single-cell chromatin accessibility reveals principles of regulatory variation}},
volume = {523},
year = {2015}
}
@article{ES05,
abstract = {Gene microarray technology is often used to compare the expression of thousand of genes in two different cell lines. Typically, one does not expect measurable changes in transcription amounts for a large number of genes; furthermore, the noise level of array experiments is rather high in relation to the available number of replicates. For the purpose of statistical analysis, inference on the "population'' difference in expression for genes across the two cell lines is often cast in the framework of hypothesis testing, with the null hypothesis being no change in expression. Given that thousands of genes are investigated at the same time, this requires some multiple comparison correction procedure to be in place. We argue that hypothesis testing, with its emphasis on type I error and family analogues, may not address the exploratory nature of most microarray experiments. We instead propose viewing the problem as one of estimation of a vector known to have a large number of zero components. In a Bayesian framework, we describe the prior knowledge on expression changes using mixture priors that incorporate a mass at zero, and we choose a loss function that favors the selection of sparse solutions. We consider two different models applicable to the microarray problem, depending on the nature of replicates available, and show how to explore the posterior distributions of the parameters using MCMC. Simulations show an interesting connection between this Bayesian estimation framework and false discovery rate (FDR) control. Finally, two empirical examples illustrate the practical advantages of this Bayesian estimation paradigm.},
annote = {16646840},
author = {Erickson, S and Sabatti, C},
doi = {10.2202/1544-6115.1132},
journal = {Stat Appl Genet Mol Biol},
keywords = {empirical Bayes,gene expression,genetics},
mendeley-tags = {empirical Bayes,gene expression,genetics},
title = {{Empirical bayes estimation of a sparse vector of gene expression changes}},
url = {http://www.hubmed.org/display.cgi?uids=16646840},
volume = {4},
year = {2005}
}
@article{ZetL11,
abstract = {Current disease association studies are routinely conducted on a genome-wide scale, testing hundreds of thousands or millions of genetic markers. Besides detecting marginal associations of individual markers with the disease, it is also of interest to identify gene-gene and gene-environment interactions, which confer susceptibility to the disease risk. The astronomical number of possible combinations of markers and environmental factors, however, makes interaction mapping a daunting task both computationally and statistically. In this paper, we review and discuss a set of Bayesian partition methods developed recently for mapping single-nucleotide polymorphisms in case-control studies, their extension to quantitative traits, and further generalization to multiple traits. We use simulation and real data sets to demonstrate the performance of these methods, and we compare them with some existing interaction mapping algorithms. With the recent advance in high-throughput sequencing technologies, genome-wide measurements of epigenetic factor enrichment, structural variations, and transcription activities become available at the individual level. The tsunami of data creates more challenges for gene-gene interaction mapping, but at the same time provides new opportunities that, if utilized properly through sophisticated statistical means, can improve the power of mapping interactions at the genome scale.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/21091453{\}}{\{}21091453{\}}},
author = {Zhang, Y and Jiang, B and Zhu, J and Liu, J S},
doi = {10.1111/j.1469-1809.2010.00621.x},
journal = {Annals of Human Genetics},
number = {1},
pages = {183--193},
title = {{Bayesian models for detecting epistatic interactions from genetic data}},
url = {http://www.hubmed.org/display.cgi?uids=21091453},
volume = {75},
year = {2011}
}
@article{Ernst2011,
abstract = {Chromatin profiling has emerged as a powerful means of genome annotation and detection of regulatory activity. The approach is especially well suited to the characterization of non-coding portions of the genome, which critically contribute to cellular phenotypes yet remain largely uncharted. Here we map nine chromatin marks across nine cell types to systematically characterize regulatory elements, their cell-type specificities and their functional interactions. Focusing on cell-type-specific patterns of promoters and enhancers, we define multicell activity profiles for chromatin state, gene expression, regulatory motif enrichment and regulator expression. We use correlations between these profiles to link enhancers to putative target genes, and predict the cell-type-specific activators and repressors that modulate them. The resulting annotations and regulatory predictions have implications for the interpretation of genome-wide association studies. Top-scoring disease single nucleotide polymorphisms are frequently positioned within enhancer elements specifically active in relevant cell types, and in some cases affect a motif instance for a predicted regulator, thus suggesting a mechanism for the association. Our study presents a general framework for deciphering cis-regulatory connections and their roles in disease.},
author = {Ernst, Jason and Kheradpour, Pouya and Mikkelsen, Tarjei S. and Shoresh, Noam and Ward, Lucas D. and Epstein, Charles B. and Zhang, Xiaolan and Wang, Li and Issner, Robbyn and Coyne, Michael and Ku, Manching and Durham, Timothy and Kellis, Manolis and Bernstein, Bradley E.},
doi = {10.1038/nature09906},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Ernst et al. - 2011 - Mapping and analysis of chromatin state dynamics in nine human cell types.pdf:pdf},
issn = {00280836},
journal = {Nature},
keywords = {Kathryn,epigenetics,gene-enhancer},
mendeley-tags = {Kathryn,epigenetics,gene-enhancer},
number = {7345},
pages = {43--49},
publisher = {Nature Publishing Group},
title = {{Mapping and analysis of chromatin state dynamics in nine human cell types}},
volume = {473},
year = {2011}
}
@article{Schoenfelder2019,
abstract = {Spatiotemporal gene expression programmes are orchestrated by transcriptional enhancers, which are key regulatory DNA elements that engage in physical contacts with their target-gene promoters, often bridging considerable genomic distances. Recent progress in genomics, genome editing and microscopy methodologies have enabled the genome-wide mapping of enhancer–promoter contacts and their functional dissection. In this Review, we discuss novel concepts on how enhancer–promoter interactions are established and maintained, how the 3D architecture of mammalian genomes both facilitates and constrains enhancer–promoter contacts, and the role they play in gene expression control during normal development and disease. For appropriate control of gene expression, enhancers must communicate with the right target genes at the right time, typically over large genomic distances. In this Review, Schoenfelder and Fraser discuss our latest understanding of long-range enhancer–promoter crosstalk, including target-gene specificity, interaction dynamics, protein and RNA architects of interactions, roles of 3D genome organization and the pathological consequences of regulatory rewiring.},
author = {Schoenfelder, Stefan and Fraser, Peter},
doi = {10.1038/s41576-019-0128-0},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Reviews Genetics/Schoenfelder, Fraser - 2019 - Long-range enhancer–promoter contacts in gene expression control.pdf:pdf},
issn = {14710064},
journal = {Nature Reviews Genetics},
keywords = {Kathryn,gene-enhancer,to-read},
mendeley-tags = {Kathryn,gene-enhancer,to-read},
publisher = {Springer US},
title = {{Long-range enhancer–promoter contacts in gene expression control}},
url = {http://dx.doi.org/10.1038/s41576-019-0128-0},
year = {2019}
}
@article{GetT12,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23028291{\}}{\{}23028291{\}}},
author = {Guan, Y and Gorenshteyn, D and Burmeister, M and Wong, A K and Schimenti, J C and Handel, M A and Bult, C J and Hibbs, M A and Troyanskaya, O G},
journal = {PLoS Comput. Biol.},
keywords = {genetics,networks},
mendeley-tags = {genetics,networks},
number = {9},
pages = {e1002694},
title = {{{\{}T{\}}issue-specific functional networks for prioritizing phenotype and disease genes}},
volume = {8},
year = {2012}
}
@article{Pearl2010,
abstract = {This paper addresses the problem of measurement errors in causal inference and highlights several algebraic and graphical methods for eliminating systematic bias induced by such errors. In particulars, the paper discusses the control of partially observable confounders in parametric and non parametric models and the computational problem of obtaining biasfree effect estimates in such models.},
author = {Pearl, Judea},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence, UAI 2010/Pearl - 2010 - On measurement bias in causal inference.pdf:pdf},
isbn = {9780974903965},
journal = {Proceedings of the 26th Conference on Uncertainty in Artificial Intelligence, UAI 2010},
keywords = {causality,missing data},
mendeley-tags = {causality,missing data},
pages = {425--432},
title = {{On measurement bias in causal inference}},
year = {2010}
}
@article{BetS17a,
abstract = {With the rise of both the number and the complexity of traits of interest, control of the false discovery rate (FDR) in genetic association studies has become an increasingly appealing and accepted target for multiple comparison adjustment. While a number of robust FDR controlling strategies exist, the nature of this error rate is intimately tied to the precise way in which discoveries are counted, and the performance of FDR controlling procedures is satisfactory only if there is a one-to-one correspondence between what scientists describe as unique discoveries and the number of rejected hypotheses. The presence of linkage disequilibrium between markers in genome-wide association studies (GWAS) often leads researchers to consider the signal associated to multiple neighboring SNPs as indicating the existence of a single genomic locus with possible influence on the phenotype. This a posteriori aggregation of rejected hypotheses results in inflation of the relevant FDR. We propose a novel approach to FDR control that is based on pre-screening to identify the level of resolution of distinct hypotheses. We show how FDR controlling strategies can be adapted to account for this initial selection both with theoretical results and simulations that mimic the dependence structure to be expected in GWAS. We demonstrate that our approach is versatile and useful when the data are analyzed using both tests based on single marker and multivariate regression. We provide an R package that allows practitioners to apply our procedure on standard GWAS format data, and illustrate its performance on lipid traits in the NFBC66 cohort study.},
author = {Brzyski, Damian and Peterson, Christine B. and Sobczyk, Piotr and Candes, Emmanuel J. and Bogdan, Malgorzata and Sabatti, Chiara},
journal = {Genetics},
keywords = {FDR,GWAS},
mendeley-tags = {FDR,GWAS},
number = {1},
pages = {61--75},
title = {{Controlling the rate of GWAS false discoveries}},
volume = {205},
year = {2017}
}
@article{FR01,
author = {Finner, Helmut and Roters, M},
doi = {10.1002/1521-4036(200112)43:8<985::AID-BIMJ985>3.0.CO;2-4},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrical Journal/Finner, Roters - 2001 - On the false discovery rate and expected type I errors.pdf:pdf},
issn = {0323-3847},
journal = {Biometrical Journal},
keywords = {FDR,Multiple testing},
mendeley-tags = {FDR,Multiple testing},
number = {8},
pages = {985--1005},
title = {{On the false discovery rate and expected type I errors}},
volume = {43},
year = {2001}
}
@article{Klasen2016,
abstract = {All common genome-wide association (GWA) methods rely on population structure correction, to avoid false genotype-to-phenotype associations. However, population structure correction is a stringent penalization, which also impedes identification of real associations. Using recent statistical advances, we developed a new GWA method, called Quantitative Trait Cluster Association Test (QTCAT), enabling simultaneous multi-marker associations while considering correlations between markers. With this, QTCAT overcomes the need for population structure correction and also reflects the polygenic nature of complex traits better than single-marker methods. Using simulated data, we show that QTCAT clearly outperforms linear mixed model approaches. Moreover, using QTCAT to reanalyse public human, mouse and Arabidopsis GWA data revealed nearly all known and some previously undetected associations. Following up on the most significant novel association in the Arabidopsis data allowed us to identify a so far unknown component of root growth.},
author = {Klasen, Jonas R and Barbez, Elke and Meier, Lukas and Meinshausen, Nicolai and B{\"{u}}hlmann, Peter and Koornneef, Maarten and Busch, Wolfgang and Schneeberger, Korbinian},
doi = {10.1038/ncomms13299},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Klasen et al. - 2016 - A multi-marker association method for genome-wide association studies without the need for population structure c.pdf:pdf},
journal = {Nature Communications},
keywords = {GWAS,Multiple testing},
mendeley-tags = {GWAS,Multiple testing},
title = {{A multi-marker association method for genome-wide association studies without the need for population structure correction}},
url = {www.nature.com/naturecommunications},
volume = {7},
year = {2016}
}
@article{BB14,
author = {Benjamini, Yoav and Bogomolov, Marina},
doi = {10.1111/rssb.12028},
issn = {1369-7412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
number = {1},
pages = {297--318},
title = {{Selective inference on multiple families of hypotheses}},
url = {http://dx.doi.org/10.1111/rssb.12028},
volume = {76},
year = {2014}
}
@article{Wong2016,
abstract = {The orchestrated action of genes controls complex biological phenotypes, yet the systematic discovery of gene and drug combinations that modulate these phenotypes in human cells is labor intensive and challenging to scale. Here, we created a platform for the massively parallel screening of barcoded combinatorial gene perturbations in human cells and translated these hits into effective drug combinations. This technology leverages the simplicity of the CRISPR-Cas9 system for multiplexed targeting of specific genomic loci and the versatility of combinatorial genetics en masse (Combi- GEM) to rapidly assemble barcoded combinatorial genetic libraries that can be tracked with high-throughput sequencing. We applied CombiGEM-CRISPR to create a library of 23,409 barcoded dual guide-RNA (gRNA) combinations and then perform a high-throughput pooled screen to identify gene pairs that inhibited ovarian cancer cell growth when they were targeted. We validated the growth-inhibiting effects of specific gene sets, including epigenetic regulators KDM4C/BRD4 and KDM6B/BRD4, via individual assays with CRISPR-Cas-based knockouts and RNA-interference-based knockdowns. We also tested small-molecule drug pairs directed against our pairwise hits and showed that they exerted synergistic antiproliferative effects against ovarian cancer cells. We envision that the CombiGEM-CRISPR platform will be applicable to a broad range of biological settings and will accelerate the systematic identification of genetic combinations and their translation into novel drug combinations that modulate complex human disease phenotypes.},
author = {Wong, Alan S.L. and Choi, Gigi C.G. and Cui, Cheryl H. and Pregernig, Gabriela and Milani, Pamela and Adam, Miriam and Perli, Samuel D. and Kazer, Samuel W. and Gaillard, Aleth and Hermann, Mario and Shalek, Alex K. and Fraenkel, Ernest and Lu, Timothy K.},
doi = {10.1073/pnas.1517883113},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Proceedings of the National Academy of Sciences of the United States of America/Wong et al. - 2016 - Multiplexed barcoded CRISPR-Cas9 screening enabled by CombiGEM.pdf:pdf},
isbn = {1517883113},
issn = {10916490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {CRISPR,CRISPR-Cas,CombiGEM,Genetic perturbations,High-throughput screening,Multifactorial genetics},
mendeley-tags = {CRISPR},
number = {9},
pages = {2544--2549},
pmid = {26864203},
title = {{Multiplexed barcoded CRISPR-Cas9 screening enabled by CombiGEM}},
volume = {113},
year = {2016}
}
@article{Finkelstein2020,
abstract = {When data contains measurement errors, it is necessary to make assumptions relating the observed, erroneous data to the unobserved true phenomena of interest. These assumptions should be justifiable on substantive grounds, but are often motivated by mathematical convenience, for the sake of exactly identifying the target of inference. We adopt the view that it is preferable to present bounds under justifiable assumptions than to pursue exact identification under dubious ones. To that end, we demonstrate how a broad class of modeling assumptions involving discrete variables, including common measurement error and conditional independence assumptions, can be expressed as linear constraints on the parameters of the model. We then use linear programming techniques to produce sharp bounds for factual and counterfactual distributions under measurement error in such models. We additionally propose a procedure for obtaining outer bounds on non-linear models. Our method yields sharp bounds in a number of important settings -- such as the instrumental variable scenario with measurement error -- for which no bounds were previously known.},
archivePrefix = {arXiv},
arxivId = {2012.12449},
author = {Finkelstein, Noam and Adams, Roy and Saria, Suchi and Shpitser, Ilya},
eprint = {2012.12449},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Finkelstein et al. - 2020 - Partial Identifiability in Discrete Data With Measurement Error.pdf:pdf},
journal = {arXiv},
title = {{Partial Identifiability in Discrete Data With Measurement Error}},
url = {http://arxiv.org/abs/2012.12449},
year = {2020}
}
@article{Kai-HowFarh2015,
abstract = {Genome-wide association studies have identified loci underlying human diseases, but the causal nucleotide changes and mechanisms remain largely unknown. Here we developed a fine-mapping algorithm to identify candidate causal variants for 21 autoimmune diseases from genotyping data. We integrated these predictions with transcription and cis-regulatory element annotations, derived by mapping RNA and chromatin in primary immune cells, including resting and stimulated CD4 1 T-cell subsets, regulatory T cells, CD8 1 T cells, B cells, and monocytes. We find that 90{\%} of causal variants are non-coding, with 60{\%} mapping to immune-cell enhancers, many of which gain histone acetylation and transcribe enhancer-associated RNA upon immune stimulation. Causal variants tend to occur near binding sites for master regulators of immune differentiation and stimulus-dependent gene activation, but only 10-20{\%} directly alter recognizable transcription factor binding motifs. Rather, most non-coding risk variants, including those that alter gene expression, affect non-canonical sequence determinants not well-explained by current gene regulatory models. Genome-wide association studies (GWAS) have revolutionized the study of complex human traits by identifying thousands of genetic loci that contribute susceptibility for a diverse set of diseases 1,2. However, progress towards understanding disease mechanisms has been limited by difficulty in assigning molecular function to the vast majority of GWAS hits that do not affect protein-coding sequence. Efforts to decipher biological consequences of non-coding variation face two major challenges. First, due to haplotype structure, GWAS tend to nominate large clusters of single nucleotide polymorphisms (SNPs) in linkage disequilibrium (LD), making it difficult to distinguish causal SNPs from neutral variants in linkage. Second, even assuming the causal variant can be identified, interpretation is limited by incomplete knowledge of non-coding regulatory elements, their mechanisms of action, and the cellular states and processes in which they function. Inflammatory autoimmune diseases, which reflect complex interactions between genetic variation and environment, are important systems for genetic investigation of human disease 3. They share a substantial degree of immunopathology, with increased activity of auto-reactive CD4 1 T cells secreting inflammatory cytokines and loss of regulatory T-cell (T reg) function 4. A critical role for B cells in certain diseases has also been revealed with the therapeutic efficacy of anti-CD20 antibodies 5. Immune homeostasis depends on a balance of CD4 1 pro-inflammatory (TH1, TH2, TH17) cells and FOXP3 1 suppressive T regs , each of which expresses distinct cytokines and surface molecules 6. Each cell type is controlled by a unique set of master transcription factors (TFs) that directly shape cell-type-specific gene expression programs, which include genes implicated in autoimmune diseases 7-9. Immune subsets also have characteristic cis-regulatory landscapes, including distinct sets of enhancers that may be distinguished by their chromatin states 9-13 and associated enhancer RNAs (eRNA) 14. Familial clustering of different autoimmune diseases suggests that heritable factors underlie common disease pathways, although dis-parate clinical presentations and paradoxical effects of drugs in different diseases support key distinctions 15. GWAS have identified hundreds of risk loci for autoimmunity 15. Although most risk variants have subtle effects on disease susceptibility , they provide unbiased support for possible aetiological pathways, including antigen presentation, cytokine signalling, and NF-kB tran-scriptional regulation 15. The associated loci are enriched for immune cell-specific enhancers 10,16,17 and expansive enhancer clusters 18,19 , termed 'super-enhancers', implicating gene regulatory processes in disease aeti-ology. However, as is typical of GWAS, the implicated loci comprise multiple variants in LD and rarely alter protein-coding sequence, which complicates their interpretation. Here, we integrated genetic and epigenetic fine mapping to identify causal variants in autoimmune disease-associated loci and explore their functions. Based on dense genotyping data 20 , we developed a novel algorithm to predict for each individual variant associated with 21 auto-immune diseases, the likelihood that it represents a causal variant. In parallel, we generated cis-regulatory element maps for a spectrum of immune cell types. Remarkably, ,60{\%} of likely causal variants map to},
author = {{Kai-How Farh}, Kyle and Marson, Alexander and Zhu, Jiang and Kleinewietfeld, Markus and Housley, William J and Beik, Samantha and Shoresh, Noam and Whitton, Holly and {H Ryan}, Russell J and Shishkin, Alexander A and Hatan, Meital and Carrasco-Alfonso, Marlene J and Mayer, Dita and {John Luckey}, C and Patsopoulos, Nikolaos A and {De Jager}, Philip L and Kuchroo, Vijay K and Epstein, Charles B and Daly, Mark J and Hafler, David A and Bernstein, Bradley E},
doi = {10.1038/nature13835},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Kai-How Farh et al. - 2015 - Genetic and epigenetic fine mapping of causal autoimmune disease variants.pdf:pdf},
journal = {Nature},
keywords = {applied,genetics},
mendeley-tags = {applied,genetics},
pages = {337--343},
title = {{Genetic and epigenetic fine mapping of causal autoimmune disease variants}},
url = {http://www.broadinstitute.org/pubs/},
volume = {518},
year = {2015}
}
@article{AetL06,
author = {Alexa, Adrian and Rahnenf{\"{u}}hrer, J{\"{o}}rg and Lengauer, Thomas},
journal = {Bioinformatics},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
number = {13},
pages = {1600--1607},
publisher = {Oxford University Press},
title = {{Improved scoring of functional groups from gene expression data by decorrelating GO graph structure}},
volume = {22},
year = {2006}
}
@article{FetP15,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/26414678{\}}{\{}26414678{\}}},
author = {Finucane, H K and Bulik-Sullivan, B and Gusev, A and Trynka, G and Reshef, Y and Loh, P R and Anttila, V and Xu, H and Zang, C and Farh, K and Ripke, S and Day, F R and Purcell, S and Stahl, E and Lindstrom, S and Perry, J R and Okada, Y and Raychaudhuri, S and Daly, M J and Patterson, N and Neale, B M and Price, A L},
journal = {Nature Genetics},
keywords = {GWAS,functional annotation},
mendeley-tags = {GWAS,functional annotation},
month = {nov},
number = {11},
pages = {1228--1235},
title = {{{\{}P{\}}artitioning heritability by functional annotation using genome-wide association summary statistics}},
volume = {47},
year = {2015}
}
@article{Rosenblatt2018,
abstract = {The most prevalent approach to activation localization in neuroimaging is to identify brain regions as contiguous supra-threshold clusters, check their significance using random field theory, and correct for the multiple clusters being tested. Besides recent criticism on the validity of the random field assumption, a spatial specificity paradox remains: the larger the detected cluster, the less we know about the location of activation within that cluster. This is because cluster inference implies “there exists at least one voxel with an evoked response in the cluster”, and not that “all the voxels in the cluster have an evoked response”. Inference on voxels within selected clusters is considered bad practice, due to the voxel-wise false positive rate inflation associated with this circular inference. Here, we propose a remedy to the spatial specificity paradox. By applying recent results from the multiple testing statistical literature, we are able to quantify the proportion of truly active voxels within selected clusters, an approach we call All-Resolutions Inference (ARI). If this proportion is high, the paradox vanishes. If it is low, we can further “drill down” from the cluster level to sub-regions, and even to individual voxels, in order to pinpoint the origin of the activation. In fact, ARI allows inference on the proportion of activation in all voxel sets, no matter how large or small, however these have been selected, all from the same data. We use two fMRI datasets to demonstrate the non-triviality of the spatial specificity paradox, and its resolution using ARI. We verify that the endless circularity permitted by ARI does not render its estimates overly conservative using both simulation, and a data split.},
author = {Rosenblatt, Jonathan D. and Finos, Livio and Weeda, Wouter D. and Solari, Aldo and Goeman, Jelle J.},
doi = {10.1016/j.neuroimage.2018.07.060},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/NeuroImage/Rosenblatt et al. - 2018 - All-Resolutions Inference for brain imaging.pdf:pdf},
issn = {10959572},
journal = {NeuroImage},
number = {March},
pages = {786--796},
publisher = {Elsevier Inc.},
title = {{All-Resolutions Inference for brain imaging}},
url = {https://doi.org/10.1016/j.neuroimage.2018.07.060},
volume = {181},
year = {2018}
}
@article{KetE10,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/20208533{\}}{\{}20208533{\}}},
author = {Kang, H M and Sul, J H and Service, S K and Zaitlen, N A and Kong, S and Freimer, N B and Sabatti, C and Eskin, E},
journal = {Nature Genetics},
keywords = {GWAS,genetics,linear mixed models},
mendeley-tags = {GWAS,genetics,linear mixed models},
number = {4},
pages = {348--354},
title = {{Variance component model to account for sample structure in genome-wide association studies}},
volume = {42},
year = {2010}
}
@article{SetE13,
address = {United States},
author = {Sul, Jae Hoon and Han, Buhm and Ye, Chun and Choi, Ted and Eskin, Eleazar},
issn = {1553-7404},
journal = {PLoS Genetics},
keywords = {Expression QTLs,Meta-Analysis,Mixed Models,Multiple Phenotypes,eQTL,multiple phenotypes},
mendeley-tags = {eQTL,multiple phenotypes},
number = {6},
pages = {e1003491},
publisher = {Public Library of Science},
title = {{Effectively identifying {\{}eQTLs{\}} from multiple tissues by combining mixed model and meta-analytic approaches}},
url = {http://dx.doi.org/10.1371{\%}2Fjournal.pgen.1003491},
volume = {9},
year = {2013}
}
@article{Salameh2019,
abstract = {Accurately predicting chromatin loops from genome-wide interaction matrices such as Hi-C data is critical to deepen our understanding of proper gene regulation events. Current approaches are mainly focused on searching for statistically enriched dots on a genome-wide map. However, given the availability of a wide variety of orthogonal data types such as ChIA-PET, GAM, SPRITE, and high-throughput imaging, a supervised learning approach could facilitate the discovery of a comprehensive set of chromatin interactions. Here we present Peakachu, a Random Forest classification framework that predicts chromatin loops from genome-wide contact maps. Compared with current enrichment-based approaches, Peakachu identified more meaningful short-range interactions. We show that our models perform well in different platforms such as Hi-C, Micro-C, and DNA SPRITE, across different sequencing depths, and across different species. We applied this framework to systematically predict chromatin loops in 56 Hi-C datasets, and the results are available at the 3D Genome Browser (www.3dgenome.org).},
author = {Salameh, Tarik J and Wang, Xiaotao and Song, Fan and Zhang, Bo and Wright, Sage M. and Khunsriraksakul, Chachrit and Yue, Feng},
doi = {10.1101/739698},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Salameh et al. - 2019 - A supervised learning framework for chromatin loop detection in genome-wide contact maps.pdf:pdf},
journal = {bioRxiv},
keywords = {HI-C,Kathryn,gene-enhancer,genetics},
mendeley-tags = {HI-C,Kathryn,gene-enhancer,genetics},
title = {{A supervised learning framework for chromatin loop detection in genome-wide contact maps}},
url = {https://www.biorxiv.org/content/10.1101/739698v1},
year = {2019}
}
@article{SS07,
annote = {17676998},
author = {Servin, B and Stephens, M},
journal = {PLoS Genetics},
month = {jul},
pages = {e114},
title = {{{\{}I{\}}mputation-based analysis of association studies: candidate regions and quantitative traits}},
volume = {3},
year = {2007}
}
@article{MT07,
abstract = {A method is described to discover if a gene carries one or more allelic mutations that confer risk for any specified common disease. The method does not depend upon genetic linkage of risk-conferring mutations to high frequency genetic markers such as single nucleotide polymorphisms. Instead, the sums of allelic mutation frequencies in case and control cohorts are determined and a statistical test is applied to discover if the difference in these sums is greater than would be expected by chance. A statistical model is presented that defines the ability of such tests to detect significant gene-disease relationships as a function of case and control cohort sizes and key confounding variables: zygosity and genicity, environmental risk factors, errors in diagnosis, limits to mutant detection, linkage of neutral and risk-conferring mutations, ethnic diversity in the general population and the expectation that among all exonic mutants in the human genome greater than 90{\%} will be neutral with regard to any effect on disease risk. Means to test the null hypothesis for, and determine the statistical power of, each test are provided. For this "cohort allelic sums test" or "CAST", the statistical model and test are provided as an Excel program, CASTAT(c) at . Based on genetics, technology and statistics, a strategy of enumerating the mutant alleles carried in the exons and splice sites of the estimated approximately 25,000 human genes in case cohort samples of 10,000 persons for each of 100 common diseases is proposed and evaluated: A wide range of possible conditions of multi-allelic or mono-allelic and monogenic, multigenic or polygenic (including epistatic) risk are found to be detectable using the statistical criteria of 1 or 10 "false positive" gene associations approximately 25,000 gene-disease pair-wise trials and a statistical power of {\textgreater}0.8. Using estimates of the distribution of both neutral and gene-inactivating nondeleterious mutations in humans and the sensitivity of the test to multigenic or multicausal risk, it is estimated that about 80{\%} of nullizygous, heterozygous and functionally dominant gene-common disease associations may be discovered. Limitations include relative insensitivity of CAST to about 60{\%} of possible associations given homozygous (wild type) risk and, more rarely, other stochastic limits when the frequency of mutations in the case cohort approaches that of the control cohort and biases such as absence of genetic risk masked by risk derived from a shared cultural environment.},
annote = {17101154},
author = {Morgenthaler, S and Thilly, W G},
doi = {10.1016/j.mrfmmm.2006.09.003},
journal = {Mutat Res},
number = {1-2},
pages = {28--56},
title = {{A strategy to discover genes that carry multi-allelic or mono-allelic risk for common diseases: a cohort allelic sums test (CAST)}},
url = {http://www.hubmed.org/display.cgi?uids=17101154},
volume = {615},
year = {2007}
}
@article{Kvon2020,
author = {Kvon, Evgeny Z and Waymack, Rachel and Elabd, Mario G and Wunderlich, Zeba},
doi = {10.1038/s41576-020-00311-x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Reviews Genetics/Kvon et al. - 2020 - Enhancer redundancy in development and disease.pdf:pdf},
issn = {1471-0064},
journal = {Nature Reviews Genetics},
publisher = {Springer US},
title = {{Enhancer redundancy in development and disease}},
url = {http://dx.doi.org/10.1038/s41576-020-00311-x},
year = {2020}
}
@article{Hart2015,
abstract = {Summary The ability to perturb genes in human cells is crucial for elucidating gene function and holds great potential for finding therapeutic targets for diseases such as cancer. To extend the catalog of human core and context-dependent fitness genes, we have developed a high-complexity second-generation genome-scale CRISPR-Cas9 gRNA library and applied it to fitness screens in five human cell lines. Using an improved Bayesian analytical approach, we consistently discover 5-fold more fitness genes than were previously observed. We present a list of 1,580 human core fitness genes and describe their general properties. Moreover, we demonstrate that context-dependent fitness genes accurately recapitulate pathway-specific genetic vulnerabilities induced by known oncogenes and reveal cell-type-specific dependencies for specific receptor tyrosine kinases, even in oncogenic KRAS backgrounds. Thus, rigorous identification of human cell line fitness genes using a high-complexity CRISPR-Cas9 library affords a high-resolution view of the genetic vulnerabilities of a cell.},
author = {Hart, Traver and Chandrashekhar, Megha and Aregger, Michael and Steinhart, Zachary and Brown, Kevin R. and MacLeod, Graham and Mis, Monika and Zimmermann, Michal and Fradet-Turcotte, Amelie and Sun, Song and Mero, Patricia and Dirks, Peter and Sidhu, Sachdev and Roth, Frederick P. and Rissland, Olivia S. and Durocher, Daniel and Angers, Stephane and Moffat, Jason},
doi = {10.1016/j.cell.2015.11.015},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Hart et al. - 2015 - High-Resolution CRISPR Screens Reveal Fitness Genes and Genotype-Specific Cancer Liabilities.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {6},
pages = {1515--1526},
pmid = {26627737},
publisher = {Elsevier Inc.},
title = {{High-Resolution CRISPR Screens Reveal Fitness Genes and Genotype-Specific Cancer Liabilities}},
url = {http://dx.doi.org/10.1016/j.cell.2015.11.015},
volume = {163},
year = {2015}
}
@article{WK12,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23138309{\}}{\{}23138309{\}}},
author = {Ward, L D and Kellis, M},
journal = {Nature Biotechnology},
keywords = {epigenetics},
mendeley-tags = {epigenetics},
month = {nov},
number = {11},
pages = {1095--1106},
title = {{{\{}I{\}}nterpreting noncoding genetic variation in complex traits and human disease}},
volume = {30},
year = {2012}
}
@article{LeightonJ2008,
author = {Core, Leighton J and Waterfall, Joshua J and Lis, John T},
doi = {10.1126/science.1162228},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Core, Waterfall, Lis - 2008 - Nascent RNA Sequencing Reveals Widespread Pausing and Divergent Initiation at Human Promoters.pdf:pdf},
journal = {Science},
keywords = {Kathryn,eRNA,genetics},
mendeley-tags = {Kathryn,eRNA,genetics},
number = {5909},
pages = {1845--1848},
title = {{Nascent RNA Sequencing Reveals Widespread Pausing and Divergent Initiation at Human Promoters}},
url = {www.sciencemag.org/cgi/content/full/1162228/DC1},
volume = {322},
year = {2008}
}
@article{NMR09,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/19684899{\}}{\{}19684899{\}}},
author = {Soininen, P and Kangas, A J and Wurtz, P and Tukiainen, T and Tynkkynen, T and Laatikainen, R and Jarvelin, M R and Kahonen, M and Lehtimaki, T and Viikari, J and Raitakari, O T and Savolainen, M J and Ala-Korpela, M},
journal = {Analyst},
month = {sep},
number = {9},
pages = {1781--1785},
title = {{{\{}H{\}}igh-throughput serum {\{}N{\}}{\{}M{\}}{\{}R{\}} metabonomics for cost-effective holistic studies on systemic metabolism}},
volume = {134},
year = {2009}
}
@article{BetH14,
author = {Belloni, Alexandre and Chernozhukov, Victor and Hansen, Christian},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Review of Economic Studies/Belloni, Chernozhukov, Hansen - 2014 - Inference on treatment effects after selection among high-dimensional controls.pdf:pdf},
journal = {The Review of Economic Studies},
number = {2},
pages = {608--650},
publisher = {Oxford University Press},
title = {{Inference on treatment effects after selection among high-dimensional controls}},
volume = {81},
year = {2014}
}
@article{Shah2018,
abstract = {It is a common saying that testing for conditional independence, i.e., testing whether whether two random vectors {\$}X{\$} and {\$}Y{\$} are independent, given {\$}Z{\$}, is a hard statistical problem if {\$}Z{\$} is a continuous random variable (or vector). In this paper, we prove that conditional independence is indeed a particularly difficult hypothesis to test for. Valid statistical tests are required to have a size that is smaller than a predefined significance level, and different tests usually have power against a different class of alternatives. We prove that a valid test for conditional independence does not have power against any alternative. Given the non-existence of a uniformly valid conditional independence test, we argue that tests must be designed so their suitability for a particular problem may be judged easily. To address this need, we propose in the case where {\$}X{\$} and {\$}Y{\$} are univariate to nonlinearly regress {\$}X{\$} on {\$}Z{\$}, and {\$}Y{\$} on {\$}Z{\$} and then compute a test statistic based on the sample covariance between the residuals, which we call the generalised covariance measure (GCM). We prove that validity of this form of test relies almost entirely on the weak requirement that the regression procedures are able to estimate the conditional means {\$}X{\$} given {\$}Z{\$}, and {\$}Y{\$} given {\$}Z{\$}, at a slow rate. We extend the methodology to handle settings where {\$}X{\$} and {\$}Y{\$} may be multivariate or even high-dimensional. While our general procedure can be tailored to the setting at hand by combining it with any regression technique, we develop the theoretical guarantees for kernel ridge regression. A simulation study shows that the test based on GCM is competitive with state of the art conditional independence tests. Code is available as the R package GeneralisedCovarianceMeasure on CRAN.},
archivePrefix = {arXiv},
arxivId = {1804.07203},
author = {Shah, Rajen D. and Peters, Jonas},
eprint = {1804.07203},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics, to appear/Shah, Peters - 2020 - The Hardness of Conditional Independence Testing and the Generalised Covariance Measure.pdf:pdf},
issn = {0090-5364},
journal = {Annals of Statistics, to appear},
keywords = {causality,conditional randomization test},
mendeley-tags = {causality,conditional randomization test},
title = {{The Hardness of Conditional Independence Testing and the Generalised Covariance Measure}},
url = {http://arxiv.org/abs/1804.07203},
year = {2020}
}
@article{Wang2014,
abstract = {The bacterial clustered regularly interspaced short palindromic repeats (CRISPR)-Cas9 system for genome editing has greatly expanded the toolbox for mammalian genetics, enabling the rapid generation of isogenic cell lines and mice with modified alleles. Here, we describe a pooled, loss-of-function genetic screening approach suitable for both positive and negative selection that uses a genome-scale lentiviral single-guide RNA (sgRNA) library. sgRNA expression cassettes were stably integrated into the genome, which enabled a complex mutant pool to be tracked by massively parallel sequencing. We used a library containing 73,000 sgRNAs to generate knockout collections and performed screens in two human cell lines. A screen for resistance to the nucleotide analog 6-thioguanine identified all expected members of the DNA mismatch repair pathway, whereas another for the DNA topoisomerase II (TOP2A) poison etoposide identified TOP2A, as expected, and also cyclin-dependent kinase 6, CDK6. A negative selection screen for essential genes identified numerous gene sets corresponding to fundamental processes. Last, we show that sgRNA efficiency is associated with specific sequence motifs, enabling the prediction of more effective sgRNAs. Collectively, these results establish Cas9/sgRNA screens as a powerful tool for systematic genetic analysis in mammalian cells.},
author = {Wang, Tim and Wei, Jenny J. and Sabatini, David M. and Lander, Eric S.},
doi = {10.1136/bmjspcare-2011-000063},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Wang et al. - 2014 - Genetic screens in human cells using the CRISPR-Cas9 system.pdf:pdf},
issn = {20454368},
journal = {Science},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
pages = {80--84},
pmid = {24336569},
title = {{Genetic screens in human cells using the CRISPR-Cas9 system}},
volume = {343},
year = {2014}
}
@article{YL06,
author = {Yuan, Ming and Lin, Yi},
doi = {10.1111/j.1467-9868.2005.00532.x},
issn = {1369-7412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {Lasso,canonical,groups,high-dimensional regression},
mendeley-tags = {Lasso,canonical,groups,high-dimensional regression},
number = {1},
pages = {49--67},
title = {{Model selection and estimation in regression with grouped variables}},
url = {http://dx.doi.org/10.1111/j.1467-9868.2005.00532.x},
volume = {68},
year = {2006}
}
@article{Delattre2015,
abstract = {The false discovery proportion (FDP) is a convenient way to account for false positives when a large number m of tests are performed simultaneously. Romano and Wolf [Ann. Statist. 35 (2007) 1378-1408] have proposed a general principle that builds FDP controlling procedures from k-family-wise error rate controlling procedures while incorporating dependencies in an appropriate manner; see Korn et al. [J. Statist. Plann. Inference 124 (2004) 379-398]; Romano and Wolf (2007). However, the theoretical validity of the latter is still largely unknown. This paper provides a careful study of this heuris-tic: first, we extend this approach by using a notion of "bounding device" that allows us to cover a wide range of critical values, including those that adapt to m 0 , the number of true null hypotheses. Second, the theoretical validity of the latter is investigated both nonasymptotically and asymptotically. Third, we introduce suitable modifications of this heuristic that provide new methods, overcoming the existing procedures with a proven FDP control.},
author = {Delattre, Sylvain and Roquain, Etienne},
doi = {10.1214/14-AOS1302},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics/Delattre, Roquain - 2015 - NEW PROCEDURES CONTROLLING THE FALSE DISCOVERY PROPORTION VIA ROMANO-WOLF'S HEURISTIC.pdf:pdf},
journal = {The Annals of Statistics},
keywords = {60F17,62H15,FDX,Gaussian multivariate distribution,Multiple testing,Simes's inequality,equi-correlation,false discovery rate,positive dependence},
mendeley-tags = {FDX,Multiple testing},
number = {3},
pages = {1141--1177},
title = {{NEW PROCEDURES CONTROLLING THE FALSE DISCOVERY PROPORTION VIA ROMANO-WOLF'S HEURISTIC}},
volume = {43},
year = {2015}
}
@article{XetW03,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/12925518{\}}{\{}12925518{\}}},
author = {Xu, Xin and Tian, Lu and Wei, L J},
journal = {Biostatistics},
keywords = {genetics,multiple phenotypes},
mendeley-tags = {genetics,multiple phenotypes},
number = {2},
pages = {223--229},
publisher = {Biometrika Trust},
title = {{Combining dependent tests for linkage or association across multiple phenotypic traits}},
volume = {4},
year = {2003}
}
@article{katsevich17mkf,
author = {Katsevich, Eugene and Sabatti, Chiara},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Applied Statistics/Katsevich, Sabatti - 2019 - Multilayer knockoff filter Controlled variable selection at multiple resolutions.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Applied Statistics/Katsevich, Sabatti - 2019 - Multilayer knockoff filter Controlled variable selection at multiple resolutions(2).pdf:pdf},
journal = {The Annals of Applied Statistics},
keywords = {FDR,Multiple testing,groups,knockoffs},
mendeley-tags = {FDR,Multiple testing,groups,knockoffs},
number = {1},
pages = {1--33},
publisher = {Institute of Mathematical Statistics},
title = {{Multilayer knockoff filter: Controlled variable selection at multiple resolutions}},
volume = {13},
year = {2019}
}
@article{Nasser2020,
author = {Nasser, Joseph and Bergman, Drew T and Fulco, Charles P and Guckelberger, Philine and Doughty, Benjamin R and Patwardhan, Tejal A. and Jones, Thouis R. and Nguyen, Tung H. and Ulirsch, Jacob C. and Natri, Heini M. and Weeks, Elle M. and Munson, Glen and Kane, Michael and Kang, Helen Y. and Cui, Ang and Ray, John P. and Eisenhaure, Tom M. and Mualim, Kristy and Collins, Ryan L. and Dey, Kushal and Price, Alkes L. and Epsteil, Charles B. and Kundaje, Anshul and Xavier, Ramnik J. and Daly, Mark J. and Huang, Dailiang and Finucane, Hilary K. and Hacohen, Nir and Lander, Eric S. and {Jesse M. Engreitz}},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Nasser et al. - 2020 - Genome-wide maps of enhancer regulation connect risk variants to disease genes.pdf:pdf},
journal = {bioRxiv},
keywords = {CRISPR,activity by contact model,gene-enhancer},
mendeley-tags = {CRISPR,activity by contact model,gene-enhancer},
title = {{Genome-wide maps of enhancer regulation connect risk variants to disease genes}},
year = {2020}
}
@article{IetL11,
abstract = {Rapid advances in sequencing technologies set the stage for the large-scale medical sequencing efforts to be performed in the near future, with the goal of assessing the importance of rare variants in complex diseases. The discovery of new disease susceptibility genes requires powerful statistical methods for rare variant analysis. The low frequency and the expected large number of such variants pose great difficulties for the analysis of these data. We propose here a robust and powerful testing strategy to study the role rare variants may play in affecting susceptibility to complex traits. The strategy is based on assessing whether rare variants in a genetic region collectively occur at significantly higher frequencies in cases compared with controls (or vice versa). A main feature of the proposed methodology is that, although it is an overall test assessing a possibly large number of rare variants simultaneously, the disease variants can be both protective and risk variants, with moderate decreases in statistical power when both types of variants are present. Using simulations, we show that this approach can be powerful under complex and general disease models, as well as in larger genetic regions where the proportion of disease susceptibility variants may be small. Comparisons with previously published tests on simulated data show that the proposed approach can have better power than the existing methods. An application to a recently published study on Type-1 Diabetes finds rare variants in gene IFIH1 to be protective against Type-1 Diabetes.},
annote = {21304886},
author = {Ionita-Laza, Iuliana and Buxbaum, Joseph D and Laird, Nan M and Lange, Christoph},
journal = {PLoS Genetics},
keywords = {genetics,rare variants},
mendeley-tags = {genetics,rare variants},
pages = {e1001289--e1001289},
title = {{{\{}A{\}} new Testing Strategy to Identify rare Variants with Either risk or Protective Effect on Disease}},
volume = {7},
year = {2011}
}
@article{Ron2017,
abstract = {Proximity-ligation methods such as Hi-C allow us to map physical DNA-DNA interactions along the genome, and reveal its organization into topologically associating domains (TADs). As the Hi-C data accumulate, computational methods were developed for identifying domain borders in multiple cell types and organisms. Here, we present PSYCHIC, a computational approach for analyzing Hi-C data and identifying promoter-enhancer interactions. We use a unified probabilistic model to segment the genome into domains, which we then merge hierarchically and fit using a local background model, allowing us to identify over-represented DNA-DNA interactions across the genome. By analyzing the published Hi-C data sets in human and mouse, we identify hundreds of thousands of putative enhancers and their target genes, and compile an extensive genome-wide catalog of gene regulation in human and mouse. As we show, our predictions are highly enriched for ChIP-seq and DNA accessibility data, evolutionary conservation, eQTLs and other DNA-DNA interaction data.},
author = {Ron, Gil and Globerson, Yuval and Moran, Dror and Kaplan, Tommy},
doi = {10.1038/s41467-017-02386-3},
journal = {Nature Communications},
keywords = {Kathryn,gene-enhancer,genetics,to-read},
mendeley-tags = {Kathryn,gene-enhancer,genetics,to-read},
number = {1},
title = {{Promoter-enhancer interactions identified from Hi-C data using probabilistic models and hierarchical topological domains}},
url = {www.nature.com/naturecommunications},
volume = {8},
year = {2017}
}
@book{ville_etude_1939,
address = {Paris},
author = {Ville, J},
publisher = {Gauthier-Villars},
title = {{Etude critique de la notion de collectif}},
year = {1939}
}
@article{Ge2020,
author = {Ge, Xinzhou and Chen, Yiling Elaine and Song, Dongyuan and Mcdermott, Meilu and Woyshner, Kyla},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Ge et al. - 2020 - Clipper p-value-free FDR control on high-throughput data from two conditions.pdf:pdf},
journal = {bioRxiv},
keywords = {FDR,genomics},
mendeley-tags = {FDR,genomics},
pages = {1--63},
title = {{Clipper : p-value-free FDR control on high-throughput data from two conditions}},
year = {2020}
}
@article{Genga2019,
abstract = {Genga et al. utilize a single-cell RNA-sequencing-based CRISPR interference approach to screen transcription factors predicted to have a role in human definitive endoderm differentiation. The perturbation screen identifies an important role of TGF$\beta$ signaling-related factors. Follow-up of FOXA2 reveals genome-wide molecular changes and altered differentiation competency in endoderm.},
author = {Genga, Ryan M.J. and Kernfeld, Eric M. and Parsi, Krishna M. and Parsons, Teagan J. and Ziller, Michael J. and Maehr, Ren{\'{e}}},
doi = {10.1016/j.celrep.2019.03.076},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell Reports/Genga et al. - 2019 - Single-Cell RNA-Sequencing-Based CRISPRi Screening Resolves Molecular Drivers of Early Human Endoderm Development.pdf:pdf},
issn = {22111247},
journal = {Cell Reports},
keywords = {CRISPR,CRISPRi,chromatin accessibility,dCas9-KRAB,endoderm,hepatic endoderm,human development,perturbation screen,pluripotent stem cells,single cell,single-cell RNA-seq,stem cell differentiation},
mendeley-tags = {CRISPR,single cell},
number = {3},
pages = {708--718.e10},
pmid = {30995470},
title = {{Single-Cell RNA-Sequencing-Based CRISPRi Screening Resolves Molecular Drivers of Early Human Endoderm Development}},
volume = {27},
year = {2019}
}
@article{SB09,
abstract = {Bayesian statistical methods have recently made great inroads into many areas of science, and this advance is now extending to the assessment of association between genetic variants and disease or other phenotypes. We review these methods, focusing on single-SNP tests in genome-wide association studies. We discuss the advantages of the Bayesian approach over classical (frequentist) approaches in this setting and provide a tutorial on basic analysis steps, including practical guidelines for appropriate prior specification. We demonstrate the use of Bayesian methods for fine mapping in candidate regions, discuss meta-analyses and provide guidance for refereeing manuscripts that contain Bayesian analyses.},
annote = {19763151},
author = {Stephens, M and Balding, D J},
doi = {10.1038/nrg2615},
journal = {Nature Reviews Genetics},
keywords = {GWAS},
mendeley-tags = {GWAS},
number = {10},
pages = {681--690},
title = {{Bayesian statistical methods for genetic association studies}},
url = {http://www.hubmed.org/display.cgi?uids=19763151},
volume = {10},
year = {2009}
}
@article{Larke2019,
abstract = {Gene transcription occurs via a cycle of linked events including initiation, promoter proximal pausing and elongation of RNA polymerase II (Pol II). A key question is how do transcriptional enhancers influence these events to control gene expression? Here we have used a new approach to quantify transcriptional initiation and pausing in vivo , while simultaneously identifying transcription start sites (TSSs) and pause-sites (TPSs) from single RNA molecules. When analyzed in parallel with nascent RNA-seq, these data show that differential gene expression is achieved predominantly via changes in transcription initiation rather than Pol II pausing. Using genetically engineered mouse models deleted for specific enhancers we show that these elements control gene expression via Pol II recruitment and/or initiation rather than via promoter proximal pause release. Together, our data show that enhancers, in general, control gene expression predominantly by Pol II recruitment and initiation rather than via pausing.},
author = {Larke, Martin S. C. and Nojima, Takayuki and Telenius, Jelena and Sharpe, Jacqueline A. and Sloane-Stanley, Jacqueline A. and Butler, Sue and Beagrie, Robert A. and Downes, Damien J. and Schwessinger, Ron and Oudelaar, A. Marieke and Truch, Julia and Crompton, Bryony and Bender, M. A. and Proudfoot, Nicholas J. and Higgs, Douglas R. and Hughes, Jim R.},
doi = {10.1101/844191},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Larke et al. - 2019 - Enhancers predominantly regulate gene expression in vivo via transcription initiation.pdf:pdf},
journal = {bioRxiv},
pages = {844191},
title = {{Enhancers predominantly regulate gene expression in vivo via transcription initiation}},
url = {https://www.biorxiv.org/content/10.1101/844191v1},
volume = {60},
year = {2019}
}
@article{LetT14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25574062{\}}{\{}25574062{\}}},
author = {Lockhart, R and Taylor, J and Tibshirani, R J and Tibshirani, R},
journal = {The Annals of Statistics},
month = {apr},
number = {2},
pages = {413--468},
title = {{{\{}A{\}} significance test for the lasso}},
volume = {42},
year = {2014}
}
@article{Mccarty2020,
author = {Mccarty, Nicholas S and Graham, Alicia E and Studen{\'{a}}, Lucie and Ledesma-amaro, Rodrigo},
doi = {10.1038/s41467-020-15053-x},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Communications/Mccarty et al. - 2020 - Multiplexed CRISPR technologies for gene editing.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications},
keywords = {CRISPR},
mendeley-tags = {CRISPR},
publisher = {Springer US},
title = {{Multiplexed CRISPR technologies for gene editing}},
url = {http://dx.doi.org/10.1038/s41467-020-15053-x},
volume = {11},
year = {2020}
}
@article{Catarino2018,
abstract = {Enhancers are important genomic regulatory elements directing cell type-specific transcription. They assume a key role during development and disease, and their identification and functional characterization have long been the focus of scientific interest. The advent of next-generation sequencing and clustered regularly interspaced short palindromic repeat (CRISPR)/Cas9-based genome editing has revolutionized the means by which we study enhancer biology. In this review, we cover recent developments in the prediction of enhancers based on chromatin characteristics and their identification by functional reporter assays and endogenous DNA perturbations. We discuss that the two latter approaches provide different and complementary insights, especially in assessing enhancer sufficiency and necessity for transcription activation. Furthermore, we discuss recent insights into mechanistic aspects of enhancer function, including findings about cofactor requirements and the role of post-translational histone modifications such as monomethylation of histone H3 Lys4 (H3K4me1). Finally, we survey how these approaches advance our understanding of transcription regulation with respect to promoter specificity and transcriptional bursting and provide an outlook covering open questions and promising developments.},
author = {Catarino, Rui R. and Stark, Alexander},
doi = {10.1101/gad.310367.117},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genes and Development/Catarino, Stark - 2018 - Assessing sufficiency and necessity of enhancer activities for gene expression and the mechanisms of transcript.pdf:pdf},
issn = {15495477},
journal = {Genes and Development},
keywords = {Enhancer prediction,Enhancers,Gene expression,Genetic screens,Kathryn,Reporter assays,Transcription regulation,enhancer,epigenetics,gene-enhancer},
mendeley-tags = {Kathryn,enhancer,epigenetics,gene-enhancer},
number = {3-4},
pages = {202--223},
title = {{Assessing sufficiency and necessity of enhancer activities for gene expression and the mechanisms of transcription activation}},
volume = {32},
year = {2018}
}
@article{McFaline-Figueroa2019a,
abstract = {Integrating single-cell trajectory analysis with pooled genetic screening could reveal the genetic architecture that guides cellular decisions in development and disease. We applied this paradigm to probe the genetic circuitry that controls epithelial-to-mesenchymal transition (EMT). We used single-cell RNA sequencing to profile epithelial cells undergoing a spontaneous spatially determined EMT in the presence or absence of transforming growth factor-$\beta$. Pseudospatial trajectory analysis identified continuous waves of gene regulation as opposed to discrete ‘partial' stages of EMT. KRAS was connected to the exit from the epithelial state and the acquisition of a fully mesenchymal phenotype. A pooled single-cell CRISPR-Cas9 screen identified EMT-associated receptors and transcription factors, including regulators of KRAS, whose loss impeded progress along the EMT. Inhibiting the KRAS effector MEK and its upstream activators EGFR and MET demonstrates that interruption of key signaling events reveals regulatory ‘checkpoints' in the EMT continuum that mimic discrete stages, and reconciles opposing views of the program that controls EMT.},
author = {McFaline-Figueroa, Jos{\'{e}} L. and Hill, Andrew J. and Qiu, Xiaojie and Jackson, Dana and Shendure, Jay and Trapnell, Cole},
doi = {10.1038/s41588-019-0489-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/McFaline-Figueroa et al. - 2019 - A pooled single-cell genetic screen identifies regulatory checkpoints in the continuum of the epitheli.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {CRISPR,single cell},
mendeley-tags = {CRISPR,single cell},
number = {9},
pages = {1389--1398},
pmid = {31477929},
publisher = {Springer US},
title = {{A pooled single-cell genetic screen identifies regulatory checkpoints in the continuum of the epithelial-to-mesenchymal transition}},
url = {http://dx.doi.org/10.1038/s41588-019-0489-5},
volume = {51},
year = {2019}
}
@article{Holm1979,
author = {Holm, S},
journal = {Scandinavian Journal of Statistics},
keywords = {FWER,Multiple testing,canonical},
mendeley-tags = {FWER,Multiple testing,canonical},
number = {2},
pages = {65--70},
title = {{A simple sequentially rejective multiple test procedure}},
volume = {6},
year = {1979}
}
@article{GetV07,
author = {Grossmann, Steffen and Bauer, Sebastian and Robinson, Peter N and Vingron, Martin},
journal = {Bioinformatics},
number = {22},
pages = {3024--3031},
publisher = {Oxford University Press},
title = {{Improved detection of overrepresentation of Gene-Ontology annotations with parent--child analysis}},
volume = {23},
year = {2007}
}
@article{Burman2009,
abstract = {In this paper we describe Bonferroni-based multiple testing procedures (MTPs) as strategies to split and recycle test mass. Here, ‘test mass' refers to (parts of) the nominal level ? at which the family-wise error rate is controlled. Briefly, test mass is split between different null hypotheses, and whenever a null hypothesis is rejected, the part of ? allocated to it may be recycled to the testing of other hypotheses. These recycling MTPs are closed testing procedures based on raw p-values associated with testing the individual null hypotheses, and the class of such MTPs includes, for example, serial and parallel gatekeeping, fallback and Holm procedures. Graphical displays and a concise algebraic notation are provided for such MTPs. This recycling approach has pedagogical advantages and may facilitate the tailoring of MTPs for different purposes. Copyright},
author = {Burman, C. F. and Sonesson, C. and Guilbaud, O.},
doi = {10.1002/sim},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistics in Medicine/Burman, Sonesson, Guilbaud - 2009 - A recycling framework for the construction of Bonferroni-based multiple tests.pdf:pdf},
journal = {Statistics in Medicine},
keywords = {Bonferroni,FWER,Holm,Multiple testing,closed tests,family-wise error rate,gatekeeping,multiplicity,to-read},
mendeley-tags = {FWER,Multiple testing,to-read},
pages = {739--761},
title = {{A recycling framework for the construction of Bonferroni-based multiple tests}},
volume = {28},
year = {2009}
}
@article{S13multi,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/23861737{\}}{\{}23861737{\}}},
author = {Stephens, M},
journal = {PLoS ONE},
keywords = {multiple phenotypes},
mendeley-tags = {multiple phenotypes},
number = {7},
pages = {e65245},
title = {{{\{}A{\}} unified framework for association analysis with multiple related phenotypes}},
volume = {8},
year = {2013}
}
@article{Fan2001,
abstract = {Likelihood ratio theory has had tremendous success in parametric inference, due to the fundamental theory of Wilks. Yet, there is no general applicable approach for nonparametric inferences based on function estimation. Maximum likelihood ratio test statistics in general may not exist in nonparametric function estimation setting. Even if they exist, they are hard to find and can not be optimal as shown in this paper. We introduce the generalized likelihood statistics to overcome the drawbacks of nonparametric maximum likelihood ratio statistics. A new Wilks phenomenon is unveiled. We demonstrate that a class of the generalized likelihood statistics based on some appropriate nonparametric estimators are asymptotically distribution free and follow x2-distributions under null hypotheses for a number of useful hypotheses and a variety of useful models including Gaussian white noise models, nonparametric regression models, varying coefficient models and generalized varying coefficient models. We further demonstrate that generalized likelihood ratio statistics are asymptotically optimal in the sense that they achieve optimal rates of convergence given by Ingster. They can even be adaptively optimal in the sense of Spokoiny by using a simple choice of adaptive smoothing parameter. Our work indicates that the generalized likelihood ratio statistics are indeed general and powerful for nonparametric testing problems based on function estimation.},
author = {Fan, Jianqing and Zhang, Chunming and Zhang, Jian},
doi = {10.1214/aos/996986505},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Fan, Zhang, Zhang - 2001 - Generalized likelihood ratio statistics and Wilks phenomenon.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Asymptotic null distribution,Gaussian white noise models,Generalized likelihood,Nonparametric test,Optimal rates,Power function,Wilks thoerem,asymptotics},
mendeley-tags = {asymptotics},
number = {1},
pages = {153--193},
title = {{Generalized likelihood ratio statistics and Wilks phenomenon}},
volume = {29},
year = {2001}
}
@article{MTHESS,
author = {Lewin, A and Saadi, H and Peters, J E and Moreno-Moral, A and Lee, J C and Smith, K G and Petretto, E and Bottolo, L and Richardson, S},
journal = {Bioinformatics},
keywords = {genetics},
mendeley-tags = {genetics},
number = {4},
pages = {523--532},
title = {{{\{}MT-HESS{\}}: an efficient {\{}B{\}}ayesian approach for simultaneous association detection in {\{}OMICS{\}} datasets, with application to {\{}eQTL{\}} mapping in multiple tissues}},
volume = {32},
year = {2016}
}
@article{Pfanzagl1993,
abstract = {Consistency of choice is a fundamental and recurring theme in decision theory, social choice theory, behavioral economics, and psychological sciences. The purpose of this paper is to study the consistency of choice independent of the particular decision model at hand. Consistency is viewed as an inherently logical concept that is fundamentally void of connotation and is thus disentangled from traditional rationality or consistency conditions imposed on decision models. The proposed formalization of consistency takes two forms: internal consistency, which refers to the property that a choice model does not generate contradictory statements; and semantic consistency, which refers to the idea that a theory's predictions are valid with respect to some observed data. In addressing semantic consistency, the relationship between theory and data is analyzed in terms of so-called duality mappings, which allow a passage between the two universes in a way that consistency is preserved. The formalization of consistency concepts relies on adapting the revealed preference theory to the context-dependent setting. The paper concludes by discussing the implications of the proposed framework and how it relates to classical revealed preference theory and other formalizations of the relationship between the theory and reality of choice.},
author = {Pfanzagl, J.},
doi = {10.1007/s11238-017-9635-7},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Ann. Inst. Statist. Math/Pfanzagl - 1993 - ON THE CONSISTENCY OF CONDITIONAL MAXIMUM LIKELIHOOD ESTIMATORS.pdf:pdf},
issn = {15737187},
journal = {Ann. Inst. Statist. Math.},
keywords = {Estimation,asymptotics,consistency,logistic distribution,nuisance parameters},
mendeley-tags = {asymptotics},
number = {4},
pages = {703--719},
title = {{ON THE CONSISTENCY OF CONDITIONAL MAXIMUM LIKELIHOOD ESTIMATORS}},
volume = {45},
year = {1993}
}
@article{Tansey2018,
abstract = {We consider the problem of feature selection using black box predictive models. For example, high-throughput devices in science are routinely used to gather thousands of features for each sample in an experiment. The scientist must then sift through the many candidate features to find explanatory signals in the data, such as which genes are associated with sensitivity to a prospective therapy. Often, predictive models are used for this task: the model is fit, error on held out data is measured, and strong performing models are assumed to have discovered some fundamental properties of the system. A model-specific heuristic is then used to inspect the model parameters and rank important features, with top features reported as "discoveries." However, such heuristics provide no statistical guarantees and can produce unreliable results. We propose the holdout randomization test (HRT) as a principled approach to feature selection using black box predictive models. The HRT is model agnostic and produces a valid p-value for each feature, enabling control over the false discovery rate (or Type I error) for any predictive model. Further, the HRT is computationally efficient and, in simulations, has greater power than a competing knockoffs-based approach. Code is available at https://github.com/tansey/hrt.},
archivePrefix = {arXiv},
arxivId = {1811.00645},
author = {Tansey, Wesley and Veitch, Victor and Zhang, Haoran and Rabadan, Raul and Blei, David M.},
eprint = {1811.00645},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Tansey et al. - 2018 - The Holdout Randomization Test Principled and Easy Black Box Feature Selection.pdf:pdf},
journal = {arXiv},
keywords = {conditional randomization test,high-dimensional regression,variable selection},
mendeley-tags = {conditional randomization test,high-dimensional regression,variable selection},
title = {{The Holdout Randomization Test: Principled and Easy Black Box Feature Selection}},
url = {http://arxiv.org/abs/1811.00645},
year = {2018}
}
@article{Franberg2017,
abstract = {A complex disease has, by definition, multiple genetic causes. In theory, these causes could be identified individually, but their identification will likely benefit from informed use of anticipated interactions between causes. In addition, characterizing and understanding interactions must be considered key to revealing the etiology of any complex disease. Large-scale collaborative efforts are now paving the way for comprehensive studies of interaction. As a consequence, there is a need for methods with a computational efficiency sufficient for modern data sets as well as for improvements of statistical accuracy and power. Another issue is that, currently, the relation between different methods for interaction inference is in many cases not transparent, complicating the comparison and interpretation of results between different interaction studies. In this paper we present computationally efficient tests of interaction for the complete family of generalized linear models (GLMs). The tests can be applied for inference of single or multiple interaction parameters, but we show, by simulation, that jointly testing the full set of interaction parameters yields superior power and control of false positive rate. Based on these tests we also describe how to combine results from multiple independent studies of interaction in a meta-analysis. We investigate the impact of several assumptions commonly made when modeling interactions. We also show that, across the important class of models with a full set of interaction parameters, jointly testing the interaction parameters yields identical results. Further, we apply our method to genetic data for car-diovascular disease. This allowed us to identify a putative interaction involved in Lp(a) plasma levels between two 'tag' variants in the LPA locus (p = 2.42 {\'{A}} 10 −09) as well as repli-cate the interaction (p = 6.97 {\'{A}} 10 −07). Finally, our meta-analysis method is used in a small (N = 16,181) study of interactions in myocardial infarction. PLOS Computational Biology | https://doi.},
author = {Fr{\aa}nberg, Mattias and Strawbridge, Rona J and Hamsten, Anders and {De Faire}, Ulf and Lagergren, Jens and Sennblad, Bengt},
doi = {10.1371/journal.pcbi.1005556},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/PLoS Computational Biology/Fr{\aa}nberg et al. - 2017 - Fast and general tests of genetic interaction for genome-wide association studies.pdf:pdf},
isbn = {1111111111},
journal = {PLoS Computational Biology},
keywords = {GWAS,interactions},
mendeley-tags = {GWAS,interactions},
title = {{Fast and general tests of genetic interaction for genome-wide association studies}},
url = {https://doi.org/10.1371/journal.pcbi.1005556},
year = {2017}
}
@article{Belloni2011,
abstract = {We propose a pivotal method for estimating high-dimensional sparse linear regression models, where the overall number of regressors $\rho$ is large, possibly much larger than n, but only s regres sors are significant. The method is a modification of the lasso, called the square-root lasso. The method is pivotal in that it neither relies on the knowledge of the standard deviation $\sigma$ nor does it need to pre-estimate $\sigma$. Moreover, the method does not rely on normality or sub-Gaussianity of noise. It achieves near-oracle performance, attaining the convergence rate a{\{}(s/n) logp{\}}{\^{}}2 in the prediction norm, and thus matching the performance of the lasso with known $\sigma$. These per formance results are valid for both Gaussian and non-Gaussian errors, under some mild moment restrictions. We formulate the square-root lasso as a solution to a convex conic programming problem, which allows us to implement the estimator using efficient algorithmic methods, such as interior-point and first-order methods. Some key words: Conic programming; High-dimensional sparse model; Moderate deviation theory.},
author = {Belloni, A and Chernozhukov, V and Wang, L},
doi = {10.1093/biomet/asr043},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Belloni, Chernozhukov, Wang - 2011 - Square-root lasso pivotal recovery of sparse signals via conic programming.pdf:pdf},
journal = {Biometrika},
keywords = {Lasso,high-dimensional regression,to-skim},
mendeley-tags = {Lasso,high-dimensional regression,to-skim},
number = {4},
pages = {791--806},
title = {{Square-root lasso: pivotal recovery of sparse signals via conic programming}},
url = {https://about.jstor.org/terms},
volume = {98},
year = {2011}
}
@article{SetF14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/24497850{\}}{\{}24497850{\}}},
author = {Service, S K and Teslovich, T M and Fuchsberger, C and Ramensky, V and Yajnik, P and Koboldt, D C and Larson, D E and Zhang, Q and Lin, L and Welch, R and Ding, L and McLellan, M D and O'Laughlin, M and Fronick, C and Fulton, L L and Magrini, V and Swift, A and Elliott, P and Jarvelin, M R and Kaakinen, M and McCarthy, M I and Peltonen, L and Pouta, A and Bonnycastle, L L and Collins, F S and Narisu, N and Stringham, H M and Tuomilehto, J and Ripatti, S and Fulton, R S and Sabatti, C and Wilson, R K and Boehnke, M and Freimer, N B},
journal = {PLoS Genetics},
month = {jan},
number = {1},
pages = {e1004147},
title = {{{\{}R{\}}e-sequencing expands our understanding of the phenotypic impact of variants at {\{}G{\}}{\{}W{\}}{\{}A{\}}{\{}S{\}} loci}},
volume = {10},
year = {2014}
}
@article{Fan1996,
author = {Fan, Yanqin and Li, Qi},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Econometrica/Fan, Li - 1996 - Consistent Model Specification Tests Omitted Variables and Semiparametric Functional Forms.pdf:pdf},
journal = {Econometrica},
keywords = {asymptotics,consistent tests,degenerate u-statistics,kernel estimation,omitted},
mendeley-tags = {asymptotics},
number = {4},
pages = {865--890},
title = {{Consistent Model Specification Tests : Omitted Variables and Semiparametric Functional Forms}},
volume = {64},
year = {1996}
}
@article{YetL11,
annote = {22144906},
author = {Yi, N and Liu, N and Zhi, D and Li, J},
journal = {PLoS Genetics},
keywords = {genetics,rare variants},
mendeley-tags = {genetics,rare variants},
month = {dec},
pages = {e1002382},
title = {{{\{}H{\}}ierarchical generalized linear models for multiple groups of rare and common variants: jointly estimating group and individual-variant effects}},
volume = {7},
year = {2011}
}
@misc{geneSLOPE,
annote = {$\backslash$url{\{}https://cran.r-project.org/web/packages/geneSLOPE/index.html{\}} [Accessed: 2016]},
author = {Brzyski, D and Peterson, C and Bogdan, M and Sabatti, C and Sobczyk, P},
keywords = {FDR,genetics,high-dimensional regression},
mendeley-tags = {FDR,genetics,high-dimensional regression},
title = {{{\{}$\backslash$tt geneSLOPE{\}}: Genome-Wide Association Study with SLOPE}},
year = {2015}
}
@article{GillesBlanchard2019,
author = {Blanchard, Gilles and Neuvial, Pierre and Roquain, Etienne},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/The Annals of Statistics, to appear/Blanchard, Neuvial, Roquain - 2020 - Post hoc confidence bounds on false positives using reference families.pdf:pdf},
journal = {The Annals of Statistics, to appear},
keywords = {and phrases,dependence,family-,higher criticism,multiple testing,post hoc inference,simes inequality,step-down algorithm,wise error rate},
title = {{Post hoc confidence bounds on false positives using reference families}},
year = {2020}
}
@article{BH08,
annote = {18261164},
author = {Benjamini, Y and Heller, R},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrics/Benjamini, Heller - 2008 - Screening for partial conjunction hypotheses.pdf:pdf},
journal = {Biometrics},
keywords = {FDR,GWAS,Multiple testing,partial conjunction,reproducibility},
mendeley-tags = {FDR,GWAS,Multiple testing,partial conjunction,reproducibility},
month = {dec},
number = {4},
pages = {1215--1222},
title = {{Screening for partial conjunction hypotheses}},
volume = {64},
year = {2008}
}
@article{Xu2020,
archivePrefix = {arXiv},
arxivId = {stat.ME/2001.01541},
author = {Xu, Ningning and Solari, Aldo and Goeman, Jelle},
eprint = {2001.01541},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Xu, Solari, Goeman - 2020 - Closed testing with Globaltest with applications on metabolomics data.pdf:pdf},
journal = {arXiv},
keywords = {closed testing,simultaneous inference,variable selection},
mendeley-tags = {closed testing,simultaneous inference,variable selection},
primaryClass = {stat.ME},
title = {{Closed testing with Globaltest with applications on metabolomics data}},
year = {2020}
}
@article{SR02,
abstract = {We illustrate how homozygosity of haplotypes can be used to measure the level of disequilibrium between two or more markers. An excess of either homozygosity or heterozygosity signals a departure from the gametic phase equilibrium: We describe the specific form of dependence that is associated with high (low) homozygosity and derive various linkage disequilibrium measures. They feature a clear biological interpretation, can be used to construct tests, and are standardized to allow comparison across loci and populations. They are particularly advantageous to measure linkage disequilibrium between highly polymorphic markers.},
annote = {11973323},
author = {Sabatti, C and Risch, N},
journal = {Genetics},
keywords = {genetics},
mendeley-tags = {genetics},
number = {4},
pages = {1707--1719},
title = {{Homozygosity and linkage disequilibrium}},
url = {http://www.hubmed.org/display.cgi?uids=11973323},
volume = {160},
year = {2002}
}
@article{BY05g,
abstract = {False discovery rate control has become an essential tool in any study that has a very large multiplicity problem. False discovery rate-controlling procedures have also been found to be very effective in QTL analysis, ensuring reproducible results with few falsely discovered linkages and offering increased power to discover QTL, although their acceptance has been slower than in microarray analysis, for example. The reason is partly because the methodological aspects of applying the false discovery rate to QTL mapping are not well developed. Our aim in this work is to lay a solid foundation for the use of the false discovery rate in QTL mapping. We review the false discovery rate criterion, the appropriate interpretation of the FDR, and alternative formulations of the FDR that appeared in the statistical and genetics literature. We discuss important features of the FDR approach, some stemming from new developments in FDR theory and methodology, which deem it especially useful in linkage analysis. We review false discovery rate-controlling procedures--the BH, the resampling procedure, and the adaptive two-stage procedure-and discuss the validity of these procedures in single- and multiple-trait QTL mapping. Finally we argue that the control of the false discovery rate has an important role in suggesting, indicating the significance of, and confirming QTL and present guidelines for its use.},
author = {Benjamini, Yoav and Yekutieli, Daniel},
journal = {Genetics},
keywords = {FDR,genetics},
mendeley-tags = {FDR,genetics},
pages = {783--790},
pmid = {15956674},
title = {{{\{}Quantitative{\}} Trait {\{}Loci{\}} Analysis Using the False Discovery rate}},
volume = {171},
year = {2005}
}
@article{Shu2019,
abstract = {Inverse probability weighting estimation has been popularly used to consistently estimate the average treatment effect. Its validity, however, is challenged by the presence of error-prone variables. In this paper, we explore the inverse probability weighting estimation with mismeasured outcome variables. We study the impact of measurement error for both continuous and discrete outcome variables and reveal interesting consequences of the naive analysis which ignores measurement error. When a continuous outcome variable is mismeasured under an additive measurement error model, the naive analysis may still yield a consistent estimator; when the outcome is binary, we derive the asymptotic bias in a closed-form. Furthermore, we develop consistent estimation procedures for practical scenarios where either validation data or replicates are available. With validation data, we propose an efficient method for estimation of average treatment effect; the efficiency gain is substantial relative to usual methods of using validation data. To provide protection against model misspecification, we further propose a doubly robust estimator which is consistent even when either the treatment model or the outcome model is misspecified. Simulation studies are reported to assess the performance of the proposed methods. An application to a smoking cessation dataset is presented.},
author = {Shu, Di and Yi, Grace Y.},
doi = {10.1177/0962280217743777},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistical Methods in Medical Research/Shu, Yi - 2019 - Causal inference with measurement error in outcomes Bias analysis and estimation methods.pdf:pdf},
issn = {14770334},
journal = {Statistical Methods in Medical Research},
keywords = {Asymptotic bias,causal inference,causality,doubly robust,efficiency,estimating function,inverse probability weighting,measurement error,misclassification,missing data},
mendeley-tags = {causality,missing data},
number = {7},
pages = {2049--2068},
title = {{Causal inference with measurement error in outcomes: Bias analysis and estimation methods}},
volume = {28},
year = {2019}
}
@article{Dey2015,
abstract = {Single-cell genomics and single-cell transcriptomics have emerged as powerful tools to study the biology of single cells at a genome-wide scale. However, a major challenge is to sequence both genomic DNA and mRNA from the same cell, which would allow direct comparison of genomic variation and transcriptome heterogeneity. We describe a quasilinear amplification strategy to quantify genomic DNA and mRNA from the same cell without physically separating the nucleic acids before amplification. We show that the efficiency of our integrated approach is similar to existing methods for single-cell sequencing of either genomic DNA or mRNA. Further, we find that genes with high cell-to-cell variability in transcript numbers generally have lower genomic copy numbers, and vice versa, suggesting that copy number variations may drive variability in gene expression among individual cells. Applications of our integrated sequencing approach could range from gaining insights into cancer evolution and heterogeneity to understanding the transcriptional consequences of copy number variations in healthy and diseased tissues.},
author = {Dey, Siddharth S. and Kester, Lennart and Spanjaard, Bastiaan and Bienko, Magda and {Van Oudenaarden}, Alexander},
doi = {10.1038/nbt.3129},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Biotechnology/Dey et al. - 2015 - Integrated genome and transcriptome sequencing of the same cell.pdf:pdf},
issn = {15461696},
journal = {Nature Biotechnology},
keywords = {multi-omics},
mendeley-tags = {multi-omics},
number = {3},
pages = {285--289},
pmid = {25599178},
title = {{Integrated genome and transcriptome sequencing of the same cell}},
volume = {33},
year = {2015}
}
@article{Hall2010,
abstract = {Higher criticism is a method for detecting signals that are both sparse and weak. Although first proposed in cases where the noise variables are independent, higher criticism also has reasonable performance in settings where those variables are correlated. In this paper we show that, by exploiting the nature of the correlation, performance can be improved by using a modified approach which exploits the potential advantages that correlation has to offer. Indeed, it turns out that the case of independent noise is the most difficult of all, from a statistical viewpoint, and that more accurate signal detection (for a given level of signal sparsity and strength) can be obtained when correlation is present. We characterize the advantages of correlation by showing how to incorporate them into the definition of an optimal detection boundary. The boundary has particularly attractive properties when correlation decays at a polynomial rate or the correlation matrix is Toeplitz. 1. Introduction. Donoho and Jin [18] developed Tukey's. {\textcopyright} 2010 Institute of Mathematical Statistics.},
author = {Hall, Peter and Jin, Jiashun},
doi = {10.1214/09-AOS764},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Statistics/Hall, Jin - 2010 - Innovated higher criticism for detecting sparse signals in correlated noise.pdf:pdf},
issn = {00905364},
journal = {Annals of Statistics},
keywords = {Adding noise,Cholesky factorization,Empirical process,Innovation,Multiple hypothesis testing,Sparse normal means,Spectral density,Toeplitz matrix,correlation},
mendeley-tags = {correlation},
number = {3},
pages = {1686--1732},
title = {{Innovated higher criticism for detecting sparse signals in correlated noise}},
volume = {38},
year = {2010}
}
@article{kostic,
author = {Kostic, Aleksandar D and Gevers, Dirk and Pedamallu, Chandra Sekhar and Michaud, Monia and Duke, Fujiko and Earl, Ashlee M and Ojesina, Akinyemi I and Jung, Joonil and Bass, Adam J and Tabernero, Josep and Others},
journal = {Genome Research},
keywords = {applied,genetics},
mendeley-tags = {applied,genetics},
number = {2},
pages = {292--298},
title = {{Genomic analysis identifies association of $\backslash$textit{\{}{\{}F{\}}usobacterium{\}} with colorectal carcinoma}},
volume = {22},
year = {2012}
}
@article{LG16,
author = {Lynch, Gavin and Guo, Wenge},
journal = {arXiv},
keywords = {unpublished},
mendeley-tags = {unpublished},
title = {{On Procedures Controlling the FDR for Testing Hierarchically Ordered Hypotheses}},
year = {2016}
}
@misc{selectiveR,
annote = {$\backslash$url{\{}https://cran.r-project.org/web/packages/selectiveInference/index.html{\}} [Accessed: 2016]},
author = {Tibshirani, R and Tibshirani, R and Taylor, J and Loftus, J and Reid, S},
keywords = {post-selection inference,software},
mendeley-tags = {post-selection inference,software},
title = {{{\{}$\backslash$tt selectiveInference{\}}: Tools for Post-Selection Inference}},
year = {2016}
}
@article{LB16,
author = {Li, Ang and Barber, Rina Foygel},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {FDR,Multiple testing,structured multiple testing},
mendeley-tags = {FDR,Multiple testing,structured multiple testing},
number = {1},
pages = {45--74},
publisher = {Wiley Online Library},
title = {{Multiple testing with the structure-adaptive Benjamini--Hochberg algorithm}},
volume = {81},
year = {2019}
}
@article{NMR12,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/22916037{\}}{\{}22916037{\}}},
author = {Inouye, M and Ripatti, S and Kettunen, J and Lyytikainen, L P and Oksala, N and Laurila, P P and Kangas, A J and Soininen, P and Savolainen, M J and Viikari, J and Kahonen, M and Perola, M and Salomaa, V and Raitakari, O and Lehtimaki, T and Taskinen, M R and Jarvelin, M R and Ala-Korpela, M and Palotie, A and de Bakker, P I},
journal = {PLoS Genetics},
number = {8},
pages = {e1002907},
title = {{{\{}N{\}}ovel {\{}L{\}}oci for metabolic networks and multi-tissue expression studies reveal genes for atherosclerosis}},
volume = {8},
year = {2012}
}
@article{Efron1975,
author = {Efron, Bradley},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Efron - 1975 - The efficiency of logistic regression compared to normal discriminant analysis.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {linear discriminant analysis,logistic regression},
mendeley-tags = {linear discriminant analysis,logistic regression},
number = {352},
pages = {892--898},
title = {{The efficiency of logistic regression compared to normal discriminant analysis}},
volume = {70},
year = {1975}
}
@article{Katsevich2020b,
abstract = {Conditional independence testing is an important problem, yet provably hard without assumptions. One of the assumptions that has become popular of late is called "model-X", where we assume we know the joint distribution of the covariates, but assume nothing about the conditional distribution of the outcome given the covariates. Knockoffs is a popular methodology associated with this framework, but it suffers from two main drawbacks: only one-bit {\$}p{\$}-values are available for inference on each variable, and the method is randomized with significant variability across runs in practice. The conditional randomization test (CRT) is thought to be the "right" solution under model-X, but usually viewed as computationally inefficient. This paper proposes a computationally efficient leave-one-covariate-out (LOCO) CRT that addresses both drawbacks of knockoffs. LOCO CRT produces valid {\$}p{\$}-values that can be used to control the familywise error rate, and has nearly zero algorithmic variability. For L1 regularized M-estimators, we develop an even faster variant called L1ME CRT, which reuses computation by leveraging a novel observation about the stability of the cross-validated lasso to removing inactive variables. Last, for multivariate Gaussian covariates, we present a closed form expression for the LOCO CRT {\$}p{\$}-value, thus completely eliminating resampling in this important special case.},
archivePrefix = {arXiv},
arxivId = {2006.08482},
author = {Katsevich, Eugene and Ramdas, Aaditya},
eprint = {2006.08482},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Katsevich, Ramdas - 2020 - The leave-one-covariate-out conditional randomization test.pdf:pdf},
journal = {arXiv},
keywords = {conditional randomization test,model-X},
mendeley-tags = {conditional randomization test,model-X},
title = {{The leave-one-covariate-out conditional randomization test}},
url = {http://arxiv.org/abs/2006.08482},
year = {2020}
}
@article{Dezeure2015,
abstract = {We present a (selective) review of recent frequentist highdimensional inference methods for constructing p-values and confidence intervals in linear and generalized linear models. We include a broad, comparative empirical study which complements the viewpoint from statistical methodology and theory. Furthermore, we introduce and illustrate the Rpackage hdi which easily allows the use of different methods and supports reproducibility.},
author = {Dezeure, Ruben and B{\"{u}}hlmann, Peter and Meier, Lukas and Meinshausen, Nicolai},
doi = {10.1214/15-STS527},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistical Science/Dezeure et al. - 2015 - High-dimensional inference Confidence intervals, P-values and R-software hdi.pdf:pdf},
issn = {08834237},
journal = {Statistical Science},
keywords = {Clustering,Confidence interval,Generalized linear model,High-dimensional statistical inference,Linear model,Multiple testing,P-value,R-software},
number = {4},
pages = {533--558},
title = {{High-dimensional inference: Confidence intervals, P-values and R-software hdi}},
volume = {30},
year = {2015}
}
@article{Fisher1990,
author = {Fisher, Nicholas I and Hall, Peter},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Australian and New Zealand Journal of Statistics/Fisher, Hall - 1990 - On bootstrap hypothesis testing.pdf:pdf},
journal = {Australian and New Zealand Journal of Statistics},
keywords = {analysis of variance,behrens-fisher problem,bootstrap,hy-,level error,monte car10 test,pivotal,pothesis test,resample,testing},
mendeley-tags = {bootstrap,testing},
number = {February 1989},
pages = {177--190},
title = {{On bootstrap hypothesis testing}},
volume = {32},
year = {1990}
}
@article{Jordan2019,
author = {Jordan, Michael I.},
doi = {10.1162/99608f92.f06c6e61},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Harvard Data Science Review/Jordan - 2019 - Artificial Intelligence—The Revolution Hasn't Happened Yet.pdf:pdf},
journal = {Harvard Data Science Review},
keywords = {AI,to-read},
mendeley-tags = {AI,to-read},
title = {{Artificial Intelligence—The Revolution Hasn't Happened Yet}},
year = {2019}
}
@article{Bi2017,
abstract = {We describe inferactive data analysis, so-named to denote an interactive approach to data analysis with an emphasis on inference after data analysis. Our approach is a compromise between Tukey's exploratory (roughly speaking "model free") and confirmatory data analysis (roughly speaking classical and "model based"), also allowing for Bayesian data analysis. We view this approach as close in spirit to current practice of applied statisticians and data scientists while allowing frequentist guarantees for results to be reported in the scientific literature, or Bayesian results where the data scientist may choose the statistical model (and hence the prior) after some initial exploratory analysis. While this approach to data analysis does not cover every scenario, and every possible algorithm data scientists may use, we see this as a useful step in concrete providing tools (with frequentist statistical guarantees) for current data scientists. The basis of inference we use is selective inference [Lee et al., 2016, Fithian et al., 2014], in particular its randomized form Tian and Taylor [2015a]. The randomized framework, besides providing additional power and shorter confidence intervals, also provides explicit forms for relevant reference distributions (up to normalization) through the selective sampler of Tian et al. [2016]. The reference distributions are constructed from a particular conditional distribution formed from what we call a DAG-DAG-a Data Analysis Generative DAG. As sampling conditional distributions in DAGs is generally complex, the selective sampler is crucial to any practical implementation of inferactive data analysis. Our principal goal is in reviewing the recent developments in selective inference as well as describing the general philosophy of selective inference. The idea of a scientist, struck, as if by lightning with a question, is far from the truth.-Tukey [1980].},
archivePrefix = {arXiv},
arxivId = {1707.06692v1},
author = {Bi, Nan and Markovic, Jelena and Xia, Lucy and Taylor, Jonathan},
eprint = {1707.06692v1},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Bi et al. - 2017 - Inferactive data analysis.pdf:pdf},
journal = {arXiv},
keywords = {adaptive data analysis,high-dimensional regression,post-selection inference,to-skim,unpublished},
mendeley-tags = {adaptive data analysis,high-dimensional regression,post-selection inference,to-skim,unpublished},
title = {{Inferactive data analysis}},
year = {2017}
}
@article{Wang2019c,
abstract = {Cell behaviors are dictated by epigenetic and transcriptional programs. Little is known about how extracellular stimuli modulate these programs to reshape gene expression and control cell behavioral responses. Here, we interrogated the epigenetic and transcriptional response of endothelial cells to VEGFA treatment and found rapid chromatin changes that mediate broad transcriptomic alterations. VEGFA-responsive genes were associated with active promoters, but changes in promoter histone marks were not tightly linked to gene expression changes. VEGFA altered transcription factor occupancy and the distal epigenetic landscape, which profoundly contributed to VEGFA-dependent changes in gene expression. Integration of gene expression, dynamic enhancer, and transcription factor occupancy changes induced by VEGFA yielded a VEGFA-regulated transcriptional regulatory network, which revealed that the small MAF transcription factors are master regulators of the VEGFA transcriptional program and angiogenesis. Collectively these results revealed that extracellular stimuli rapidly reconfigure the chromatin landscape to coordinately regulate biological responses. {\textcopyright} 2019 Wang et al.},
author = {Wang, Shiyan and Chen, Jiahuan and Garcia, Sara P. and Liang, Xiaodong and Zhang, Fang and Yan, Pengyi and Yu, Huijing and Wei, Weiting and Li, Zixuan and Wang, Jingfang and Le, Huangying and Han, Zeguang and Luo, Xusheng and Day, Daniel S. and Stevens, Sean M. and Zhang, Yan and Park, Peter J. and Liu, Zhi Jie and Sun, Kun and Yuan, Guo Cheng and Pu, William T. and Zhang, Bing},
doi = {10.1101/gr.239053.118},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Research/Wang et al. - 2019 - A dynamic and integrated epigenetic program at distal regions orchestrates transcriptional responses to VEGFA.pdf:pdf},
issn = {15495469},
journal = {Genome Research},
keywords = {Kathryn,epigenetics,genetics},
mendeley-tags = {Kathryn,epigenetics,genetics},
number = {2},
pages = {193--207},
title = {{A dynamic and integrated epigenetic program at distal regions orchestrates transcriptional responses to VEGFA}},
volume = {29},
year = {2019}
}
@book{V04,
address = {Providence, RI},
author = {Vempala, Santosh S},
isbn = {0-8218-2018-4},
pages = {x+105},
publisher = {American Mathematical Society},
series = {DIMACS Series in Discrete Mathematics and Theoretical Computer Science, 65},
title = {{The random projection method}},
year = {2004}
}
@article{M08,
author = {Meinshausen, Nicolai},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Meinshausen - 2008 - Hierarchical testing of variable importance.pdf:pdf},
journal = {Biometrika},
keywords = {FWER,Multiple testing,correlation,hierarchical multiple testing,high-dimensional regression},
mendeley-tags = {FWER,Multiple testing,correlation,hierarchical multiple testing,high-dimensional regression},
number = {2},
pages = {265--278},
publisher = {Oxford University Press},
title = {{Hierarchical testing of variable importance}},
volume = {95},
year = {2008}
}
@article{Kuroki2014,
abstract = {This paper highlights several areas where graphical techniques can be harnessed to address the problem of measurement errors in causal inference. In particular, it discusses the control of unmeasured confounders in parametric and nonparametric models and the computational problem of obtaining bias-free effect estimates in such models. We derive new conditions under which causal effects can be restored by observing proxy variables of unmeasured confounders with/without external studies. {\textcopyright} 2014 Biometrika Trust.},
author = {Kuroki, Manabu and Pearl, Judea},
doi = {10.1093/biomet/ast066},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Kuroki, Pearl - 2014 - Measurement bias and effect restoration in causal inference.pdf:pdf},
issn = {14643510},
journal = {Biometrika},
keywords = {Causal diagram,Confounder,Instrumental variable method,Proxy variable,Regression coefficient,Total effect},
number = {2},
pages = {423--437},
title = {{Measurement bias and effect restoration in causal inference}},
volume = {101},
year = {2014}
}
@article{Core2014,
abstract = {Despite the conventional distinction between them, promoters and enhancers share many features in mammals, including divergent transcription and similar modes of transcription factor binding. Here we examine the architecture of transcription initiation through comprehensive mapping of transcription start sites (TSSs) in human lymphoblastoid B cell (GM12878) and chronic myelogenous leukemic (K562) ENCODE Tier 1 cell lines. Using a nuclear run-on protocol called GRO-cap, which captures TSSs for both stable and unstable transcripts, we conduct detailed comparisons of thousands of promoters and enhancers in human cells. These analyses identify a common architecture of initiation, including tightly spaced (110 bp apart) divergent initiation, similar frequencies of core promoter sequence elements, highly positioned flanking nucleosomes and two modes of transcription factor binding. Post-initiation transcript stability provides a more fundamental distinction between promoters and enhancers than patterns of histone modification and association of transcription factors or co-activators. These results support a unified model of transcription initiation at promoters and enhancers.},
author = {Core, Leighton J. and Martins, Andr{\'{e}} L. and Danko, Charles G. and Waters, Colin T. and Siepel, Adam and Lis, John T.},
doi = {10.1038/ng.3142},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Core et al. - 2014 - Analysis of nascent RNA identifies a unified architecture of initiation regions at mammalian promoters and enhancer.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {Kathryn,eRNA,enhancer},
mendeley-tags = {Kathryn,eRNA,enhancer},
number = {12},
pages = {1311--1320},
pmid = {25383968},
publisher = {Nature Publishing Group},
title = {{Analysis of nascent RNA identifies a unified architecture of initiation regions at mammalian promoters and enhancers}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25383968{\%}0Ahttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4254663},
volume = {46},
year = {2014}
}
@article{EetY09,
abstract = {BACKGROUND Since the inception of the GO annotation project, a variety of tools have been developed that support exploring and searching the GO database. In particular, a variety of tools that perform GO enrichment analysis are currently available. Most of these tools require as input a target set of genes and a background set and seek enrichment in the target set compared to the background set. A few tools also exist that support analyzing ranked lists. The latter typically rely on simulations or on union-bound correction for assigning statistical significance to the results. RESULTS GOrilla is a web-based application that identifies enriched GO terms in ranked lists of genes, without requiring the user to provide explicit target and background sets. This is particularly useful in many typical cases where genomic data may be naturally represented as a ranked list of genes (e.g. by level of expression or of differential expression). GOrilla employs a flexible threshold statistical approach to discover GO terms that are significantly enriched at the top of a ranked gene list. Building on a complete theoretical characterization of the underlying distribution, called mHG, GOrilla computes an exact p-value for the observed enrichment, taking threshold multiple testing into account without the need for simulations. This enables rigorous statistical analysis of thousand of genes and thousands of GO terms in order of seconds. The output of the enrichment analysis is visualized as a hierarchical structure, providing a clear view of the relations between enriched GO terms. CONCLUSION GOrilla is an efficient GO analysis tool with unique features that make a useful addition to the existing repertoire of GO enrichment tools. GOrilla's unique features and advantages over other threshold free enrichment tools include rigorous statistics, fast running time and an effective graphical representation. GOrilla is publicly available at: http://cbl-gorilla.cs.technion.ac.il},
author = {Yakhini, Zohar and Eden, Eran and Navon, Roy and Steinfeld, Israel and Lipson, Doron},
doi = {10.1186/1471-2105-10-48},
issn = {1471-2105},
journal = {BMC Bioinformatics},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
pages = {48},
pmid = {19192299},
publisher = {BioMed Central},
title = {{GOrilla: a tool for discovery and visualization of enriched GO terms in ranked gene lists}},
url = {https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-10-48{\%}0Ahttp://www.ncbi.nlm.nih.gov/pubmed/19192299{\%}0Ahttp://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2644678},
volume = {10},
year = {2009}
}
@article{Wainberg2019,
abstract = {Transcriptome-wide association studies (TWAS) integrate genome-wide association studies (GWAS) and gene expression datasets to identify gene–trait associations. In this Perspective, we explore properties of TWAS as a potential approach to prioritize causal genes at GWAS loci, by using simulations and case studies of literature-curated candidate causal genes for schizophrenia, low-density-lipoprotein cholesterol and Crohn's disease. We explore risk loci where TWAS accurately prioritizes the likely causal gene as well as loci where TWAS prioritizes multiple genes, some likely to be non-causal, owing to sharing of expression quantitative trait loci (eQTL). TWAS is especially prone to spurious prioritization with expression data from non-trait-related tissues or cell types, owing to substantial cross-cell-type variation in expression levels and eQTL strengths. Nonetheless, TWAS prioritizes candidate causal genes more accurately than simple baselines. We suggest best practices for causal-gene prioritization with TWAS and discuss future opportunities for improvement. Our results showcase the strengths and limitations of using eQTL datasets to determine causal genes at GWAS loci.},
author = {Wainberg, Michael and Sinnott-Armstrong, Nasa and Mancuso, Nicholas and Barbeira, Alvaro N and Knowles, David A and Golan, David and Ermel, Raili and Ruusalepp, Arno and Quertermous, Thomas and Hao, Ke and {M Bj{\"{o}}rkegren}, Johan L and {Kyung Im}, Hae and Pasaniuc, Bogdan and Rivas, Manuel A and Kundaje, Anshul},
doi = {10.1038/s41588-019-0385-z},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Wainberg et al. - 2019 - Opportunities and challenges for transcriptome-wide association studies.pdf:pdf},
journal = {Nature Genetics},
keywords = {TWAS,gene expression,genetics,to-skim},
mendeley-tags = {TWAS,gene expression,genetics,to-skim},
pages = {592--599},
title = {{Opportunities and challenges for transcriptome-wide association studies}},
url = {https://doi.org/10.1038/s41588-019-0385-z},
volume = {51},
year = {2019}
}
@article{Andersson2019,
abstract = {The proper activities of enhancers and gene promoters are essential for coordinated transcription within a cell. Although diverse methodologies have been developed to identify enhancers and promoters, most have tacitly assumed that these elements are distinct. However, studies have unexpectedly shown that regulatory elements may have both enhancer and promoter functions. Here we review these results, focusing on the factors that determine the promoter and/or enhancer activity of regulatory elements. We discuss emerging models that define regulatory elements by accessible DNA and their non-mutually-exclusive abilities to drive transcription initiation (promoter activity) and/or to enhance transcription at other such regions (enhancer activity).},
author = {Andersson, Robin and Sandelin, Albin},
doi = {10.1038/s41576-019-0173-8},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Reviews Genetics/Andersson, Sandelin - 2019 - Determinants of enhancer and promoter activities of regulatory elements.pdf:pdf},
issn = {14710064},
journal = {Nature Reviews Genetics},
pmid = {31605096},
publisher = {Springer US},
title = {{Determinants of enhancer and promoter activities of regulatory elements}},
url = {http://dx.doi.org/10.1038/s41576-019-0173-8},
year = {2019}
}
@article{YetR11,
annote = {21700766},
author = {Yandell, M and Huff, C and Hu, H and Singleton, M and Moore, B and Xing, J and Jorde, L B and Reese, M G},
journal = {Genome Research},
month = {sep},
pages = {1529--1542},
title = {{{\{}A{\}} probabilistic disease-gene finder for personal genomes}},
volume = {21},
year = {2011}
}
@article{LetN13,
archivePrefix = {arXiv},
arxivId = {stat.ME/1311.2948},
author = {Li, G and Shabalin, A.{\~{}}A. and Rusyn, I and Wright, F.{\~{}}A. and Nobel, A.{\~{}}B.},
eprint = {1311.2948},
journal = {arXiv},
keywords = {Statistics - Methodology,eQTL,gene expression,multiple phenotypes,unpublished},
mendeley-tags = {eQTL,gene expression,multiple phenotypes,unpublished},
month = {nov},
primaryClass = {stat.ME},
title = {{An empirical {\{}B{\}}ayes approach for multiple tissue {\{}eQTL{\}} analysis}},
year = {2013}
}
@article{Heller2014,
abstract = {The paramount importance of replicating associations is well recognized in the genome-wide associaton (GWA) research community, yet methods for assessing replicability of associations are scarce. Published GWA studies often combine separately the results of primary studies and of the follow-up studies. Informally, reporting the two separate meta-analyses, that of the primary studies and follow-up studies, gives a sense of the replicability of the results. We suggest a formal empirical Bayes approach for discovering whether results have been replicated across studies, in which we estimate the optimal rejection region for discovering replicated results. We demonstrate, using realistic simulations, that the average false discovery proportion of our method remains small. We apply our method to six type two diabetes (T2D) GWA studies. Out of 803 SNPs discovered to be associated with T2D using a typical meta-analysis, we discovered 219 SNPs with replicated associations with T2D. We recommend complementing a meta-analysis with a replicability analysis for GWA studies. {\textcopyright} Institute of Mathematical Statistics, 2014.},
archivePrefix = {arXiv},
arxivId = {1209.2829},
author = {Heller, Ruth and Yekutiel, Daniel},
doi = {10.1214/13-AOAS697},
eprint = {1209.2829},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Annals of Applied Statistics/Heller, Yekutiel - 2014 - Replicability analysis for genome-wide association studies.pdf:pdf},
issn = {19417330},
journal = {Annals of Applied Statistics},
keywords = {Combined analysis,Empirical bayes,False discovery rate,Meta-analysis,Replication,Reproducibility,Type 2 diabetes,partial conjunction,reproducibility},
mendeley-tags = {partial conjunction,reproducibility},
number = {1},
pages = {481--498},
title = {{Replicability analysis for genome-wide association studies}},
volume = {8},
year = {2014}
}
@article{Turchin2019,
abstract = {1 Genome-wide association studies (GWAS) have now been conducted for 2 hundreds of phenotypes of relevance to human health. Many such GWAS 3 involve multiple closely-related phenotypes collected on the same samples. 4 However, the vast majority of these GWAS have been analyzed using simple 5 univariate analyses, which consider one phenotype at a time. This is de-6 spite the fact that, at least in simulation experiments, multivariate analyses 7 have been shown to be more powerful at detecting associations. Here, we 8 conduct multivariate association analyses on 13 different publicly-available 9 GWAS datasets that involve multiple closely-related phenotypes. These data 10},
author = {Turchin, Michael C and Stephens, Matthew},
doi = {10.1101/638882},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Turchin, Stephens - 2019 - Bayesian multivariate reanalysis of large genetic studies identifies many new associations(2).pdf:pdf},
journal = {bioRxiv},
keywords = {GWAS,genetics,multiple phenotypes,to-skim},
mendeley-tags = {GWAS,genetics,multiple phenotypes,to-skim},
title = {{Bayesian multivariate reanalysis of large genetic studies identifies many new associations}},
url = {http://dx.doi.org/10.1101/638882},
year = {2019}
}
@article{Turchin2019a,
abstract = {Genome-wide association studies (GWAS) have now been conducted for hundreds of phenotypes of relevance to human health. Many such GWAS involve multiple closely-related phenotypes collected on the same samples. However, the vast majority of these GWAS have been analyzed using simple univariate analyses, which consider one phenotype at a time. This is de-spite the fact that, at least in simulation experiments, multivariate analyses have been shown to be more powerful at detecting associations. Here, we conduct multivariate association analyses on 13 different publicly-available GWAS datasets that involve multiple closely-related phenotypes. These data include large studies of anthropometric traits (GIANT), plasma lipid traits (GlobalLipids), and red blood cell traits (HaemgenRBC). Our analyses identify many new associations (433 in total across the 13 studies), many of which replicate when follow-up samples are available. Overall, our results demonstrate that multivariate analyses can help make more effective use of data from both existing and future GWAS.Author Summary Genome-wide association studies (GWAS) have become a common and powerful tool for identifying significant correlations between markers of genetic variation and physical traits of interest. Often these studies are conducted by comparing genetic variation against single traits one at a time (‘univariate'); however, it has previously been shown that it is possible to increase your power to detect significant associations by comparing genetic variation against multiple traits simultaneously (‘multivariate'). Despite this apparent increase in power though, researchers still rarely conduct multivariate GWAS, even when studies have multiple traits readily available. Here, we reanalyze 13 previously published GWAS using a multivariate method and find {\&}gt;400 additional associations. Our method makes use of univariate GWAS summary statistics and is available as a software package, thus making it accessible to other researchers interested in conducting the same analyses. We also show, using studies that have multiple releases, that our new associations have high rates of replication. Overall, we argue multivariate approaches in GWAS should no longer be overlooked and how, often, there is low-hanging fruit in the form of new associations by running these methods on data already collected.},
author = {Turchin, Michael C and Stephens, Matthew},
doi = {10.1101/638882},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/bioRxiv/Turchin, Stephens - 2019 - Bayesian multivariate reanalysis of large genetic studies identifies many new associations.pdf:pdf},
isbn = {1111111111},
journal = {bioRxiv},
keywords = {GWAS,multiple phenotypes},
mendeley-tags = {GWAS,multiple phenotypes},
pages = {638882},
title = {{Bayesian multivariate reanalysis of large genetic studies identifies many new associations}},
url = {http://biorxiv.org/content/early/2019/08/07/638882.abstract},
year = {2019}
}
@article{SetT13,
author = {Simon, Noah and Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
doi = {10.1080/10618600.2012.681250},
issn = {1061-8600},
journal = {J. Comput. Graph. Statist.},
keywords = {groups,high-dimensional regression},
mendeley-tags = {groups,high-dimensional regression},
number = {2},
pages = {231--245},
title = {{A sparse-group lasso}},
url = {http://dx.doi.org/10.1080/10618600.2012.681250},
volume = {22},
year = {2013}
}
@article{Hart2014,
abstract = {Technological advancement has opened the door to systematic genetics in mammalian cells. Genome-scale loss-of-function screens can assay fitness defects induced by partial gene knockdown, using RNA interference, or complete gene knockout, using new CRISPR techniques. These screens can reveal the basic blueprint required for cellular proliferation. Moreover, comparing healthy to cancerous tissue can uncover genes that are essential only in the tumor; these genes are targets for the development of specific anticancer therapies. Unfortunately, progress in this field has been hampered by off-target effects of perturbation reagents and poorly quantified error rates in large-scale screens. To improve the quality of information derived from these screens, and to provide a framework for understanding the capabilities and limitations of CRISPR technology, we derive gold-standard reference sets of essential and nonessential genes, and provide a Bayesian classifier of gene essentiality that outperforms current methods on both RNAi and CRISPR screens. Our results indicate that CRISPR technology is more sensitive than RNAi and that both techniques have nontrivial false discovery rates that can be mitigated by rigorous analytical methods.},
author = {Hart, Traver and Brown, Kevin R and Sircoulomb, Fabrice and Rottapel, Robert and Moffat, Jason},
doi = {10.15252/msb.20145216},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Molecular Systems Biology/Hart et al. - 2014 - Measuring error rates in genomic perturbation screens gold standards for human functional genomics.pdf:pdf},
issn = {1744-4292},
journal = {Molecular Systems Biology},
keywords = {15252,20145216,CRISPR,Kathryn,cancer,chromatin,crispr,doi 10,epigenetics,essential genes,functional genomics,genomics,msb,received 20 february 2014,resources,revised 10 april,rnai,shrna,subject categories methods},
mendeley-tags = {CRISPR,Kathryn},
number = {7},
pages = {733},
title = {{Measuring error rates in genomic perturbation screens: gold standards for human functional genomics}},
volume = {10},
year = {2014}
}
@article{Hahn2015,
abstract = {Multiple hypothesis tests are often carried out in practice using p-value estimates obtained with bootstrap or permutation tests since the analytical p-values underlying all hypotheses are usually unknown. This article considers the allocation of a pre-specified total number of Monte Carlo simulations {\$}K \backslashin \backslashmathbb{\{}N{\}}{\$} (i.e., permutations or draws from a bootstrap distribution) to a given number of {\$}m \backslashin \backslashmathbb{\{}N{\}}{\$} hypotheses in order to approximate their p-values {\$}p \backslashin [0,1]{\^{}}m{\$} in an optimal way, in the sense that the allocation minimises the total expected number of misclassified hypotheses. A misclassification occurs if a decision on a single hypothesis, obtained with an approximated p-value, differs from the one obtained if its p-value was known analytically. The contribution of this article is threefold: Under the assumption that {\$}p{\$} is known and {\$}K \backslashin \backslashmathbb{\{}R{\}}{\$}, and using a normal approximation of the Binomial distribution, the optimal real-valued allocation of {\$}K{\$} simulations to {\$}m{\$} hypotheses is derived when correcting for multiplicity with the Bonferroni correction, both when computing the p-value estimates with or without a pseudo-count. Computational subtleties arising in the former case will be discussed. Second, with the help of an algorithm based on simulated annealing, empirical evidence is given that the optimal integer allocation is likely of the same form as the optimal real-valued allocation, and that both seem to coincide asympotically. Third, an empirical study on simulated and real data demonstrates that a recently proposed sampling algorithm based on Thompson sampling asympotically mimics the optimal (real-valued) allocation when the p-values are unknown and thus estimated at runtime.},
archivePrefix = {arXiv},
arxivId = {1502.07864},
author = {Hahn, Georg},
eprint = {1502.07864},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Hahn - 2015 - Optimal allocation of Monte Carlo simulations to multiple hypothesis tests.pdf:pdf},
journal = {arXiv},
keywords = {Monte Carlo,Multiple testing,bonferroni correction,monte carlo simulation,multiple testing,optimal alloca-,permutation test,quickmmctest,thompson sampling,tion},
mendeley-tags = {Monte Carlo,Multiple testing,permutation test},
title = {{Optimal allocation of Monte Carlo simulations to multiple hypothesis tests}},
url = {http://arxiv.org/abs/1502.07864},
year = {2015}
}
@article{Wang2002,
abstract = {Linear errors-in-covariables models are considered, assuming the availability of independent validation data on the covariables in addition to primary data on the response variable and surrogate covariables. We first develop an estimated empirical loglikelihood with the help of validation data and prove that its asymptotic distribution is that of a weighted sum of independent standard $\chi$12 random variables with unknown weights. By estimating the unknown weights consistently, we construct an estimated empirical likelihood confidence region for the regression parameter vector. We also suggest an adjusted empirical loglikelihood and prove that its asymptotic distribution is a standard $\chi$2. To avoid estimating the unknown weights or the adjustment factor, we propose a partially smoothed bootstrap empirical loglikelihood for constructing a confidence region which has asymptotically correct coverage probability. A simulation study is conducted to compare the proposed methods with a method based on a normal approximation in terms of coverage accuracy and average length of the confidence interval. {\textcopyright} 2002 Biometrika Trust.},
author = {Wang, Qihua and Rao, J. N.K.},
doi = {10.1093/biomet/89.2.345},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Biometrika/Wang, Rao - 2002 - Empirical likelihood-based inference in linear errors-in-covariables models with validation data.pdf:pdf},
issn = {00063444},
journal = {Biometrika},
keywords = {Bootstrap empirical likelihood,Confidence region,Measurement error,Surrogate variable,error-in-variables},
mendeley-tags = {error-in-variables},
number = {2},
pages = {345--358},
title = {{Empirical likelihood-based inference in linear errors-in-covariables models with validation data}},
volume = {89},
year = {2002}
}
@article{Wang2020,
abstract = {In many scientific problems, researchers try to relate a response variable {\$}Y{\$} to a set of potential explanatory variables {\$}X = (X{\_}1,\backslashdots,X{\_}p){\$}, and start by trying to identify variables that contribute to this relationship. In statistical terms, this goal can be posed as trying to identify {\$}X{\_}j{\$}'s upon which {\$}Y{\$} is conditionally dependent. Sometimes it is of value to simultaneously test for each {\$}j{\$}, which is more commonly known as variable selection. The conditional randomization test (CRT) and model-X knockoffs are two recently proposed methods that respectively perform conditional independence testing and variable selection by, for each {\$}X{\_}j{\$}, computing any test statistic on the data and assessing that test statistic's significance by comparing it to test statistics computed on synthetic variables generated using knowledge of {\$}X{\$}'s distribution. Our main contribution is to analyze their power in a high-dimensional linear model where the ratio of the dimension {\$}p{\$} and the sample size {\$}n{\$} converge to a positive constant. We give explicit expressions of the asymptotic power of the CRT, variable selection with CRT {\$}p{\$}-values, and model-X knockoffs, each with a test statistic based on either the marginal covariance, the least squares coefficient, or the lasso. One useful application of our analysis is the direct theoretical comparison of the asymptotic powers of variable selection with CRT {\$}p{\$}-values and model-X knockoffs; in the instances with independent covariates that we consider, the CRT provably dominates knockoffs. We also analyze the power gain from using unlabeled data in the CRT when limited knowledge of {\$}X{\$}'s distribution is available, and the power of the CRT when samples are collected retrospectively.},
author = {Wang, Wenshuo and Janson, Lucas},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Wang, Janson - 2020 - A Power Analysis of the Conditional Randomization Test and Knockoffs.pdf:pdf},
journal = {arXiv},
keywords = {approximate message passing,benjamini,conditional randomization test,conditional randomization testing,hochberg,knockoffs,model-X,model-x,power analysis,retrospective,sampling},
mendeley-tags = {conditional randomization test,knockoffs,model-X,power analysis},
title = {{A Power Analysis of the Conditional Randomization Test and Knockoffs.}},
url = {http://arxiv.org/abs/2010.02304},
year = {2020}
}
@article{Andersson2014,
abstract = {Enhancers control the correct temporal and cell-type-specific activation of gene expression in multicellular eukaryotes. Knowing their properties, regulatory activity and targets is crucial to understand the regulation of differentiation and homeostasis. Here we use the FANTOM5 panel of samples, covering the majority of human tissues and cell types, to produce an atlas of active, in vivo-transcribed enhancers. We show that enhancers share properties with CpG-poor messenger RNA promoters but produce bidirectional, exosome-sensitive, relatively short unspliced RNAs, the generation of which is strongly related to enhancer activity. The atlas is used to compare regulatory programs between different cells at unprecedented depth, to identify disease-associated regulatory single nucleotide polymorphisms, and to classify cell-type-specific and ubiquitous enhancers. We further explore the utility of enhancer redundancy, which explains gene expression strength rather than expression patterns. The online FANTOM5 enhancer atlas represents a unique resource for studies on cell-type-specific enhancers and gene regulation.},
author = {Andersson, Robin and Gebhard, Claudia and Miguel-Escalada, Irene and Hoof, Ilka and Bornholdt, Jette and Boyd, Mette and Chen, Yun and Zhao, Xiaobei and Schmidl, Christian and Suzuki, Takahiro and Ntini, Evgenia and Arner, Erik and Valen, Eivind and Li, Kang and Schwarzfischer, Lucia and Glatz, Dagmar and Raithel, Johanna and Lilje, Berit and Rapin, Nicolas and Bagger, Frederik Otzen and J{\o}rgensen, Mette and Andersen, Peter Refsing and Bertin, Nicolas and Rackham, Owen and Burroughs, A. Maxwell and Baillie, J. Kenneth and Ishizu, Yuri and Shimizu, Yuri and Furuhata, Erina and Maeda, Shiori and Negishi, Yutaka and Mungall, Christopher J. and Meehan, Terrence F. and Lassmann, Timo and Itoh, Masayoshi and Kawaji, Hideya and Kondo, Naoto and Kawai, Jun and Lennartsson, Andreas and Daub, Carsten O. and Heutink, Peter and Hume, David A. and Jensen, Torben Heick and Suzuki, Harukazu and Hayashizaki, Yoshihide and M{\"{u}}ller, Ferenc and Forrest, Alistair R.R. and Carninci, Piero and Rehli, Michael and Sandelin, Albin},
doi = {10.1038/nature12787},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Andersson et al. - 2014 - An atlas of active enhancers across human cell types and tissues.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {7493},
pages = {455--461},
title = {{An atlas of active enhancers across human cell types and tissues}},
volume = {507},
year = {2014}
}
@article{VetY14,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/24721987{\}}{\{}24721987{\}}},
author = {Visscher, P M and Hemani, G and Vinkhuyzen, A A and Chen, G B and Lee, S H and Wray, N R and Goddard, M E and Yang, J},
journal = {PLoS Genetics},
month = {apr},
number = {4},
pages = {e1004269},
title = {{{\{}S{\}}tatistical power to detect genetic (co)variance of complex traits using {\{}S{\}}{\{}N{\}}{\{}P{\}} data in unrelated samples}},
volume = {10},
year = {2014}
}
@article{OR99,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/10077732{\}}{\{}10077732{\}}},
author = {Ott, J and Rabinowitz, D},
journal = {Hum. Hered.},
month = {mar},
number = {2},
pages = {106--111},
title = {{{\{}A{\}} principal-components approach based on heritability for combining phenotype information}},
volume = {49},
year = {1999}
}
@article{BetS17b,
author = {Bogomolov, Marina and Peterson, Christine B and Benjamini, Yoav and Sabatti, Chiara},
journal = {arXiv},
keywords = {FDR,hierarchical multiple testing,unpublished},
mendeley-tags = {FDR,hierarchical multiple testing,unpublished},
title = {{Testing hypotheses on a tree: new error rates and controlling strategies}},
year = {2017}
}
@article{Edwards2013,
abstract = {Genome-wide association studies (GWASs) have enabled the discovery of common genetic variation contributing to normal and pathological traits and clinical drug responses, but recognizing the precise targets of these associations is now the major challenge. Here, we review recent approaches to the functional follow-up of GWAS loci, including fine mapping of GWAS signal(s), prioritization of putative functional SNPs by the integration of genetic epidemiological and bioinformatic methods, and in vitro and in vivo experimental verification of predicted molecular mechanisms for identifying the targeted genes. The majority of GWAS-identified variants fall in noncoding regions of the genome. Therefore, this review focuses on strategies for assessing likely mechanisms affected by noncoding variants; such mechanisms include transcriptional regulation, noncoding RNA function, and epigenetic regulation. These approaches have already accelerated progress from genetic studies to biological knowledge and might ultimately guide the development of prognostic, preventive, and therapeutic measures. {\textcopyright} 2013 by The American Society of Human Genetics. All rights reserved.},
author = {Edwards, Stacey L. and Beesley, Jonathan and French, Juliet D. and Dunning, M.},
doi = {10.1016/j.ajhg.2013.10.012},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/American Journal of Human Genetics/Edwards et al. - 2013 - Beyond GWASs Illuminating the dark road from association to function.pdf:pdf},
issn = {15376605},
journal = {American Journal of Human Genetics},
number = {5},
pages = {779--797},
publisher = {The American Society of Human Genetics},
title = {{Beyond GWASs: Illuminating the dark road from association to function}},
volume = {93},
year = {2013}
}
@article{Love2014,
abstract = {In comparative high-throughput sequencing assays, a fundamental task is the analysis of count data, such as read counts per gene in RNA-seq, for evidence of systematic changes across experimental conditions. Small replicate numbers, discreteness, large dynamic range and the presence of outliers require a suitable statistical approach. We present DESeq2, a method for differential analysis of count data, using shrinkage estimation for dispersions and fold changes to improve stability and interpretability of estimates. This enables a more quantitative analysis focused on the strength rather than the mere presence of differential expression. The DESeq2 package is available at http://www. bioconductor.org/packages/release/bioc/html/DESeq2.html. Background},
author = {Love, Michael I and Huber, Wolfgang and Anders, Simon},
doi = {10.1186/s13059-014-0550-8},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Genome Biology/Love, Huber, Anders - 2014 - Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2.pdf:pdf},
journal = {Genome Biology},
keywords = {Kathryn,gene expression,genetics},
mendeley-tags = {Kathryn,gene expression,genetics},
pages = {550},
title = {{Moderated estimation of fold change and dispersion for RNA-seq data with DESeq2}},
volume = {15},
year = {2014}
}
@article{Rubin2019,
abstract = {Here, we present Perturb-ATAC, a method that combines multiplexed CRISPR interference or knockout with genome-wide chromatin accessibility profiling in single cells based on the simultaneous detection of CRISPR guide RNAs and open chromatin sites by assay of transposase-accessible chromatin with sequencing (ATAC-seq). We applied Perturb-ATAC to transcription factors (TFs), chromatin-modifying factors, and noncoding RNAs (ncRNAs) in ∼4,300 single cells, encompassing more than 63 genotype-phenotype relationships. Perturb-ATAC in human B lymphocytes uncovered regulators of chromatin accessibility, TF occupancy, and nucleosome positioning and identified a hierarchy of TFs that govern B cell state, variation, and disease-associated cis-regulatory elements. Perturb-ATAC in primary human epidermal cells revealed three sequential modules of cis-elements that specify keratinocyte fate. Combinatorial deletion of all pairs of these TFs uncovered their epistatic relationships and highlighted genomic co-localization as a basis for synergistic interactions. Thus, Perturb-ATAC is a powerful strategy to dissect gene regulatory networks in development and disease.},
author = {Rubin, Adam J. and Parker, Kevin R. and Satpathy, Ansuman T. and Qi, Yanyan and Wu, Beijing and Ong, Alvin J. and Mumbach, Maxwell R. and Ji, Andrew L. and Kim, Daniel S. and Cho, Seung Woo and Zarnegar, Brian J. and Greenleaf, William J. and Chang, Howard Y. and Khavari, Paul A.},
doi = {10.1016/j.cell.2018.11.022},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Rubin et al. - 2019 - Coupled Single-Cell CRISPR Screening and Epigenomic Profiling Reveals Causal Gene Regulatory Networks.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {ATAC-seq,CRISPR,chromatin accessibility,epigenomics,pooled screens,single-cell genomics},
number = {1-2},
pages = {361--376.e17},
pmid = {30580963},
publisher = {Elsevier Inc.},
title = {{Coupled Single-Cell CRISPR Screening and Epigenomic Profiling Reveals Causal Gene Regulatory Networks}},
url = {https://doi.org/10.1016/j.cell.2018.11.022},
volume = {176},
year = {2019}
}
@article{SM07,
annote = {17676998},
author = {Servin, Bertrand and Stephens, Matthew},
journal = {PLoS Genetics},
pages = {e114--e114},
title = {{{\{}Imputation-based{\}} Analysis of Association Studies: Candidate Regions and Quantitative Traits}},
volume = {3},
year = {2007}
}
@article{Benjamini2019a,
abstract = {Practical or scientific considerations often lead to selecting a subset of parameters as ``important.'' Inferences about those parameters often are based on the same data used to select them in the first place. That can make the reported uncertainties deceptively optimistic: confidence intervals that ignore selection generally have less than their nominal coverage probability. Controlling the probability that one or more intervals for selected parameters do not cover---the ``simultaneous over the selected'' (SoS) error rate---is crucial in many scientific problems. Intervals that control the SoS error rate can be constructed in ways that take advantage of knowledge of the selection rule. We construct SoS-controlling confidence intervals for parameters deemed the most ``important'' {\$}k{\$} of {\$}m{\$} shift parameters because they are estimated (by independent estimators) to be the largest. The new intervals improve substantially over $\backslash$v{\{}S{\}}id$\backslash$'{\{}a{\}}k intervals when {\$}k{\$} is small compared to {\$}m{\$}, and approach the standard Bonferroni-corrected intervals when {\$}k \backslashapprox m{\$}. Standard, unadjusted confidence intervals for location parameters have the correct coverage probability for {\$}k=1{\$}, {\$}m=2{\$} if, when the true parameters are zero, the estimators are exchangeable and symmetric.},
archivePrefix = {arXiv},
arxivId = {1906.00505},
author = {Benjamini, Yoav and Hechtlinger, Yotam and Stark, Philip B.},
eprint = {1906.00505},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Benjamini, Hechtlinger, Stark - 2019 - Confidence Intervals for Selected Parameters.pdf:pdf},
journal = {arXiv},
pages = {1--36},
title = {{Confidence Intervals for Selected Parameters}},
url = {http://arxiv.org/abs/1906.00505},
year = {2019}
}
@article{Simeonov2017,
abstract = {The majority of genetic variants associated with common human diseases map to enhancers, non-coding elements that shape cell-type-specific transcriptional programs and responses to extracellular cues1-3. Systematic mapping of functional enhancers and their biological contexts is required to understand the mechanisms by which variation in non-coding genetic sequences contributes to disease. Functional enhancers can be mapped by genomic sequence disruption4-6, but this approach is limited to the subset of enhancers that are necessary in the particular cellular context being studied. We hypothesized that recruitment of a strong transcriptional activator to an enhancer would be sufficient to drive target gene expression, even if that enhancer was not currently active in the assayed cells. Here we describe a discovery platform that can identify stimulus-responsive enhancers for a target gene independent of stimulus exposure. We used tiled CRISPR activation (CRISPRa)7 to synthetically recruit a transcriptional activator to sites across large genomic regions (more than 100 kilobases) surrounding two key autoimmunity risk loci, CD69 and IL2RA. We identified several CRISPRa-responsive elements with chromatin features of stimulus-responsive enhancers, including an IL2RA enhancer that harbours an autoimmunity risk variant. Using engineered mouse models, we found that sequence perturbation of the disease-associated Il2ra enhancer did not entirely block Il2ra expression, but rather delayed the timing of gene activation in response to specific extracellular signals. Enhancer deletion skewed polarization of naive T cells towards a pro-inflammatory T helper (TH17) cell state and away from a regulatory T cell state. This integrated approach identifies functional enhancers and reveals how non-coding variation associated with human immune dysfunction alters context-specific gene programs.},
author = {Simeonov, Dimitre R. and Gowen, Benjamin G. and Boontanrart, Mandy and Roth, Theodore L. and Gagnon, John D. and Mumbach, Maxwell R. and Satpathy, Ansuman T. and Lee, Youjin and Bray, Nicolas L. and Chan, Alice Y. and Lituiev, Dmytro S. and Nguyen, Michelle L. and Gate, Rachel E. and Subramaniam, Meena and Li, Zhongmei and Woo, Jonathan M. and Mitros, Therese and Ray, Graham J. and Curie, Gemma L. and Naddaf, Nicki and Chu, Julia S. and Ma, Hong and Boyer, Eric and {Van Gool}, Frederic and Huang, Hailiang and Liu, Ruize and Tobin, Victoria R. and Schumann, Kathrin and Daly, Mark J. and Farh, Kyle K. and Ansel, K. Mark and Ye, Chun J. and Greenleaf, William J. and Anderson, Mark S. and Bluestone, Jeffrey A. and Chang, Howard Y. and Corn, Jacob E. and Marson, Alexander},
doi = {10.1038/nature23875},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature/Simeonov et al. - 2017 - Discovery of stimulation-responsive immune enhancers with CRISPR activation.pdf:pdf},
issn = {14764687},
journal = {Nature},
keywords = {CRISPR,Kathryn},
mendeley-tags = {CRISPR,Kathryn},
number = {7670},
pages = {111--115},
pmid = {28854172},
publisher = {Nature Publishing Group},
title = {{Discovery of stimulation-responsive immune enhancers with CRISPR activation}},
volume = {549},
year = {2017}
}
@article{owen2005variance,
author = {Owen, A B},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the Royal Statistical Society Series B (Statistical Methodology)/Owen - 2005 - Variance of the number of false discoveries.pdf:pdf},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {Multiple testing,correlation},
mendeley-tags = {Multiple testing,correlation},
number = {3},
pages = {411--426},
publisher = {Wiley Online Library},
title = {{Variance of the number of false discoveries}},
volume = {67},
year = {2005}
}
@article{Liu2020b,
abstract = {We present deterministic barcoding in tissue for spatial omics sequencing (DBiT-seq) for co-mapping of mRNAs and proteins in a formaldehyde-fixed tissue slide via next-generation sequencing (NGS). Parallel microfluidic channels were used to deliver DNA barcodes to the surface of a tissue slide, and crossflow of two sets of barcodes, A1-50 and B1-50, followed by ligation in situ, yielded a 2D mosaic of tissue pixels, each containing a unique full barcode AB. Application to mouse embryos revealed major tissue types in early organogenesis as well as fine features like microvasculature in a brain and pigmented epithelium in an eye field. Gene expression profiles in 10-$\mu$m pixels conformed into the clusters of single-cell transcriptomes, allowing for rapid identification of cell types and spatial distributions. DBiT-seq can be adopted by researchers with no experience in microfluidics and may find applications in a range of fields including developmental biology, cancer biology, neuroscience, and clinical pathology.},
author = {Liu, Yang and Yang, Mingyu and Deng, Yanxiang and Su, Graham and Enninful, Archibald and Guo, Cindy C. and Tebaldi, Toma and Zhang, Di and Kim, Dongjoo and Bai, Zhiliang and Norris, Eileen and Pan, Alisia and Li, Jiatong and Xiao, Yang and Halene, Stephanie and Fan, Rong},
doi = {10.1016/j.cell.2020.10.026},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell/Liu et al. - 2020 - High-Spatial-Resolution Multi-Omics Sequencing via Deterministic Barcoding in Tissue.pdf:pdf},
issn = {10974172},
journal = {Cell},
keywords = {high spatial resolution,in situ barcoding,mouse embryo,multi-omics,next-generation sequencing,spatial multi-omics},
mendeley-tags = {multi-omics},
number = {6},
pages = {1665--1681.e18},
pmid = {33188776},
publisher = {Elsevier},
title = {{High-Spatial-Resolution Multi-Omics Sequencing via Deterministic Barcoding in Tissue}},
url = {http://dx.doi.org/10.1016/j.cell.2020.10.026},
volume = {183},
year = {2020}
}
@article{YB99,
annote = {Multiple comparisons (Tel Aviv, 1996)},
author = {Yekutieli, Daniel and Benjamini, Yoav},
doi = {10.1016/S0378-3758(99)00041-5},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of Statistical Planning and Inference/Yekutieli, Benjamini - 1999 - Resampling-based false discovery rate controlling multiple test procedures for correlated test statisti(2).pdf:pdf},
issn = {0378-3758},
journal = {Journal of Statistical Planning and Inference},
keywords = {Multiple testing,correlation,resampling},
mendeley-tags = {Multiple testing,correlation,resampling},
number = {1-2},
pages = {171--196},
title = {{Resampling-based false discovery rate controlling multiple test procedures for correlated test statistics}},
url = {https://doi.org/10.1016/S0378-3758(99)00041-5},
volume = {82},
year = {1999}
}
@article{Davies2019,
abstract = {In this paper we propose a completely new approach to the problem of covariate selection in linear regression. It is intuitive, very simple, fast and powerful, non-frequentist and non-Bayesian. It does not overfit, there is no shrinkage of the least squares coefficients, and it is model-free. A covariate or a set of covariates is included only if they are better in the sense of least squares than the same number of Gaussian covariates consisting of i.i.d. {\$}N(0,1){\$} random variables. The degree to which they are better is measured by the P-value which is the probability that the Gaussian covariates are better. This probability is given in terms of the Beta distribution, it is exact and it holds for the data at hand whatever this may be. The idea extends to a stepwise procedure, the main contribution of the paper, where the best of the remaining covariates is only accepted if it is better than the best of the same number of random Gaussian covariates. Again this probability is given in terms of the Beta distribution, it is exact and it holds for the data at hand whatever this may be. We use a version with default parameters which works for a large collection of known data sets with up to a few hundred thousand covariates. The computing time for the largest data sets was about four seconds, and it outperforms all other selection procedures of which we are aware. The paper gives the results of simulations, applications to real data sets and theorems on the asymptotic behaviour under the standard linear model. An R-package {\{}$\backslash$it gausscov{\}} is available. $\backslash$},
archivePrefix = {arXiv},
arxivId = {1906.01990},
author = {Davies, Laurie and D{\"{u}}mbgen, Lutz},
eprint = {1906.01990},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/arXiv/Davies, D{\"{u}}mbgen - 2019 - Covariate Selection Based on a Model-free Approach to Linear Regression with Exact Probabilities.pdf:pdf},
journal = {arXiv},
title = {{Covariate Selection Based on a Model-free Approach to Linear Regression with Exact Probabilities}},
url = {http://arxiv.org/abs/1906.01990},
year = {2019}
}
@article{Rabinovich2020,
abstract = {Multiple hypothesis testing is a central topic in statistics, but despite abundant work on the false discovery rate (FDR) and the corresponding Type-II error concept known as the false non-discovery rate (FNR), a fine-grained understanding of the fundamental limits of multiple testing has not been developed. Our main contribution is to derive a precise non-asymptotic tradeoff between FNR and FDR for a variant of the generalized Gaussian sequence model. Our analysis is flexible enough to permit analyses of settings where the problem parameters vary with the number of hypotheses {\$}n{\$}, including various sparse and dense regimes (with {\$}o(n){\$} and {\$}\backslashmathcal{\{}O{\}}(n){\$} signals). Moreover, we prove that the Benjamini-Hochberg algorithm as well as the Barber-Cand$\backslash$`{\{}e{\}}s algorithm are both rate-optimal up to constants across these regimes.},
archivePrefix = {arXiv},
arxivId = {1705.05391},
author = {Rabinovich, Maxim and Ramdas, Aaditya and Jordan, Michael I. and Wainwright, Martin J.},
doi = {10.5705/ss.202017.0468},
eprint = {1705.05391},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Statistica Sinica/Rabinovich et al. - 2019 - Optimal Rates and Tradeoffs in Multiple Testing.pdf:pdf},
issn = {10170405},
journal = {Statistica Sinica},
keywords = {Multiple testing},
mendeley-tags = {Multiple testing},
title = {{Optimal Rates and Tradeoffs in Multiple Testing}},
year = {2019}
}
@article{NMR16,
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/27005778{\}}{\{}27005778{\}}},
author = {Kettunen, J and Demirkan, A and Wurtz, P and Draisma, H H and Haller, T and Rawal, R and Vaarhorst, A and Kangas, A J and Lyytikainen, L P and Pirinen, M and Pool, R and Sarin, A P and Soininen, P and Tukiainen, T and Wang, Q and Tiainen, M and Tynkkynen, T and Amin, N and Zeller, T and Beekman, M and Deelen, J and van Dijk, K W and Esko, T and Hottenga, J J and van Leeuwen, E M and Lehtimaki, T and Mihailov, E and Rose, R J and de Craen, A J and Gieger, C and Kahonen, M and Perola, M and Blankenberg, S and Savolainen, M J and Verhoeven, A and Viikari, J and Willemsen, G and Boomsma, D I and van Duijn, C M and Eriksson, J and Jula, A and Jarvelin, M R and Kaprio, J and Metspalu, A and Raitakari, O and Salomaa, V and Slagboom, P E and Waldenberger, M and Ripatti, S and Ala-Korpela, M},
journal = {Nat Commun},
pages = {11122},
title = {{{\{}G{\}}enome-wide study for circulating metabolites identifies 62 loci and reveals novel systemic effects of {\{}L{\}}{\{}P{\}}{\{}A{\}}}},
volume = {7},
year = {2016}
}
@book{Imbens2015,
abstract = {Most questions in social and biomedical sciences are causal in nature: what would happen to individuals, or to groups, if part of their environment were changed? In this groundbreaking text, two world-renowned experts present statistical methods for studying such questions. This book starts with the notion of potential outcomes, each corresponding to the outcome that would be realized if a subject were exposed to a particular treatment or regime. In this approach, causal effects are comparisons of such potential outcomes. The fundamental problem of causal inference is that we can only observe one of the potential outcomes for a particular subject. The authors discuss how randomized experiments allow us to assess causal effects and then turn to observational studies. They lay out the assumptions needed for causal inference and describe the leading analysis methods, including, matching, propensity-score methods, and instrumental variables. Many detailed applications are included, with special focus on practical aspects for the empirical researcher.},
author = {Imbens, Guido W. and Rubin, Donald B.},
doi = {10.1017/CBO9781139025751},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Unknown/Imbens, Rubin - 2015 - Causal inference For statistics, social, and biomedical sciences an introduction.pdf:pdf},
isbn = {9781139025751},
keywords = {causality},
mendeley-tags = {causality},
publisher = {Cambridge University Press},
title = {{Causal inference: For statistics, social, and biomedical sciences an introduction}},
year = {2015}
}
@article{JetK11,
abstract = {The increased accessibility of gene expression tools has enabled a wide variety of experiments utilizing transcriptomic analyses. As these tools increase in prevalence, the need for improved standardization in processing and presentation of data increases, as does the need to guard against interpretation bias. Gene Ontology (GO) analysis is a powerful method of interpreting and summarizing biological functions. However, while there are many tools available to investigate GO enrichment, there remains a need for methods that directly remove redundant terms from enriched GO lists that often provide little, if any, additional information.},
author = {Stuart, J and Ben, S and David, M and Ben, K},
doi = {10.1186/1756-0500-4-267},
issn = {1756-0500},
journal = {BMC Research Notes},
keywords = {Gene Ontology},
mendeley-tags = {Gene Ontology},
number = {1},
pages = {267},
pmid = {21798041},
publisher = {BioMed Central},
title = {{GO Trimming: Systematically reducing redundancy in large Gene Ontology datasets}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3160396{\&}tool=pmcentrez{\&}rendertype=abstract{\%}5Cnhttp://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:GO+Trimming+:+Systematically+reducing+redundancy+in+large+Gene+Ontology+datasets{\#}0},
volume = {4},
year = {2011}
}
@article{He2013,
abstract = {De novo mutations affect risk for many diseases and disorders, especially those with early-onset. An example is autism spectrum disorders (ASD). Four recent whole-exome sequencing (WES) studies of ASD families revealed a handful of novel risk genes, based on independent de novo loss-of-function (LoF) mutations falling in the same gene, and found that de novo LoF mutations occurred at a twofold higher rate than expected by chance. However successful these studies were, they used only a small fraction of the data, excluding other types of de novo mutations and inherited rare variants. Moreover, such analyses cannot readily incorporate data from case-control studies. An important research challenge in gene discovery, therefore, is to develop statistical methods that accommodate a broader class of rare variation. We develop methods that can incorporate WES data regarding de novo mutations, inherited variants present, and variants identified within cases and controls. TADA, for Transmission And De novo Association, integrates these data by a gene-based likelihood model involving parameters for allele frequencies and gene-specific penetrances. Inference is based on a Hierarchical Bayes strategy that borrows information across all genes to infer parameters that would be difficult to estimate for individual genes. In addition to theoretical development we validated TADA using realistic simulations mimicking rare, large-effect mutations affecting risk for ASD and show it has dramatically better power than other common methods of analysis. Thus TADA's integration of various kinds of WES data can be a highly effective means of identifying novel risk genes. Indeed, application of TADA to WES data from subjects with ASD and their families, as well as from a study of ASD subjects and controls, revealed several novel and promising ASD candidate genes with strong statistical support.},
author = {He, Xin and Sanders, Stephan J. and Liu, Li and {De Rubeis}, Silvia and Lim, Elaine T. and Sutcliffe, James S. and Schellenberg, Gerard D. and Gibbs, Richard A. and Daly, Mark J. and Buxbaum, Joseph D. and State, Matthew W. and Devlin, Bernie and Roeder, Kathryn},
doi = {10.1371/journal.pgen.1003671},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/PLoS Genetics/He et al. - 2013 - Integrated Model of De Novo and Inherited Genetic Variants Yields Greater Power to Identify Risk Genes.pdf:pdf;:Users/ekatsevi/Documents/Mendeley Desktop/PLoS Genetics/He et al. - 2013 - Integrated Model of De Novo and Inherited Genetic Variants Yields Greater Power to Identify Risk Genes(2).pdf:pdf},
issn = {15537390},
journal = {PLoS Genetics},
keywords = {Kathryn,TADA,autism,de novo mutations,psychiatric genomics,whole exome sequencing},
mendeley-tags = {Kathryn,TADA,autism,de novo mutations,psychiatric genomics,whole exome sequencing},
number = {8},
title = {{Integrated Model of De Novo and Inherited Genetic Variants Yields Greater Power to Identify Risk Genes}},
url = {www.plosgenetics.org},
volume = {9},
year = {2013}
}
@book{Marina11,
address = {Tel Aviv University},
author = {Bogomolov, Marina},
isbn = {0-387-95389-2},
keywords = {Multiple testing},
mendeley-tags = {Multiple testing},
pages = {xviii+361},
publisher = {Doctoral thesis},
title = {{Testing of Several Families of Hypotheses}},
year = {2011}
}
@article{Fan2018a,
abstract = {Interpretability and stability are two important features that are desired in many contemporary big data applications arising in economics and finance. While the former is enjoyed to some extent by many existing forecasting approaches, the latter in the sense of controlling the fraction of wrongly discovered features which can enhance greatly the interpretability is still largely underdeveloped in the econometric settings. To this end, in this paper we exploit the general framework of model-X knockoffs introduced recently in Cand{\`{e}}s, Fan, Janson and Lv (2018), which is nonconventional for reproducible large-scale inference in that the framework is completely free of the use of p-values for significance testing, and suggest a new method of intertwined probabilistic factors decoupling (IPAD) for stable interpretable forecasting with knockoffs inference in high-dimensional models. The recipe of the method is constructing the knockoff variables by assuming a latent factor model that is exploited widely in economics and finance for the association structure of covariates. Our method and work are distinct from the existing literature in that we estimate the covariate distribution from data instead of assuming that it is known when constructing the knockoff variables, our procedure does not require any sample splitting, we provide theoretical justifications on the asymptotic false discovery rate control, and the theory for the power analysis is also established. Several simulation examples and the real data analysis further demonstrate that the newly suggested method has appealing finite-sample performance with desired interpretability and stability compared to some popularly used forecasting methods. Running title: IPAD},
author = {Fan, Yingying and Lv, Jinchi and Sharifvaghefi, Mahrad and Uematsu, Yoshimasa},
doi = {10.2139/ssrn.3245137},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Fan et al. - 2019 - IPAD Stable Interpretable Forecasting with Knockoffs Inference.pdf:pdf},
issn = {0162-1459},
journal = {Journal of the American Statistical Association},
keywords = {Multiple testing,applied,fdr,knockoffs,large-scale inference and,latent factors,model-x,to-skim},
mendeley-tags = {Multiple testing,applied,knockoffs,to-skim},
publisher = {Taylor {\&} Francis},
title = {{IPAD: Stable Interpretable Forecasting with Knockoffs Inference}},
url = {https://doi.org/10.1080/01621459.2019.1654878},
year = {2019}
}
@misc{economist,
howpublished = {$\backslash$em The Economist},
keywords = {reproducibility},
mendeley-tags = {reproducibility},
month = {oct},
title = {{{\{}T{\}}rouble at the lab}},
year = {2013}
}
@inproceedings{Liu2019,
abstract = {The knockoff filter introduced by Barber and Cand$\backslash$`es 2016 is an elegant framework for controlling the false discovery rate in variable selection. While empirical results indicate that this methodology is not too conservative, there is no conclusive theoretical result on its power. When the predictors are i.i.d. Gaussian, it is known that as the signal to noise ratio tend to infinity, the knockoff filter is consistent in the sense that one can make FDR go to 0 and power go to 1 simultaneously. In this work we study the case where the predictors have a general covariance matrix {\$}\backslashSigma{\$}. We introduce a simple functional called effective signal deficiency (ESD) of the covariance matrix {\$}\backslashSigma{\$} that predicts consistency of various variable selection methods. In particular, ESD reveals that the structure of the precision matrix {\$}\backslashSigma{\^{}}{\{}-1{\}}{\$} plays a central role in consistency and therefore, so does the conditional independence structure of the predictors. To leverage this connection, we introduce Conditional Independence knockoff, a simple procedure that is able to compete with the more sophisticated knockoff filters and that is defined when the predictors obey a Gaussian tree graphical models (or when the graph is sufficiently sparse). Our theoretical results are supported by numerical evidence on synthetic data.},
archivePrefix = {arXiv},
arxivId = {1910.12428},
author = {Liu, Jingbo and Rigollet, Philippe},
booktitle = {33rd Conference on Neural Information Processing Systems},
eprint = {1910.12428},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/33rd Conference on Neural Information Processing Systems/Liu, Rigollet - 2019 - Power analysis of knockoff filters for correlated designs.pdf:pdf},
title = {{Power analysis of knockoff filters for correlated designs}},
url = {http://arxiv.org/abs/1910.12428},
year = {2019}
}
@article{Jaitin2014,
author = {Jaitin, Diego Adhemar and Kenigsberg, Ephraim and Keren-Shaul, Hadas and Elefant, Naama and Paul, Franziska and Zaretsky, Irina and Mildner, Alexander and Cohen, Nadav and Jung, Steffen and Tanay, Amos and Amit, Ido},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Science/Jaitin et al. - 2014 - Massively parallel single-cell RNA-seq for marker-free decomposition of tissues into cell types.pdf:pdf},
journal = {Science},
keywords = {single cell},
mendeley-tags = {single cell},
number = {776-779},
title = {{Massively parallel single-cell RNA-seq for marker-free decomposition of tissues into cell types}},
volume = {343},
year = {2014}
}
@article{Alda-Catalinas2020,
abstract = {Zygotic genome activation (ZGA) is an essential transcriptional event in embryonic development that coincides with extensive epigenetic reprogramming. Complex manipulation techniques and maternal stores of proteins preclude large-scale functional screens for ZGA regulators within early embryos. Here, we combined pooled CRISPR activation (CRISPRa) with single-cell transcriptomics to identify regulators of ZGA-like transcription in mouse embryonic stem cells, which serve as a tractable, in vitro proxy of early mouse embryos. Using multi-omics factor analysis (MOFA+) applied to ∼200,000 single-cell transcriptomes comprising 230 CRISPRa perturbations, we characterized molecular signatures of ZGA and uncovered 24 factors that promote a ZGA-like response. Follow-up assays validated top screen hits, including the DNA-binding protein Dppa2, the chromatin remodeler Smarca5, and the transcription factor Patz1, and functional experiments revealed that Smarca5's regulation of ZGA-like transcription is dependent on Dppa2. Together, our single-cell transcriptomic profiling of CRISPRa-perturbed cells provides both system-level and molecular insights into the mechanisms that orchestrate ZGA.},
author = {Alda-Catalinas, Celia and Bredikhin, Danila and Hernando-Herraez, Irene and Santos, F{\'{a}}tima and Kubinyecz, Oana and Eckersley-Maslin, M{\'{e}}lanie A. and Stegle, Oliver and Reik, Wolf},
doi = {10.1016/j.cels.2020.06.004},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Cell Systems/Alda-Catalinas et al. - 2020 - A Single-Cell Transcriptomics CRISPR-Activation Screen Identifies Epigenetic Regulators of the Zygotic Ge.pdf:pdf},
issn = {24054720},
journal = {Cell Systems},
keywords = {CRISPR,CRISPRa,Dppa2,MOFA,Patz1,Smarca5,ZGA,scRNA-seq,screen,single cell,zygotic genome activation},
mendeley-tags = {CRISPR,single cell},
number = {1},
pages = {25--41.e9},
pmid = {32634384},
title = {{A Single-Cell Transcriptomics CRISPR-Activation Screen Identifies Epigenetic Regulators of the Zygotic Genome Activation Program}},
volume = {11},
year = {2020}
}
@article{Whalen2016,
abstract = {Discriminating the gene target of a distal regulatory element from other nearby transcribed genes is a challenging problem with the potential to illuminate the causal underpinnings of complex diseases. We present TargetFinder, a computational method that reconstructs regulatory landscapes from diverse features along the genome. The resulting models accurately predict individual enhancer-promoter interactions across multiple cell lines with a false discovery rate up to 15 times smaller than that obtained using the closest gene. By evaluating the genomic features driving this accuracy, we uncover interactions between structural proteins, transcription factors, epigenetic modifications, and transcription that together distinguish interacting from non-interacting enhancer-promoter pairs. Most of this signature is not proximal to the enhancers and promoters but instead decorates the looping DNA. We conclude that complex but consistent combinations of marks on the one-dimensional genome encode the three-dimensional structure of fine-scale regulatory interactions.},
author = {Whalen, Sean and Truty, Rebecca M. and Pollard, Katherine S.},
doi = {10.1038/ng.3539},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Nature Genetics/Whalen, Truty, Pollard - 2016 - Enhancer-promoter interactions are encoded by complex genomic signatures on looping chromatin.pdf:pdf},
issn = {15461718},
journal = {Nature Genetics},
keywords = {Kathryn,gene-enhancer},
mendeley-tags = {Kathryn,gene-enhancer},
number = {5},
pages = {488--496},
title = {{Enhancer-promoter interactions are encoded by complex genomic signatures on looping chromatin}},
volume = {48},
year = {2016}
}
@article{Davidson2005,
author = {Davidson, Ian and Ravi, S S},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/European Conference on Principles of Data Mining and Knowledge Discovery/Davidson, Ravi - 2005 - Agglomerative Hierarchical Clustering with Constraints Theoretical and Empirical Results.pdf:pdf},
journal = {European Conference on Principles of Data Mining and Knowledge Discovery},
pages = {59--70},
title = {{Agglomerative Hierarchical Clustering with Constraints : Theoretical and Empirical Results}},
year = {2005}
}
@article{Mandozzi2016a,
author = {Mandozzi, Jacopo and B{\"{u}}hlmann, Peter},
doi = {10.1080/01621459.2015.1007209},
file = {:Users/ekatsevi/Documents/Mendeley Desktop/Journal of the American Statistical Association/Mandozzi, B{\"{u}}hlmann - 2016 - Hierarchical Testing in the High-Dimensional Setting With Correlated Variables Hierarchical Testing in the.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {Multiple testing,detection,familywise error rate,hierarchical clustering,high-dimensional variable selection,lassol,linear model,minimal true,multiple testing,sample splitting,variable selection},
mendeley-tags = {Multiple testing,variable selection},
number = {513},
title = {{Hierarchical Testing in the High-Dimensional Setting With Correlated Variables Hierarchical Testing in the High-Dimensional Setting}},
volume = {111},
year = {2016}
}
@article{FS03,
annote = {12721547},
author = {Freimer, N and Sabatti, C},
doi = {10.1038/ng0503-15},
journal = {Nature Genetics},
keywords = {genetics},
mendeley-tags = {genetics},
number = {1},
pages = {15--21},
title = {{The human phenome project}},
url = {http://www.hubmed.org/display.cgi?uids=12721547},
volume = {34},
year = {2003}
}
@article{GR14,
abstract = {For predicting genetic risk, we propose a statistical approach that is specifically adapted to dealing with the challenges imposed by disease phenotypes and case-control sampling. Our approach (termed Genetic Risk Scores Inference [GeRSI]), combines the power of fixed-effects models (which estimate and aggregate the effects of single SNPs) and random-effects models (which rely primarily on whole-genome similarities between individuals) within the framework of the widely used liability-threshold model. We demonstrate in extensive simulation that GeRSI produces predictions that are consistently superior to current state-of-the-art approaches. When applying GeRSI to seven phenotypes from the Wellcome Trust Case Control Consortium (WTCCC) study, we confirm that the use of random effects is most beneficial for diseases that are known to be highly polygenic: hypertension (HT) and bipolar disorder (BD). For HT, there are no significant associations in the WTCCC data. The fixed-effects model yields an area under the ROC curve (AUC) of 54{\%}, whereas GeRSI improves it to 59{\%}. For BD, using GeRSI improves the AUC from 55{\%} to 62{\%}. For individuals ranked at the top 10{\%} of BD risk predictions, using GeRSI substantially increases the BD relative risk from 1.4 to 2.5.},
annote = {$\backslash$href{\{}http://www.ncbi.nlm.nih.gov/pubmed/25279982{\}}{\{}25279982{\}}},
author = {Golan, David and Rosset, Saharon},
doi = {10.1016/j.ajhg.2014.09.007},
issn = {15376605},
journal = {American Journal of Human Genetics},
keywords = {genetics,linear mixed models},
mendeley-tags = {genetics,linear mixed models},
month = {oct},
number = {4},
pages = {383--393},
title = {{Effective genetic-risk prediction using mixed models}},
volume = {95},
year = {2014}
}

@article{Datlinger2019,
  title={Ultra-high throughput single-cell RNA sequencing by combinatorial fluidic indexing},
  author={Datlinger, Paul and Rendeiro, Andr{\'e} F and Boenke, Thorina and Krausgruber, Thomas and Barreca, Daniele and Bock, Christoph},
  journal={BioRxiv},
  year={2019},
  publisher={Cold Spring Harbor Laboratory}
}

@article{Datlinger2021,
  title={Ultra-high-throughput single-cell RNA sequencing and perturbation screening with combinatorial fluidic indexing},
  author={Datlinger, Paul and Rendeiro, Andr{\'e} F and Boenke, Thorina and Senekowitsch, Martin and Krausgruber, Thomas and Barreca, Daniele and Bock, Christoph},
  journal={Nature Methods},
  volume={18},
  number={6},
  pages={635--642},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{Morris2021,
  title={Discovery of target genes and pathways of blood trait loci using pooled CRISPR screens and single cell RNA sequencing},
  author={Morris, John A and Daniloski, Zharko and Domingo, J{\'u}lia and Barry, Timothy and Ziosi, Marcello and Glinos, Dafni A and Hao, Stephanie and Mimitou, Eleni and Smibert, Peter and Roeder, Kathryn and others},
  journal={bioRxiv},
  year={2021},
  publisher={Cold Spring Harbor Laboratory}
}
@article{Pierce2020,
  title={High-throughput single-cell chromatin accessibility CRISPR screens enable unbiased identification of regulatory networks in cancer},
  author={Pierce, Sarah Elisabeth and Granja, Jeffrey Michael and Greenleaf, William James},
  journal={bioRxiv},
  year={2020},
  publisher={Cold Spring Harbor Laboratory}
}

@article{Alda2020,
  title={A single-cell transcriptomics CRISPR-activation screen identifies epigenetic regulators of the zygotic genome activation program},
  author={Alda-Catalinas, Celia and Bredikhin, Danila and Hernando-Herraez, Irene and Santos, F{\'a}tima and Kubinyecz, Oana and Eckersley-Maslin, M{\'e}lanie A and Stegle, Oliver and Reik, Wolf},
  journal={Cell systems},
  volume={11},
  number={1},
  pages={25--41},
  year={2020},
  publisher={Elsevier}
}

@misc{barrycode,
  author={Barry, Timothy and Wang, Xuran and Morris, John A. and Roeder, Kathryn and Katsevich, Eugene},
  title={SCEPTRE improves calibration and sensitivity in single-cell CRISPR screen analysis},
  howpublished={Github. katsevich-lab.github.io/sceptre/.},
  year={2021},
 }

@article{Przybyla2021,
  title={A new era in functional genomics screens},
  author={Przybyla, Laralynne and Gilbert, Luke A},
  journal={Nature Reviews Genetics},
  pages={1--15},
  year={2021},
  publisher={Nature Publishing Group}
}